中文字幕志愿者 李宗盛
欢迎的各位来宾
欢迎来到2024世界人工智能大会
阿里云MARS加速大模型应用落地主题论坛
活动将于五分钟后正式开始
为了确保活动的顺利进行和良好的现场体验
请您尽快入座
并将手机调为振动或静音模式
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
感谢您的配合
尊敬的各位来宾
尊敬的各位来宾
本次会议即将开始
请您尽快就座
并将手机等通讯设备关闭
或置于静音状态
谢谢您的合作
 Ladies and gentlemen
The event will begin shortly
Can we please ask for you to kindly take your seats
We would like to remind you again
To switch off all mobile phones
To switch off all mobile phones
And put electronic devices to silent mode
And put electronic devices to silent mode
谢谢您的协调
加速大模型应用落地主题论坛的现场
我是本次大会的主持人朱荣
现如今
人工智能一直是社会各界关注的焦点话题
越来越多的人们开始谈论AI
谈论大模型
以及AIGC所带来的变革
随着科技和产业革命的不断推进
AI大模型的应用越来越广泛
不仅推动了企业效率的
显著提升
还催生了很多新的商业模式和创新业务
AI正成为引领时代发展的重要引擎
推动着社会向更加智能化
数字化的方向迈进
今天我们很荣幸地邀请到了
产学研各界嘉宾共聚一堂
一起深度探讨大模型的前沿技术
开发经验
以及最新的应用落地
让我们带着这些期待
共同开启今天的AI大模型之旅
首先让我们掌声有请
上海市经济和信息化委员会副主任汤文侃先生
为本次论坛做开场致辞
有请
尊敬的各位来宾
女士们 先生们
大家上午好
非常高兴与大家相聚在此
共同参加由阿里云主办的
MARS加速大模型应用落地的主题论坛
首先我仅代表上海经讯委
对各位嘉宾的到来
以及我们线上云参与的各位朋友
表示诚挚的欢迎
也向长期以来支持和关心
上海经济和信息化委员会的
上海人工智能产业发展的社会各界同仁
表示衷心的感谢
当今的大模型技术创新体系
在加速演进
正进入行业全面的应用
商业路径逐步形成的新阶段
国际竞争日益激烈
基础模型参数
以性能纪录屡屡创新
随着模型在新兴领域的应用
遍地开花
诸多现象性应用拓运而出
甚至部分场景
已经能够细致的
模拟
现实世界的微妙
这也预示着通用人工智能的黄金时代
已近在咫尺
面对大模型时代的挑战
上海在抢抓新一代
人工智能的发展机遇
以人工智能驱动形成新制生产力
加快打造世界级的产业机器
我们突出的表现在三个方面
首先是
大模型的龙头企业不断的急剧
目前上海全市
已经有三十四款
大模型
已通过了备案
产生了制造业
金融等锤类领域的应用
全国首个大模型
创新生态市区
魔术空间
也吸引了将近八十多家的企业
在这里急剧
已经形成了算力调度
开放数据
评测服务
金融服务
综合服务
等全方位的
创新创业的保障体系
第二的是
在自主可控的
自算生态上
不断升级
我们着力突破
卡脖子的环节
已经有数十款
多技术路线的
智能芯片
以及流片量产
上海人工智能实验室
也建立了
DeepLink
软硬件的试配方案
尤其欣喜的是
上海已建成了
规模化的自算中心
为大模型的训练
提供强有力的支撑
第三的是
钥匙资源
能不断地提升
我们大模型
语调数据联盟
持续为模型训练
提供了生产资料
上海已经开源了
四千万的
四千二百亿
Token的语调数据
以市场化机制
为大模型企业
提供专业的服务
面向未来
上海将进一步地
系统推进
人工智能
赋能经济发展
我们要着力做好
三项工作
首先的是
要夯实
产业的技术底座
要推进基于
国产自算芯片的公关
促进大模型训练框架
和国产芯片的适配
我们要推动
基础大模型训练迭代
探索AI自算体的
新产品
新模式
我们要组织语调公司
要打造专业的运营平台
抓紧形成市场化的
语调产品
其次呢
要加速
人工智能的落地和应用
要持续地做大做强
模式空间
要推动上海大模型企业
要打造
制造
金融和政务
等领域里的市场应用
要加快技术规模化的落地
最后呢
要培育开源的活跃生态
要鼓励各位
开源的社会组织
优秀人才
创新项目
要露出上海
进一步
促使开源技术
产业化
要营造活跃的产业生态
各位来宾
今天的论坛
搭建了人工智能大模型领域里的
交流对话平台
我们来自于
头部企业
科研机构
垂内应用场景的用户
各个领域里的专家
大家齐聚一堂
我们非常期待
各位能够激荡创新智慧
砥砺科研思维
发表
深刻的洞见
上台创新观点
我们也非常地希望
我们阿里
能够发挥大模型的创新优势
与上海丰富的应用场景
能够深度融合
加强合作
加快形成产业化的成果
共创人工智能的美好未来
最后也希望这次的论坛取得成功
谢谢大家
感谢汤主任的精彩致辞
接下来将进入今天的演讲环节
首先
有请我们的首位演讲嘉宾
阿里云首席技术官周靖仁先生
周靖仁先生
作为阿里云的技术领军人物
长期致力于推动AI技术的前沿发展
和应用创新
也是国内最早提出MaaS
模型及服务概念的谦虚者
在今天的演讲中
他将围绕通一大模型能力
阿里云白链等
深入探讨阿里云
在MaaS体系内的最新进展与思考
让我们欢迎周靖仁先生
带来阿里云让AI创新
触手可及的主题演讲
掌声有请
大家早上好
非常高兴又再次跟大家见面
能够去跟大家同步一下
我们阿里云在MaaS服务
包括今天AI模型应用
各方面的一个进展
今天在我们AI引领的
这次技术变革中间
我们可以看到
所有的技术的发展
是在突飞猛进的速度
创新日新
可以说是日新月异
随着今天我们大模型的
广泛的进展和进展的进展
一个研发的一个突破
今天我们也看到
产业界的应用
也在快速地迭代起来
今天基于大模型
能够延展到各行各业
应用在各行各业的例子
也今天可以说是
日新月异越来越多
在这个时代里面
我们认为了
模型及服务这个概念
就更加的重要
就真正我们要做到
以模型为中心
去延展今天
我们所有的技术体系
也延展到
业务的推进
我们在两年前
首次提出了
Model as a Service
这样一个概念
我们也非常欣喜地看到
在短短的过去的一段时间
整个这个概念
得到全行业的一个认可
今天Model as a Service
已经成为了今天
我们云上服务
包括AI领域发展的
一个重要的技术的方面
谈到Model as a Service
其实这中间
涉及到了很多层次的概念
包括底层的云计算的
一系列的支持
对AI的支持
也涉及到今天
我们模型本身
生态模型的发展
模型的方方面面
以及今天在整个生态
开发者的环境里面的
一个演进
最终模型还涉及到
如何去应用在
各自的业务场景里面
今天如何能够把模型
更好地适配在
业务场景里面
也是成为了今天
Model as a Service
的一个重要的环节
今天我们就围绕着
Model as a Service
跟大家同步
我们阿里云在这方面的
一系列的进展
首先我们会谈到
模型这一层
大家可以看到
在过去一年里面
我们整个大模型的领域
应该说是发展得
非常的迅猛
包括我们整个阿里云
推出的通议签问的系列
包括通议模型的
其他的方方面面
都在有快速的一个发展
我们可以从去年
我们正式4月份
提出发表通议签问
到后来我们的万象
包括后来我们听悟
所有的这些模型的发布
我们整个阿里云
在模型的创新这方面
在持续地发力
大家也可以看到
整个模型的能力
也越来越强
也非常感谢大家
特别我们的开发
特别的企业
对我们的支持
今天我们都有
上亿的每次的调用量
也包括了今天在
特别是模型的
开源模型方面
我们已经有
2000多万的模型的下载量
除了今天我们在
做模型的研发
去提升模型的
方方面面的能力之外
很重要的一个环节
就今天我们会坚持
开源的策略
真正我们希望
能够把模型的能力
能够带给我们的开发者
带给我们的企业
能够降低今天
模型使用的门槛
只有这样
我们认为
我们才能真正的去促进
今天AI整个产业的一个发展
整个行业的一个变革
能够真正的
让我们的AI的开发的门槛
进一步的降低
能够带动
整个产业界的发展
过去阿里云一直是
坚持在开源的这条战略上面
我们也是全球
几乎说是唯一一家
继做模型的研发
也同时开源我们的
所有的系列的模型
今天借助我们云的
相关面的技术的支持
结合我们开源模型的矩阵
我们真正的把AI的能力
赋能给我们的开发者
赋能给我们的企业
在过去的一年里面
我们整个通易的开源模型家族
已经形成了一个矩阵
涉及到今天的各种的尺寸
也涉及到了各种的模态
而且我们在开源领域里
还是在不断的去突破
不断的去发展
尤其是我们在几周之前
发布的Coin2
就是我们新一代的
这样一个开源的模型
整个的模型的发布
在短短的几周里面
也得到了业界
非常好的一个反馈
包括在海外的Hugging Face
今天已经把Coin2
认为是我们全球范围里面
最强的开源模型
也在很多的海外的榜单
也在居于榜首
同时在中文的领域
我们也有很多的评测
像Compass Arena
也是把通易签文的
这样开源一个模型
也是排在了第一位
整体我们这一代的开源模型
不单单是在很多的评测指标上面
有大幅度的提升
超过了很多必然的模型
而且是在全球
是属于非洲的模型
非常领先的地位
同时我们也在代码
在今天推理
在今天逻辑思考这方面
有大幅度的一个能力的提升
整个这个模型
从发布到现在
受到了我们的开发者
受到我们的企业的广泛的关注
这也是非常希望
能够跟大家继续去
推进今天模型
在各个方面的一系列的应用
除了今天我们
这样一个通一签问的模型的发布
我们还积极地去推动
今天这个通一灵码
通一灵码是基于
我们通一签问模型之上的
面向于编程的这样一个助手
在昨天晚上
通一灵码
也获得了本次大会的
政店之宝的奖
也是对我们这个项目
有一个重大的肯定
今天我们会结合
今天基础语言模型的能力
针对代码的补全
针对代码的理解
代码的问答
我们在开发流程中的
每一个环节
能够帮助到我们的开发者
同时我们整个通一灵码
也集成到了各种各样的
开发的框架里面
包括各种的IDE
能够让我们的
开发者能够快速地使用
我们也非常欣喜地看到
在过去通一灵码
有快速的发展
今天已经成为了国内
用户规模最全面的
一个产品
我们在过去的一段时间
已经有超过350万的
这样一个下载量
而且每天推荐都是在
几千万次的这样一个量级
我们也得到了很多开发者
积极的一个反馈
除了今天面向开发者
我们也更多地把通一灵码
推给了我们的企业
也就是说今天
在企业的环境里面
往往有自己的一系列的代码
有自己的一系列的
数据安全的考虑
这个时候我们一方面
能够在绝对的安全的情况下
去帮助企业去梳理自身的代码
同时也可以把通一灵码
智能化的能力
跟本地的代码库结合在一起
让我们的模型更加懂得
本地的包括开发的逻辑
包括编程的习惯
能够更加精准地去推送
跟针对企业特殊场景的
这样一个代码助手的功能
整个通一灵码的企业版
从推出到现在
也受到了很多企业的
关注
包括我们的一七
哈罗
还有中华财险等等
都在积极地使用我们
这样一款企业的产品服务
另外我们在通一的APP里面
也是在不断地迭代
不断地发展
今天通一APP
已经成为了一个全能的AI助手
不管是今天在我们的手机上
去做任何的知识的问答
或者说今天一些常规的
搜索
包括今天文件的处理
还是在我们的PC端
能够去做详细的一些
工作学习的规划等等
那它也集成了今天
像我们听悟
像我们今天万象的
各方面的一个能力
那真正意义上成为了
今天我们日常工作学习生活的
全能的AI助手
也希望大家有这个有时间的话
线下可以去下载通一的APP
去体验今天通一模型的方方面面
那刚才我们讲到了
整个通一模型的持续的开源
那另外一个方面
我们也是积极地在运作AI的社区
那这里也跟大家汇报一下
摩大社区也是感谢大家的关爱
也是在快速地
一直从快速地茁壮地在发展
那到了今天
我们的整个的数据
各个方面又有大幅度的提升
那今天我们已经设计了
全国560万的这样一个开发者
也承载了今天
我们整个中国境内
甚至海外重要的一系列的模型
那值得一提的是
这个摩大这个项目
也是受到了
大家开发者的积极的一些
共同的开发
那这次也是非常有幸地
获得了今天我们
CL之星的这样一个奖
那讲完了这样一个模型层
当我们模型真正要应用到
各行各业
还需要今天对行业
进行一个特别的
特殊的一个适配
那在这个环节里面
如何能够把模型的能力释放出来
同时又去理解
各行各业的这个需求
这是今天我们要解决的
一个重要的一个技术方面
那我们过去呢
这个推出了
阿里云的百链产品
那百链这个名字呢
就取之于今天千锤百链
那我们希望呢
借助今天我们云的能力
借助模型的能力
能够再结合今天
我们企业的专属的这个信息
能够更好的去
适配相关的这个模型应用
那百链呢
首先我们集成了
所有的这样一个模型的生态
那不光是中间有
我们刚才讲到的
通益本身的模型家族
也包括了今天开源的
所有的模型
还有呢
这个其他的模型公司呢
也积极参与在里面
那我们希望呢
给我们的开发者
给我们的企业呢
提供全方位的一个选择
他们可以根据自己的需求
去选择
适合于
适合于这个自己
包括这个适合于
自己的模型的类型
以及模型的尺寸
能够更好的去权衡
今天业务效果
以及这个
这个推理成本
各个方面的一个综合的考虑
那另外呢
我们在过去也是
不断的能够降本
能够让我们的
这个大模型
使用的成本的进步的降低
那过去呢
我们一直在
不断的去提升
整个
云的这样一个推理的
这样一个架构
那一方面呢
可以提醒
能够有更好的
各种的算力
能够汇聚在一起
能够提高
更极致的一个性能
那我们在过去的几个月里
我们整个推理的
这个整个的价格呢
也在大幅度的去下降
那我们最终的这个初衷的是
希望今天
那我们大模型的
那每位开发者
每位企业都能够使用
而且都能一个
高性价比的方式去使用
那我们也非常欣喜的看到
在过去一段时间
短短的一个月左右
我们整个
整个这个模型
使用的这个体量
应该说是一个成倍的在增加
那我们也非常欢心看到
今天各行各业
都来尝试
今天把人工智能的能力
融合在自己的业务体系里面来
当然
我们有了这个模型的
所有的这个
一个丰富的这个提供
有了今天这个
非常
强有力的推理的架构
那还需要今天有基于模型
为中心的这样一个开发的环境
那中间一方面带领的是
今天我们模型的调用
能够让大家非常简单的方式
以API的方式去试使用模型
那更重要的是
我们也需要有一个流程
能够帮助今天我们的企业
我们的开发者进行模型的定制
那在过去呢
我们百链就是在去解决
这样一个业务的一个需求
那今天呢
我也是非常高兴的
跟大家同步我们的进展
百链到正式的发布
到现在也就短短的几个月的这个时间
那我们今天服务的客户呢
也是在大幅度的增加
现在已经超过了20万
那具体到今天
为了帮助我们的业务场景
去做业务的适配
需要做哪些环境呢
那首先
那使用模型的时候
就我们第一步会提到的是
prompting一个engineering
也就是说
prompt的一些定制和优化
那一方面呢
我们会根据各行各业的场景
去提用一个prompt的模板
也就是说
真正能够让我们的企业
能够快速的进行选择相关的模板
能够去选择它
适合于自己业务的这样一个场景
能够很快速的去上手
那同时我们也理解
今天真正的prompting engineering
这也是一个非常繁琐的事情
那我们希望呢
今天通过我们通译模型的
方方面面的这个能力呢
能够帮助大家
去简化prompting engineering
也就是说
今天真正用metaprompting的这种方式
能够今天让企业呢
能够描述自己的需求
能够让模型自动的去帮助
做prompting engineering
prompting的优化
能够提升今天业务的效果
那另外呢
我们还涉及到今天
如何把企业的知识
企业的信息
跟模型融合在一起
那这首先就需要解决一个
数据安全的问题
那同时也要去解决
今天能够如何
让模型去有一些增强的知识的
学习的方方面面
那这是我们摆练的一个重要的
一个发展的一个技术的方向
那首先呢
我们会支持各种各样的一个
RAC的框架
特别是今天我们非常流行的
在各种的开源的框架
能够让我们的快速的
这个开发者快速的上手
能够今天有一个安全的数据域
能够让我们的企业
能够把自己的数据进行一个分享
能够让模型去学习
但同时呢
这部分的数据呢
并没有出我们客户的
这样一个专属的域
也能保证这个极致的数据的安全
那与此同时呢
我们简化了各种的流程
今天不管是用任何的一个框架
包括今天各种的RAC的体系
简简单单的几行
就能够快速的把本身企业的知识
或者说专属的一些信息
跟模型的能力融合在一起
那与此同时呢
我们也提供一个
个人的信息
一个高效的低延迟
高并发的这样一个特殊的RAC
一方面能够在整个数据处理上面
能够进一步的降低
大家开发的这样一个复杂度
那同时呢
在效果的这个方面
在算法的优化方面
能够更加自动的去调优
那这些都是为今天我们企业
能够真正的把自己的行业的知识
融合大模型提供了一个坚实的基础
那所有的这些方方面面呢
不管是从prompting
还是说今天使用各种的插件
还是说今天我们越来越多的
增加了一些功能
像memory等等
其实都是相对来说比较繁琐
当然今天虽然我们有工具
在进一步的简化
各种环节之间的
整个的开发的这个复杂度
但我们希望呢
能够有system API的方式
能够把相关的这个编排
把这个编排的方式
把这个插件的工具的管理等等的
能够整合在一起
那通过这个system API呢
我们一方面可以使用
各种各样的一个插件
那同时呢
也可以今天
把我们前面讲的prompt engineering的工作
把我们的memory的管理
也能够有效的编排在一起
能极度的去简化
今天各种应用的一系列的这个开发
能够把这个流程呢
更加的提供一个一站式的一个体验
那最后呢
我们也认识就今天
除了今天模型的这个
包括刚刚讲到的RAG
或者说这个prompt engineering
那有一些特殊的场景呢
还需要进行模型
还要进行再训练
还要进行一些微调
那这个时候呢
我们会提供完整的这样一套工具
不光从这个数据的这个提供
从今天整个模型
微调架构的支持
以及到今天评审
这个模型的提供
这个各种评测的工具
能够帮助我们的开发者
能够有效的去评价
今天开发出来的这个模型
微调后的模型
在各个维度之间的这个表现
那这些呢
都能够快速的帮助我们的开发者
去更好的去基于我们的
这个摆链的模型的底座
能够在上面进行二次的开发
能够去在上面进行
更有效的一个评价
这对我们今天业务的落地
起到了一个极大的推动的作用
那上面讲到的这些方方面面呢
是我们摆链的这个
很多个技术环节中间的一环
那我们也是希望大家有兴趣的话
能够在会后啊
能够再到阿里云的官网上面
去体验
去使用
去真正的去利用摆链
去做各种模型的定制
那我们最近呢
我们也看到很多的这个企业呢
这个也是在海外进行这个业务的拓展
那这里呢
我们也很高兴的跟大家
同步我们摆链这个产品呢
也会今天部署在我们的海外
为我们的企业的提供
全方位的支持
那在海外呢
我们这个模型
这个产品叫Model Studio
那今天也会在这个国际性的
这样一个全球化的
在我们阿里云的基础设施的
这个布局上面
为大家提供全面的
这样一个模型的支持和模型的服务
让大家真正在出海的过程中间
能够高枕无忧
那上面呢
我是通过这次短短的这个20分钟
能够跟大家汇报了
今天我们阿里云在今天
在Mars方面的各个方面的一个进展
从今天开源模型的这个快速的发展
和开源模型的这个最新版本的推出
到今天我们的摩达
到我们今天整个摆链产品
能够帮助今天进行产业界的落地
那我们认为呢
今天在这个时代里面
我们只能够在这个时代里面呢
我们只有真正的做到今天
AI和云的一个高度的协同
能够今天一方面支持好模型的发展
模型的这个研发
那更重要的是今天基于模型
能够帮助我们各行各业
去更以低门槛的方式去使用
去结合自己的场景的知识
去解决真实的业务的场景
那只有这样呢
我们才能推动整个AI产业的这个发展
那我们也是非常期待
跟我们的企业
跟我们的开发者一同
去做这些的发展
去加速大模型应用的产业落地
谢谢大家
再次感谢周静仁先生的精彩演讲
也期待白链和摩达社区
为大模型生态贡献更多的力量
那么在芯片的发展过程中呢
有一个著名的法则
叫做摩尔定律
摩尔定律指出
每隔大约18至24个月
单位面积上的晶体管数量
将翻一倍
使得芯片的性能大幅提升
成本则相对降低
这一规律在过去的几十年间
深刻影响了半导体行业
也驱动了计算机技术的快速迭代
和性能飞跃
和摩尔定律类似
大模型也遵循着类似规律
接下来
有请清华大学计算机系
常聘副教授
面壁智能首席科学家
刘志远先生带来演讲
大模型时代的摩尔定律
迈入更高效的大模型时代
掌声欢迎
好
大家上午好
非常荣幸有这样的一个机会
然后来在这个场合
跟大家分享
我们在大模型这个领域
然后所进行的探索思考
已经对未来的研判
那么我们是希望能够
跟大家分享
我们所认为的
大模型未来发展的
这么多的东西
那么应该说
面壁智能
可能是大家还不是特别的熟悉
但是相信呢
我们在过去的一年
我们努力发布的一系列的
端侧的这些大模型
可能大家已经耳熟能详
包括miniCPM的机座模型
包括miniCPM-V的
这个多模态的这个模型
那么这些模型的一个
最大的特点
就是它们能够在
我们的端侧
我们的计算机
然后我们的
手机等等的
这么一些端侧的设备上
然后来能够运行
那么我们为什么会在
过去的一年的时间里面
然后会去选择
去卷这个端侧大模型
那么今天
我们就想跟大家分享
我们的这么一个相关的思考
那我们会认为
所有的这些端侧模型
它的背后
其实是有一个
更加挑战的这么一个问题
也就是说
如何在一个端侧
更加有限的算力
内存
还有能耗的
这么一个情况下
我们要极致地把这个知识
能够浓缩到一个
更小的参数规模里面
那么整个的这个过程呢
其实需要我们来对
大模型它的这个建设
然后进行一个
更加科学化的道路的
这么一个探索
那么在这个方面
我们的一个努力
就是构造了一个
模型的沙盒
那也就是说
我真正地去训练一个
模型之前
我会在这个沙盒里面
去做成千上百次的演练
我会在很多的
小模型上
然后高效地去寻找
最优的数据
最优的超参的配置
并且能够让它成功地
外推到大模型上
真正地寻找到
这个大模型上的
这么一个最优的配置
那么这个其实相当于
寻找到了这个大模型的
一个成长的规律
那么通过这一点
我们可以去找到一个
更高的知识密度
从而带来一个
更加高效的模型
所以看到用途可以看
我们在2024年
2月份发布的
Mini-CPM的第一个版本
2.4B的模型
24亿参数
实际上是在当时
已经能够超过
像Mixtral 7B
Lama 2 13B
等几倍于这个参数规模的
一些模型的能力
那么这个的话呢
就是体现了我们大模型
科学化的
这么一个
非常重要的这么一个价值
所以我们会认为呢
在这样的一个科学化的历程里面
正如刚才的主持人所提到的
我们会看到
过去的这80多年的时间
我们见证了
在芯片的这个领域
那么由于芯片制程的
这么一个不断的增强
带来了终端算力的
这么一个持续的提升
我们会看到了
这么一个算力的小型化
我们在我们的手机上
然后就可以拥有
几十年前
用几间屋子才能装得下的
这么一个机器所具备的算力
那么同时
我们其实也会看到
大模型的科学化的领域
将会不断地提升我们模型的制程
而模型的制程将会带来
模型知识密度的持续的增强
而这两者的交汇
将会揭示
端测智能的一个非常巨大的潜力
所以可以看到右图
我们的这个红色的这么一个虚线
代表的是过去一个多模态模型
从GP4V的一个数百亿参数的规模
到我们今年的五月份
发布的miniCPM-V2.5
这么一个模型
只用8B左右的参数
然后就可以完成相关的能力
也是体现了多模态领域的
这么一个知识持续增强的这么一个过程
那么同时的话呢
我们会看到从下方的
这么一个蓝色的这么一个虚线
那么它体现的是在端测的
算力的持续增强下
我们可以在端测上
可以放得下一个更大的
更强的这么一个大模型
那么这两个曲线的这么一个交汇
我们会看到
面向未来
我们有可能在半年到一年内
我们可以把GP3.5水平的模型能力
放到端测上去运行
而在未来的两年内
我们可以把GP4O的相关的能力
放到端测上去运行
而这一点的话呢
具有非常重要的这么一个价值
所以从这点上来讲的话呢
我们会认为
大模型时代将会拥有
它自己的一个摩尔定律
这个摩尔定律其实就是
知识密度的持续增强
我们去回顾
摩尔定律它在1965年提出的时候
它所提出的思路就是
芯片上的电路密度
每20就是每两年
后来是修正成了18个月
能够提升一倍
那我们可以想象
对于大模型来讲
OPI其实已经验证的是
规模法则
也就是在过去的五年
我们会看到
大模型规模越大
那它的能力越强
但是我们难道是要持续
的无限制的把这个模型
越新越大吗
在我们来看
大模型的大不是这个本质
大模型它的知识密度
它的制程
才是这个大模型的
更加本质的东西
所以呢我们在过去的这五年里面
其实是见证了
一个在2020年6月份
OPI发布的GP3的水平的能力
我们现在在2024年的2月份
我们的miniCPM2.4B
它就能够达到这个水平了
它能够达到相同的水平
所以呢模型的知识密度
大致呈现每八个月
提升一倍的这么一个规律
那我们未来一个非常重要的使命
就是能够让这个规律持续下去
那么这件事情本身是需要
我们能够在数据
在模型的架构
然后在相关的成长的算法
这个方面
不断地去探索它的这种科学化的
这么一个道路
那么从而极致地去提升
这个模型的制程
所以呢我们会认为
未来高效大模型的第一性原理
它的关键词应该是知识密度
那什么是知识密度呢
我们会认为
大致应该是对应
第一就是它的能力
而这个能力
所依托的这个参数的规模
它们每一次的这个计算
所需要参与的这个参数
也就是对应的它的能力的消耗
那么从这一点上来讲
一个知识密度越强的模型
就意味着它的能力越强
它的每一次计算
所需要的参数规模越小
那么对应的其实就是这两个要素
所组成的这么一个知识密度的概念
而我们会看到
大模型它的这种
数据驱动的技术方向
大致已经确定
但是呢
模型的架构
算法
数据
这些相关的技术方案
仍然在高速地迭代
所以我们接下来非常重要的使命
就是要持续地改进
模型的制程
持续地去高速地迭代这些
相关的这种技术方案
然后来去极致地提升
这个模型的知识密度
这个应该会成为我们接下来
各大模型团队
然后努力的方向
那么从这个方面
那么今天我们说
我们既然努力的方向是知识密度
那我们今天就要给大家带来
我们最新的一个进展
当然这个进展一如既往
我们不去卷
运测的这个大模型
我们想给大家带来的是一个
更加极致地提升这个模型知识密度的
这么一个努力
那么今天就要给大家带来的是一个
叫MiniCPM-S
那么这么一个版本
那么这个版本呢
我们现在推出的是一个1.2B的模型
那么它是一个新一代的
高效的大模型的架构
那么目前的话呢
它的论文
它的相关的这个模型的参数
然后都已经公开可以访问
包括刚才金人总
然后提到的摩大社区
我们也都已经公开
那么这个架构它体现在哪几个方面呢
首先它是一个高效的稀疏的这么一个架构
那么从而能够带来在端测的一个更低的能耗
那么它能够达到88%左右的这么一个稀疏度
从而能够让我们的这个全连接层
然后它的这个能耗要降低84%
那么同时它就会带来一个
更加极致的一个快速的一个推理的能力
能够比相对应的这个稠密的模型
它的推理速度能够提高接近三倍
那么同时它是一个没有性能损失的这么一个模型
然后它能够在我们的这个性能不变的情况下
能让它变得稀疏化
那么从而对应让它的这个知识密度
能够持续的可以增强下去
那么实际上这个就是我们现在
所看到的一个稀疏的模型
和一个稠密的模型
在相同的水平下
然后它能够达到的一个更快的
这么一个推理的速度
而这一点的话呢
也要非常感谢上海交大团队
所推出的PowerInfo的这么一个推理的框架
那么同时这么一个模型的架构
其实是体现了我们在刚才所提到的三大要素
也就是架构 算法和数据三个方面里面的模型
在某一个方面
就是架构这个方面的这么一个提升
那么实际上我们会看到
它其实是向人脑学习
我们人脑是一个非常典型的功能分区的
稀疏激活的这么一个大脑的这么一个结构
那么它从而能够带来
单次的推理能耗和反应速度
都能够非常非常的强
那么对应的我们的miniCPM-S
它的这个架构
实际上就是极致的吸取了这么一个
稀疏的这么一个思想
那么首先它回归到了ReLU
这样的一个激活函数
从中让这个模型呢
能够自发的涌现出一个更强的
稀疏激活的这么一个机制
那么从而带来一个渐进式的
稀疏感知的这么一个训练的能力
也就是在整个的这个训练过程中
这个模型会自发的变得越来越稀疏
那么从而在这个稀疏的过程中
我们还有能力去保证
它的这个训练的效果不会受到损失
那么正是在这样的一个架构里面
在这个架构的情况下
那么我们会看到miniCPM-S
它将会对我们大模型的知识密度的
这个持续增强
其实是带来一个强行剂
那么这个强行剂其实可以看到
它会在过去的这么一个曲线之上
然后有一个更陡峭的这么一个发展
那我们就可以设想
在类似的这个架构下
我们去训练任何一个规模的这么一个模型
都可以达到一个更强的
这么一个模型的能力
那么这个其实是我们想要跟大家分享的
所以呢我们会说miniCPM-S
它其实是一个高效的模型的架构
它能够带来一个更低的能耗
它能够带来一个更快的这么一个推进速度
那么同时我们也是能够希望跟大家分享
我们所见证的面向未来
一个非常重要的趋势
就是要揭开端测智能的一个非常重要的
这么一个发展的这么一个态势
那么在这个方面呢
我们也是希望能够通过我们开源的力量
然后来去推进这个进程
然后能够加速我们的端测智能的这么一个推背感
那我们在接下来的话呢
也会给大家推出我们马上要发布的
一个叫mobileCPM的这么一个套件
那么这个套件呢
能够帮助我们每个人一键的去开发
大模型在端测的APP
能够成为我们在端测上
就能够拥有我们自己的大模型的应用
那么它本身会包括相应的基础的SDK的套件
然后会包括我们所带有的一些通用的端测的模型
此外的话呢
还包含预装了非常多intent的
这么一些旗式的这么一些相关的平台
那么通过这种方式呢
我们可以让所有的开发者
能够非常低门槛的速成
在端测上的这么一个大模型应用的这种开发的这种工作
那么本身呢它整个的这个架构呢
其实就是要有这个SDK
然后同时呢可以去接入非常非常多的端测的这种通用的模型
然后我们可以提供非常多的相关的插件的平台
让我们的这些模型呢具备相应的人设相关的功能
然后来去支持我们的各种各样的这种端测的这种应用
那么这样的话呢
实际上我们就会想跟大家总结
我们今天其实想给大家去带来的
一个是MiniCPM-S
这么一个知识密度持续拉满的这么一个模型
那么同时的话呢
我们也会带来MobileCPM
然后能够帮助大家一键的去集成端测的这个模型
来去开发相应的这种端测大模型的这种小这个应用
那么这个的话呢
是我们的一个
相关的一个demo
首先我们可以把这个手机变成飞行模式
在飞行模式下
我们的端测模型可以只利用端测的算力
来去完成以下的这种功能
那我们会看到相关的这种情感陪伴
相关的一些基本的文本的这么一些应用
那么基本上都可以在端测上
然后非常快速顺滑
然后去进行运行
那么这个的话呢将会极大的去揭开
我们在端测应用上的大模型的这么一个威力
所以呢我们会说
这个未来的大模型
它是一个云端协同的这么一个模式
我们既要有云上的一个极强的System2的这么一个大模型
那么我们也会需要充分的去利用端测的算力
然后来去形成端测上的System1的这么一个端测的大模型
那么我们在端测上
然后我们可以有非常快的毫秒级的这么一个响应
我们每秒可以有40个Token的这么一个生成的能力
那么我们也可以在飞行模式下
就只利用端测的这么一个算力
就可以完成相关的计算
也能够充分的去注重我们用户的这个隐私
相关的隐私数据不上网
就可以在端测完成相关的计算
那么所有的这些呢都需要依赖端测模型的这么一个支持
而本身Mobile CPM呢
已经预装了数十种
然后相关的这种Intent
可以帮助我们一键的去完成
相应的这些包括机器翻译
人设等等的这么一些
这种大模型的这么一些预设的这种能力
那我们会认为呢
通过我们大家一起
然后来去开展这种端测模型的研发
我们端测推理的这么一个加速
那么我们形成这种端测的这么一个生态
那么将会揭开
端测AI的生态的这么一个序幕
我们会看到端测
既有像智能手机
穿戴设备
巨声智能
智能家居
汽车PC等等
非常非常多样的这么一些场景
而这些场景的端测的算力
其实是远远没有被挖掘的
而我们会认为
我们需要利用端测的模型
来充分的去挖掘在端测上的这么一个应用
我们的使命就是要把模型
装到距离用户最近的地方去
那么我们刚才所推出的MobileCPM
也即将会在最近
然后就能够在GateHub上开源
并且开启公测
那么大家最近非常关注的WWDC
2024年
这个Apple Intelligence
提出的这么一个概念
那么本身里面就是包含了端测和云测的
这么一个端云协同的方案
但是这个方案需要到明年
然后才能够与大家见面
而我们希望
我们通过MobileCPM
和MiniCPM-S的相关的这种努力
让大家能够更快的去见证
在端测上的大模型的这么一个应用
所以今天总结一下
我们就是希望能够建设最强的端测模型
来去推动大模型知识密度
这样的一个定律的持续的推进
能够以更快
更简单
更低的成本
然后我们一起来迈向更加高效的大模型时代
那以上是我的分享
谢谢大家
感谢刘志远教授对摩尔定律的全新解读
也让我们对大模型的端测模型有了更多期待
其实除了摩尔定律以外
大模型模型参数量的多与少
也直接影响着模型推理的算力和效率
神功智能和个人计算机的完美结合
正在迅速迈入个人PC的消费市场
作为业内的知名品牌
联想始终致力于探索和开发AIPC的前沿创新
并取得多项突破性进展
在AIPC领域
联想究竟做了哪些令人瞩目的创新
又是如何结合大模型技术来优化用户体验呢
接下来让我们以热烈掌声
欢迎联想集团研发总监杜洋洲先生
上台带来主题演讲
联想AIPC创新实践
掌声有请
大家好
我是杜洋洲
来自于联想集团
联想营业院的人工智能实验室
今天很高兴
来到世界人工智能大学
跟大家分享
我们在AIPC方面的创新实践
我的演讲分三部分内容
分别是
框架
技术
和产品
框架部分的话
首先我会跟大家回顾一下
大模型时代
两个技术发展趋势
那么我们根据这两个技术发展趋势
制定了联想自己的AI发展框架
在技术部分
我主要讲
我们如何在端测设备AIPC为代表
那么如何让它流畅的运行
个人大迷行
并以此来构建智能体应用
那有了这个技术之后的话
我们来真正的推出了业界首款
真正意义上的AIPC
并且我给大家介绍一下
我们最近发布的一体多端战略
也就是一个智能体游走于多个终端之间
好
我们先看框架部分
第一个趋势
第一个趋势是混合式人工智能
它的意思是说
云测智能
端测智能
跟边测智能相结合
其实刚才清华大学的刘志源老师
已经给大家讲了
这个端测智能的可能性
跟做的优秀的工作
那么其实大部分人
我相信大部分人接触大模型
都是从ChadGPT开始
ChadGPT属于云测智能
因为它的服务是在云测提供
但是它跟云计算一样
有云计算优势和缺陷
比如说如果是交互式应用
和对实时要求
实时性要求高的这种应用的情况下
网络不稳定性跟延迟
都对用户体验有所影响
那第二个是说
如果是对焦点事件
或者高峰时段
多用户高并发的情况下
也产生资源竞争的问题
还有一个用户
可能会很关心它的隐私问题
因为如果要处理个人数据
那你的个人文档
私人信息要上载的公有云
被AI去分析去理解
这么强大的AI去理解
你的私人的东西
恐怕用户也不是很放心
再有一个就是能耗问题
能耗的话
其实随着数据中心
对于AI系统的广泛的应用
已经对电力系统造成了
不可忽视的冲击
这也是对绿色环保
产生的一个重大问题
既然云测AI有这些问题的话
其实边测AI跟端测AI
也正在发展
边测AI代表的话
是企业大模型
意思是说
用企业的知识
跟企业的私有数据
来训练
或者微调一个模型
它能够连接企业的业务系统
调用企业的软件模块API
然后完成企业内部的问答
跟企业的一些事务
同时它也部署在私有云上面
这样的话
不会有企业商业机密
被泄露的风险
所有这些
都是公有云上的公有大模型
做不到的
那么相应
如果是模型运行在个人设备上
比如说我们的手机PC
甚至Pi的
还有一些物联网设备的话
那就构成了个人大模型
也就是刚才刘老师讲到的
那可以预见
未来的话AI应该是三者的融合
有云边端智能的三者的融合
其实很多企业
跟我们的学界也在践行
这样的包括我们的联想的AIPC
包括微软的Copyright加PC
还有像苹果也一样
然后包括现在的芯片企业
包括高通和英特尔
英特尔也在做一些端测芯片的支持
第二个趋势
大模型的下一步发展趋势是智能体
因为相信大家都能够意识到
大模型其实有不少的局限性
Chad Gibby刚问世的时候
我们被他的能力震惊了
以为只要把模型做大
就无所不能AGI指日可待
其实后来学界的
还有一些行业的专家
来分析这件事情
发现没有这么简单
不是说把大网络大算力
还有大数据堆叠起来
就能够解决所有的问题
它有很多局限性
就像左上角
这是一些文章
来深入的分析跟实验
结论是什么呢
就是它没有真正的推理能力
没有真正的理解能力
不能建立真正的因果关系
不能建立真正的视觉模型
所有这些东西
我们可以认为
对于一个很强大的公司
对于一个黑盒系统
既然我们不知道
它的内部的工作的机制的话
那可以用测试用力来探究它
那如果说正真需要无穷多正力
正伪只需要一个反例就够了
那针对大模型的这些区限
我们怎么做呢
那业界其实已经提出了
不同的解决方案
比如说
对于它不能使用工具的问题
那去年早些时候
Meta公司提出了Twoformer
后来OpenAI也提出了这个
也就是推出了这个Function Calling
其实都使得它能够使用工具
使用API模块这些功能
扩展机的能力
像知识库的这个问题
那大家熟知的这个RAG
也就是检索生成增强
这个事情的话
能够避免
一定程度上避免它的幻觉问题
就所有这些东西不再详述了
那我们综合业界的这些进展
画了这张图
是代表了一个智能体的技术架构
我们联想来做
这个智能体
也就是按照这个思路来做
那刚才讲了两个趋势
根据这两个趋势呢
我们制定了联想自己的AI的框架
这张图竖着看
是刚才讲的第一个趋势
混合式人工智能
也就是结合云测的公有大模型
和本地的私有大模型
横着看是第二个趋势
构建以大模型为基础的智能体
那么它能够对于个人智能来讲
它的产品形态就是我们说的AI PC
对于企业智能来讲
那对于企业来讲是降本增效
其实它有很多有
无论对个人还是对企业
这个智能体的构建方式
有很多的相似之处
技术也是相通的
大家注意这里
我用了这个双胞胎这个词
其实这张图是去年10月
联想创新科技大会
对外就公布了这张图
那么只不过当时的时候
智能体的概念还没有那么流行
我们用的词是
双胞胎它跟智能体是一个意思
好 讲完了框架
我们看技术
那首先呢
感谢我们的合作伙伴阿里
为我们提供了通一千万模型
我们在此基础上
做了一些创新
使得它能够流畅地运行在端测设备上面
然后这些创新呢
包括端测的优化
然后个人知识库的构建
还有智能体的一些能力的增强
所以呢我来给大家解析这些能力
首先
遇到的一个问题是说在端测设备上面
运行大模型的最
先遇到的问题是什么
是内存不够用
比如说我们以常用的7B为例子
一个权重占两个字节
如果是FP16的话
那这样的话7B它占14G的空间对吗
但是这是静态
如果运行设备呢
由于Transformer里边的KVCache
也就是建制缓存的问题
其实耗的工作内存要比它的静态的
内存要大几倍
因为它要以空间换时间来避免重复计算
那这样的话
主流的PC其实内存是不够用的
那怎么办呢
我们分静态优化跟动态优化两种
左边静态优化
也是压缩分三步
第一个是说这个结构化的
简直所谓结构化就是
节点跟边构成一个子结构
那首先把神经元神经网络
拆成这样的子结构
判断每一个子结构的重要性
来看这个
子结构是不是可以把它删掉
对整体的结构对整体的性能
还不是很有很明显的影响
那什么样东西的能力
是我们关心的呢
比如说我们说大部分任务级跟知识级
这两级是吧
任务像摘要总结啊
还需调用
然后和这个关键信息提取
这些能力是不能被砍掉的
那能砍掉什么呢
比如说常委的知识
因为大家可以想见像175BG的GPT-3
这样的话其实它
绝大多数的权重用于存储
海量的这个百货全书的东西
那对于对个人用户
如果用的话可以走云色的模型
好
做完简直之后的话量化
量化我们不仅要看压缩比的问题
还得要看硬件对数据类型的支持
跟反量化的时候的额外开销
那有了简直跟量化之后
模型多少会有一些性能损失
我们可以做一些后处理
做一个翻Tune
把性能再提升一些
这是静态部分
动态部分怎么做呢
其实就是构建一个推理引擎
推理引擎这件事刚才NVIDIA的同事也分享
其实也有很多挑战
我们要解决它
我们做了三件事情
第一件事情对于异构
异构计算这件事情
因为AIPC里面除了CPUGPU还有NPU
那每个算力单元它们的特征不一样
适用性不一样
我们需要把大模型相关的计算任务
拆解成一些子任务
然后看它的并行度
看它的依赖关系
重拍流水分配到不同的计算单元上面
使得计算单元的总体利用率最大
并且单任务的质量最大
计算时间最短
这是第一个工作
推理引擎的第一个工作
就是这个异构计算
第二件事情刚才讲到的就是KV开是建制缓存
那么在主存跟显存之间
我们要考虑这个开始的问题
哪些建制需要保留
更有价值
让它保留在开始里面
然后哪些可以把它剔除
使得工作内存尽量的少的情况下
性能还不是下降很多
第三件事就是兼容
因为我们要做产品
我们要用KV平台和AMD平台
兼容独立显卡 集成显卡
那其实我们是跟
这些合作伙伴的铸厂工程师一起
做深度的
算子底层的源与货的优化
最终使得大模型
能够流畅地运行在主流的
这个PC的平台上面
好
那第二个
关键技术是说个人知识库
大家知道大模型为什么要在端测
设备上运行
其中很大的一个原因是说
需要掌握你的个人知识
能够对你产生一个
就像一个灵魂伴侣一样的
一个知识问答
那这件事就需要大模型
来存取你的一些文档
那有两个办法了
一个是说做翻替用
翻替用这件事其实是不太可行的
为什么呢
因为一旦翻替用的话
它可能会影响破坏原来的知识结构
并且还会产生一些幻觉问题
失效性问题这些问题
所以我们采用的方案是
RAG
也就是检索增强生成
那其实原始的RAG的话
它还是不能够满足用户的需求
具体来讲我们把RAG拆开
把每一个环节
做了深入细致的分析跟优化
那就像我们右图红色这个部分
比如说其实RAG
是一个里面借鉴了很多搜索引擎的技术
RAG做好了
不亚于是一个搜索引擎
那像这个
对于查询的一些处理
我们借鉴搜索引擎的技术像
根据一些上下文的信息
比如说时间 地点 设备
用户的user profile的信息
做一些core write
就是这个查询重写和
这个消奇
那对于文档处理的话
大家看到这里有三种index
就是像关键字索引
语意索引 层次索引
那其实我们是发了multipath
这个跟搜索引擎的思路也是比较类似
然后做multipath之后的话
做fusion
其实这里的话我们有一个特色的技术
就是说
检索器跟生成器
这两者的协同优化
什么意思呢
大模型在这里扮演了一个
检索器
大模型在这里扮演一个生成器的角色
那当大模型固定的时候
其实我们可以优化检索器
让它生成对于检索器
更友好的结果
那具体来讲
检索器可以优化它的embedding
优化它到点反而会top级的结果
给大模型
那如果当
检索器的结果固定的时候
大模型也可以优化
去微调大模型
然后来使得它生成的结果
对用户来讲更加友好
或者更接近ground truth
所以我们管这件事情叫做
检索器跟生成器的
二者系统优化
二者相向而行
这里还有一个特色
就是我们做的其实是
跨设备的个人知识的问答
然后呢因为
检索器可以散落在不同的设备上
比如说每个人都有好多个人设备
像你工作电脑家里有电脑
然后有手机有平板
你的数据其实是产生
跟分布于不同的个人设备上面
这样的话其实呢
非常有必要就建立一个分布
是所以使得你散落在
不同设备上的数据
互联互通能够生成一个整体
这样的话才形成一个完整的
这个智能问答系统
第三个技术就是
其实有两件事情很关键
一个是说意图理解
一个是说任务规划跟执行
那大家知道大模型
其实是个端到端的系统
那现在我把它拆开了
变成一个模块化的设计
那大家说了是不是没有必要呢
直接上大模型
我告诉他什么他就做什么
没有必要把它拆成模块
但大家都有经验
其实大模型有的时候会把复杂的问题
做对让我们很惊讶
然后呢这么复杂的事情他能做对
他有的时候经常犯一些愚蠢的错误
简单事情他会搞错
所以我呢
我如果对这种时灵时不灵的
这个产品用户是没有办法接受的
那具体来讲我们怎么做呢
走的是结合的路线
就是大模型加小模型的结合
甚至于规则的结合
比如说做图
意图理解第一列
我们把用户的常用意图归纳出来
成一个列表
然后呢用小模型做一个分类器
能够保证他的分类准确性非常高
然后对于一些复杂意图
走大模型
比如说做图的第二列
那什么叫复杂意图
像一句话用户说的很冗长
包含了多个意图
或者包括多跳就是multi-hop的问题
或者这里需要一个对话管理
我们看这个例子
用户说我要玩游戏了
那我们首先构造一个prime的模板
然后把这个用户的这个原始输入
模板化
给大模型
专属化格式化的一个输出
那其中明确的意图是要打开
杜比的这个圈卷声
这种模式来支持这个游戏模式
那这是明确的意图
不明确的意图呢
他要继续构成一个dialogflow
问用户你想要玩什么样的游戏
好把它启动起来
那其实大模型跟小模型的
这个无论是并联串联
还有跟规则的这个混合利用呢
在一般来讲在成熟的产品里面
大家都是这么做的
基本不可能说一个模型一统天下
如果我们就是可以回顾了
搜索引擎里面比如说white list
然后一些这个最后一步
我们要规则来最后来卡一下
它的这个安全性
都走的这种混合的道路
其实我们也会这样做的
任务规划也是一样
就是说什么叫做任务规划呢
用户的意图跟我们的可执行的
这个API模块
它经常不是个一一对应关系
经常是用户说了一件事
需要把它拆解成几个原子级的
这个子任务
看一下它们的依赖关系限制条件
再看对于每一个子任务
能够有哪些模块可用
然后来完成这个最终目标
那这件事我们叫做一个全盘规划
那大模型本身
它毕竟是一个下一个词预测
在做这么一件本质的事情
它只能做直觉
适合于做直接类的事情
不太适合于做全球规划的这种事情
那我们叫做一些外挂的一种机制
那最右边大家可以看到
这里有一个蒙特卡罗数搜索是吧
这里是alpha go的算法
其实下棋典型的
它是一个典型的规划问题
我们不是看眼前能吃几个子
而是要看终局的胜利
那如果说大家可以想象一下
这件事如果我不用
这么复杂的机制
不用蒙特卡罗那个搜索数
那现在把它拍张照片
发给gpt4o
或者其他方式把棋局
发给gpt4o
问我下一步应该走什么子
当然了我没有试过
那我相信它可能是不行
对于很多经典的规划问题
对于一些典型的规划问题
我们是有经典解法的
不能说因为有了大模型
就把那些经典的东西扔掉了
应该是采取一个结合的道路
比如说像现在的巨神智能的前沿
其实也是走的传统的强化学习
和大模型相结合的路子
所以右图的最左边这一列
列的马尔科夫角色过程
这些其实是
强化学习的一些经典解法
那意思是说我们对于不同的任务
用一种结合的方案来做
这都是构建智能体技术的关键
有了这些技术的话
其实我们就可以打造出
一个真正意义上的AI PC
那么它有五大特征
第一个我们刚才讲过了
它本身是以大模型为基础
构建了个人智能体
然后本身智能体是运行在本地
但是可以与云端的大模型相辅助
第二件事刚才也提到过了
是混合算力
CPU GPU NPU的一个计算
第三件事呢
它既然成为你的知你懂你
帮你的一个
灵魂伴侣或者助手
然后呢所以说它必须要
掌握你的知识库比你还热化设备的
第四件事刚才没有提到过
它是我们是构建了一个
开放的生态也就是说
智能体有能力
发现新的可用的AI的应用
把它也一样调度起来成为一个工具
完成更复杂的任务
同时这个平台开放给
开发者
更强大的新的智能体应用
第三件事
第四最后一件事这个安全的问题
刚才也提到过本地模型本身处理的话
它也保证了安全
并且我们还有芯片级的这个方案
可以做如果真的要传输的话
可以做芯片级的这种安全的这个加密跟脱密
好
那么其实还有一个事情啊
就是在上海有一句俗话
叫做罗斯科里做道场
那我们其实真的实现了这一点
罗斯科里做道场的意思是说
在空间狭小
条件简陋的情况下做精妙的事情
那其实PC本身计算能力有限
资源有限
我们真的把它这个端子模型流畅地运行起来了
要做了智能体的应用
真的实现了这一点
那我们在4月18号
也是在上海创新科技大会上
发布了AIPC产品
在5月20号已经开售AIPC
所以大家在市场上是能买得到的
这是真正意义上的落地的产品
而不是停留在口床上的宣传
那其实
从工作到生活
都是覆盖了不同的智能体应用
产品上面的话
其实分三个系列
向左下角商用的就是高端路线
然后呢中间呢
就是走的这个
就是高性价比的路线
最右侧的话
是走的这个信创国产化的路线
在6月25号
就是大概10天前
我们又公布了这个一体多端的战略
所谓一体就是一个智能体
构成一个智能体系统
多端呢就是多个互联互通的个人的设备
那一个智能体
可以游走在不同的终端之间
给用户提供一个
统一的一个完善的体验
那这样的话用户
其实说整个来讲的话
就是这也是提供了一个
更大的一个机会
那最后呢
我想
首先是我们愿意跟
合作伙伴阿里继续深入的合作
来发展以智能体
以大波形为基础的智能体技术
与易介煌一伙伴
的合作
来发展这个混合式的AI框架
那对于个人智能来讲
继续把AIPC做得更好用
对于企业智能来讲
做的真正的降本增效
谢谢大家
感谢杜洋洲先生的
精彩演讲
期待有更多业界伙伴和联想一起
打造混合式AI技术
让AIPC的不断发展
当然除了个人PC以外
AI智能助手在手机 汽车 机器人
等多种物联网设备中
也越来越普及
大模型技术的引入
让终端智能助手不再局限于简单问答
而是能够在视觉识别
实时翻译 图片生成等多个领域
提供更为智能的帮助和服务
接下来
让我们有请小爱团队
大模型产品负责人乔国辉先生
带来主题演讲
小爱同学的实践历程
为大家进一步介绍
小爱同学如何通过软硬件的深度结合
带来全场景
多模态的深度体验
让我们热烈欢迎乔国辉先生上台
大家好
我是小米公司小爱同学的乔国辉
今天很荣幸
作为一个大模型的应用者
在这里给大家分享一下
小爱同学在大模型的实践历程
先简单的介绍一下小爱同学
小爱同学是
小米的人工智能助手
不知道大家知不知道
小爱同学的名字是怎么来的
其实我们的名字就是
小AI
我们是在16年的时候
开始去做AI相关的功能
经过8年的时间
就覆盖了小米的各个硬件设备
包括小米的汽车
手机 AIoT
机器人
还有可穿戴设备等等
这些上面都有小爱同学
小爱同学是一个
软硬件深度结合的场景
我们想做好这个功能
非常的不容易
除了在AI的云端上
我们要更好地理解用户以外
我们也需要跟硬件去做
深度的结合
包括硬件的声学链路
硬件的前端语音识别等等
我们要针对硬件做很多
针对性的处理和优化
这样才能实现
这种体验的效果
大家可能熟知的小爱同学
主要是小爱的语音助手
但实际上我们也还有
很多其他的系统服务
包括像小爱的
主动建议 建议场景
小爱视觉 小爱翻译
小爱通话
未来我们还会有更多的
功能推出
给大家简单地介绍一下
小爱同学的技术架构
在最上面是
设备层
左边是内置小爱的设备
用户可以通过这样的设备
跟小爱进行交互
获得相应的内容和服务
右边是受控设备
就是通过米家的
接入这种IoT的设备
通过小爱同学我们把主控设备
和被控设备连接起来
中间是能够
用户的同一层
用户的一个请求来了之后
我们通过小爱同学
去理解用户的意图
去感知用户周边的环境
感知他的信息
最后提供他相应的功能和服务
我们提供的服务
大概可能就是
下面这些类型
包括设备的控制
这个也是用户用的最多的场景
还有一些基础的工具
像闹钟 计算器这样的
还有信息的查询 内容的服务
还有这种场景的互动对话等等
那么截止到今天为止
小爱同学我们目前搭载了
54类的主控设备
我们的越活跃用户
已经有1.3亿
我们每天的请求次数有2个亿
我们是在2年的10月份
开始去做大模型相关的
这种功能的落地
我们做了很多的打磨
我们在23年的8月
首次进行了大模型功能的内测
一经推出之后
还是收获了非常多的用户的好评
我们在今年的3月
我们在汽车上是正式的
上线了小爱的大模型功能
我们针对汽车也做了很多
针对性的优化
那么可以看到
大模型这种体验的提升
给用户带来了非常大的一些
变化
我们过去很多做不了
或者是做不好的功能
在大模型之后
是有一个非常大幅的提升的
尤其是我们这种中长尾的请求
比如说像知识的问答
或者这种闲聊场景的对话
我们过去可能我们的满足度
大概就只有30%
但是我们有了大模型之后
我们经过打磨
我们现在已经提升到了80%多
并且随着这个模型的能力提升
它还是在继续的优化的
另外就是这种大模型能力
也给我们的活跃用户的留存
带来了一个非常大的提升
我们大概提升了10%
做过互联网产品的同事们
可能都了解
就是留存每提升5%
其实它体验都是非常巨大的提升
其实它体验都是非常巨大的提升
其实它体验都是非常巨大的提升
那么在这里
大模型技术给小爱
带来了哪些的跨越式升级呢
我们主要是分成了三个事情
我们主要是分成了三个事情
一个就是通用的对话
通过大模型的这种通用的能力
去更好的回答用户的问题
第二个就是在一些垂直领域的场景
第二个就是在一些垂直领域的场景
我们也做了很多的功能
小爱其实我们背后的场景很丰富
我们有很多垂直领域的场景
比如说小米的商品出手
比如说小米的商品出手
用户可能会问一些小米相关的设备的参数
用户可能会问一些小米相关的设备的参数
然后小米设备的这种使用指南
甚至是小米设备如果故障了该怎么办
过去我们想做好这样的场景其实很难
过去我们想做好这样的场景其实很难
我们想用这种人工训练的数据
这种QA段
然后去满足用户
但实际上这个最终的效果上来
做的也并不是很好
但有了大模型之后我们看到
给这样的垂直领域场景
给这样的垂直领域场景
带来了新的解决的方式
我们通过这种RAG的技术
然后通过大模型的检索匹配
我们很好的在这样的场景下就满足了用户
我们很好的在这样的场景下就满足了用户
第三类就是NLP的任务
因为小爱这样的场景
来了之后我们是需要去理解用户的意图的
来了之后我们是需要去理解用户的意图的
那么用户的每一句话表达的到底是什么意思
它是其实有非常多的不同的任务的
它是其实有非常多的不同的任务的
那么我们过去想做好
我们每个任务其实都要构建大量的这个训练数据
并且我们的产品经理
针对每个任务场景都会去做相应的这种产品策略
针对每个任务场景都会去做相应的这种产品策略
过去不是一直有句话吗
就是有多少人工就有多少智能
但是大模型来了之后呢
但是我们利用大模型这种比较强的通用的知识
但是我们利用大模型这种比较强的通用的知识
我们通过小量的数据结合大模型
我们通过小量的数据结合大模型
然后在每一个任务场景做一些训练
我们就可以很好的解决这种场景了
我们就可以很好的解决这种场景了
对 那么总结来讲
就大模型之后呢
小爱的这个技术架构可能大概就是这样的
我们的一个用户的请求来了之后呢
我们会先用大模型来做一些简单的意图理解
我们会先用大模型来做一些简单的意图理解
我们把任务大概分成了四类
那么第一类呢
相对比较简单
就是一些工具或者是控制类的任务
我们在意图分发到这个任务场景之后呢
我们在意图分发到这个任务场景之后呢
我们通过这样的LP小模型
就能去直接执行相应的操作了
第二类呢 相对会复杂一些
是一些内容类的场景
就比如说我们的音乐或者视频
做过音乐的同事都知道
想做好音乐的话
我们需要大量的音乐数据
我们需要对数据去打标签
这个搜索和推荐的能力
所以在这个场景呢
我们主要是用大模型来做好用户的意图理解
我们还是要依赖传统的
这个搜索和推荐去满足用户
那么第三类场景呢
就是生成类的场景
这个是我过去小爱其实做不好的
或者我们做不了的场景
这个其实在大模型之后现在表现得非常的好
那么第四类呢
我们认为是最难的一类
也是现在用户需求其实最大的一类
就是知识类的场景
这些场景其实非常的困难
如果我们做好的话
我们需要给用户准确的答案
因为它只有唯一的答案
基本上大部分的情况
它不像生成类你可能写个作文或者写个诗
其实言之有理的话
用户都会觉得是OK的
但是在这样的场景下
我们必须要做对
这个时候其实就对大模型的通用能力
带来了非常大的挑战
其实我们现在看到啊
就行业内现在最好的模型
其实在这类的问题解决上
还是有非常多的问题的
其实我们也欣喜的去发现
就我们跟很多行业的大模型做了交流
大家都觉得就是随着这个
大模型能力的提升
我们用更大的参数
然后通过更多的这种模型训练
是能够让这样的场景变得更好的
那么在小爱这边
我们是如何去选择大模型的呢
其实我们应该跟很多在座的
大模型开发者是一样的
我们大概就是这样三步
我们第一步呢
会去建设满足业务需求的评测体系
会搭建业务适合的
这个评测集
第二个我们在对应的这个业务场景下
去选择适合的模型
因为小爱呢背后有很多的场景
我们每个场景的要求是不一样的
所以我们尽量的
都把每个场景去选到
相对来说最适合的一个模型
那第三个呢就是我们
随着做的越来越深入
我们发现一个场景
通用的模型是不能做到最好的
我们一定有很多定制化的需求
这个时候其实就需要对模型
做大量的工作
包括模型的优化
也包括模型的微调等等
那么在小爱这边呢
其实我们最关心的主要是两件事情
一个是效果的指标
一个是性能的指标
在效果上呢
我们搭建了九大类四十多个小项的
这个评测体系
很多就是和小爱合作过的大明云厂商
就是在我们初期合作的时候
我们都会给他提供一份这样的评测结果
甚至是跟同行的这个对比
然后另外一个指标呢
我们也很关心性能
在这个场景用户一个请求发出之后
他是要求很快的就要得到结果的
所以这个时候
我们对模型的实验的速度
也是有要求的
因此我们搭建了
这样一套基于小爱的知识
然后基于不同大模型
这样的混合的体系
我们基本上便利了行业内
所有的大模型
我们在每一个场景都找到了
相对比较适合的内容
接下来呢
给大家简单的便利一下
我们在这个模型上
其实我们在大模型上
是有了一个很强大的
就是大模型的能力
就是大模型在做的一些能力
就是随着大模型能力的越来越强
大模型开始在智能座舱
智能手机甚至是智能家居上
有更多的功能落地
那小爱呢除了传统的这种语音交互以外
我们其实也做了很多其他的事情
包括在手机上
我们做了很多多模态的应用场景
比如说图片问答
图片的一句话编辑
小爱呢控制IoT
其实是我们非常常用的一个场景
但这样的场景其实想做好
是很困难的
因为我们需要理解用户的家庭房间
你设备的这个信息
设备的名字
甚至等等这样的内容
我们现在在通过大模型
通过agent的技术
在更好的去探索怎么去能更好的控制
用户智能家居的能力
那么第二个呢就是小米的商品助手
在前面也提过了
我们通过大模型这样的能力呢
去复杂的知识注入
然后去更好的回答用户的问题
另外我们其实也结合小米的输入法
我们在AI输入的场景
给用户提供更多智能的回复帮助
比如说在微信的场景
我们帮助用户写一些
更高情商的回复等等
那么在今年的汽车发布会上
其实我们也发布了很多
小米的大模型功能
包括像走哪问哪
比如说你到了一个城市
对吧你开车的时候
可能问这里的河叫什么
这种地理的位置的问答
我们也做了基于多模态的
这种前面的车是什么这样的问答
我们也做了汽车说明书
相关的一些功能
在这里呢
我给大家准备了一个
一分钟的短视频
简单的再看一下汽车上
我们做的一些功能的应用
我们还来自于力量准备的
所以调到最后
停下了
甚至跨界的想法
它也能心灵神会
我的手机掉哪了
打开家里的扫地机器人
打开家里的摄像头
小二同学
我在
打开手机复卡码
完成了
搭载AI大模型的它
无所不知
有没有离鬼街和望京都很近的川菜馆
为你找到了十家位置合适的川菜馆
介绍一下七方三项
是三方七项
前面的车是什么车
我来看看
甚至它可以像人一样观察
是感染力的小米苏7
满足你的所有好奇
前面的山是什么山
这就是全新的小爱
更懂车的事
更懂设备的事
更懂你好奇的事
全新小爱大模型智能语音
已登陆小米苏7
好
刚刚大家看到的都是一些
我们用大模型
或者结合大模型去做的一些功能
接下来想简单地再给大家分享一下
小爱同学对于大模型未来的规划
首先我们可以看到
大模型的能力越来越强
大模型开始可以做更多更复杂的任务
它的准确率也很高
我们现在大家其实都知道
有一个非常热的概念叫做AI Agent
就是通过大模型来去做这种复杂的任务
然后更好的去满足用户
但是我们其实也知道
这样的场景其实落地是很困难的
我们都知道
一个任务它如果最后的执行准确率
没有办法达到95%的话
其实这个对用户来说是不可用的
但是像这种Agent的场景
其实目前准确率上还是有非常大的挑战的
这个也是我们
希望能够和大模型一起去做的这种技术升级
在小爱的场景下
我通过Agent来做更多更复杂的任务
去满足用户
第二个就是多模态的场景
小爱在手机和车载上
我们做了很多多模态的能力
用户其实表现的都非常的喜欢
我们接下来还会持续地
在这个方向推出更多的新功能
第三个是OS的深度整合
随着这个模型能力的增强
我们希望能够跟系统去做更深度的偶合
我们会提供更多的底层的系统的控制
然后给用户提供更多的内容服务
我们相信在今年下半年
大家去看行业内的手机的时候
应该都会看到有很多AI的应用开始落地
我们可能未来就会叫AI的手机了
第四个就是端侧大模型
其实这个也是小爱
非常重点在投入的一个方向
因为我们觉得当用户的数据
没有办法上传的时候
或者用户其实有很多的场景
其实对它的隐私非常的关注
这个时候云端大模型是没有办法去满足的
比如说我们在手机上
我们去对用户的信息的检索
去对手机里面的一些内容的这种操作
或者问答
包括在车上
其实端侧也是一个非常重要的场景
大家都知道
车是在很多地带是很容易出现
无网或者弱网的情况的
这时候我们通过这种端侧大模型
就能更好的满足用户
给用户提供更多的内容和服务
最后想简单地总结一下
就是小爱这样的开发者
我们对大模型最关注的事情
其实主要是两个
一个是效果
一个是成本
这个里面我们最关注的是效果
效果里面我们又分成了两个事情
一个事情是大模型的
通用能力是不是足够的强
能够更多的满足用户的基础的能力
第二个就是针对小爱这样的场景
我们在过去一段时间探索发现
我们的很多场景就是要定制化的
所以我们也很关注
大模型是不是能针对业务
去做定制化的诉求
在这里也非常感谢我们的阿里云同事
在我们小爱的很多场景里
其实都做了很多针对性的优化
包括前面大家看到的多摩泰的场景
也包括刚刚像小米商品这样复杂的
知识植物的场景
那么在未来非常期待说
大模型的能力能够进一步的提升
然后这样的话能够帮助像我们这样
小米的这样的开发者
能够更好的去调优我们的效果
给用户更多的更丰富的内容
好 以上就是我今天分享的内容
谢谢大家
感谢
谢谢乔国辉先生的精彩演讲
结尾影片里的小爱同样让我们眼前一亮
相信在未来小爱同学一定会成为一个更懂你的小爱
其实阿里巴巴集团一直致力于用科技力量
提升我们的幸福生活
实现商业之上的价值
有这样一群特别的小朋友
被大家叫做新型的孩子
或者说叫新宝
他们就是孤独症普系障碍儿童
根据第五版
中国孤独症教育康复行业发展状况报告
的估计
我国零至十四岁孤独症儿童
约有两百万人
有那么一群志愿者
他们愿意为这群孩子
打造一方能够会梦成真的小天地
他们历时近三个月
开发出了一套专门关照孤独症儿童的AI绘本工具
并免费为这些儿童家庭提供定制化的AI绘本服务
仅需一句话的故事梗概
就可以直接生成符合新宝需求的有词称故事绘本
一经上线
并获得了苹果应用市场精选栏目的推荐
那么这个绘本工具是如何诞生的
让我们一起来看一看
我们是一群追星星的小伙伴
两个月前
这张志愿者招募令把我们汇聚在了一起
我是一名前端工程师
也是孩子的父亲
我是一名幼儿设计师
想一起给小朋友们点亮星光
我是一名软件PT
我是一名普系儿童家长
也是一名
特教老师
我是一名儿童故事编剧
希望给这个群体带来更多的光和爱
这里是上海美术电影制片厂
这个活动我们可以一起参与
我们来自天南海北
开始为孤独症儿童打造专属他们的定制AI绘本工具
这次故事绘本主要是基于通讯大模型
结合了孤独症儿童专家的一些指导意见
创造了一个专门为儿童打造的故事绘本
对于纹身图大模型来说的话
我们其实希望能给星宝提供一些
更符合着儿童的一些喜好
MotorScope Agent在这里头做了一个底层的一个知识
我们把它的纹身图
还有本身的个性化
生成一些文本的能力调用起来
能够为像孤独症儿童生成一些特定的这种绘本故事
这项工作或许是会开源出来的
希望能够通过开源这种技术捐赠的方式
为孤独症儿童和家庭做更多的事情
你们愿意和我一起为他们打造一个
充满星光的世界吗?
相信在座的各位和我一样
都被这群追星星的志愿者们的善意和投入所打动
正如影片中所说
是人有了温度
AI才会有温度
目前追星星的AI已经上线通议APP公测
也受到了很多星宝家庭和关注者的好评
今天我们特别邀请到了一路见证
和关注者的好评
和支持这个公益项目的机构代表
正式为我们开启这个有爱的项目
让我们掌声有请
上海美术电影制片厂有限公司
党委副书记 副总经理 彭勇
中国青少年发展基金会
网络公益与公众推广部副部长 齐齐格
摩达社区负责人 石洪竺
阿里通益实验室产品负责人 金路瑶
以及公益项目发起方代表
阿里巴巴集团 金路瑶
公共关系部总监 好方奖
有请各位嘉宾上台
请各位嘉宾把手放在对应的心形位置上
让我们共同开启这一段
星光璀璨的旅程
五 四 三 二
一
关怀孤独症儿童公益AI绘本工具
追星星的AI正式发布
那么请各位嘉宾上前一步
我们合影留恋
该项目还得到了孤独症儿童干预的机构
恒星乐乐 海豚乐乐等的专业支持
以及浙江工业大学王永固教授团队
等专家顾问团队 童语故事等不少
爱心人士机构的合力支持
感谢大家
好的 请各位嘉宾入座
请彭总和陆瑶两位留步
绘本项目能够顺利发布
离不开阿里通艺实验室
和上海美术电影制片厂的全程支持
通艺实验室在这个项目背后
提供了很多技术知识
有请陆瑶为我们分享其中的一些细节
谢谢
这个是我们第一次参加这样的项目
但是也是一个让我们特别兴奋的项目
因为在这个过程里
我相信每一个参与者
包括我们的产品经理
我们的技术 我们的算法
都是充满了爱在对待这件事情
所以我相信今天通艺的大模型
它也会用爱来输出
来普惠到我们每一个人
包括帮助到每一个人
这也是我们一直以来想去做的一件事情
那谢谢
好的 谢谢陆瑶
那么除了通艺提供的技术支持外
当然也离不开上海美术电影制片厂
众多优秀的绘画设计
那么就请彭总为我们本次活动
做机遇分享
好的 谢谢大家
那个上海美术电影制片厂
就是非常有幸
能够参与到这个项目中间来
其实一开始我们也是
被这个阿丽的小伙伴
还有就是我们的广大的志愿者
他们的热心和爱所感动
所以我们上海美术电影制片厂
也愿意用我们的一己之力
让我们的深具中国美学的一些动画的
一些形象来陪伴我们的新宝
随着那个活动
还有我们合作的深入呢
我们是觉得在这个AIGC大爆发的时代
就是我们这个传统的IP形象
与这个Z世代的人的生活方式
它可能有一个更新的一个链接方式
所以我们
我们上海美术电影制片厂
也愿意说
跟大家一起来推动这样的事情
我们相信通过这样的活动
让这个公益
变得有更多的多元性和多样性
让我们所有通过公益的活动
能够让我们继续去热爱这个世界和他人
也让我们付出的点点滴滴
让这个公益的活动能够让我们继续去热爱这个世界和他人
让这个世界变得更温暖
好 谢谢大家
好的 谢谢彭总
感谢两位嘉宾
那么也希望呢
追星星的AI项目
能够点亮新宝的夜空
成为父母老师的好助手
小好工具
陪伴新宝们共同成长
那么接下来呢
让我们进入本场论坛的最后一个环节
圆桌讨论
随着大模型生态的不断完善
我们也看到越来越多的大模型走上了开源开放的道路
我们相信开源开放
互惠共享
将是今后大模型技术生态繁荣的必然选择
本次圆桌对话的主题就是
开互惠共享
大模型技术生态的必选项
让我们有请圆桌主持人
摩达社区技术运营负责人程程
以及各位嘉宾上台
他们是阿里云
无影事业部产品总监程希
面壁智能副总裁
OpenBNB社区联合发起人贾超
通议实验室
通议签问
开源负责人林俊阳
上海人工智能实验室研究员张松阳
以及摩达社区模型服务负责人张文蒙
让我们以热烈掌声
欢迎各位嘉宾上台
欢迎大家
那我们现在进入我们的这个圆桌环节
然后其实圆桌环节
我们今天能看到
其实有做大模型的同学
然后也有评测大模型的同学
有做开源社区的同学
也有做产业落地的同学
那我们今天开始我们第一个主题
就是这一年
突发的大模型的同学
就是这一年突发的大模型的同学
是非猛进的中国的大模型
那这个问题我想先问一下
签问的那个俊阳同学
其实去年七月份的时候
我们第一次开始讨论
就是签问开源的事情
那个时候我还记得第一代的是一个签问的7B
那其实当时开源的那个模型
怎么说
就是我觉得可能在
开源社区里面是一个很好的模型
但在整个大模型的纵观下来
并不是一个非常非常出挑的模型
但是在这一年的时间里面
其实签问迭代的速度
很快
而且每一次发布都有非常大的这样一个进步
那甚至到现在做到了一个全球领先的
这样的一个大模型的话
那其中有什么样的一些关键的点
对
非常感谢诚诚的提问
然后对通讯签问也有很多褒奖
首先当时呢
确实我们出了一个7B的模型
开源社区的话呢
比较长时间的话
其实是落后于币源的大模型的状况
所以当时其实我们在
在研发大模型的过程当中
其实是不断地收集
开源社区的开发者的反馈
不断地去优化我们的模型
所以我们后面不管是做14B还是72B
其实都不是简单的7B去扩大模型size
而是对我们的数据做了比较多迭代的相关的工作
那后来非常有幸
我们开源了1.5
然后系列也比较多
有比较多学界的朋友也一起参与进来
去给了我们非常多一些意见
告诉我们
一些优化模型的一些经验
所以才能走到今天Quantum这一步吧
所以如果要我感谢大家的话
其实还是感谢这个众多开发者以及用户的支持
才能让我们的模型迭代速度迭代这么快
可以说今天去一定程度上在追赶OpenAI
好的
谢谢俊阳
然后下一个问题
我想问一下甲超
然后就是其实我们也知道说像miniCPM在端测大模型
在多模态视觉的这样的一些模型
专注在多模态中小模型的场景
但是做到了非常非常好的这样一个效果
然后今天我们也听刘老师讲知识密度这样一个词
然后甚至在miniCPM前一段时间也被全球领先的一些大学做了一些借鉴
那就是其实今年很多很多人都讲第一性原则是scaling low
那为什么面壁今天坚持做这样的一个端测的这样的一个大模型
做这样的一个小而美的大模型的想法是什么
OK
其实是这样的
就是刚才其实也提到了一个scaling low的和知识密度的一个极致体现
那其实面壁早在其实我们整个整个公司就是清华团队出来的
我们从2020年就开始训大模型
那其实到23年这个GPT爆发的元年开始
我们训了非常多的百亿千亿规模的大模型
但是我们发现就是
千亿规模这种大模型训出来以后
它在推理成本上是巨大的
就是当有用户有一个千万级这样量级的DAU以后
其实它GPU成本是非常大的
那得益于我们其实整个实验室就是清华团队加面壁团队
我们在去年六月中
就是去年年中时候
其实我们就开展了scaling low相关的工作啊
我们做了大量的
在小规模模型上的实验来得到了一组最优的参数配比
同时我们独创的创新性的提出了一种最新的训练方法
然后再加上这都是算法层面的
另一方面就是加上我们在数据层面的一个完全新一代的升级
包括数据配比的一些实验得到我们模型的支撑啊
所以说我们在去年
年底我们就有有坚信
我们通过训练一个更小的
好比说两币参数规模的模型来比肩十币左右的模型
然后让他发挥这样的一个足够好的性的
因为当这样以后我们就可以去在很多场景去替换这样一个大规模量级的一个模型以后
那他的场景也是足够多的
而且我们发现其实在座的大家都有智能手机
其实我们近期一个报调研报告
发现其实国内大家终端上算力的一个大家都没有开发出来
但其实每个人智能手机的算力其实和去年差不多像就是GPU这样对比
其实差不多有能够和一百万张H100这样的量级的算力去对比
所以说我们觉得端测才有足够的想象力啊
那其实今年就是面壁
其实小钢炮在二月一号发布以来
已经受到了足够多的关注和业内的认可
那其实刚才晨晨也提到就是那个国外的那个事件
其实我觉得我觉得更重要的其实就是对我们这个模型的认可
对中国技术的一个认可
因为其实他所所所说的
其实他之所以在国外能出圈
也是因为他说就是
这个模型和GPT-4V Gemini Pro这样的模型是能够比肩的
但他其实是花了五百美金
但其实前两个是对的
后一个五百美金是不可能迅出这样模型的
所以说但反过来推
其实这个我们也觉得他和整个机构其实也不是很相关
所以我们也没有着重的去说这件事情
了解
就是其实
我也想继续再追问一下
就是说就是前一段时间非常火的那个模型
miniCPM2.5这样2.5V这样的一个模型
他其实也是基于像NAMA3这样的一些模型上
基础上有个G模型在做这样的一个训练
那这个这么就是其实他的在上面做的这样的一个多模态的继续训练
其实效果很好
未来有没有考虑过和中国很厉害的这样的一个大模型合作
然后比如说千问呢
嗯
那就是首先其实我们选了一个啊
我们当时之所以选那个喇嘛三吧
B来训练
其实是因为当时就是喇嘛三额效果也很好
然后其实在全球非常火吗
那我们当时就选了这样一个模型
就是在我们下一代模型没有出来之前
所以说他的一个出圈
我觉得下一步我们也会考虑
好比说和国内的好比说千万
我们联手一起也可以搞一个这样的一个联动
我觉得这个是非常好的
因为对国外可能大家觉得用Lama3
那其实我们国内也有非常好的模型
那其实同时的话
面壁也会持续的在端侧
因为刚才刘老师也是讲了
大模型的摩尔定律之密度
我们也会在更小的尺寸上
去寻一个更好的模型
来做我们多摩泰的一个基座
所以说这些我们都是会同步来做的
也会在未来
我觉得就是好比说和俊阳他们的合作
包括面壁未来更小更强的基座
这些都会我相信在不远的几个月
都会逐步的发出来
对对对
好的好的
那我们刚刚聊到了就是大模型的整个的发展
然后其实前一段时间
Open Compass其实有讲一个理论
就是松阳分享的时候我印象很深刻
就是过去一年闭元大模型的这个能力的上升
和这个开元大模型的能力上升
显然开元大模型会更强一点
那其实Open Compass在大模型的客观评价上面
其实做了非常多的工作
而且整个大模型的发展是离不开评测的
而且即将也会有这样的一个多摩泰的这样一个榜单出来
那如何就是客观公正的这个评价这样一个大模型
然后包括也有人反馈说现在的Benchmark
怎么来保障这样一个防止刷榜公允性
那Arena怎么来去覆盖方方面面的一些
就是肠胃的这样的一些问题
然后怎么样以及未来垂直行业的一些评价怎么来做
也希望松阳跟我们分享一下大模型的评测的下一步
你是怎么想的
OK谢谢啊
我这边对自我介绍一下
我是来自上海工程实验室的张松阳
然后我们之前去年到现在
一直在做的一个项目叫做Open Compass
就主要是在做模型的评测
对那这个相信很多做模型的同学或者老师们可能很了解
对我们也给大家制造了很多的压力
因为我们可能定期就会去放一些榜单
对然后我想分享几个观点吧
就第一个观点是说评测这件事情其实是前置的
就刚才这个小艾同学的这个朋友也讲了
就是评测肯定是
无论是模型的研发还是应用的研发都要先提前去做的
但这里边是说如何去构建一个满足自己预期的一个评测体系
这个其实每家的业务属性或者是场景不一样
比如说像千问像这个拉玛像英特尔这种做通用大模型的
他其实更关心的是通用能力
那在这个角度大家可能会面临很多基础的问题的
这样当这些评测和构建
然后但对于行业来讲其实是需要有一些快速的把行业知识能够高效的转换成行业评测集的这样一些方法论或者工具的
对这块其实整个的在学术界包括工业界的实践可能都不是很多
对大家其实还是一些比较handcraft手工的去构造一些场景的评测集
对但其实如果后边想让大模型进到更多的业务或者是更多的行业里边
就会有一定的支持比如说我们能不能构建一些agent的工作流
这个agent的工作流能够帮助我去把一些垂域的评测集自动化的快速的构建一个高精度的这样的一个评测集出来
然后来指挥我下游的应用的研发
对这是这是第一个点
第二个点就是说对于整个模型的刷榜或者是能力的一个准确的评估
这里边大家现在评模型的这样一个逻辑其实
是一个
这种折中吧就是大家现在只能通过一些benchmark的分数来去对模型能力有一个更好的表达
对那因为通过这种像像arena像人工的这种评价
它可能各种各样的随机性的因素都会很难有一个特别公允的一个判断
对大家也也也会去说ok这个这个产品或者这个大模型的用户量调用量这个业务量
这是一方面的指标
但对于比如说做模型研发的角度来讲
确实是需要
这些客观的评测集或者是一些榜单来去push大家往前走
那这里边我觉得榜单它其实很多时候是保一个模型的下限
就是你在这个榜单上的成绩不能太差
太差的话就意味着你的基础能力不达标
那很多的应用你可能做不好
对但就是大家也不能陷入一种怪圈
就是我为了让这个榜上的成绩我排到第一名第二名
我就想尽各种奇奇怪怪的操作
对这个其实也不是我们作为评测的研究机构
希望
给大家一个良性的一个反馈
然后这个一个公允的一个评价
那包括说对于能力的更细度的分析
然后至于刷榜这件事情
我们其实过去一段时间也遇到了就有一些模型的机构
其实他们可能通过一些各种手段去去去想试图去刷榜
对这个其实就跟那个安全对抗是一样的
就是在评测上面有一种能力的对抗
就评测体系会不断的演化
然后我们会有一些新的评测机构
然后我们会有一些新的评测机构
比如说学术界每天都有新的论文
这些新的论文可能都会构造一些新的高质量的评测机
同时我们作为研究机构
我们也在研究一些自动化的评测的一些算法
比如说抓取最新的新闻
最新的学术论文
然后去把它构建成评测机
一些这种大模型可能还没有训练到的语料
对但是其实也是蛮大的挑战的
因为对于我相信很多的这种大厂来讲
大家蓄模型
就是每天海量的数据
都会回来
对然后这是两个点
然后最后还有就是刚才提到的
这个多模态的问题
就是多模态的评测
其实可能现在还是属于一个
相对大模型来讲初期的一个状态
大家还是在关心一些榜单指标的这样一个阶段
对不像大圆模型已经到了产品应用
或者是用户体验的这样一些提升上
我觉得这个可能需要学术界和产业界一起来去推进
就包括像miniCPM这种性能很强的模型
对我们其实也是希望后边对于多模态模型来讲
除了在客观指标上面
就是这种任务型的指标上能够体现出的优势
也能在日常的这种人的自然对话的场景下面能够体现的更好
对那我觉得主要是这几个点
谢谢
好谢谢
然后其实大模型的整个发展
我们会看到有两个主流的方向
一个是开发者生态
还有一个是产业应用
那我们今天也听到了
就是面壁在这个端册上面的这样的一个大模型的
这样的一个大模型的发展
这样的一个工作
那我们也想今天问一下吴映
就是吴映在这样的一个大模型时代
怎么样通过云端结合的这样一个方式
来推动这样的一个大模型在产业场景的落地
那我们来问一下光昭
谢谢孙子
其实这是一个很有趣的问题
坦白说之前也困扰了吴映一段时间
因为众所周知
就是包括这场论坛和我们刚才讨论的端册
作为一个集数据用户
用户的行为
用户的交互和用户的应用
这四大主要因素为一体的一个平台
实际上是拥抱AI和结合AI非常好的一个点
那我们也看到了无论是从英特尔和AMD的NPU也好
还有说端册小模型也好
还是说呢是产业化以后的AIPC
AI手机等等
其实呢
我觉得都是业界炙手可热的一个趋势
那作为一个云端业界的一个模型
关于一体的云电脑或者云手机的吴映这样的一个产品呢
我也分享一下我们的Chain of Thought
因为我是本场应该是唯一的产品经理
那那个首先呢
我们分析我们分析了用户呢
在无影场景中呢
他可能会用到AI的两个主流的大的场景
那第一个场景的是生产力场景
那他可以细分为两个子场景
一个是生产力的体效场景
那那个可能包括了现在
很多的Copilot或者是Agent
所做的文字的优化处理
表格的优化处理
翻译等等这样的一些场景
那第二块呢是提升
提升管理效率的一些场景
这个子场景呢
比如说是远程的智能化运维
智能化的故障检测等等
这是2B的
我们认为生产力场景的这一块
第二块是个人和娱乐场景
那他又能分为两个子场景
第一个场景呢
第一个子场景呢
实际上是降低用户对多安侧设备的影响
实际上是降低用户对多安侧设备的影响
实际上是降低用户对多安侧设备的影响
那这里其实刚才小艾的那个分享也说了
比如说语音的控制
语音的用户行为
自然语言的操作等等
那那个也包括快速的设备的使用问答
那第二块呢是提升用户的使用趣味性
增加用户的粘性
包括比如说个人的知识库
微软前段时间发布的Recall
那也包括了像纹身图等等这样的能力
智能分身的能力
那这是我们认为的
无影呢我们需要覆盖的两大类的场景
那基于这两大类的场景呢
实际上我们也看到了业界
主流的两种解决方案
第一种解决方案呢
是纯云端的SaaS解决方案
那刚才其实联想的同事也分享了
纯SaaS解决方案呢
它在模型的迭代速度
模型的选择
模型的质量上呢
其实是有本身固然的优势的
但是呢它在实验
在端云的数据流转
然后在模型的选择
在个人隐私方面其实是有一定的弊端
那同时呢它在应用
应用跨应用的结合
这上面呢因为它没有深入系统层
所以很难做到跨应用的一个结合
那第二块呢
第二种业界的方向呢是
本地的小模型
类似于AIPC
那这个呢其实在实验
在推理速度等等方面呢
是有一定的优势
包括数据的安全性
但是呢在模型的迭代
在模型的性能
然后对于
对端测性能的要求
对端测性能的消耗等等
实际上它们的不足也是
显而易见的
所以无影呢就从这一块呢
我们就想到我们无影有什么优势
或者我们能在云端一体的
这一块和AI结合
能做出点什么不一样的东西
那我们就想到了三个点
第一个点呢
我总结成两个
就是整个叫系统级和应用感知
那它细分为三个点
第一个点呢实际上是
云端一体是一个端一体的产品
所以我们深入了系统层
我们可以去跨应用
端云一体的去
控制云电脑或者云手机的各种行为
这是第一个优势
那第二个优势呢
是我们有协议
那协议呢我可以做到对用户行为
真实行为的实时感知
比如说它开了
它开了优酷
那至于优酷里面是什么样的内容
我其实都是实时感知的
同时因为我对
就是用户的交互流程
IO
就是输入和输出
应该是实时处理的
所以我其实是对用户的交互行为
是密切能够识别和感知
这时候我可以
帮助用户去做很多交互的动作
那第三呢是云端一体
因为它是一个云原生的形态
所以我们其实不依赖于本地的算力
那我们在整体的算力
无论是对类层的消耗
对存储资源的消耗
对算力消耗
我可以为用户单独在云端开一个资源去承接
所以对用户来说
它其实是算力无感的
叫消耗负载无感
同时呢
它对模型的调应
因为是存云端的
所以它的实时性会非常的高
这是我们的三个优势吧
那至于这三个优势呢
其实我们打造了一款AP
应用叫小影
那这款小影呢
除了刚才很多同学分享的
生产力场景 知识库场景
聊天场景以外呢
我们其实还有四个稍微不一样的
能力
第一个能力呢
是类似于微软的recall能力
我们其实也做了个人用户的
快速的历史行为的回溯
以及快速的搜索
而且这个呢
不占用任何它电脑的资源和存储空间
我在云端单独给它开了一个
空间
那这是第一个
第二个呢我们还实现了
快应用的业务流程处理
那可以帮助用户很快速的
快应用的完成很多繁琐的操作
举个例子
比如说报销
比如说提报
最近大学刚高考嘛
提报我大学的各种资料
它可以资助的帮助用户去
提交这样的能力
第三呢就是我们其实实现了
端音协同的管理
实际的行为
我可以在管控台上实时的进行智能化的
检测
帮助用户和管理员提供
非常快捷的解决方案
最后呢
实际上来说呢
那个
因为我们
我们克服了端测的这个
就是性能的开销
所以我们其实做到了在任何端上
它其实都是同样的体验
就没有兼容性的这样的问题
这是我们对产业化
在大萌新这个浪潮中的一些思考
最后呢
其实从无影角度来说
我们未来会做好两个开放
第一个开放是把无影
刚才我说的三个
无论是在GuestOS系统级精神上
还是在协议上
还是在云测的弹性上
这三个能力开放给合作伙伴
让合作伙伴更好地基于我们这些能力
在无影上打造AI的生态
第二块呢
就是让用户自己开放出来
它里面的我们会有AI的
各种工具的市场
让用户自己去选择
大概就是这样
好的好的
那我们也特别期待像无影这样的
云原生云端一体的这样的一些产品
借助于大模型这个时代
可以大大的提高用户的效率
然后在很多的娱乐场景中
也可以提高用户的体验
但其实在过去的一年的时间里面
我们能看到非常多的一些创新的idea
和更新的一些想法
其实是来自于开源社区
那我们也想问一下那个周文猛
就是说
在过去的这样一个时间里面
然后怎么样通过开源社区
和大模型的结合
然后通过开源的工具
然后来提升整个开发者的体验
和提升对大模型的易用性
这个你是怎么想的
对 就是
摩大社区其实去年一整年
都围绕着LM和AIGC
这样的两个核心技术
再去不断地提供给
社区的开发者们
不管是大模型的推理
微调或者评测
这样的一系列的工具链
让大家能够更好地把
模型给它用起来
那我觉得就是我们从用户的角度
去考虑用户最多的需求
是什么
然后我们重点去投入什么
这样的思路来去做
那其实在现今的阶段
应该是80%到90%的用户需求
其实是直接调用模型
不管是local的调用模型
或者说远程的调用模型的API
然后通过prompt engineering的方式
来去完成一些业务上的事情
那因此来说我们第一步做的
其实是联合
开源已有的这些
推理引擎 包括像VM
Lama CPP 包括像Olama
这样的一系列的工具
让用户可以方便地把
模型用起来 那第二步
其实在一些锤类的场景
用户可能需要自己的
数据去做模型的反tuning
去做模型的评测 最后再去
做模型的上限 那围绕着这个
我们其实来去做了一些
非常简化易用的
评测和训练的工具链
方便用户在锤类的场景
去使用
另外还有一个在应用的场景
刚刚漏题的
就是RAG的场景
RAG的场景其实
现在也是非常主流的一个场景
那在这个场景我们其实是通过
联合像Lama CPP
Lama的index或者说Lanechain里边的
这样的retrieval的模块
让用户方便的把RAG的链路搭起来
当然在
开源设计和生产上可能会有一些
不一样 就是生产上面可能会
需要更多生产级别的
RAG链路的高并发的支持
那这个我们也是通过联合阿里云的
云平台白链
大模型开发平台上面去提供
更扩展的RAG的能力
来去方便
企业级的用户去使用
主要是这些 谢谢
好的 好的 那我们今天的
圆桌就到这里 谢谢大家
谢谢
好的 谢谢各位嘉宾
请大家就坐
嘉宾今天的分享和探讨
让我们从不同维度
对大模型开源生态
有了更多的认识和思考
那么今天我们的主题论坛
到此也告一段落
感谢大家的到来
我们也为大家准备了一些小礼品
券领取 也欢迎大家
前往场馆阿里巴巴展区
进一步了解阿里云
在AI领域的先进技术
和最新实践 谢谢大家
谢谢大家
谢谢大家