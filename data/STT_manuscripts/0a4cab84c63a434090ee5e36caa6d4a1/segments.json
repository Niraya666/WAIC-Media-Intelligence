[
    "中文字幕志愿者 李宗盛欢迎的各位来宾欢迎来到2024世界人工智能大会阿里云MARS加速大模型应用落地主题论坛活动将于五分钟后正式开始为了确保活动的顺利进行和良好的现场体验请您尽快入座并将手机调为振动或静音模式感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合感谢您的配合尊敬的各位来宾尊敬的各位来宾本次会议即将开始请您尽快就座并将手机等通讯设备关闭或置于静音状态谢谢您的合作Ladies and gentlemenThe event will begin shortlyCan we please ask for you to kindly take your seatsWe would like to remind you againTo switch off all mobile phonesTo switch off all mobile phonesAnd put electronic devices to silent modeAnd put electronic devices to silent mode谢谢您的协调",
    "加速大模型应用落地主题论坛的现场我是本次大会的主持人朱荣现如今人工智能一直是社会各界关注的焦点话题越来越多的人们开始谈论AI谈论大模型以及AIGC所带来的变革随着科技和产业革命的不断推进AI大模型的应用越来越广泛不仅推动了企业效率的显著提升还催生了很多新的商业模式和创新业务AI正成为引领时代发展的重要引擎推动着社会向更加智能化数字化的方向迈进今天我们很荣幸地邀请到了产学研各界嘉宾共聚一堂一起深度探讨大模型的前沿技术开发经验以及最新的应用落地让我们带着这些期待共同开启今天的AI大模型之旅首先让我们掌声有请上海市经济和信息化委员会副主任汤文侃先生为本次论坛做开场致辞",
    "有请尊敬的各位来宾女士们 先生们大家上午好非常高兴与大家相聚在此共同参加由阿里云主办的MARS加速大模型应用落地的主题论坛首先我仅代表上海经讯委对各位嘉宾的到来以及我们线上云参与的各位朋友表示诚挚的欢迎也向长期以来支持和关心上海经济和信息化委员会的上海人工智能产业发展的社会各界同仁表示衷心的感谢当今的大模型技术创新体系在加速演进正进入行业全面的应用商业路径逐步形成的新阶段国际竞争日益激烈基础模型参数以性能纪录屡屡创新随着模型在新兴领域的应用遍地开花诸多现象性应用拓运而出甚至部分场景已经能够细致的模拟现实世界的微妙这也预示着通用人工智能的黄金时代已近在咫尺面对大模型时代的挑战上海在抢抓新一代人工智能的发展机遇以人工智能驱动形成新制生产力加快打造世界级的产业机器我们突出的表现在三个方面首先是大模型的龙头企业不断的急剧目前上海全市已经有三十四款大模型已通过了备案产生了制造业金融等锤类领域的应用全国首个大模型创新生态市区魔术空间也吸引了将近八十多家的企业在这里急剧已经形成了算力调度开放数据评测服务金融服务综合服务等全方位的创新创业的保障体系第二的是在自主可控的自算生态上不断升级我们着力突破卡脖子的环节已经有数十款多技术路线的智能芯片以及流片量产上海人工智能实验室也建立了DeepLink软硬件的试配方案尤其欣喜的是上海已建成了规模化的自算中心为大模型的训练提供强有力的支撑第三的是钥匙资源能不断地提升我们大模型语调数据联盟持续为模型训练提供了生产资料上海已经开源了四千万的四千二百亿Token的语调数据以市场化机制为大模型企业提供专业的服务面向未来上海将进一步地系统推进人工智能赋能经济发展我们要着力做好三项工作首先的是要夯实产业的技术底座要推进基于国产自算芯片的公关促进大模型训练框架和国产芯片的适配我们要推动基础大模型训练迭代探索AI自算体的新产品新模式我们要组织语调公司要打造专业的运营平台抓紧形成市场化的语调产品其次呢要加速人工智能的落地和应用要持续地做大做强模式空间要推动上海大模型企业要打造制造金融和政务等领域里的市场应用要加快技术规模化的落地最后呢要培育开源的活跃生态要鼓励各位开源的社会组织优秀人才创新项目要露出上海进一步促使开源技术产业化要营造活跃的产业生态各位来宾今天的论坛搭建了人工智能大模型领域里的交流对话平台我们来自于头部企业科研机构垂内应用场景的用户各个领域里的专家大家齐聚一堂我们非常期待各位能够激荡创新智慧砥砺科研思维发表深刻的洞见上台创新观点我们也非常地希望我们阿里能够发挥大模型的创新优势与上海丰富的应用场景能够深度融合加强合作加快形成产业化的成果共创人工智能的美好未来最后也希望这次的论坛取得成功谢谢大家",
    "感谢汤主任的精彩致辞接下来将进入今天的演讲环节首先有请我们的首位演讲嘉宾阿里云首席技术官周靖仁先生周靖仁先生作为阿里云的技术领军人物长期致力于推动AI技术的前沿发展和应用创新也是国内最早提出MaaS模型及服务概念的谦虚者在今天的演讲中他将围绕通一大模型能力阿里云白链等深入探讨阿里云在MaaS体系内的最新进展与思考让我们欢迎周靖仁先生带来阿里云让AI创新触手可及的主题演讲",
    "掌声有请大家早上好非常高兴又再次跟大家见面能够去跟大家同步一下我们阿里云在MaaS服务包括今天AI模型应用各方面的一个进展今天在我们AI引领的这次技术变革中间我们可以看到所有的技术的发展是在突飞猛进的速度创新日新可以说是日新月异随着今天我们大模型的广泛的进展和进展的进展一个研发的一个突破今天我们也看到产业界的应用也在快速地迭代起来今天基于大模型能够延展到各行各业应用在各行各业的例子也今天可以说是日新月异越来越多在这个时代里面我们认为了模型及服务这个概念就更加的重要就真正我们要做到以模型为中心去延展今天我们所有的技术体系也延展到业务的推进我们在两年前首次提出了Model as a Service这样一个概念我们也非常欣喜地看到在短短的过去的一段时间整个这个概念得到全行业的一个认可今天Model as a Service已经成为了今天我们云上服务包括AI领域发展的一个重要的技术的方面谈到Model as a Service其实这中间涉及到了很多层次的概念包括底层的云计算的一系列的支持对AI的支持也涉及到今天我们模型本身生态模型的发展模型的方方面面以及今天在整个生态开发者的环境里面的一个演进最终模型还涉及到如何去应用在各自的业务场景里面今天如何能够把模型更好地适配在业务场景里面也是成为了今天Model as a Service的一个重要的环节今天我们就围绕着Model as a Service跟大家同步我们阿里云在这方面的一系列的进展首先我们会谈到模型这一层大家可以看到在过去一年里面我们整个大模型的领域应该说是发展得非常的迅猛包括我们整个阿里云推出的通议签问的系列包括通议模型的其他的方方面面都在有快速的一个发展我们可以从去年我们正式4月份提出发表通议签问到后来我们的万象包括后来我们听悟所有的这些模型的发布我们整个阿里云在模型的创新这方面在持续地发力大家也可以看到整个模型的能力也越来越强也非常感谢大家特别我们的开发特别的企业对我们的支持今天我们都有上亿的每次的调用量也包括了今天在特别是模型的开源模型方面我们已经有2000多万的模型的下载量除了今天我们在做模型的研发去提升模型的方方面面的能力之外很重要的一个环节就今天我们会坚持开源的策略真正我们希望能够把模型的能力能够带给我们的开发者带给我们的企业能够降低今天模型使用的门槛只有这样我们认为我们才能真正的去促进今天AI整个产业的一个发展整个行业的一个变革能够真正的让我们的AI的开发的门槛进一步的降低能够带动整个产业界的发展过去阿里云一直是坚持在开源的这条战略上面我们也是全球几乎说是唯一一家继做模型的研发也同时开源我们的所有的系列的模型今天借助我们云的相关面的技术的支持结合我们开源模型的矩阵我们真正的把AI的能力赋能给我们的开发者赋能给我们的企业在过去的一年里面我们整个通易的开源模型家族已经形成了一个矩阵涉及到今天的各种的尺寸也涉及到了各种的模态而且我们在开源领域里还是在不断的去突破不断的去发展尤其是我们在几周之前发布的Coin2就是我们新一代的这样一个开源的模型整个的模型的发布在短短的几周里面也得到了业界非常好的一个反馈包括在海外的Hugging Face今天已经把Coin2认为是我们全球范围里面最强的开源模型也在很多的海外的榜单也在居于榜首同时在中文的领域我们也有很多的评测像Compass Arena也是把通易签文的这样开源一个模型也是排在了第一位整体我们这一代的开源模型不单单是在很多的评测指标上面有大幅度的提升超过了很多必然的模型而且是在全球是属于非洲的模型非常领先的地位同时我们也在代码在今天推理在今天逻辑思考这方面有大幅度的一个能力的提升整个这个模型从发布到现在受到了我们的开发者受到我们的企业的广泛的关注这也是非常希望能够跟大家继续去推进今天模型在各个方面的一系列的应用除了今天我们这样一个通一签问的模型的发布我们还积极地去推动今天这个通一灵码通一灵码是基于我们通一签问模型之上的面向于编程的这样一个助手在昨天晚上通一灵码也获得了本次大会的政店之宝的奖也是对我们这个项目有一个重大的肯定今天我们会结合今天基础语言模型的能力针对代码的补全针对代码的理解代码的问答我们在开发流程中的每一个环节能够帮助到我们的开发者同时我们整个通一灵码也集成到了各种各样的开发的框架里面包括各种的IDE能够让我们的开发者能够快速地使用我们也非常欣喜地看到在过去通一灵码有快速的发展今天已经成为了国内用户规模最全面的一个产品我们在过去的一段时间已经有超过350万的这样一个下载量而且每天推荐都是在几千万次的这样一个量级我们也得到了很多开发者积极的一个反馈除了今天面向开发者我们也更多地把通一灵码推给了我们的企业也就是说今天在企业的环境里面往往有自己的一系列的代码有自己的一系列的数据安全的考虑这个时候我们一方面能够在绝对的安全的情况下去帮助企业去梳理自身的代码同时也可以把通一灵码智能化的能力跟本地的代码库结合在一起让我们的模型更加懂得本地的包括开发的逻辑包括编程的习惯能够更加精准地去推送跟针对企业特殊场景的这样一个代码助手的功能整个通一灵码的企业版从推出到现在也受到了很多企业的关注包括我们的一七哈罗还有中华财险等等都在积极地使用我们这样一款企业的产品服务另外我们在通一的APP里面也是在不断地迭代不断地发展今天通一APP已经成为了一个全能的AI助手不管是今天在我们的手机上去做任何的知识的问答或者说今天一些常规的搜索包括今天文件的处理还是在我们的PC端能够去做详细的一些工作学习的规划等等那它也集成了今天像我们听悟像我们今天万象的各方面的一个能力那真正意义上成为了今天我们日常工作学习生活的全能的AI助手也希望大家有这个有时间的话线下可以去下载通一的APP去体验今天通一模型的方方面面那刚才我们讲到了整个通一模型的持续的开源那另外一个方面我们也是积极地在运作AI的社区那这里也跟大家汇报一下摩大社区也是感谢大家的关爱也是在快速地一直从快速地茁壮地在发展那到了今天我们的整个的数据各个方面又有大幅度的提升那今天我们已经设计了全国560万的这样一个开发者也承载了今天我们整个中国境内甚至海外重要的一系列的模型那值得一提的是这个摩大这个项目也是受到了大家开发者的积极的一些共同的开发那这次也是非常有幸地获得了今天我们CL之星的这样一个奖那讲完了这样一个模型层当我们模型真正要应用到各行各业还需要今天对行业进行一个特别的特殊的一个适配那在这个环节里面如何能够把模型的能力释放出来同时又去理解各行各业的这个需求这是今天我们要解决的一个重要的一个技术方面那我们过去呢这个推出了阿里云的百链产品那百链这个名字呢就取之于今天千锤百链那我们希望呢借助今天我们云的能力借助模型的能力能够再结合今天我们企业的专属的这个信息能够更好的去适配相关的这个模型应用那百链呢首先我们集成了所有的这样一个模型的生态那不光是中间有我们刚才讲到的通益本身的模型家族也包括了今天开源的所有的模型还有呢这个其他的模型公司呢也积极参与在里面那我们希望呢给我们的开发者给我们的企业呢提供全方位的一个选择他们可以根据自己的需求去选择适合于适合于这个自己包括这个适合于自己的模型的类型以及模型的尺寸能够更好的去权衡今天业务效果以及这个这个推理成本各个方面的一个综合的考虑那另外呢我们在过去也是不断的能够降本能够让我们的这个大模型使用的成本的进步的降低那过去呢我们一直在不断的去提升整个云的这样一个推理的这样一个架构那一方面呢可以提醒能够有更好的各种的算力能够汇聚在一起能够提高更极致的一个性能那我们在过去的几个月里我们整个推理的这个整个的价格呢也在大幅度的去下降那我们最终的这个初衷的是希望今天那我们大模型的那每位开发者每位企业都能够使用而且都能一个高性价比的方式去使用那我们也非常欣喜的看到在过去一段时间短短的一个月左右我们整个整个这个模型使用的这个体量应该说是一个成倍的在增加那我们也非常欢心看到今天各行各业都来尝试今天把人工智能的能力融合在自己的业务体系里面来当然我们有了这个模型的所有的这个一个丰富的这个提供有了今天这个非常强有力的推理的架构那还需要今天有基于模型为中心的这样一个开发的环境那中间一方面带领的是今天我们模型的调用能够让大家非常简单的方式以API的方式去试使用模型那更重要的是我们也需要有一个流程能够帮助今天我们的企业我们的开发者进行模型的定制那在过去呢我们百链就是在去解决这样一个业务的一个需求那今天呢我也是非常高兴的跟大家同步我们的进展百链到正式的发布到现在也就短短的几个月的这个时间那我们今天服务的客户呢也是在大幅度的增加现在已经超过了20万那具体到今天为了帮助我们的业务场景去做业务的适配需要做哪些环境呢那首先那使用模型的时候就我们第一步会提到的是prompting一个engineering也就是说prompt的一些定制和优化那一方面呢我们会根据各行各业的场景去提用一个prompt的模板也就是说真正能够让我们的企业能够快速的进行选择相关的模板能够去选择它适合于自己业务的这样一个场景能够很快速的去上手那同时我们也理解今天真正的prompting engineering这也是一个非常繁琐的事情那我们希望呢今天通过我们通译模型的方方面面的这个能力呢能够帮助大家去简化prompting engineering也就是说今天真正用metaprompting的这种方式能够今天让企业呢能够描述自己的需求能够让模型自动的去帮助做prompting engineeringprompting的优化能够提升今天业务的效果那另外呢我们还涉及到今天如何把企业的知识企业的信息跟模型融合在一起那这首先就需要解决一个数据安全的问题那同时也要去解决今天能够如何让模型去有一些增强的知识的学习的方方面面那这是我们摆练的一个重要的一个发展的一个技术的方向那首先呢我们会支持各种各样的一个RAC的框架特别是今天我们非常流行的在各种的开源的框架能够让我们的快速的这个开发者快速的上手能够今天有一个安全的数据域能够让我们的企业能够把自己的数据进行一个分享能够让模型去学习但同时呢这部分的数据呢并没有出我们客户的这样一个专属的域也能保证这个极致的数据的安全那与此同时呢我们简化了各种的流程今天不管是用任何的一个框架包括今天各种的RAC的体系简简单单的几行就能够快速的把本身企业的知识或者说专属的一些信息跟模型的能力融合在一起那与此同时呢我们也提供一个个人的信息一个高效的低延迟高并发的这样一个特殊的RAC一方面能够在整个数据处理上面能够进一步的降低大家开发的这样一个复杂度那同时呢在效果的这个方面在算法的优化方面能够更加自动的去调优那这些都是为今天我们企业能够真正的把自己的行业的知识融合大模型提供了一个坚实的基础那所有的这些方方面面呢不管是从prompting还是说今天使用各种的插件还是说今天我们越来越多的增加了一些功能像memory等等其实都是相对来说比较繁琐当然今天虽然我们有工具在进一步的简化各种环节之间的整个的开发的这个复杂度但我们希望呢能够有system API的方式能够把相关的这个编排把这个编排的方式把这个插件的工具的管理等等的能够整合在一起那通过这个system API呢我们一方面可以使用各种各样的一个插件那同时呢也可以今天把我们前面讲的prompt engineering的工作把我们的memory的管理也能够有效的编排在一起能极度的去简化今天各种应用的一系列的这个开发能够把这个流程呢更加的提供一个一站式的一个体验那最后呢我们也认识就今天除了今天模型的这个包括刚刚讲到的RAG或者说这个prompt engineering那有一些特殊的场景呢还需要进行模型还要进行再训练还要进行一些微调那这个时候呢我们会提供完整的这样一套工具不光从这个数据的这个提供从今天整个模型微调架构的支持以及到今天评审这个模型的提供这个各种评测的工具能够帮助我们的开发者能够有效的去评价今天开发出来的这个模型微调后的模型在各个维度之间的这个表现那这些呢都能够快速的帮助我们的开发者去更好的去基于我们的这个摆链的模型的底座能够在上面进行二次的开发能够去在上面进行更有效的一个评价这对我们今天业务的落地起到了一个极大的推动的作用那上面讲到的这些方方面面呢是我们摆链的这个很多个技术环节中间的一环那我们也是希望大家有兴趣的话能够在会后啊能够再到阿里云的官网上面去体验去使用去真正的去利用摆链去做各种模型的定制那我们最近呢我们也看到很多的这个企业呢这个也是在海外进行这个业务的拓展那这里呢我们也很高兴的跟大家同步我们摆链这个产品呢也会今天部署在我们的海外为我们的企业的提供全方位的支持那在海外呢我们这个模型这个产品叫Model Studio那今天也会在这个国际性的这样一个全球化的在我们阿里云的基础设施的这个布局上面为大家提供全面的这样一个模型的支持和模型的服务让大家真正在出海的过程中间能够高枕无忧那上面呢我是通过这次短短的这个20分钟能够跟大家汇报了今天我们阿里云在今天在Mars方面的各个方面的一个进展从今天开源模型的这个快速的发展和开源模型的这个最新版本的推出到今天我们的摩达到我们今天整个摆链产品能够帮助今天进行产业界的落地那我们认为呢今天在这个时代里面我们只能够在这个时代里面呢我们只有真正的做到今天AI和云的一个高度的协同能够今天一方面支持好模型的发展模型的这个研发那更重要的是今天基于模型能够帮助我们各行各业去更以低门槛的方式去使用去结合自己的场景的知识去解决真实的业务的场景那只有这样呢我们才能推动整个AI产业的这个发展那我们也是非常期待跟我们的企业跟我们的开发者一同去做这些的发展去加速大模型应用的产业落地谢谢大家",
    "再次感谢周静仁先生的精彩演讲也期待白链和摩达社区为大模型生态贡献更多的力量那么在芯片的发展过程中呢有一个著名的法则叫做摩尔定律摩尔定律指出每隔大约18至24个月单位面积上的晶体管数量将翻一倍使得芯片的性能大幅提升成本则相对降低这一规律在过去的几十年间深刻影响了半导体行业也驱动了计算机技术的快速迭代和性能飞跃和摩尔定律类似大模型也遵循着类似规律接下来有请清华大学计算机系常聘副教授面壁智能首席科学家刘志远先生带来演讲大模型时代的摩尔定律迈入更高效的大模型时代掌声欢迎好大家上午好非常荣幸有这样的一个机会然后来在这个场合跟大家分享我们在大模型这个领域然后所进行的探索思考已经对未来的研判那么我们是希望能够跟大家分享我们所认为的大模型未来发展的这么多的东西那么应该说面壁智能可能是大家还不是特别的熟悉但是相信呢我们在过去的一年我们努力发布的一系列的端侧的这些大模型可能大家已经耳熟能详包括miniCPM的机座模型包括miniCPM-V的这个多模态的这个模型那么这些模型的一个最大的特点就是它们能够在我们的端侧我们的计算机然后我们的手机等等的这么一些端侧的设备上然后来能够运行那么我们为什么会在过去的一年的时间里面然后会去选择去卷这个端侧大模型那么今天我们就想跟大家分享我们的这么一个相关的思考那我们会认为所有的这些端侧模型它的背后其实是有一个更加挑战的这么一个问题也就是说如何在一个端侧更加有限的算力内存还有能耗的这么一个情况下我们要极致地把这个知识能够浓缩到一个更小的参数规模里面那么整个的这个过程呢其实需要我们来对大模型它的这个建设然后进行一个更加科学化的道路的这么一个探索那么在这个方面我们的一个努力就是构造了一个模型的沙盒那也就是说我真正地去训练一个模型之前我会在这个沙盒里面去做成千上百次的演练我会在很多的小模型上然后高效地去寻找最优的数据最优的超参的配置并且能够让它成功地外推到大模型上真正地寻找到这个大模型上的这么一个最优的配置那么这个其实相当于寻找到了这个大模型的一个成长的规律那么通过这一点我们可以去找到一个更高的知识密度从而带来一个更加高效的模型所以看到用途可以看我们在2024年2月份发布的Mini-CPM的第一个版本2.4B的模型24亿参数实际上是在当时已经能够超过像Mixtral 7BLama 2 13B等几倍于这个参数规模的一些模型的能力那么这个的话呢就是体现了我们大模型科学化的这么一个非常重要的这么一个价值所以我们会认为呢在这样的一个科学化的历程里面正如刚才的主持人所提到的我们会看到过去的这80多年的时间我们见证了在芯片的这个领域那么由于芯片制程的这么一个不断的增强带来了终端算力的这么一个持续的提升我们会看到了这么一个算力的小型化我们在我们的手机上然后就可以拥有几十年前用几间屋子才能装得下的这么一个机器所具备的算力那么同时我们其实也会看到大模型的科学化的领域将会不断地提升我们模型的制程而模型的制程将会带来模型知识密度的持续的增强而这两者的交汇将会揭示端测智能的一个非常巨大的潜力所以可以看到右图我们的这个红色的这么一个虚线代表的是过去一个多模态模型从GP4V的一个数百亿参数的规模到我们今年的五月份发布的miniCPM-V2.5这么一个模型只用8B左右的参数然后就可以完成相关的能力也是体现了多模态领域的这么一个知识持续增强的这么一个过程那么同时的话呢我们会看到从下方的这么一个蓝色的这么一个虚线那么它体现的是在端测的算力的持续增强下我们可以在端测上可以放得下一个更大的更强的这么一个大模型那么这两个曲线的这么一个交汇我们会看到面向未来我们有可能在半年到一年内我们可以把GP3.5水平的模型能力放到端测上去运行而在未来的两年内我们可以把GP4O的相关的能力放到端测上去运行而这一点的话呢具有非常重要的这么一个价值所以从这点上来讲的话呢我们会认为大模型时代将会拥有它自己的一个摩尔定律这个摩尔定律其实就是知识密度的持续增强我们去回顾摩尔定律它在1965年提出的时候它所提出的思路就是芯片上的电路密度每20就是每两年后来是修正成了18个月能够提升一倍那我们可以想象对于大模型来讲OPI其实已经验证的是规模法则也就是在过去的五年我们会看到大模型规模越大那它的能力越强但是我们难道是要持续的无限制的把这个模型越新越大吗在我们来看大模型的大不是这个本质大模型它的知识密度它的制程才是这个大模型的更加本质的东西所以呢我们在过去的这五年里面其实是见证了一个在2020年6月份OPI发布的GP3的水平的能力我们现在在2024年的2月份我们的miniCPM2.4B它就能够达到这个水平了它能够达到相同的水平所以呢模型的知识密度大致呈现每八个月提升一倍的这么一个规律那我们未来一个非常重要的使命就是能够让这个规律持续下去那么这件事情本身是需要我们能够在数据在模型的架构然后在相关的成长的算法这个方面不断地去探索它的这种科学化的这么一个道路那么从而极致地去提升这个模型的制程所以呢我们会认为未来高效大模型的第一性原理它的关键词应该是知识密度那什么是知识密度呢我们会认为大致应该是对应第一就是它的能力而这个能力所依托的这个参数的规模它们每一次的这个计算所需要参与的这个参数也就是对应的它的能力的消耗那么从这一点上来讲一个知识密度越强的模型就意味着它的能力越强它的每一次计算所需要的参数规模越小那么对应的其实就是这两个要素所组成的这么一个知识密度的概念而我们会看到大模型它的这种数据驱动的技术方向大致已经确定但是呢模型的架构算法数据这些相关的技术方案仍然在高速地迭代所以我们接下来非常重要的使命就是要持续地改进模型的制程持续地去高速地迭代这些相关的这种技术方案然后来去极致地提升这个模型的知识密度这个应该会成为我们接下来各大模型团队然后努力的方向那么从这个方面那么今天我们说我们既然努力的方向是知识密度那我们今天就要给大家带来我们最新的一个进展当然这个进展一如既往我们不去卷运测的这个大模型我们想给大家带来的是一个更加极致地提升这个模型知识密度的这么一个努力那么今天就要给大家带来的是一个叫MiniCPM-S那么这么一个版本那么这个版本呢我们现在推出的是一个1.2B的模型那么它是一个新一代的高效的大模型的架构那么目前的话呢它的论文它的相关的这个模型的参数然后都已经公开可以访问包括刚才金人总然后提到的摩大社区我们也都已经公开那么这个架构它体现在哪几个方面呢首先它是一个高效的稀疏的这么一个架构那么从而能够带来在端测的一个更低的能耗那么它能够达到88%左右的这么一个稀疏度从而能够让我们的这个全连接层然后它的这个能耗要降低84%那么同时它就会带来一个更加极致的一个快速的一个推理的能力能够比相对应的这个稠密的模型它的推理速度能够提高接近三倍那么同时它是一个没有性能损失的这么一个模型然后它能够在我们的这个性能不变的情况下能让它变得稀疏化那么从而对应让它的这个知识密度能够持续的可以增强下去那么实际上这个就是我们现在所看到的一个稀疏的模型和一个稠密的模型在相同的水平下然后它能够达到的一个更快的这么一个推理的速度而这一点的话呢也要非常感谢上海交大团队所推出的PowerInfo的这么一个推理的框架那么同时这么一个模型的架构其实是体现了我们在刚才所提到的三大要素也就是架构 算法和数据三个方面里面的模型在某一个方面就是架构这个方面的这么一个提升那么实际上我们会看到它其实是向人脑学习我们人脑是一个非常典型的功能分区的稀疏激活的这么一个大脑的这么一个结构那么它从而能够带来单次的推理能耗和反应速度都能够非常非常的强那么对应的我们的miniCPM-S它的这个架构实际上就是极致的吸取了这么一个稀疏的这么一个思想那么首先它回归到了ReLU这样的一个激活函数从中让这个模型呢能够自发的涌现出一个更强的稀疏激活的这么一个机制那么从而带来一个渐进式的稀疏感知的这么一个训练的能力也就是在整个的这个训练过程中这个模型会自发的变得越来越稀疏那么从而在这个稀疏的过程中我们还有能力去保证它的这个训练的效果不会受到损失那么正是在这样的一个架构里面在这个架构的情况下那么我们会看到miniCPM-S它将会对我们大模型的知识密度的这个持续增强其实是带来一个强行剂那么这个强行剂其实可以看到它会在过去的这么一个曲线之上然后有一个更陡峭的这么一个发展那我们就可以设想在类似的这个架构下我们去训练任何一个规模的这么一个模型都可以达到一个更强的这么一个模型的能力那么这个其实是我们想要跟大家分享的所以呢我们会说miniCPM-S它其实是一个高效的模型的架构它能够带来一个更低的能耗它能够带来一个更快的这么一个推进速度那么同时我们也是能够希望跟大家分享我们所见证的面向未来一个非常重要的趋势就是要揭开端测智能的一个非常重要的这么一个发展的这么一个态势那么在这个方面呢我们也是希望能够通过我们开源的力量然后来去推进这个进程然后能够加速我们的端测智能的这么一个推背感那我们在接下来的话呢也会给大家推出我们马上要发布的一个叫mobileCPM的这么一个套件那么这个套件呢能够帮助我们每个人一键的去开发大模型在端测的APP能够成为我们在端测上就能够拥有我们自己的大模型的应用那么它本身会包括相应的基础的SDK的套件然后会包括我们所带有的一些通用的端测的模型此外的话呢还包含预装了非常多intent的这么一些旗式的这么一些相关的平台那么通过这种方式呢我们可以让所有的开发者能够非常低门槛的速成在端测上的这么一个大模型应用的这种开发的这种工作那么本身呢它整个的这个架构呢其实就是要有这个SDK然后同时呢可以去接入非常非常多的端测的这种通用的模型然后我们可以提供非常多的相关的插件的平台让我们的这些模型呢具备相应的人设相关的功能然后来去支持我们的各种各样的这种端测的这种应用那么这样的话呢实际上我们就会想跟大家总结我们今天其实想给大家去带来的一个是MiniCPM-S这么一个知识密度持续拉满的这么一个模型那么同时的话呢我们也会带来MobileCPM然后能够帮助大家一键的去集成端测的这个模型来去开发相应的这种端测大模型的这种小这个应用那么这个的话呢是我们的一个相关的一个demo首先我们可以把这个手机变成飞行模式在飞行模式下我们的端测模型可以只利用端测的算力来去完成以下的这种功能那我们会看到相关的这种情感陪伴相关的一些基本的文本的这么一些应用那么基本上都可以在端测上然后非常快速顺滑然后去进行运行那么这个的话呢将会极大的去揭开我们在端测应用上的大模型的这么一个威力所以呢我们会说这个未来的大模型它是一个云端协同的这么一个模式我们既要有云上的一个极强的System2的这么一个大模型那么我们也会需要充分的去利用端测的算力然后来去形成端测上的System1的这么一个端测的大模型那么我们在端测上然后我们可以有非常快的毫秒级的这么一个响应我们每秒可以有40个Token的这么一个生成的能力那么我们也可以在飞行模式下就只利用端测的这么一个算力就可以完成相关的计算也能够充分的去注重我们用户的这个隐私相关的隐私数据不上网就可以在端测完成相关的计算那么所有的这些呢都需要依赖端测模型的这么一个支持而本身Mobile CPM呢已经预装了数十种然后相关的这种Intent可以帮助我们一键的去完成相应的这些包括机器翻译人设等等的这么一些这种大模型的这么一些预设的这种能力那我们会认为呢通过我们大家一起然后来去开展这种端测模型的研发我们端测推理的这么一个加速那么我们形成这种端测的这么一个生态那么将会揭开端测AI的生态的这么一个序幕我们会看到端测既有像智能手机穿戴设备巨声智能智能家居汽车PC等等非常非常多样的这么一些场景而这些场景的端测的算力其实是远远没有被挖掘的而我们会认为我们需要利用端测的模型来充分的去挖掘在端测上的这么一个应用我们的使命就是要把模型装到距离用户最近的地方去那么我们刚才所推出的MobileCPM也即将会在最近然后就能够在GateHub上开源并且开启公测那么大家最近非常关注的WWDC2024年这个Apple Intelligence提出的这么一个概念那么本身里面就是包含了端测和云测的这么一个端云协同的方案但是这个方案需要到明年然后才能够与大家见面而我们希望我们通过MobileCPM和MiniCPM-S的相关的这种努力让大家能够更快的去见证在端测上的大模型的这么一个应用所以今天总结一下我们就是希望能够建设最强的端测模型来去推动大模型知识密度这样的一个定律的持续的推进能够以更快更简单更低的成本然后我们一起来迈向更加高效的大模型时代那以上是我的分享谢谢大家",
    "感谢刘志远教授对摩尔定律的全新解读也让我们对大模型的端测模型有了更多期待其实除了摩尔定律以外大模型模型参数量的多与少也直接影响着模型推理的算力和效率神功智能和个人计算机的完美结合正在迅速迈入个人PC的消费市场作为业内的知名品牌联想始终致力于探索和开发AIPC的前沿创新并取得多项突破性进展在AIPC领域联想究竟做了哪些令人瞩目的创新又是如何结合大模型技术来优化用户体验呢接下来让我们以热烈掌声欢迎联想集团研发总监杜洋洲先生上台带来主题演讲联想AIPC创新实践掌声有请大家好我是杜洋洲来自于联想集团联想营业院的人工智能实验室今天很高兴来到世界人工智能大学跟大家分享我们在AIPC方面的创新实践我的演讲分三部分内容分别是框架技术和产品框架部分的话首先我会跟大家回顾一下大模型时代两个技术发展趋势那么我们根据这两个技术发展趋势制定了联想自己的AI发展框架在技术部分我主要讲我们如何在端测设备AIPC为代表那么如何让它流畅的运行个人大迷行并以此来构建智能体应用那有了这个技术之后的话我们来真正的推出了业界首款真正意义上的AIPC并且我给大家介绍一下我们最近发布的一体多端战略也就是一个智能体游走于多个终端之间好我们先看框架部分第一个趋势第一个趋势是混合式人工智能它的意思是说云测智能端测智能跟边测智能相结合其实刚才清华大学的刘志源老师已经给大家讲了这个端测智能的可能性跟做的优秀的工作那么其实大部分人我相信大部分人接触大模型都是从ChadGPT开始ChadGPT属于云测智能因为它的服务是在云测提供但是它跟云计算一样有云计算优势和缺陷比如说如果是交互式应用和对实时要求实时性要求高的这种应用的情况下网络不稳定性跟延迟都对用户体验有所影响那第二个是说如果是对焦点事件或者高峰时段多用户高并发的情况下也产生资源竞争的问题还有一个用户可能会很关心它的隐私问题因为如果要处理个人数据那你的个人文档私人信息要上载的公有云被AI去分析去理解这么强大的AI去理解你的私人的东西恐怕用户也不是很放心再有一个就是能耗问题能耗的话其实随着数据中心对于AI系统的广泛的应用已经对电力系统造成了不可忽视的冲击这也是对绿色环保产生的一个重大问题既然云测AI有这些问题的话其实边测AI跟端测AI也正在发展边测AI代表的话是企业大模型意思是说用企业的知识跟企业的私有数据来训练或者微调一个模型它能够连接企业的业务系统调用企业的软件模块API然后完成企业内部的问答跟企业的一些事务同时它也部署在私有云上面这样的话不会有企业商业机密被泄露的风险所有这些都是公有云上的公有大模型做不到的那么相应如果是模型运行在个人设备上比如说我们的手机PC甚至Pi的还有一些物联网设备的话那就构成了个人大模型也就是刚才刘老师讲到的那可以预见未来的话AI应该是三者的融合有云边端智能的三者的融合其实很多企业跟我们的学界也在践行这样的包括我们的联想的AIPC包括微软的Copyright加PC还有像苹果也一样然后包括现在的芯片企业包括高通和英特尔英特尔也在做一些端测芯片的支持第二个趋势大模型的下一步发展趋势是智能体因为相信大家都能够意识到大模型其实有不少的局限性Chad Gibby刚问世的时候我们被他的能力震惊了以为只要把模型做大就无所不能AGI指日可待其实后来学界的还有一些行业的专家来分析这件事情发现没有这么简单不是说把大网络大算力还有大数据堆叠起来就能够解决所有的问题它有很多局限性就像左上角这是一些文章来深入的分析跟实验结论是什么呢就是它没有真正的推理能力没有真正的理解能力不能建立真正的因果关系不能建立真正的视觉模型所有这些东西我们可以认为对于一个很强大的公司对于一个黑盒系统既然我们不知道它的内部的工作的机制的话那可以用测试用力来探究它那如果说正真需要无穷多正力正伪只需要一个反例就够了那针对大模型的这些区限我们怎么做呢那业界其实已经提出了不同的解决方案比如说对于它不能使用工具的问题那去年早些时候Meta公司提出了Twoformer后来OpenAI也提出了这个也就是推出了这个Function Calling其实都使得它能够使用工具使用API模块这些功能扩展机的能力像知识库的这个问题那大家熟知的这个RAG也就是检索生成增强这个事情的话能够避免一定程度上避免它的幻觉问题就所有这些东西不再详述了那我们综合业界的这些进展画了这张图是代表了一个智能体的技术架构我们联想来做这个智能体也就是按照这个思路来做那刚才讲了两个趋势根据这两个趋势呢我们制定了联想自己的AI的框架这张图竖着看是刚才讲的第一个趋势混合式人工智能也就是结合云测的公有大模型和本地的私有大模型横着看是第二个趋势构建以大模型为基础的智能体那么它能够对于个人智能来讲它的产品形态就是我们说的AI PC对于企业智能来讲那对于企业来讲是降本增效其实它有很多有无论对个人还是对企业这个智能体的构建方式有很多的相似之处技术也是相通的大家注意这里我用了这个双胞胎这个词其实这张图是去年10月联想创新科技大会对外就公布了这张图那么只不过当时的时候智能体的概念还没有那么流行我们用的词是双胞胎它跟智能体是一个意思好 讲完了框架我们看技术那首先呢感谢我们的合作伙伴阿里为我们提供了通一千万模型我们在此基础上做了一些创新使得它能够流畅地运行在端测设备上面然后这些创新呢包括端测的优化然后个人知识库的构建还有智能体的一些能力的增强所以呢我来给大家解析这些能力首先遇到的一个问题是说在端测设备上面运行大模型的最先遇到的问题是什么是内存不够用比如说我们以常用的7B为例子一个权重占两个字节如果是FP16的话那这样的话7B它占14G的空间对吗但是这是静态如果运行设备呢由于Transformer里边的KVCache也就是建制缓存的问题其实耗的工作内存要比它的静态的内存要大几倍因为它要以空间换时间来避免重复计算那这样的话主流的PC其实内存是不够用的那怎么办呢我们分静态优化跟动态优化两种左边静态优化也是压缩分三步第一个是说这个结构化的简直所谓结构化就是节点跟边构成一个子结构那首先把神经元神经网络拆成这样的子结构判断每一个子结构的重要性来看这个子结构是不是可以把它删掉对整体的结构对整体的性能还不是很有很明显的影响那什么样东西的能力是我们关心的呢比如说我们说大部分任务级跟知识级这两级是吧任务像摘要总结啊还需调用然后和这个关键信息提取这些能力是不能被砍掉的那能砍掉什么呢比如说常委的知识因为大家可以想见像175BG的GPT-3这样的话其实它绝大多数的权重用于存储海量的这个百货全书的东西那对于对个人用户如果用的话可以走云色的模型好做完简直之后的话量化量化我们不仅要看压缩比的问题还得要看硬件对数据类型的支持跟反量化的时候的额外开销那有了简直跟量化之后模型多少会有一些性能损失我们可以做一些后处理做一个翻Tune把性能再提升一些这是静态部分动态部分怎么做呢其实就是构建一个推理引擎推理引擎这件事刚才NVIDIA的同事也分享其实也有很多挑战我们要解决它我们做了三件事情第一件事情对于异构异构计算这件事情因为AIPC里面除了CPUGPU还有NPU那每个算力单元它们的特征不一样适用性不一样我们需要把大模型相关的计算任务拆解成一些子任务然后看它的并行度看它的依赖关系重拍流水分配到不同的计算单元上面使得计算单元的总体利用率最大并且单任务的质量最大计算时间最短这是第一个工作推理引擎的第一个工作就是这个异构计算第二件事情刚才讲到的就是KV开是建制缓存那么在主存跟显存之间我们要考虑这个开始的问题哪些建制需要保留更有价值让它保留在开始里面然后哪些可以把它剔除使得工作内存尽量的少的情况下性能还不是下降很多第三件事就是兼容因为我们要做产品我们要用KV平台和AMD平台兼容独立显卡 集成显卡那其实我们是跟这些合作伙伴的铸厂工程师一起做深度的算子底层的源与货的优化最终使得大模型能够流畅地运行在主流的这个PC的平台上面好那第二个关键技术是说个人知识库大家知道大模型为什么要在端测设备上运行其中很大的一个原因是说需要掌握你的个人知识能够对你产生一个就像一个灵魂伴侣一样的一个知识问答那这件事就需要大模型来存取你的一些文档那有两个办法了一个是说做翻替用翻替用这件事其实是不太可行的为什么呢因为一旦翻替用的话它可能会影响破坏原来的知识结构并且还会产生一些幻觉问题失效性问题这些问题所以我们采用的方案是RAG也就是检索增强生成那其实原始的RAG的话它还是不能够满足用户的需求具体来讲我们把RAG拆开把每一个环节做了深入细致的分析跟优化那就像我们右图红色这个部分比如说其实RAG是一个里面借鉴了很多搜索引擎的技术RAG做好了不亚于是一个搜索引擎那像这个对于查询的一些处理我们借鉴搜索引擎的技术像根据一些上下文的信息比如说时间 地点 设备用户的user profile的信息做一些core write就是这个查询重写和这个消奇那对于文档处理的话大家看到这里有三种index就是像关键字索引语意索引 层次索引那其实我们是发了multipath这个跟搜索引擎的思路也是比较类似然后做multipath之后的话做fusion其实这里的话我们有一个特色的技术就是说检索器跟生成器这两者的协同优化什么意思呢大模型在这里扮演了一个检索器大模型在这里扮演一个生成器的角色那当大模型固定的时候其实我们可以优化检索器让它生成对于检索器更友好的结果那具体来讲检索器可以优化它的embedding优化它到点反而会top级的结果给大模型那如果当检索器的结果固定的时候大模型也可以优化去微调大模型然后来使得它生成的结果对用户来讲更加友好或者更接近ground truth所以我们管这件事情叫做检索器跟生成器的二者系统优化二者相向而行这里还有一个特色就是我们做的其实是跨设备的个人知识的问答然后呢因为检索器可以散落在不同的设备上比如说每个人都有好多个人设备像你工作电脑家里有电脑然后有手机有平板你的数据其实是产生跟分布于不同的个人设备上面这样的话其实呢非常有必要就建立一个分布是所以使得你散落在不同设备上的数据互联互通能够生成一个整体这样的话才形成一个完整的这个智能问答系统第三个技术就是其实有两件事情很关键一个是说意图理解一个是说任务规划跟执行那大家知道大模型其实是个端到端的系统那现在我把它拆开了变成一个模块化的设计那大家说了是不是没有必要呢直接上大模型我告诉他什么他就做什么没有必要把它拆成模块但大家都有经验其实大模型有的时候会把复杂的问题做对让我们很惊讶然后呢这么复杂的事情他能做对他有的时候经常犯一些愚蠢的错误简单事情他会搞错所以我呢我如果对这种时灵时不灵的这个产品用户是没有办法接受的那具体来讲我们怎么做呢走的是结合的路线就是大模型加小模型的结合甚至于规则的结合比如说做图意图理解第一列我们把用户的常用意图归纳出来成一个列表然后呢用小模型做一个分类器能够保证他的分类准确性非常高然后对于一些复杂意图走大模型比如说做图的第二列那什么叫复杂意图像一句话用户说的很冗长包含了多个意图或者包括多跳就是multi-hop的问题或者这里需要一个对话管理我们看这个例子用户说我要玩游戏了那我们首先构造一个prime的模板然后把这个用户的这个原始输入模板化给大模型专属化格式化的一个输出那其中明确的意图是要打开杜比的这个圈卷声这种模式来支持这个游戏模式那这是明确的意图不明确的意图呢他要继续构成一个dialogflow问用户你想要玩什么样的游戏好把它启动起来那其实大模型跟小模型的这个无论是并联串联还有跟规则的这个混合利用呢在一般来讲在成熟的产品里面大家都是这么做的基本不可能说一个模型一统天下如果我们就是可以回顾了搜索引擎里面比如说white list然后一些这个最后一步我们要规则来最后来卡一下它的这个安全性都走的这种混合的道路其实我们也会这样做的任务规划也是一样就是说什么叫做任务规划呢用户的意图跟我们的可执行的这个API模块它经常不是个一一对应关系经常是用户说了一件事需要把它拆解成几个原子级的这个子任务看一下它们的依赖关系限制条件再看对于每一个子任务能够有哪些模块可用然后来完成这个最终目标那这件事我们叫做一个全盘规划那大模型本身它毕竟是一个下一个词预测在做这么一件本质的事情它只能做直觉适合于做直接类的事情不太适合于做全球规划的这种事情那我们叫做一些外挂的一种机制那最右边大家可以看到这里有一个蒙特卡罗数搜索是吧这里是alpha go的算法其实下棋典型的它是一个典型的规划问题我们不是看眼前能吃几个子而是要看终局的胜利那如果说大家可以想象一下这件事如果我不用这么复杂的机制不用蒙特卡罗那个搜索数那现在把它拍张照片发给gpt4o或者其他方式把棋局发给gpt4o问我下一步应该走什么子当然了我没有试过那我相信它可能是不行对于很多经典的规划问题对于一些典型的规划问题我们是有经典解法的不能说因为有了大模型就把那些经典的东西扔掉了应该是采取一个结合的道路比如说像现在的巨神智能的前沿其实也是走的传统的强化学习和大模型相结合的路子所以右图的最左边这一列列的马尔科夫角色过程这些其实是强化学习的一些经典解法那意思是说我们对于不同的任务用一种结合的方案来做这都是构建智能体技术的关键有了这些技术的话其实我们就可以打造出一个真正意义上的AI PC那么它有五大特征第一个我们刚才讲过了它本身是以大模型为基础构建了个人智能体然后本身智能体是运行在本地但是可以与云端的大模型相辅助第二件事刚才也提到过了是混合算力CPU GPU NPU的一个计算第三件事呢它既然成为你的知你懂你帮你的一个灵魂伴侣或者助手然后呢所以说它必须要掌握你的知识库比你还热化设备的第四件事刚才没有提到过它是我们是构建了一个开放的生态也就是说智能体有能力发现新的可用的AI的应用把它也一样调度起来成为一个工具完成更复杂的任务同时这个平台开放给开发者更强大的新的智能体应用第三件事第四最后一件事这个安全的问题刚才也提到过本地模型本身处理的话它也保证了安全并且我们还有芯片级的这个方案可以做如果真的要传输的话可以做芯片级的这种安全的这个加密跟脱密好那么其实还有一个事情啊就是在上海有一句俗话叫做罗斯科里做道场那我们其实真的实现了这一点罗斯科里做道场的意思是说在空间狭小条件简陋的情况下做精妙的事情那其实PC本身计算能力有限资源有限我们真的把它这个端子模型流畅地运行起来了要做了智能体的应用真的实现了这一点那我们在4月18号也是在上海创新科技大会上发布了AIPC产品在5月20号已经开售AIPC所以大家在市场上是能买得到的这是真正意义上的落地的产品而不是停留在口床上的宣传那其实从工作到生活都是覆盖了不同的智能体应用产品上面的话其实分三个系列向左下角商用的就是高端路线然后呢中间呢就是走的这个就是高性价比的路线最右侧的话是走的这个信创国产化的路线在6月25号就是大概10天前我们又公布了这个一体多端的战略所谓一体就是一个智能体构成一个智能体系统多端呢就是多个互联互通的个人的设备那一个智能体可以游走在不同的终端之间给用户提供一个统一的一个完善的体验那这样的话用户其实说整个来讲的话就是这也是提供了一个更大的一个机会那最后呢我想首先是我们愿意跟合作伙伴阿里继续深入的合作来发展以智能体以大波形为基础的智能体技术与易介煌一伙伴的合作来发展这个混合式的AI框架那对于个人智能来讲继续把AIPC做得更好用对于企业智能来讲做的真正的降本增效谢谢大家",
    "感谢杜洋洲先生的精彩演讲期待有更多业界伙伴和联想一起打造混合式AI技术让AIPC的不断发展当然除了个人PC以外AI智能助手在手机 汽车 机器人等多种物联网设备中也越来越普及大模型技术的引入让终端智能助手不再局限于简单问答而是能够在视觉识别实时翻译 图片生成等多个领域提供更为智能的帮助和服务接下来让我们有请小爱团队大模型产品负责人乔国辉先生带来主题演讲小爱同学的实践历程为大家进一步介绍小爱同学如何通过软硬件的深度结合带来全场景多模态的深度体验让我们热烈欢迎乔国辉先生上台大家好我是小米公司小爱同学的乔国辉今天很荣幸作为一个大模型的应用者在这里给大家分享一下小爱同学在大模型的实践历程先简单的介绍一下小爱同学小爱同学是小米的人工智能助手不知道大家知不知道小爱同学的名字是怎么来的其实我们的名字就是小AI我们是在16年的时候开始去做AI相关的功能经过8年的时间就覆盖了小米的各个硬件设备包括小米的汽车手机 AIoT机器人还有可穿戴设备等等这些上面都有小爱同学小爱同学是一个软硬件深度结合的场景我们想做好这个功能非常的不容易除了在AI的云端上我们要更好地理解用户以外我们也需要跟硬件去做深度的结合包括硬件的声学链路硬件的前端语音识别等等我们要针对硬件做很多针对性的处理和优化这样才能实现这种体验的效果大家可能熟知的小爱同学主要是小爱的语音助手但实际上我们也还有很多其他的系统服务包括像小爱的主动建议 建议场景小爱视觉 小爱翻译小爱通话未来我们还会有更多的功能推出给大家简单地介绍一下小爱同学的技术架构在最上面是设备层左边是内置小爱的设备用户可以通过这样的设备跟小爱进行交互获得相应的内容和服务右边是受控设备就是通过米家的接入这种IoT的设备通过小爱同学我们把主控设备和被控设备连接起来中间是能够用户的同一层用户的一个请求来了之后我们通过小爱同学去理解用户的意图去感知用户周边的环境感知他的信息最后提供他相应的功能和服务我们提供的服务大概可能就是下面这些类型包括设备的控制这个也是用户用的最多的场景还有一些基础的工具像闹钟 计算器这样的还有信息的查询 内容的服务还有这种场景的互动对话等等那么截止到今天为止小爱同学我们目前搭载了54类的主控设备我们的越活跃用户已经有1.3亿我们每天的请求次数有2个亿我们是在2年的10月份开始去做大模型相关的这种功能的落地我们做了很多的打磨我们在23年的8月首次进行了大模型功能的内测一经推出之后还是收获了非常多的用户的好评我们在今年的3月我们在汽车上是正式的上线了小爱的大模型功能我们针对汽车也做了很多针对性的优化那么可以看到大模型这种体验的提升给用户带来了非常大的一些变化我们过去很多做不了或者是做不好的功能在大模型之后是有一个非常大幅的提升的尤其是我们这种中长尾的请求比如说像知识的问答或者这种闲聊场景的对话我们过去可能我们的满足度大概就只有30%但是我们有了大模型之后我们经过打磨我们现在已经提升到了80%多并且随着这个模型的能力提升它还是在继续的优化的另外就是这种大模型能力也给我们的活跃用户的留存带来了一个非常大的提升我们大概提升了10%做过互联网产品的同事们可能都了解就是留存每提升5%其实它体验都是非常巨大的提升其实它体验都是非常巨大的提升其实它体验都是非常巨大的提升那么在这里大模型技术给小爱带来了哪些的跨越式升级呢我们主要是分成了三个事情我们主要是分成了三个事情一个就是通用的对话通过大模型的这种通用的能力去更好的回答用户的问题第二个就是在一些垂直领域的场景第二个就是在一些垂直领域的场景我们也做了很多的功能小爱其实我们背后的场景很丰富我们有很多垂直领域的场景比如说小米的商品出手比如说小米的商品出手用户可能会问一些小米相关的设备的参数用户可能会问一些小米相关的设备的参数然后小米设备的这种使用指南甚至是小米设备如果故障了该怎么办过去我们想做好这样的场景其实很难过去我们想做好这样的场景其实很难我们想用这种人工训练的数据这种QA段然后去满足用户但实际上这个最终的效果上来做的也并不是很好但有了大模型之后我们看到给这样的垂直领域场景给这样的垂直领域场景带来了新的解决的方式我们通过这种RAG的技术然后通过大模型的检索匹配我们很好的在这样的场景下就满足了用户我们很好的在这样的场景下就满足了用户第三类就是NLP的任务因为小爱这样的场景来了之后我们是需要去理解用户的意图的来了之后我们是需要去理解用户的意图的那么用户的每一句话表达的到底是什么意思它是其实有非常多的不同的任务的它是其实有非常多的不同的任务的那么我们过去想做好我们每个任务其实都要构建大量的这个训练数据并且我们的产品经理针对每个任务场景都会去做相应的这种产品策略针对每个任务场景都会去做相应的这种产品策略过去不是一直有句话吗就是有多少人工就有多少智能但是大模型来了之后呢但是我们利用大模型这种比较强的通用的知识但是我们利用大模型这种比较强的通用的知识我们通过小量的数据结合大模型我们通过小量的数据结合大模型然后在每一个任务场景做一些训练我们就可以很好的解决这种场景了我们就可以很好的解决这种场景了对 那么总结来讲就大模型之后呢小爱的这个技术架构可能大概就是这样的我们的一个用户的请求来了之后呢我们会先用大模型来做一些简单的意图理解我们会先用大模型来做一些简单的意图理解我们把任务大概分成了四类那么第一类呢相对比较简单就是一些工具或者是控制类的任务我们在意图分发到这个任务场景之后呢我们在意图分发到这个任务场景之后呢我们通过这样的LP小模型就能去直接执行相应的操作了第二类呢 相对会复杂一些是一些内容类的场景就比如说我们的音乐或者视频做过音乐的同事都知道想做好音乐的话我们需要大量的音乐数据我们需要对数据去打标签这个搜索和推荐的能力所以在这个场景呢我们主要是用大模型来做好用户的意图理解我们还是要依赖传统的这个搜索和推荐去满足用户那么第三类场景呢就是生成类的场景这个是我过去小爱其实做不好的或者我们做不了的场景这个其实在大模型之后现在表现得非常的好那么第四类呢我们认为是最难的一类也是现在用户需求其实最大的一类就是知识类的场景这些场景其实非常的困难如果我们做好的话我们需要给用户准确的答案因为它只有唯一的答案基本上大部分的情况它不像生成类你可能写个作文或者写个诗其实言之有理的话用户都会觉得是OK的但是在这样的场景下我们必须要做对这个时候其实就对大模型的通用能力带来了非常大的挑战其实我们现在看到啊就行业内现在最好的模型其实在这类的问题解决上还是有非常多的问题的其实我们也欣喜的去发现就我们跟很多行业的大模型做了交流大家都觉得就是随着这个大模型能力的提升我们用更大的参数然后通过更多的这种模型训练是能够让这样的场景变得更好的那么在小爱这边我们是如何去选择大模型的呢其实我们应该跟很多在座的大模型开发者是一样的我们大概就是这样三步我们第一步呢会去建设满足业务需求的评测体系会搭建业务适合的这个评测集第二个我们在对应的这个业务场景下去选择适合的模型因为小爱呢背后有很多的场景我们每个场景的要求是不一样的所以我们尽量的都把每个场景去选到相对来说最适合的一个模型那第三个呢就是我们随着做的越来越深入我们发现一个场景通用的模型是不能做到最好的我们一定有很多定制化的需求这个时候其实就需要对模型做大量的工作包括模型的优化也包括模型的微调等等那么在小爱这边呢其实我们最关心的主要是两件事情一个是效果的指标一个是性能的指标在效果上呢我们搭建了九大类四十多个小项的这个评测体系很多就是和小爱合作过的大明云厂商就是在我们初期合作的时候我们都会给他提供一份这样的评测结果甚至是跟同行的这个对比然后另外一个指标呢我们也很关心性能在这个场景用户一个请求发出之后他是要求很快的就要得到结果的所以这个时候我们对模型的实验的速度也是有要求的因此我们搭建了这样一套基于小爱的知识然后基于不同大模型这样的混合的体系我们基本上便利了行业内所有的大模型我们在每一个场景都找到了相对比较适合的内容接下来呢给大家简单的便利一下我们在这个模型上其实我们在大模型上是有了一个很强大的就是大模型的能力就是大模型在做的一些能力就是随着大模型能力的越来越强大模型开始在智能座舱智能手机甚至是智能家居上有更多的功能落地那小爱呢除了传统的这种语音交互以外我们其实也做了很多其他的事情包括在手机上我们做了很多多模态的应用场景比如说图片问答图片的一句话编辑小爱呢控制IoT其实是我们非常常用的一个场景但这样的场景其实想做好是很困难的因为我们需要理解用户的家庭房间你设备的这个信息设备的名字甚至等等这样的内容我们现在在通过大模型通过agent的技术在更好的去探索怎么去能更好的控制用户智能家居的能力那么第二个呢就是小米的商品助手在前面也提过了我们通过大模型这样的能力呢去复杂的知识注入然后去更好的回答用户的问题另外我们其实也结合小米的输入法我们在AI输入的场景给用户提供更多智能的回复帮助比如说在微信的场景我们帮助用户写一些更高情商的回复等等那么在今年的汽车发布会上其实我们也发布了很多小米的大模型功能包括像走哪问哪比如说你到了一个城市对吧你开车的时候可能问这里的河叫什么这种地理的位置的问答我们也做了基于多模态的这种前面的车是什么这样的问答我们也做了汽车说明书相关的一些功能在这里呢我给大家准备了一个一分钟的短视频简单的再看一下汽车上我们做的一些功能的应用我们还来自于力量准备的所以调到最后停下了甚至跨界的想法它也能心灵神会我的手机掉哪了打开家里的扫地机器人打开家里的摄像头小二同学我在打开手机复卡码完成了搭载AI大模型的它无所不知有没有离鬼街和望京都很近的川菜馆为你找到了十家位置合适的川菜馆介绍一下七方三项是三方七项前面的车是什么车我来看看甚至它可以像人一样观察是感染力的小米苏7满足你的所有好奇前面的山是什么山这就是全新的小爱更懂车的事更懂设备的事更懂你好奇的事全新小爱大模型智能语音已登陆小米苏7好刚刚大家看到的都是一些我们用大模型或者结合大模型去做的一些功能接下来想简单地再给大家分享一下小爱同学对于大模型未来的规划首先我们可以看到大模型的能力越来越强大模型开始可以做更多更复杂的任务它的准确率也很高我们现在大家其实都知道有一个非常热的概念叫做AI Agent就是通过大模型来去做这种复杂的任务然后更好的去满足用户但是我们其实也知道这样的场景其实落地是很困难的我们都知道一个任务它如果最后的执行准确率没有办法达到95%的话其实这个对用户来说是不可用的但是像这种Agent的场景其实目前准确率上还是有非常大的挑战的这个也是我们希望能够和大模型一起去做的这种技术升级在小爱的场景下我通过Agent来做更多更复杂的任务去满足用户第二个就是多模态的场景小爱在手机和车载上我们做了很多多模态的能力用户其实表现的都非常的喜欢我们接下来还会持续地在这个方向推出更多的新功能第三个是OS的深度整合随着这个模型能力的增强我们希望能够跟系统去做更深度的偶合我们会提供更多的底层的系统的控制然后给用户提供更多的内容服务我们相信在今年下半年大家去看行业内的手机的时候应该都会看到有很多AI的应用开始落地我们可能未来就会叫AI的手机了第四个就是端侧大模型其实这个也是小爱非常重点在投入的一个方向因为我们觉得当用户的数据没有办法上传的时候或者用户其实有很多的场景其实对它的隐私非常的关注这个时候云端大模型是没有办法去满足的比如说我们在手机上我们去对用户的信息的检索去对手机里面的一些内容的这种操作或者问答包括在车上其实端侧也是一个非常重要的场景大家都知道车是在很多地带是很容易出现无网或者弱网的情况的这时候我们通过这种端侧大模型就能更好的满足用户给用户提供更多的内容和服务最后想简单地总结一下就是小爱这样的开发者我们对大模型最关注的事情其实主要是两个一个是效果一个是成本这个里面我们最关注的是效果效果里面我们又分成了两个事情一个事情是大模型的通用能力是不是足够的强能够更多的满足用户的基础的能力第二个就是针对小爱这样的场景我们在过去一段时间探索发现我们的很多场景就是要定制化的所以我们也很关注大模型是不是能针对业务去做定制化的诉求在这里也非常感谢我们的阿里云同事在我们小爱的很多场景里其实都做了很多针对性的优化包括前面大家看到的多摩泰的场景也包括刚刚像小米商品这样复杂的知识植物的场景那么在未来非常期待说大模型的能力能够进一步的提升然后这样的话能够帮助像我们这样小米的这样的开发者能够更好的去调优我们的效果给用户更多的更丰富的内容好 以上就是我今天分享的内容谢谢大家",
    "感谢谢谢乔国辉先生的精彩演讲结尾影片里的小爱同样让我们眼前一亮相信在未来小爱同学一定会成为一个更懂你的小爱其实阿里巴巴集团一直致力于用科技力量提升我们的幸福生活实现商业之上的价值有这样一群特别的小朋友被大家叫做新型的孩子或者说叫新宝他们就是孤独症普系障碍儿童根据第五版中国孤独症教育康复行业发展状况报告的估计我国零至十四岁孤独症儿童约有两百万人有那么一群志愿者他们愿意为这群孩子打造一方能够会梦成真的小天地他们历时近三个月开发出了一套专门关照孤独症儿童的AI绘本工具并免费为这些儿童家庭提供定制化的AI绘本服务仅需一句话的故事梗概就可以直接生成符合新宝需求的有词称故事绘本一经上线并获得了苹果应用市场精选栏目的推荐那么这个绘本工具是如何诞生的让我们一起来看一看我们是一群追星星的小伙伴两个月前这张志愿者招募令把我们汇聚在了一起我是一名前端工程师也是孩子的父亲我是一名幼儿设计师想一起给小朋友们点亮星光我是一名软件PT我是一名普系儿童家长也是一名特教老师我是一名儿童故事编剧希望给这个群体带来更多的光和爱这里是上海美术电影制片厂这个活动我们可以一起参与我们来自天南海北开始为孤独症儿童打造专属他们的定制AI绘本工具这次故事绘本主要是基于通讯大模型结合了孤独症儿童专家的一些指导意见创造了一个专门为儿童打造的故事绘本对于纹身图大模型来说的话我们其实希望能给星宝提供一些更符合着儿童的一些喜好MotorScope Agent在这里头做了一个底层的一个知识我们把它的纹身图还有本身的个性化生成一些文本的能力调用起来能够为像孤独症儿童生成一些特定的这种绘本故事这项工作或许是会开源出来的希望能够通过开源这种技术捐赠的方式为孤独症儿童和家庭做更多的事情你们愿意和我一起为他们打造一个充满星光的世界吗?相信在座的各位和我一样都被这群追星星的志愿者们的善意和投入所打动正如影片中所说是人有了温度AI才会有温度目前追星星的AI已经上线通议APP公测也受到了很多星宝家庭和关注者的好评今天我们特别邀请到了一路见证和关注者的好评和支持这个公益项目的机构代表正式为我们开启这个有爱的项目",
    "让我们掌声有请上海美术电影制片厂有限公司党委副书记 副总经理 彭勇中国青少年发展基金会网络公益与公众推广部副部长 齐齐格摩达社区负责人 石洪竺阿里通益实验室产品负责人 金路瑶以及公益项目发起方代表阿里巴巴集团 金路瑶公共关系部总监 好方奖有请各位嘉宾上台请各位嘉宾把手放在对应的心形位置上让我们共同开启这一段星光璀璨的旅程五 四 三 二一关怀孤独症儿童公益AI绘本工具追星星的AI正式发布那么请各位嘉宾上前一步我们合影留恋该项目还得到了孤独症儿童干预的机构恒星乐乐 海豚乐乐等的专业支持以及浙江工业大学王永固教授团队等专家顾问团队 童语故事等不少爱心人士机构的合力支持感谢大家好的 请各位嘉宾入座请彭总和陆瑶两位留步绘本项目能够顺利发布离不开阿里通艺实验室和上海美术电影制片厂的全程支持通艺实验室在这个项目背后提供了很多技术知识",
    "有请陆瑶为我们分享其中的一些细节谢谢这个是我们第一次参加这样的项目但是也是一个让我们特别兴奋的项目因为在这个过程里我相信每一个参与者包括我们的产品经理我们的技术 我们的算法都是充满了爱在对待这件事情所以我相信今天通艺的大模型它也会用爱来输出来普惠到我们每一个人包括帮助到每一个人这也是我们一直以来想去做的一件事情那谢谢",
    "好的 谢谢陆瑶那么除了通艺提供的技术支持外当然也离不开上海美术电影制片厂众多优秀的绘画设计那么就请彭总为我们本次活动做机遇分享好的 谢谢大家",
    "那个上海美术电影制片厂就是非常有幸能够参与到这个项目中间来其实一开始我们也是被这个阿丽的小伙伴还有就是我们的广大的志愿者他们的热心和爱所感动所以我们上海美术电影制片厂也愿意用我们的一己之力让我们的深具中国美学的一些动画的一些形象来陪伴我们的新宝随着那个活动还有我们合作的深入呢我们是觉得在这个AIGC大爆发的时代就是我们这个传统的IP形象与这个Z世代的人的生活方式它可能有一个更新的一个链接方式所以我们我们上海美术电影制片厂也愿意说跟大家一起来推动这样的事情我们相信通过这样的活动让这个公益变得有更多的多元性和多样性让我们所有通过公益的活动能够让我们继续去热爱这个世界和他人也让我们付出的点点滴滴让这个公益的活动能够让我们继续去热爱这个世界和他人让这个世界变得更温暖好 谢谢大家",
    "好的 谢谢彭总感谢两位嘉宾那么也希望呢追星星的AI项目能够点亮新宝的夜空成为父母老师的好助手小好工具陪伴新宝们共同成长那么接下来呢让我们进入本场论坛的最后一个环节圆桌讨论随着大模型生态的不断完善我们也看到越来越多的大模型走上了开源开放的道路我们相信开源开放互惠共享将是今后大模型技术生态繁荣的必然选择本次圆桌对话的主题就是开互惠共享大模型技术生态的必选项",
    "让我们有请圆桌主持人摩达社区技术运营负责人程程以及各位嘉宾上台他们是阿里云无影事业部产品总监程希面壁智能副总裁OpenBNB社区联合发起人贾超通议实验室通议签问开源负责人林俊阳上海人工智能实验室研究员张松阳以及摩达社区模型服务负责人张文蒙让我们以热烈掌声欢迎各位嘉宾上台欢迎大家那我们现在进入我们的这个圆桌环节然后其实圆桌环节我们今天能看到其实有做大模型的同学然后也有评测大模型的同学有做开源社区的同学也有做产业落地的同学那我们今天开始我们第一个主题就是这一年突发的大模型的同学就是这一年突发的大模型的同学是非猛进的中国的大模型那这个问题我想先问一下签问的那个俊阳同学其实去年七月份的时候我们第一次开始讨论就是签问开源的事情那个时候我还记得第一代的是一个签问的7B那其实当时开源的那个模型怎么说就是我觉得可能在开源社区里面是一个很好的模型但在整个大模型的纵观下来并不是一个非常非常出挑的模型但是在这一年的时间里面其实签问迭代的速度很快而且每一次发布都有非常大的这样一个进步那甚至到现在做到了一个全球领先的这样的一个大模型的话那其中有什么样的一些关键的点对非常感谢诚诚的提问然后对通讯签问也有很多褒奖首先当时呢确实我们出了一个7B的模型开源社区的话呢比较长时间的话其实是落后于币源的大模型的状况所以当时其实我们在在研发大模型的过程当中其实是不断地收集开源社区的开发者的反馈不断地去优化我们的模型所以我们后面不管是做14B还是72B其实都不是简单的7B去扩大模型size而是对我们的数据做了比较多迭代的相关的工作那后来非常有幸我们开源了1.5然后系列也比较多有比较多学界的朋友也一起参与进来去给了我们非常多一些意见告诉我们一些优化模型的一些经验所以才能走到今天Quantum这一步吧所以如果要我感谢大家的话其实还是感谢这个众多开发者以及用户的支持才能让我们的模型迭代速度迭代这么快可以说今天去一定程度上在追赶OpenAI好的谢谢俊阳",
    "然后下一个问题我想问一下甲超然后就是其实我们也知道说像miniCPM在端测大模型在多模态视觉的这样的一些模型专注在多模态中小模型的场景但是做到了非常非常好的这样一个效果然后今天我们也听刘老师讲知识密度这样一个词然后甚至在miniCPM前一段时间也被全球领先的一些大学做了一些借鉴那就是其实今年很多很多人都讲第一性原则是scaling low那为什么面壁今天坚持做这样的一个端测的这样的一个大模型做这样的一个小而美的大模型的想法是什么OK其实是这样的就是刚才其实也提到了一个scaling low的和知识密度的一个极致体现那其实面壁早在其实我们整个整个公司就是清华团队出来的我们从2020年就开始训大模型那其实到23年这个GPT爆发的元年开始我们训了非常多的百亿千亿规模的大模型但是我们发现就是千亿规模这种大模型训出来以后它在推理成本上是巨大的就是当有用户有一个千万级这样量级的DAU以后其实它GPU成本是非常大的那得益于我们其实整个实验室就是清华团队加面壁团队我们在去年六月中就是去年年中时候其实我们就开展了scaling low相关的工作啊我们做了大量的在小规模模型上的实验来得到了一组最优的参数配比同时我们独创的创新性的提出了一种最新的训练方法然后再加上这都是算法层面的另一方面就是加上我们在数据层面的一个完全新一代的升级包括数据配比的一些实验得到我们模型的支撑啊所以说我们在去年年底我们就有有坚信我们通过训练一个更小的好比说两币参数规模的模型来比肩十币左右的模型然后让他发挥这样的一个足够好的性的因为当这样以后我们就可以去在很多场景去替换这样一个大规模量级的一个模型以后那他的场景也是足够多的而且我们发现其实在座的大家都有智能手机其实我们近期一个报调研报告发现其实国内大家终端上算力的一个大家都没有开发出来但其实每个人智能手机的算力其实和去年差不多像就是GPU这样对比其实差不多有能够和一百万张H100这样的量级的算力去对比所以说我们觉得端测才有足够的想象力啊那其实今年就是面壁其实小钢炮在二月一号发布以来已经受到了足够多的关注和业内的认可那其实刚才晨晨也提到就是那个国外的那个事件其实我觉得我觉得更重要的其实就是对我们这个模型的认可对中国技术的一个认可因为其实他所所所说的其实他之所以在国外能出圈也是因为他说就是这个模型和GPT-4V Gemini Pro这样的模型是能够比肩的但他其实是花了五百美金但其实前两个是对的后一个五百美金是不可能迅出这样模型的所以说但反过来推其实这个我们也觉得他和整个机构其实也不是很相关所以我们也没有着重的去说这件事情了解就是其实我也想继续再追问一下就是说就是前一段时间非常火的那个模型miniCPM2.5这样2.5V这样的一个模型他其实也是基于像NAMA3这样的一些模型上基础上有个G模型在做这样的一个训练那这个这么就是其实他的在上面做的这样的一个多模态的继续训练其实效果很好未来有没有考虑过和中国很厉害的这样的一个大模型合作然后比如说千问呢嗯那就是首先其实我们选了一个啊我们当时之所以选那个喇嘛三吧B来训练其实是因为当时就是喇嘛三额效果也很好然后其实在全球非常火吗那我们当时就选了这样一个模型就是在我们下一代模型没有出来之前所以说他的一个出圈我觉得下一步我们也会考虑好比说和国内的好比说千万我们联手一起也可以搞一个这样的一个联动我觉得这个是非常好的因为对国外可能大家觉得用Lama3那其实我们国内也有非常好的模型那其实同时的话面壁也会持续的在端侧因为刚才刘老师也是讲了大模型的摩尔定律之密度我们也会在更小的尺寸上去寻一个更好的模型来做我们多摩泰的一个基座所以说这些我们都是会同步来做的也会在未来我觉得就是好比说和俊阳他们的合作包括面壁未来更小更强的基座这些都会我相信在不远的几个月都会逐步的发出来对对对好的好的那我们刚刚聊到了就是大模型的整个的发展然后其实前一段时间Open Compass其实有讲一个理论就是松阳分享的时候我印象很深刻就是过去一年闭元大模型的这个能力的上升和这个开元大模型的能力上升显然开元大模型会更强一点那其实Open Compass在大模型的客观评价上面其实做了非常多的工作而且整个大模型的发展是离不开评测的而且即将也会有这样的一个多摩泰的这样一个榜单出来那如何就是客观公正的这个评价这样一个大模型然后包括也有人反馈说现在的Benchmark怎么来保障这样一个防止刷榜公允性那Arena怎么来去覆盖方方面面的一些就是肠胃的这样的一些问题然后怎么样以及未来垂直行业的一些评价怎么来做也希望松阳跟我们分享一下大模型的评测的下一步你是怎么想的OK谢谢啊",
    "我这边对自我介绍一下我是来自上海工程实验室的张松阳然后我们之前去年到现在一直在做的一个项目叫做Open Compass就主要是在做模型的评测对那这个相信很多做模型的同学或者老师们可能很了解对我们也给大家制造了很多的压力因为我们可能定期就会去放一些榜单对然后我想分享几个观点吧就第一个观点是说评测这件事情其实是前置的就刚才这个小艾同学的这个朋友也讲了就是评测肯定是无论是模型的研发还是应用的研发都要先提前去做的但这里边是说如何去构建一个满足自己预期的一个评测体系这个其实每家的业务属性或者是场景不一样比如说像千问像这个拉玛像英特尔这种做通用大模型的他其实更关心的是通用能力那在这个角度大家可能会面临很多基础的问题的这样当这些评测和构建然后但对于行业来讲其实是需要有一些快速的把行业知识能够高效的转换成行业评测集的这样一些方法论或者工具的对这块其实整个的在学术界包括工业界的实践可能都不是很多对大家其实还是一些比较handcraft手工的去构造一些场景的评测集对但其实如果后边想让大模型进到更多的业务或者是更多的行业里边就会有一定的支持比如说我们能不能构建一些agent的工作流这个agent的工作流能够帮助我去把一些垂域的评测集自动化的快速的构建一个高精度的这样的一个评测集出来然后来指挥我下游的应用的研发对这是这是第一个点第二个点就是说对于整个模型的刷榜或者是能力的一个准确的评估这里边大家现在评模型的这样一个逻辑其实是一个这种折中吧就是大家现在只能通过一些benchmark的分数来去对模型能力有一个更好的表达对那因为通过这种像像arena像人工的这种评价它可能各种各样的随机性的因素都会很难有一个特别公允的一个判断对大家也也也会去说ok这个这个产品或者这个大模型的用户量调用量这个业务量这是一方面的指标但对于比如说做模型研发的角度来讲确实是需要这些客观的评测集或者是一些榜单来去push大家往前走那这里边我觉得榜单它其实很多时候是保一个模型的下限就是你在这个榜单上的成绩不能太差太差的话就意味着你的基础能力不达标那很多的应用你可能做不好对但就是大家也不能陷入一种怪圈就是我为了让这个榜上的成绩我排到第一名第二名我就想尽各种奇奇怪怪的操作对这个其实也不是我们作为评测的研究机构希望给大家一个良性的一个反馈然后这个一个公允的一个评价那包括说对于能力的更细度的分析然后至于刷榜这件事情我们其实过去一段时间也遇到了就有一些模型的机构其实他们可能通过一些各种手段去去去想试图去刷榜对这个其实就跟那个安全对抗是一样的就是在评测上面有一种能力的对抗就评测体系会不断的演化然后我们会有一些新的评测机构然后我们会有一些新的评测机构比如说学术界每天都有新的论文这些新的论文可能都会构造一些新的高质量的评测机同时我们作为研究机构我们也在研究一些自动化的评测的一些算法比如说抓取最新的新闻最新的学术论文然后去把它构建成评测机一些这种大模型可能还没有训练到的语料对但是其实也是蛮大的挑战的因为对于我相信很多的这种大厂来讲大家蓄模型就是每天海量的数据都会回来对然后这是两个点然后最后还有就是刚才提到的这个多模态的问题就是多模态的评测其实可能现在还是属于一个相对大模型来讲初期的一个状态大家还是在关心一些榜单指标的这样一个阶段对不像大圆模型已经到了产品应用或者是用户体验的这样一些提升上我觉得这个可能需要学术界和产业界一起来去推进就包括像miniCPM这种性能很强的模型对我们其实也是希望后边对于多模态模型来讲除了在客观指标上面就是这种任务型的指标上能够体现出的优势也能在日常的这种人的自然对话的场景下面能够体现的更好对那我觉得主要是这几个点谢谢",
    "好谢谢然后其实大模型的整个发展我们会看到有两个主流的方向一个是开发者生态还有一个是产业应用那我们今天也听到了就是面壁在这个端册上面的这样的一个大模型的这样的一个大模型的发展这样的一个工作那我们也想今天问一下吴映就是吴映在这样的一个大模型时代怎么样通过云端结合的这样一个方式来推动这样的一个大模型在产业场景的落地那我们来问一下光昭谢谢孙子",
    "其实这是一个很有趣的问题坦白说之前也困扰了吴映一段时间因为众所周知就是包括这场论坛和我们刚才讨论的端册作为一个集数据用户用户的行为用户的交互和用户的应用这四大主要因素为一体的一个平台实际上是拥抱AI和结合AI非常好的一个点那我们也看到了无论是从英特尔和AMD的NPU也好还有说端册小模型也好还是说呢是产业化以后的AIPCAI手机等等其实呢我觉得都是业界炙手可热的一个趋势那作为一个云端业界的一个模型关于一体的云电脑或者云手机的吴映这样的一个产品呢我也分享一下我们的Chain of Thought因为我是本场应该是唯一的产品经理那那个首先呢我们分析我们分析了用户呢在无影场景中呢他可能会用到AI的两个主流的大的场景那第一个场景的是生产力场景那他可以细分为两个子场景一个是生产力的体效场景那那个可能包括了现在很多的Copilot或者是Agent所做的文字的优化处理表格的优化处理翻译等等这样的一些场景那第二块呢是提升提升管理效率的一些场景这个子场景呢比如说是远程的智能化运维智能化的故障检测等等这是2B的我们认为生产力场景的这一块第二块是个人和娱乐场景那他又能分为两个子场景第一个场景呢第一个子场景呢实际上是降低用户对多安侧设备的影响实际上是降低用户对多安侧设备的影响实际上是降低用户对多安侧设备的影响那这里其实刚才小艾的那个分享也说了比如说语音的控制语音的用户行为自然语言的操作等等那那个也包括快速的设备的使用问答那第二块呢是提升用户的使用趣味性增加用户的粘性包括比如说个人的知识库微软前段时间发布的Recall那也包括了像纹身图等等这样的能力智能分身的能力那这是我们认为的无影呢我们需要覆盖的两大类的场景那基于这两大类的场景呢实际上我们也看到了业界主流的两种解决方案第一种解决方案呢是纯云端的SaaS解决方案那刚才其实联想的同事也分享了纯SaaS解决方案呢它在模型的迭代速度模型的选择模型的质量上呢其实是有本身固然的优势的但是呢它在实验在端云的数据流转然后在模型的选择在个人隐私方面其实是有一定的弊端那同时呢它在应用应用跨应用的结合这上面呢因为它没有深入系统层所以很难做到跨应用的一个结合那第二块呢第二种业界的方向呢是本地的小模型类似于AIPC那这个呢其实在实验在推理速度等等方面呢是有一定的优势包括数据的安全性但是呢在模型的迭代在模型的性能然后对于对端测性能的要求对端测性能的消耗等等实际上它们的不足也是显而易见的所以无影呢就从这一块呢我们就想到我们无影有什么优势或者我们能在云端一体的这一块和AI结合能做出点什么不一样的东西那我们就想到了三个点第一个点呢我总结成两个就是整个叫系统级和应用感知那它细分为三个点第一个点呢实际上是云端一体是一个端一体的产品所以我们深入了系统层我们可以去跨应用端云一体的去控制云电脑或者云手机的各种行为这是第一个优势那第二个优势呢是我们有协议那协议呢我可以做到对用户行为真实行为的实时感知比如说它开了它开了优酷那至于优酷里面是什么样的内容我其实都是实时感知的同时因为我对就是用户的交互流程IO就是输入和输出应该是实时处理的所以我其实是对用户的交互行为是密切能够识别和感知这时候我可以帮助用户去做很多交互的动作那第三呢是云端一体因为它是一个云原生的形态所以我们其实不依赖于本地的算力那我们在整体的算力无论是对类层的消耗对存储资源的消耗对算力消耗我可以为用户单独在云端开一个资源去承接所以对用户来说它其实是算力无感的叫消耗负载无感同时呢它对模型的调应因为是存云端的所以它的实时性会非常的高这是我们的三个优势吧那至于这三个优势呢其实我们打造了一款AP应用叫小影那这款小影呢除了刚才很多同学分享的生产力场景 知识库场景聊天场景以外呢我们其实还有四个稍微不一样的能力第一个能力呢是类似于微软的recall能力我们其实也做了个人用户的快速的历史行为的回溯以及快速的搜索而且这个呢不占用任何它电脑的资源和存储空间我在云端单独给它开了一个空间那这是第一个第二个呢我们还实现了快应用的业务流程处理那可以帮助用户很快速的快应用的完成很多繁琐的操作举个例子比如说报销比如说提报最近大学刚高考嘛提报我大学的各种资料它可以资助的帮助用户去提交这样的能力第三呢就是我们其实实现了端音协同的管理实际的行为我可以在管控台上实时的进行智能化的检测帮助用户和管理员提供非常快捷的解决方案最后呢实际上来说呢那个因为我们我们克服了端测的这个就是性能的开销所以我们其实做到了在任何端上它其实都是同样的体验就没有兼容性的这样的问题这是我们对产业化在大萌新这个浪潮中的一些思考最后呢其实从无影角度来说我们未来会做好两个开放第一个开放是把无影刚才我说的三个无论是在GuestOS系统级精神上还是在协议上还是在云测的弹性上这三个能力开放给合作伙伴让合作伙伴更好地基于我们这些能力在无影上打造AI的生态第二块呢就是让用户自己开放出来它里面的我们会有AI的各种工具的市场让用户自己去选择大概就是这样好的好的那我们也特别期待像无影这样的云原生云端一体的这样的一些产品借助于大模型这个时代可以大大的提高用户的效率然后在很多的娱乐场景中也可以提高用户的体验但其实在过去的一年的时间里面我们能看到非常多的一些创新的idea和更新的一些想法其实是来自于开源社区那我们也想问一下那个周文猛就是说在过去的这样一个时间里面然后怎么样通过开源社区和大模型的结合然后通过开源的工具然后来提升整个开发者的体验和提升对大模型的易用性这个你是怎么想的对 就是摩大社区其实去年一整年都围绕着LM和AIGC这样的两个核心技术再去不断地提供给社区的开发者们不管是大模型的推理微调或者评测这样的一系列的工具链让大家能够更好地把模型给它用起来那我觉得就是我们从用户的角度去考虑用户最多的需求是什么然后我们重点去投入什么这样的思路来去做那其实在现今的阶段应该是80%到90%的用户需求其实是直接调用模型不管是local的调用模型或者说远程的调用模型的API然后通过prompt engineering的方式来去完成一些业务上的事情那因此来说我们第一步做的其实是联合开源已有的这些推理引擎 包括像VMLama CPP 包括像Olama这样的一系列的工具让用户可以方便地把模型用起来 那第二步其实在一些锤类的场景用户可能需要自己的数据去做模型的反tuning去做模型的评测 最后再去做模型的上限 那围绕着这个我们其实来去做了一些非常简化易用的评测和训练的工具链方便用户在锤类的场景去使用另外还有一个在应用的场景刚刚漏题的就是RAG的场景RAG的场景其实现在也是非常主流的一个场景那在这个场景我们其实是通过联合像Lama CPPLama的index或者说Lanechain里边的这样的retrieval的模块让用户方便的把RAG的链路搭起来当然在开源设计和生产上可能会有一些不一样 就是生产上面可能会需要更多生产级别的RAG链路的高并发的支持那这个我们也是通过联合阿里云的云平台白链大模型开发平台上面去提供更扩展的RAG的能力来去方便企业级的用户去使用主要是这些 谢谢",
    "好的 好的 那我们今天的圆桌就到这里 谢谢大家谢谢",
    "好的 谢谢各位嘉宾请大家就坐嘉宾今天的分享和探讨让我们从不同维度对大模型开源生态有了更多的认识和思考那么今天我们的主题论坛到此也告一段落感谢大家的到来我们也为大家准备了一些小礼品券领取 也欢迎大家前往场馆阿里巴巴展区进一步了解阿里云在AI领域的先进技术和最新实践 谢谢大家",
    "谢谢大家谢谢大家"
]