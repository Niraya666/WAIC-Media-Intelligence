请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
欢迎大家来临2024世界人工智能大会智能计算与强化学习论坛的活动现场
很荣幸能够和大家共同见证智能计算与人工智能技术的新进展
本次论坛由世界人工智能大会组委会上海交通大学智能计算研究院山树科技联合举办
我是主持人曹依然
请允许我代表本次论坛的全体组委会对各位的到来表示热烈的欢迎和衷心的感谢
欢迎大家
当前智能计算正在成为时代刚需
电网 交通 金融 先进制造 供应链 工业软件等重要行业对智能计算软件的需求剧增
本次论坛活动旨在深入探讨
基于强化学习的智能算法研发历史与进展
展望智能计算的未来
如何与优化技术 GPU计算 强化学习 统计等方法相结合
以及在世界范围内的领先应用
下面请允许我为大家隆重介绍出席本次活动的嘉宾
他们分别是
斯坦福大学李国鼎奖习教授
上海交通大学访问奖习教授叶英宇
欢迎您
上海交通大学智能计算研究院院长
山树科技联合创始人首席科学家葛东东
欢迎您
纽约大学斯特仁商学院中生教授
计算机科学和数据科学中心教授陈希
欢迎您
普林斯顿大学中生教授
AI创新中心教授陈希
机器学习研究中心主任王梦迪
欢迎您
宾夕法尼亚大学沃顿商学院中生教授
机器学习研究中心主任苏伟杰
欢迎您
让我们用掌声再次欢迎所有到场的嘉宾和观众朋友们
接下来让我们进入论坛的主题分享环节
首先
有请斯坦福大学李国鼎奖旗教授
弗诺依曼理论获奖者
优化运筹领域领袖级学者叶英宇先生
他将为我们带来主题演讲
AI与数学优化
求解超大规模数学规划模型的新进展
好
掌声欢迎
谢谢大家
我跟大家汇报一些
我最近在AI和优化之间关系问题上的一些心得体会
和一些研究的成果跟大家分享
感谢这次大会给我这个机会
OK
这是介绍我自己
对上面提到弗诺依曼
我不知道大家知不知道弗诺依曼
这是计算机的顶尖
是吧
创造了计算机
其实弗诺依曼也是对AI也有贡献的
特别对数字经济
对均衡理论
说怎么样的
这样的方法上
其实我们引用的都还是他的那一套思路
OK
我跟大家介绍一下
什么叫做数学模型和规划
或者说规划有时候也叫优化
OK
提起这个数学规划
我们必须提到这几位人物
这个叫Coopman
这个叫Kantorovich
这两个人因为在
30年代40年代上世纪
发明了线性规划
或者叫线性优化
由此而获得了1975年的诺贝尔奖
经济学奖
OK
那么这两位得奖的时候
他们就邀请了中间的这个人
中间这个人叫谁呢
就叫George Danzig
这个人对线性规划的贡献
是什么呢
他提到的就是
他提到的就是
他提出了找出线性规划
或者现在叫训练的一个算法
叫单纯型法
所以当这两个人
创造了这个数学模型的时候
他们深感如果没有算法
这个都是一纸白文
都是纸上谈兵的事情
所以这样大家也知道
一个数学模型
或者一个大模型
或者一个语言模型
需要说明的
需要数据
需要模型
而且还需要算法
所以George Danzig提出这个算法的时候
还没有计算机
他的理念是
你哪怕用笔用纸
你也要征询一定的逻辑
把那个最优的方案找到
最好的解啊
找出来
所以他们就得到
他们当时就把George Danzig
也邀请到那个
Pottings上
他说You deserve the price
as much as we do
他认为他们也是资格的
那么一个数学规划呢
主要有三个要素
第一个就是数据
第二个就是变量
你能够做些什么
您能够改造那些变量的一些值
第三个就是目标
我们通常叫做目标函数
目标函数呢
可能有些人说
可能一需要最大化
也可能有时候需要最小化
那么第四个叫做约束
我不能为所欲为
我的决策一定要满足一定的物理
或者经济规律
而有时候还需要有些政策的约束
等等这样叫做约束
这个就是线性规划
X就是变量
A C B这都是数据
这个约束通过数学的表达式表达出来
比如说X必须在0和1之间
有时候X要么取0要么取1
这个application everywhere
最近也把X的变量
推广到矩阵上面
这个矩阵需要是一个半正定的对称的矩阵
通常把它叫半定线性规划
也是有很多很多用
这里我就不仔细讲了
我跟大家举个简单例子
这在我们优化的问题中
叫做背包问题
给了你一个可以承载5公斤的背包
给了你5个产品
每一个产品有数据
比如说第一个物品
2公斤重
可以值得18块美元
我一共有5个
那么我们的数学问题来了
我们的数学优化问题来了
你应该把哪个物件放在背包里
满足5公斤的重量约束
使得你总共的背包里面的价值最大
听懂了没有
再来决定放哪个
你就可以猜
你可以重启法案
每一个物品
有一个变量
0不放
1放进去
是不是每一个物品都有两种可行性呢
那么5个产品有多少种可能性呢
是不是2都5次方啊
那么大家再想想
如果我现在有几万个背包
像一个生产线一样的
我有几百个物件
需要在生前的背包里面
放进去
如果我现在有几万个生产线
需要放在背包里
放在背包里就是在那个生产线上进行生产
这可能性有多少啊
你解决不出来的
这必须要用数学的优化的方法
靠人类已经来不及
这个是海量的
是天文数字
当时我们也
我们一些山树科技的小伙伴也比较迷信那个大模型
当时
去年就问了大模型
他说
你看
这个就是把每个物件的属性都说出来了
背包一共存五件针
当时
插了GPT-4也回答了
他说这是一个经典的背包问题
可以用数学优化的问题来解决
然后怎么定义变量
怎么定义目标函数
怎么定义约束
最后他得出的结论是
求解结果表明
其实他没有求解
他说第3、第1、第3、第5个放进去最好
听懂了没有
1、3、5放进去
2和4不放
大家发现问题没有
这三件中六个问题了
这三件中六公斤
违背了五公斤的背包约束
当然插了GPT很会改正错误的
你稍微跟他提示一下
他会把它改过来
我在这里想说明一个什么问题呢
就是插了GPT这样的模型
它是给你一个近视的结
它不是给你一个科学的结
或者精美的结
或者100%正确的结
这是本身就是大模型
它不是基于一些规律
基于一些数学原理的
它是基于大量的精炼
这些东西的
所以这个错误是错误的
当然这个是很早产生的
就是想说明这一个问题
那么其实数学规划
就需要这种解
需要用一种精确的
需要基于逻辑的
基于规律的
基于数学的这样一个解
要不然我们就出错了
我们再回答一两个问题
产生一两个图片出错可以
但是如果这是一个非常精准的
需要完全100%正确的结
它可能会造成人命
可能造成其他的巨大损失的
所以我们必须要依赖数学规划
依赖刚才George Danzig的这个方法
说到George Danzig
就是刚才中间那个人
我是82年到美国去读书的
那个时候能工智能很火
叫专家系统
我们搞了很久
我当时就跟我们斯坦福大学的一个华人教授
叫谢德森搞专家系统
那位专家呢
他想当时在82年的时候
比如Simon
Cognitive Psychology
他想搞一个中医的专家系统
结果我们到去
但是那个时候没有数据
他说没有数据
你可以走出去
到那个什么三藩市的那些中医学堂
去找那些中医们
去让他给我们提供一些这样的数据
提供一些他的那个知识经验
结果我还果然去了
去问老中医
结果老中医没有出来
他儿子出来了
对不起
祖传秘方
天机不可外露
我不能告诉我父亲的这些机密
所以当时专家系统搞不下去
没有数据了
所以在毛泽东以上
现在之所以能工智能发展得很快
实际是产生了大量的数据
这个需要感觉
有很多数据都出来了
我没办法
当时没有数据
专家系统搞不下去
转头就搞了优化
跟那George Danzig
就去搞线性规划
而且当时搞线性规划呢
特别火
当时出来一个内典法
什么东西
所以就跟大家讲一讲
所以优化是依靠数据
AI需要数据
当然还需要善力
其实还有一个
主要的方法就是算法
其实本身大模型的训练
就是在解一个优化的囚犬
它也有变量
也有目标函数
也有各种各样的一些约束
条件等等这样的东西
大家也知道神经网络
神经网络它主要就是要调参
每一个参上的参数
怎么调到最佳
使我的一个损失函数的值最小
通过大量的数据放在一起
所以在矛盾意义上
大模型的训练
本身就是一个优化问题
它的变量就是神经网络的各种参数
它的目标就是让它
使得它的答案最佳
OK
我们最近
我不知道大家
可能大家只关注大模型的功能
没有功能大模型是怎么训练的
它解的优化问题
现在用的最多的
是一个算法叫ADAM
比如说这是一个喇嘛
7个billion的工作
它通常要12个
2乘以8 16个billion的数据
所以它每一个数据有4个bytes
就28个GB
加起来总共需要86个GB
才能把数据乘下去
为什么现在GPU解不了
必须用GPU
因为它存储空间大一些
精度不需要那么高
这是在800上面
我不知道大家知不知道
像训练一样
像训练一个大模型
现在需要的时间是month
按月来计算的
需要用到大量的电力
才能做一个预训练
这个和我们当时解一个大规模的
线性规划所需要的时间差不多
等一下我会讲一讲
现在我们解同样规模的线性规划
已经从月提高为秒
所以我的感觉是
虽然大模型很火
但它目前的训练方法是不可持续的
需要大量的人力物力财力
而且特别是能源的消费
这里面我就举了GPU support training
现在大家都想怎么提高这个ADAM呢
想了很多很多年了
想了很多方法
怎么把时间手挡
但是有些方法现在都没有成功
最近我们做了一个工作
因为我们懂优化
我们就把它的目标函数拿出来
就发现它有些规律
这个搞优化的人都知道
一个目标函数它有梯度
还有那个hashing证
它的hashing呢
几乎是一个block diagonal
这个可能和它的层一层一层的有关系的
就基于这个思想方法
因为ADAM为什么用得好啊
因为它就是用了
它有个scanning
你可以把scanning看成是一个preconditional diagonal
那么既然我们找到了规矩
我们就能够找到更好的preconditional
用更好的scanning
而且这个scanning不需要那么dense
那么一个block
而且每个block之间的东西都非常均匀的
它只是block block之间不同
那么我们不需要把block中间的每一个东西都要scanning
我们只要把那整个block矩阵
加一个scanning就可以了
就这么加上我们建立了自己
叫ADAM mini
已经可以降低了三分之一的时间
也就是说原来需要三个月的
一个月现在够了
这个已经被其他的individually verified
我们自己文章也挂出去了
你可以试试
save memory by 45-50%
降了一半
为什么
原来要乘两个大向量的
现在是需要乘一个就可以了
另一个只需要成立几个数就可以了
and achieve 50% higher throughput
让ADAM
现在大家都在用的
W
在喇嘛的那个7B的那个pretraining上
我想表达什么意思
优化是可以为AI起作用的
而且AI也需要依赖于优化
特别是一种比较efficient的优化
那么优化还用到哪里呀
航空
特别是载能飞船的回收技术
在最后一分钟的时间
要是能够安全的回答
原来一样mask的star X
总是失败
后来成功了
用了什么技术啊
用了优化
就是数学规划的技术
特别和Stanford这边是有一定关系的
我们都碰到
做了一个远应结合的一个求解器
是解一个二阶规划的问题
不单的调节速度
不单的调节
而且是实时的优化
是要微秒集中间要做去决策的
这个时候你不可能去问大模型的
你说我现在要把角度调到多少啊
来不及的
模型就已经产生了
人工对话的这个控制系统
你想想以后要打仗了
指挥官还问问大模型
我现在应该把这个问题A部队布置到哪里
我的那个无人机现在要飞到哪里
全部都要自动化的
都要通过数学模型进行调配
非常高兴
听说在国内
三数科技也把它用在国内
这个非常长
这个葛老师到时候会给大家讲一讲
还可以用什么东西啊
电网的调度
我不知道大家知不知道电网是怎么平衡的
经济中最大的一个规律
或者物理中的最大规律是什么
你发的电和需要的电要平衡
怎么达到平衡呢
我要通过调度
开哪些 关哪些
风电那边送多少
火电送多少
水电送多少
闸门开多大
全部都要调配的
多少的变量啊
上亿的变量
达到那个平衡
微网 各种各样的东西
同样的
你说完全靠大模型行吗
你问一答
明天上海气温
达到39度
你觉得我们要哪台机器开
哪台机器关
它可能会给你个粗略的
但是达不到实时的控制
平衡
非常高兴
南方电网
现在用上了
优化球解器
而这些优化球解器呀
原来在各个行业中
已经在欧美
已经是广泛使用的
OK
比如说电网
我们国家电网现在用的
都是国外的球解器
不是说不用
确实用
排产
华为原来就是用的
IBM的球解器
或者调配系统
这个各种各样的系统吧
我不知道
轨迹控制
刚才我提到了
生产计划
化工生产计划
大家用的最多的软件
叫什么
叫Aspen
Aspen中间的核心是什么
求解一个非线性的优化问题
大家还知道
我们芯片比较落后
大家只觉得我们工艺落后
其实我们在设计上也落后
而设计中的关键是什么
优化球解
各种各样的几何尺寸
各种各样的参数
包括路径怎么走
电板怎么排
都需要球解器
不是不用
不是我们不知道
我们原来完全的依赖国外的
但现在问题来了
2019
华为的球解器不让用了
整个就熄火了
这时候找到了我们
因为
当时我跟华为的
几位高中人都还挺熟的
郭平啊
包括任正非啊
他们经常去斯坦福
其实他们很崇洋的
经常去我们那里
特别是当时跟思科打官司
我不知道大家听说过这个事情
当时因为
所以经常去
结果他知道我搞现行规划
就找到我们
能不能赶快把这个球解器顶上去
花了半年时间
果然
我们搞出了自己的球解器
而且帮助华为度过了难关
当时发现不光顶上去了
而且用的比原来还好
为什么
我们给它给的是原程序
IBM给你的都是一个黑箱
你要适应它的水土
而不是让球解器
适应你生产的水土
或者生态环境
这个之间时间差别就非常非常大了
光数据传输啊
原来是要通过文件传输的
现在通过代码
就可以直接进来了
这也是为什么
在2019年
我们推出了
当然有各种各样的应用
这个跟老师到时候自己讲一讲
还有包括陈希老师啊
苏老师啊
等等都会讲
所以我跟大家总结一下
数学建模
或者数学优化的计算
和大模型它能够起的应用的
之间的一些区别
我们认为是基于科学和逻辑
而那边更多的是基于知识和经验
我们是要有一套物理
或者经济
或者数学的规律
原理的
你说自由落体
是吧
那个二分之一几
什么平方的这个
是牛顿观察了好久发现出来的
那已经形成一个定理了
那个物理规律必须征询的
OK
但这边的更多是观察和行为
应该说这个还是比较客观的
那个是比较主观的
现在实际上很多主观的
最后是human feedback
是要靠能耐决定
哪个好哪个坏的
我们是比较确定的
那个是基于概念的
刚才几位老师下面还会讲
因为我们是依照物理和经济规律的
它的得出来结果是可以解释的
而那边多半是黑箱的
我们可以用到在线决策
那个多半是离线训练几个月
我们需要高精度
超速度
那边可以慢节奏
低精度也可以
是吧
不是人命关天的事情
谁好谁坏
没有谁好谁坏
我的观点是
互补要结合
有些也确实不是
有些本身就不是善事的东西
确实需要人的经验去建模的
但是一旦有了一定的
有了规律的话
我们就尽量用数学和物理
这是人家几千年几千年
总结出的一些规律的东西了
是放置四海而皆准的东西
你尽量用还是要用
然后你再去重新训练
重新找
这里我就
结果斯坦福最近做了很多工作
就是在这两个方面怎么结合
这个郭老师会进一步介绍的
我就不详细讲了
特别最近有几篇文章
在怎么用数学
因为我们后来在实践中发现有很多问题
他对数学模型不是很懂
这些不懂的东西
正好我们可以通过
大模型帮助
帮你一个实际问题
怎么建立成数学模型的问题
大家也知道
我全国有多少中学生
参加数学建模比赛
这些建模比赛
说不定以后都可以通过大模型
把它代替了
所以这点
我不是说不重要
是非常必要的
所以就是怎么结合起来
这里比如说刚才的背包问题
我们演示一下吧
现在三数做了一个通过大模型建模的
对比PPT中简单的装箱问题
使用ChatGPT3.5得出的答案并不理想
现在我们向小欧抛出一个更为复杂的同类型问题
这里小欧智能助手正在给出详细的模型建议
不仅如此
小欧还输出了直接可运行的代码
使用配套COPT球解器进行高效球解
通过这样一个简单的例子
可以看出
当与GPT面对同样的情况
小欧不仅可以写对模型
还能够调用更加专业化的软件
处理约束限制更多
规模更大的复杂问题
大家想想
一个生产线
几万个生产线
几百万个物件
怎么在上面拍
怎么去装
这个不是靠人可以达成的
也不是大模型可以凭经验制
它本身是有数学规律的
我可以用线性规划
刚才要把它球解出来
球解器我们追求的是什么
准确
速度
大家也想想
南方电网
要排产
或者排生产线
有的地方是一周排一次
为什么
球解器跟不上来
我们要是能够把一周的时间
放在一天的时间
就把它排成完了
我每天都可以重排
我能够处理那些不确定状况的前景
效率是不是大得提高了
因为计划永远赶不上变化
你只有靠计划的快速性
来比较环境的动态性
和不确定性
所以我们在球解器上
一直追求速度
OK
那么这个球解器
实际上刚才说了
39年人家发明了线性规划
79年芝加哥大学
首次提出了球解器
就变成一个商业软件
或者通用软件
来帮你球解
这大家上课都知道
如果大家上线性规划
可能都用过Lingo
然后83年
爱登堡
808年
2011年
我们国内有了
开源的数学球解器
就是把公式啊什么放进去
拔上9
让它自动算出来
19年
从此我们有了自己的商业
这是国内第一次
有了自己的商业球解器
为什么2019年呢
就是因为我们帮助华为
解决了问题以后
我们觉得国内有这个需求
就在下半年
自己推出了自己的商业球解器
这个是这里面的
规划球解器的各种各样的东西
只是说非常sad的
这个方面呢
跟芯片一样
95%原来都是控制在欧美的
那么经过这么几年的放大
国内的球解器
到底是个什么水准呢
我跟大家讲一讲
这是一个有个创
因为这是一个客观的计算问题
美国建立了上千个数据库
每个月各种各样的球解器
在那里进行一个测试
解的速度是多少
比如说
Copt是我们国产的球解器
一是什么意思
你可以理解
这些问题平均解球解的时间是一秒钟
那么第二个最好的是什么
1.29什么意思啊
它比第一位的慢30%
听懂了没有
所以这都是一个答榜表
我们数学问题球解问题
有各种各样不同的问题
有的是线性规划的
有的是Facebook的问题
各种各样的东西
这里面还有很多
但是我必须说了
有一类问题
现在国内的球解器是排名第二位
是1.44第一位的
还是Globe
是美国的一个球解器
但是用的很多
但是现在也是不断地在进行追赶
在其他一些问题上
现在国内的球解器几乎都是世界第一
混合忍受这个方面也是第二
几乎是要么第一要么第二
用他们的说呢
就是拿了十几个金牌
还有好多银牌
那么现实中的问题负担性
还在迅速增长
有些问题我们现在还解决不了
目前的计算体系还解决不了
你比如说
这是一个典型的欧洲物流问题
十几年提出来的
我们一直解不动它
太大了
还有谷歌的page rank问题
我们现在
你比如说这个问题解了59400秒才解出来
而且是最近解出来的
其他这些问题都解不了
这个是蓝网的
就是我刚才说电力调度的优化问题
这个需要1951秒
什么意思
需要20分钟才能够把它调度出来
要是我们能够把速度
舒展到一分钟以内
那我们可以重新调度
因为情况总在不断地变化
需求总在不断地变化
我们现在做了一个什么尝试啊
既然大模型的训练可以用GPU
我们优化是不是也可以用GPU啊
把我们的优化在GPU上实现
这个在国外认为是不可能的
国外认为是不可能的
因为优化的计算需要高性能
高准确性
而我们的GPU通常那个floating point都比较低
整个16位啊或者什么32位就已经到底了
但是我们提出了一些远应结合的思想
非常高兴大家
59400秒的这个问题
我们现在916秒就可以解出来
所有这些原来解不下来的问题都可以解出来
难完的问题需要千秒的
百秒就可以解出来
我们还在不断地耕耘
不断地改进
这些都是实打实的
可以节省经济
节省效率的
去理一些环境的
所以
OK
大家刚才说的是依靠GPU
那么不依靠硬件的发展
软件还有什么算法
还有没有新的突破呢
刚才那个结果啊
确实是我们是
10月份
去年10月份公布的
迅速地引起了世界的一些瞩目
2030年英伟达GTC
他们也开发了自己依赖于GPU的线性球件
我们的工作是和一个芝加哥大学
当前在MIT跟卢教授一起合作的
我们都是开源地放到网上的
结果有的学生看了一下
他们的那个
基本上和我们是一样的
所以这在我来说是第一次
黄老板要学我们的东西
他这个人
我在斯坦福尔
我的那个building就是接生黄娟的
五年前还不是怎么样
现在很伟大不得了
但是他们现在也像
借这个GPU的那个仕途
尽量用一些软件开发在上面
做一些延伸的应用
这是他们讲的
这个也报道了这个
斯坦福尔当时也报道了
那么现在我们不光是在
在现行规划上
在其他方法
有些算力是提高了60倍
百倍
甚至提高了万倍
我跟大家
对
我跟大家举个例子
就是刚才那个欧洲的最大物流问题
3000万个变量
2000万个约束
变量
很多很多
这个问题
20
那个
提出来的时候
提出来先改不了
后来到了2009年的时候
终于解出来的
139天
花了4个多月
就是我刚才说的
10年以后
通过远应的结合
16个小时可以解出来
在我们刚刚发布的那个软件上
只用了27分钟
就解出来了
我刚才讲的
每一个时间的提高
就意味着经济的节省
能源的节省
环境的改变
如果放在大的范围上
不光是经济效益的话
社会效益也是很大的
我再跟大家讲一个SDP的问题
这个SDP从来认为不可能解到上万维的
原来解一个千维的时候需要5分钟
我们后来开发了一个软件
可以解到两千维
这是我的一个学生在Argon Lab解的
用了4分钟
那么如果你要解到5000以上的
非常非常难
8分钟
30到50个小时
解一个
解一个一千万乘以一千万维数的矩阵
那么现在我们需要动作早
我们是需要两分
两秒钟就可以解出来
这是对我来说是amazing
我没有想到
这个半点规划是我
也属于开创者之一
发明这个模型的之一
我从来没有想到半点规划可以解到这个规划
我认为在我的lifetime中间解不到这么高位的
现在解出来了
而这个半点规划实际上在很多量子计算的
包括很多很多这种物理计算的中间
都是非常有用的
特别是一些高性能的规划
那么大家可能说
这都是依赖硬件的改进而提速的
纯优化
纯理论
纯算法的
通过人的智慧
把算法改进的
而不应该的
而不依赖于硬件
它的中用在哪里
它的作用在多少啊
我现在就用他们参数科技的
从第一版
到现在的第七版
是不是啊
每年的速度
从第一版到第七版
现在已经提高了
速度提高了3.5倍
原来需要3.5个小时的
现在一个小时就可以了
这是完全不依赖于硬件的
我们是同样的版本的算法
放在同一个机上进行限制
我讲这个是讲什么
硬件不够
软件是可以补的
通过人的智慧
通过算法的改进和设计
人家不给你芯片
不给你H100
不给你A100
你可以在算法上去
就像我刚才说的那个大模型
我们就轻轻地用很传统的优化方法
改了一下速度
减少了三分之一
不依赖于硬件的
完全是愚人的智慧
所以在这个SDP
推出两年
速度已经提高到两倍
OK啊
我知道大家知道
在芯片设计中有个什么MORE LAW
每次都可以降低一半的
我是希望全世界
在优化算法的投入上
能够继续
使得我们优化算法
不赖于硬件的改进
每年也可以提高一倍
那些就好了
我们就可以解决很多问题了
总的来说吧
对我来说
数学优化
对我来说是非常重要的
我很热爱这个学术科目
所以我做一说
线性规划万岁
它是上世纪三十年代提出来的
直到今天
还用在各种各样的东西
而且用在非常重要的东西
像我们斯坦福专门有一个叫
钢移植配对的
钢移植怎么配对呀
线性规划
现在都用这个线性规划来进行配对了
所以不光是经济效应
不光是那个图片看得精美一些
不过是看得更生动一些
它确实影响人的生命
影响人的生活
所以最后谢谢大家
谢谢
感谢叶教授的精彩分享
为我们展示了
在球解处理复杂数学规划问题上的
最新技术突破
为该领域的研究和应用
提供了宝贵的思路
放眼全球
COPD球解器团队
已经基于新的GPU架构
开展了一系列开发与建设工作
并将球解器与大模型决策平台结合
形成了一套全新的运筹学
教学与工具应用系统
接下来
让我们用热烈的掌声
欢迎上海交通大学
智能计算研究院院长
山树科技联合创始人
首席科学家葛东东先生
为我们带来主题演讲
智能计算与大模型决策
理论与实践
掌声有请葛院长
好 谢谢大家
这个非常荣幸啊
有这个机会
来跟大家分享
我这个
其实就跟叶老师
这个等于是接着讲
接着往下讲
就是说我们这考虑的
这个就是我们主要考虑的
就两件事情
因为刚才叶老师也提到
实际上我们做这个
人工智能嘛
人工智能最重要的一件事情
就是做到现在
从十年前大模型兴起到现在嘛
最重要一件事情
落地场景在哪里
对吧
落地场景在哪里
就十年前
就是有这个大数据AI
这些东西第一次兴起的时候
大家考虑的一个问题就是说
它能解哪一些问题
到底在现实中有什么用处是吧
十年过去了嘛
就是说大家看到的
可能用的最多的还是
比如说像视觉识别啊
就这些是吧
就相对来说就是
不是特别多的行业把这个用上去了
现在像大模型兴起以后
也有同样的问题是吧
今天早上我还看到说
很多大模型公司
这个下一轮又融不到钱了嘛是吧
原因就是没有一个好的适用场景
但刚才也说到
叶老师也介绍了就是在现实中
其实我们有很多行业呢
它是需要大量的
这种基于数据的去进行这种复杂决策的能力的
对吧
那这些行业呢
就是说
很难程度上就是说
我们就是直接的去用一些
最直接的比方去做一个回归啊
做一个预测啊
这些事情呢
它不能马上直接解决问题是吧
原因就是这些问题过于复杂
对吧
它是一个现实中的问题
叶老师举的比方说
这种物流问题啊
华为的生产问题啊
就这些问题为什么就是说AI帮不上忙呢
或者说能帮上忙的幅度很小
一个很大的原因就是说
这些问题它很多的系统很复杂
对吧
就你把数据分析完以后
它变成一个各种约束互相制约
比方说有几千万条约束互相制约的一个问题了
本质上就是这些问题呢
就是说你去做任何一个决策的时候
单纯的去靠
比方说AI方法去做一个预测是不够的
就是预测这些东西呢
往往会破坏这个
比方说这些约束性
破坏这个问题的feasibility
所以这种情况啊
就是说你还是要
就是说多种方法结合嘛
就是特别是就是说
我们有很多这种优化的方法
怎么跟AI的方法去结合
包括这个
刚才提到说算法的结合
另外就是比方说优化这些年
就是说芯片这个
像GPU这个算力这个发展也很快
你怎么能够优化这些方法
怎么能用上这些硬件
真正把这些硬件用起来
这是我们最近在考虑的一些问题嘛
然后就大模型
因为就刚才说的
本身大模型目前这个处理这种
非常复杂的这种决策问题
它能帮上多大忙
这也是我们在思考一些问题
所以在我们今天
我主要就是汇报这两件事情嘛
就是说
这是我本人
就汇报两件事情
就是说一件就是说
就当我们解决一个问题
首先我们要建模对吧
就是建模这个事情
就是我待会会谈到
就是说我大模型
能不能帮助我去建模
另外一件事情就是计算
当我建完模型以后
这个复杂的系统问题
我怎么去求解它
就这两件事情
我们今天就简单讲一下
我们就是交代这个
我们这个智能计算研究院在做的
就是说我们本身呢就是说
这也提到是
我们在上海交通大学
有一个叫智能计算的研究院
我们这个研究院主要就是解决这两件事情的
这我们就是刚才叶老师也讲到
就是说我们开发过一个
或者正在开发一个
叫做COPT的一个求解器
这个求解器目前的
从水准上讲嘛
基本上你想线性目前是第一
此前一直是美国第一嘛
然后非线性是第二
就是这个还是比较成熟的一个
相对来说已经比较成熟的软件了
但这个软件它有个什么问题呢
就是
就是说所有的计算架构在
其实一直在去年之前吧
去年之前
二三年底之前
所有的这个
这个叫做数学规划
数学优化
我们做这个事情
这个叫三数科技来开发的
开发了这么七年
七年中无数投资人问我一个问题
说你这个东西为啥不能用GPU
为什么不能用GPU
为什么就在CPU上跑
而且这种计算软件
传统上不光是这个数学规划
有很多高精度的计算的这个软件
像流体力学啊
就里头有很多问题呢
如果你不用AI的话
就是说有这些软件呢
专用的一些计算软件
你会发现它都是用CPU架构的
都是用CPU架构的
就是说这种高精度
高复杂度的这种科学计算呢
很多时候呢就是说
GPU帮不上忙
就是GPU帮不上忙
帮不上忙的原因就是
我这也列了
就CPU和GPU之间这个
天然它们物理性质
带来它们能力上的一些差别
这大家想必下面听众很多也比较清楚了
所以就是我这列了几点
我是说这个
我当时跟这些几百号投资人
我讲同样的话
我讲了很多遍
就是说GPU这个事呢
对这种像数学优化算法
这些比较复杂的数学运算呢
它不友好
都不友好
我这写了比方说
我们最经常用到的
一阶算法二阶算法
和这个整数规划属于离散优化
是吧
这几个范畴它都不友好
是吧
当然大家说那不是用的
都是一阶算法吗
现实中是吧
现实中是用了一阶算法
但大多数这个机器学习的问题嘛
它本身就是一个预测
或者说它本身一个近似的
在这种情况下
你只要找一个近似级
而且对那个最后的收敛精度
要求不高的情况下
那一阶算法是很好的
是吧
但在我刚才讲到
我们做很多高科技
就科学运算
我们做的是科学运算
你比如说线性规划
刚才也是讲的
是吧
最后我们的收敛标准
要达到负6
一般要达到10的负6
负7才算收敛
甚至要达到10的负9次方
是吧
那GPU呢
它物理特性决定了
它本身它计算精度
只能达到10的负4次方
所以就无论如何
它在这个事上是做不好的
以前我们一直是这么想的
是吧
一直是这么想的
但是去年底以后呢
就是刚才叶老师也提到了
就是说它出现了一些变化
是吧
就是说这是
就是说它本来是做不好的
是吧
现在我们发现说
这个去年底的时候
做了就是说第一个
这个世界上的第一个
就是用GPU架构去做这个
线性规划的计算的
然后就以前解不出来的问题
解出来了
然后以前几万秒的
变成几百秒能解了
是吧
刚才叶老师也提到说
一个五百秒
五万九千秒了吧
是吧
最后变成了916秒
把它算出来了
对
所以就是说这个就是说
就CPU加GPU这个议构体系下
我们去做这个事情
是吧
然后刚才叶老师也提到
就是说有另外两类问题
一类是这个半征定规划
是吧
就原来是解了几万
是吧
现在能解了1.4亿乘1.4亿了
是吧
这个是非常
一个结果嘛
是吧
然后还有QCP
就是用二次图规划
二次图规划
你用这个CPU解的话
就是说
这我们有一个
比较是吧
就是说你看这个
当问题比较大了
十万维的时候
就基本上就time limit
就是7200秒
两个小时
它算不出来了
它用我们传统的求解器
然后到了100万维的时候
它直接就内存溢出了
是吧
那这些问题呢
你现在发现说
在GPU上去跑的话
我们就1.7秒
还是8秒钟
就能跑出来了
是吧
所以都是非常惊人的一些进展
是吧
这些进展呢
其实就是说
它发生在这个
就发生在最近嘛
是吧
就发生在最近
10月份就是说
我们第一件
就刚才提到
第一个PDRP嘛
这个
有一个一阶算法
是吧
用这个
用CUDA来
和这个GPU和CUDA来实现
是吧
最开始是我们那个
芝加哥大学一个姓鲁的
是吧
罗海浩老师做出来的
是吧
就是他是
当然罗老师做了以后呢
他因为他不太擅长工程实现
所以就找了我们
把这个
就是用专业软件
把它重写了
是吧
写了以后
发现这个效果是非常好的
是吧
拜托于罗老师
也是我们以前的学生
是吧
也是我们教大的学生
是吧
对
然后就这些东西呢
就是大家还是比较关注的
不管英伟达
还是这个斯坦福
都做了一些报导
是吧
所以我想说
你看到
就是这个事情
去年十一月份开始
到现在
半年功夫
是吧
发生了非常多的进展
是吧
这些进展
就是爆发式的增长
所以这个爆发式的增长
就意味着什么事情
就是说
你会发现说
这个
这种高精度
高性能的计算呢
它正在发生一个
科学范式的转变
从一个CPU为主的
为主要的这个算力基础
一定会发生的事情
对高精度
高性能计算来说
是吧
这样我也写了
英伟达做了很多事情
是吧
英伟达他发布了这个
QOPT
这个就是
贝斯在我们那个
秋节期上
刚才写了这个上
写的时候
然后英伟达
还做了两件事情
一个是他发布了一个
酷函数叫QDAS
这QDAS很重要
为什么很重要呢
就QDAS是能够
实现矩阵分解
就是我刚才讲到
就是所有的
我们这个数学优化里面
有两大类算法
是用的最多的
一类是只用T度信息的
是吧
在机器学习里
最常见的算法
第二类就是说
我们用的比较多的
就二阶算法
它要用到矩阵的
这个问题
往往会用到矩阵的
问题的
比方说那个
海森矩阵
海星metrics
二阶导数是吧
所以呢这些呢就是
最后往往要
要对应牛顿法
内点法
这些都要解一个
现行系统
那往往对应的
要解 做一个矩阵求逆
矩阵求逆这个事情呢
是所有二阶算法的base
但这个事情呢
GPU上始终实现不了
高速并行
十几年前
我跟叶老师最开始
我们就在
当时最
第一个想法
要做求解期的时候
我们就第一个
当时第一个想法
其实就想到说
为什么不用GPU
对吧
实现一个弯道超车
所以我们当时
就跟英伟达联系过
十三年前
我记得是
还是十二年前
但是英伟达就跟我们说
说我们也不知道
这个事情怎么办
就是GPU怎么在
矩阵求逆这个事情
怎么在
或者矩阵分解
这个事情
怎么在这个GPU上
实现一个高速并行
对
所以我们这个事情
其实十来年前
现在我们发现
英伟达
就是今年四月份
他终于做了
叫你做了一个
叫Kudas的函数
能够实现矩阵分解
我们现在去测了以后
发现说他这个性能
不是特别好
能做一些问题
在一些问题上
他跑得比
明显比CPU快
但是还有很多问题
跑得不如CPU
包括他这个性能不稳定
就每次输出的结果
不是比较随机
就每次分解的结果
比较随机
然后他也没有实现
这种多卡并联
只能在一个单卡上实现
所以目前
就英伟达也在
找我们讨论
说这个事情接着怎么做
也希望我们帮助他们
一起合作
继续做这个事情
就是
所以就这个事情
也是英伟达非常关注
当然大家也知道
就是他发布了这个
像B200这种新的架构
就是我刚才说
我们未来这个
计算趋势的发展
是从CPU
向这个CPU加GPU
这个混合架构发展
这个混合架构
并不是一个固定的
而是这个CPU和GPU
因为这个东西
它以后会怎么发展
你也不知道
从A100到B200
我看到就是说
CPU和GPU
这个数据传输速度
好像从15GB
变成了450GB一秒
所以它提升了30倍
这就意味着
以前我们发现
我们当时跟卢海浩去做
这个第一个
现行规划的时候
发现最大的一个问题
就是CPU和GPU之间交换
占了86%的运行时间
所以假如你这个东西
假如快了30倍
那这个Bottleneck
就不存在了
其实我们当时
就不用大费周折
去写很多特殊的算法了
那接下来就是
还有一个就是
大家提的
不管是我们这儿
还是英伟达
上海市也好称说
在做一个弯道超车的硬件
就是我听下来
可能跟英伟达的
一些想法比较像
就是我让这个CPU和GPU呢
共享一个计算显存
谁用谁去取
这样就完全不存在
一个数据传输的
这个Bottleneck
这个设计不存在了
所以在将来
如果发生这种事情
你现在设计的算法
到时候又要重新去
重新设计
所以就是说
这是一个动态的过程
不停在演进
不停在
你要跟着这个硬件走
去设计更高效的
这个做法的
所以这是很有意思的
一个问题
很有意思的一个问题
目前这块就是
关注的人不是特别多
就是我们跟芝加哥
还有MIT
还有英伟达几家
在这儿做
目前我们做的东西
应该是最多的
应该是最多的
但现在就是有一个问题
就是说
所有的东西都是在
英伟达的芯片上实现的
没有在国产芯片上做
对吧
就是依存在英伟达
那个库达架构
所以这个问题就是说
有两件事情
机遇有了
机遇就是说
它正在发生这个范式转变
而这个东西呢
对应的就是
真正的是
有很多实际场景
叶老师刚才讲了几个场景
国防
这个航空
航天
交通
物流
能源
电网
供应链
智能制造
包括工业软件设计
就是我们做过200
大概做过280多家企业
中国所有的头部企业
我们基本上都打过交道
都做过生意很多
然后从这里头讲
我们这个东西呢
其实是
用户范围是非常非常广的
不是一个简单的视觉识别
那么狭窄的
但是就是说
就是说这个东西呢
就是它非常依赖这个计算
然后这个计算
我说了
它发生一个范式转变
这个是必须把握住的一个机会
但同时呢
我们比较受制于硬件
硬件呢就是说
它有一些特殊性
你比如说
它一定要FP64
双精度
那国内现在
连华为都只有单精度
国内目前
只有一家公司
有自主的产权的
这个双精度芯片
然后呢
就是说
性能比较差
相当于A6000的70%
然后真正跑起来呢
酷寒数
你比如说
比较成熟是矩阵计算
对吧
是很成熟的
然后国产的这个
他们对应的酷寒数呢
我们测了两家
这个具有双精度能力的芯片
自主知识产权那家
它那个酷寒数
大概比英伟达同样的事
卖了18倍
另外一家买的是
那个AMD技术的
它卖了160倍
所以就是说
这种本来
应该很成熟的酷寒数
国内的这些
国内这些GPU厂商
都做得还是很差的
然后像这种
英伟达做的
第一个矩阵分解
这种酷寒数呢
国内是完全没有的
也完全没有这个能力的
我们做的
我们团队正在做
也做了一个
但是还是比酷寒数卖很多
我们正在尝试把它加速
这是我们最近的
很重要的一个工作
所以就是说
这个我们
我在交大嘛
交大这边
我们跟计算机这边
有很多老师做
像Alex良
有很多很有名的专家
做计算机体系架构的
大家跟我讨论
大家一个共同的观点
就是说
其实我们在GPU
这个硬件上的差距
没有大家想象的那么大
就基本上是
绝大部分是够用的
其实最大的一个问题
就是这个酷寒生态
跟中国的这个生态问题
就说白了就是说
这块的
像数字底层的这些
数字函数计算
这些算子
完全是非常空白的一个状态
这个差距是更大的
就软件
就是底层的这个酷寒数建设
这是其实最致命的一个差距
反而不是硬件
反而不是硬件
这是我们交大老师们的
一致共识
所以从这点上讲
这些事情是非常需要去做的
这是我们智能计算研究院
上海市分配给我们的一个任务
就是说
主要是承担去建设
这些底层的最基本的
这些数字计算的算子
对
所以这就是说
我们就是说
这个东西就是我们目前
要去解决的一个问题
因为我们这个计算院是今年
今年年初刚成立的
就是也是借这个机会
去汇报一下我们做些什么事情
我们主要就是说
在目前这个计算范式发生
这个一个大的变化的情况下
那我们是不是应该去做
这一整套新的理论
该怎么去设计
这是我们主要的一个使命
也是希望说
市里头也是说
国家也是希望说
我们去把这个这方面的
这个软件做好
这样的话我们在硬件
因为未来很长一段时间
我们肯定只能依赖
国产的GPU硬件
那我们怎么在依赖
国产硬件的基础上
来弥补这个它硬件这个短板
是吧
就是说能够让这个软硬一体化以后
别比人家英伟达那套差太远
是吧
不能指望说做的
像人家那么好吧
是吧
就不要被人家拉下
先咬住是吧
等待这个硬件这个差距上来是吧
对
再我就简单说一下
刚才你像叶老师说的
就是那几个case下
就是它那个加速效果怎么实现的
我这儿列了一些
比方说
这是我们develop的几个
你像这个是线性
这是S2
这是这个半征定是吧
每一个它都采用了一些新的
这个一些方法
或者说以前CPU的一些方法
我们把它重构了一遍是吧
做了很多理论上的工作是吧
所以它不是一个简单的
这个测算的工作
而是要重新设计很多里头
比较复杂的一些数学步骤是吧
这反正都有
这几个关键词大家可以上网搜
我们都写了paper
也都放到iCloud
在CAP上开源了
给大家参考是吧
给大家参考
对 这儿也简单写了一些
比方说一阶算法
正常情况下
解一个大的计算问题
大概是这么一个流程是吧
然后我们现在发现说
在我们新的这套体系上
它有要加很多新东西是吧
要加很多新东西
这些东西就是解决
比如说它有几个大问题
一个是一阶算法
它那个
假如你要去做一个混合架构的时候
它们之间的协调机制
CPU和GPU是吧
有些工作CPU做
有些工作GPU做是吧
它们之间有延迟是吧
有这个通讯问题是吧
有延迟问题是吧
就这些异步问题
这些你怎么去构建是吧
第二点就是
比方说它那个
一阶算法的很大一个问题
就是数值复杂的问题
它做不好是吧
就是数值困难的问题呢
它往往就不收敛了
所以这种情况下
你对这些数值困难的问题
你怎么去处理它是吧
这是另外一个
对一阶算法必须要克服的
所以你这个时候
问题进来以后
你进行这种欲求解是吧
中间去做这个收敛
这个分析步骤
这些事情都需要重构是吧
跟那个CPU
实在是完全不一样的一套体系了
对
对
包括整数规划
我刚才叶老师也提到
其实就现实中
大家遇到了
就真实的
我刚才说200多家企业
其中这些你会发现
80%的问题
是来自于整数规划的
这是非常困难的一类问题是吧
这类问题就是说
你需要去想很多办法
对这类问题来说
AI怎么帮助它是吧
其实有三个途径是吧
第一个就是说
用GPU来加速是吧
刚才我也讲了
就是它整数规划
天生这个对GPU不友好
所以
GPU加速它不太好加速
但是它也有一些方法
你比如说
整数规划每一步
要先解一个线性规划
就作为子程序
反复调用是吧
那你这个线性规划
你又可以用GPU来解是吧
但是GPU解完以后呢
它那个解呢
就GPU你用一阶算法解出来
那个线性规划最后解了
那个解了
它虽然是最后
但是其他性质很不好
这种情况
你怎么把它
变成一个好的性质去解
以便于它产生一个整数解
这是我们目前
在政界研究的一个课题是吧
我们跟MIT那边应该
跟刚才提到卢老师在合作
也跟MIT那边
一个博士生在合作
那博士生也是我们以前的学生是吧
就所以中国人在干这些事的人
还是挺多的是吧
对 而且跟我们好像都有些
千丝万缕的关系是吧
对
然后就第二个方法就是
有很多子步骤呢
就是你可以通过一些这种AI的方法
来加速
尤其是现在很多问题呢
就像电网
刚才叶老师提到的电网问题
它有很多历史数据
那你怎么就是通过
对这些历史数据的分析
找到一些
比方说它那个算法中的
某些子步骤对这些镜像加速
这是另外一个方法
第三个办法就是
你在CPU这上
你能不能设计一个好的分布式
对吧
CPU这个分布式呢
以前只有德国做过
德国有个ZIP研究院他们做过
他们把那个八万核的CPU上
做一个加速
能够解一些巨大的问题
历史上解不出来的问题
我们现在在跟那个
德国那个研究院
叫ZIP正在合作
就是考虑说
它那个解放我们研究
里头有很多步骤呢
其实也
一些调度啊什么这些方法
其实也可以通过AI来加速
他们原来做了很多
初操
所以我们现在跟他们有一个项目
做了有一年多了
在帮他们说吧
这个东西也重用AI方法
重新写一遍
所以就是用AI分布式
和这个GPU硬件
三个途径
我们都在尝试
对
所以这就是我们主要做的一些工作
当然我举了一些例子
就是举
你比如说这种很大的一个
公联网络
这个网络很复杂
它是一个飞突结构的
然后这个网络之间那种
拓扑关系
就是这些生产的
比方一些原材料到部件
到整机
就是这中间有一个
有很多拓扑关系
一些原材料
比如很多工厂
很多部件共享
就是这个关系
是有上百万条编的
那这类问题就是说
你比如说疫情
包括现在这个战争
它会带来一个很明显的问题
就是你
你在这个大规模的制造网络
或者公联网络
你要找到一些关键点
疫情的时候
我们把这个东西叫做读点
就是block了整个公联生产效率
这些关键点
然后你怎么去设置
这个安全库存
对吧
怎么去提升整个公联的效率
这些问题其实不太好做的
以前就是
就是解个两千个节点的问题
都要一千两百个小时
现在你像国内的话
你像疫情
是我们分析整个
整个这个上海周边的这些网络
大概就要一百万条编
所以怎么把这些效率给它
比方说几分钟内
把它解出来
这是我们目前
我只是举一个例子
举一个例子
像叶老师刚才举了航天
电网这些问题
对吧
对
就是
这是我们就是说
要做的这些事情
我这也列了
就是中心要做的这些
主要还是说
我们希望说
在做这套新的基础
计算架构体系的时候
我们是一个国际的引领者
就是我们去定义这些标准
定义这些架构怎么去做
对
这是第一件事情
计算
第二件事情是建模
对吧
就是做这个
刚才也讲了
我们有很多复杂的问题
你刚才想电网这种
电网它有两百万条约束
华为的生产问题
有六千万条约束
我们做过俄罗斯铁路
那个有一亿多条约束
这些约束就是
你看华为的生产约束
它有六十类
对应六千万条
那这些约束就是说
所以这个问题它很复杂
就从一开始
你看电网的问题
就是华为的问题
我们最开始做了两年
才把这个问题
从车间里提取出来
提取出来
所以就是这里头就是说
当你用大模型的时候
大模型做这一类问题
就是特别复杂的一个建模流程
其实它做得不太好
到目前为止
要是刚才举那个3.5时代
GPT3.5时代
它做一个很简单背包问题
它都做不太清楚
当然这里头我也列了
就是大家也知道
就是对这种
这种
这种通用大模型
对应这种比较针对性的
行业性的
或者锤类的这些模型训练的时候
它会带来一大堆这个长尾
包括这个幻觉
这些问题大家也知道
是非常常见的一些问题
我也就不仔细去解释了
就是说
所以导致它很难做到一个
很好的这个结果
到现在就是
你用GPT4
还是用4o1
你会发现说
它还是做不好
你比如说我这也还是
举了一个很简单的问题
这里头就是说
最后你发现说
你用4去建模的时候
其实4已经是我们
我们测过130多个大模型
测了130多个大模型
签了GPT4
包括还有几个
像那个
换方的DeepSeq
那几个就是能力最强的
大概有那么
GPT4也在前三名里头了
但即使这样的话
你一定给它一个
稍微麻烦的问题
但还是说不清楚
你看这儿就是说
像这种生产排斥约束
就是本来我们可以写
很简单线性约束
把它排除掉
但是它会去引入一些
非线性的像
这就导致说
这个模型
这个问题就一下子
就变成很难解了
本来是一个比较简单的
线性规划
它建对了
但是它建对了
建模是对了
但是解不动了
本来是很简单
能解了
它解不动了
再有就是它比方说
它可能把一些文字理解
偏差以后
它还是会把一些模型写错的
所以就你发现
它还是不太够的
所以就是说
这个东西就是说
使用怎么用大模型
来对这种优化
这个决策这些问题
进行建模
这是我们一直在
孜孜不倦研究的一个事
因为我们不光要求解
我们还得建模对吧
所以这儿就是有几个
我举了几个例子
你比方说
这个有个NRFOPT
这是一个尼泊斯办的比赛
就是说基于自然语言的
这种建模竞赛
再比如说这个最早的时候
它有一些
你像去年
那个iClear上有一篇文章
这是华为写的
华为跟浙大一些人写的
就是说一个
用这个
就是它这个在GPT下面
去做train
搞了一个建模的
这主要就是用这个
一个链式建模的思维
使用这个GPT软件
使用API
让大模型去建模
和写这个代码
是吧
然后再有就是一个
比方说斯坦福也搞了一个
去年底的时候
斯坦福也搞了一个
叫这个Optimus
Optimus就是说
这个模型呢
就是说
它就是说
它的做法是
它用多角色分工
就是Multiagent这种
是吧
然后把这个几个
几个agent
就是分别有这个主管
建模手是吧
编码手和debug
是吧
就几个角色
把这个任务拆解
是吧
然后用API
让大模型来写
就是说
这个作者里面
你看这三个作者
这有一个高文字
这也是我们以前的学生
是吧
我以前在财大的
是一个学生
后来到斯坦福去读博士了
跟他导师一起做的
是吧
所以我们都一直在这里头
干各种事情
是吧
这是微软做的
微软做的就是
它就是
还是用这个GPT
是吧
然后它就是说
它主要像刚才提到
有很多供应链的问题
它去分析供应链
这些问题
用这个
也是一个agent的模型
是吧
去分析这供应链
就是输入以后
它告诉你说
该怎么去做相应的
这个模型调整
是吧
对
然后再有就是我们做的
我们最近做了一个
叫ORRM
这么一个大模型
是吧
这是我们的一个工作
我们山树跟交大
还有港中深
是吧
就是几家
还有斯坦福
大家联合做的
是吧
这个就是说
我们这个是一个
我们也把它开源了
是一个开源的
可以
有什么优点呢
它可以私有化部组
是吧
然后可以采用任何基座
是吧
任何
对
然后它走的方法
就是说
用那个合成数据
是吧
用Skinning Law的
Skinning Law加合成数据
是吧
让大模型自己建保
然后用我们的COPT求解器
来求解这些问题
是吧
对
这是一个
就是说
我们讲的就是
运筹学
不光是运筹学
就是我们刚才说的
智能决策
它有些痛点
就是说
我刚才讲的时候
我们这个东西
它适用性比较广
就是所有
刚才提了那么多行业
它都能用
能用的
就是为什么能用呢
就是说
因为它有各种各样的困难
实际上有各种各样的困难
它都能克服
这克服我指的是
当你是一个非常有经验的专家
在对运筹学这些东西
建模这些事情非常了解的时候
这些问题
可能对你来说都不是问题
但是对大模型来说
这些都是问题
就是这个稀缺性
就数据它本身是很稀缺的
对吧
问题本身难度又很大
是吧
范围广
什么行业都有可能
我们做过大概20多个行业
就质量
数据质量低
然后就是说
另外一个事情
很重要的一个事情
就是因为这个
大家也知道这个数据
基本上都没用完了
是吧
所以你现在training得
它是很少的
是吧
所以现在大家做法
基本上做法都是一些合成数据
是吧
但是这种问题
你很难合成数据
因为它问题过于复杂
你比如说
你让它合成了数据
你会发现
你给它很复杂的一些数据
最后它给你合成新生成数据
都是很简单的
没有用的
甚至合成一些错的
所以就是说
这里头有很多瓶颈
是吧
新的这个模型好处
就是尽量去克服这些瓶颈
是吧
然后很快地
在各个行业能用上
是吧
对
这就是也列了
就是说我们这个框架里头
就是说
对我们的种子数据
我们到现在
大概做了289个企业了
所以有这点好处
是吧
我们还是有
别的人没有的这个
刚才说像京东
顺丰
滴滴
华为
就各种各样的企业
是吧
富士康
小米
是吧
南网
就各种各样的数据
我们都有
是吧
我们把它脱明以后
就是说在内部做一些训练
训练的时候
主要用了两个技术
一个是in-contact
in-contact learning
是吧
对
一个是这个
这个中文怎么说
是吧
一个是叫做
上下文
是吧
学习
是吧
对
另外一个叫
叫练试的
我也不太记得中文怎么说了
是吧
反正那个
就是说
你可以把这个复杂任务
进行拆解
是吧
然后把这个数据
给它合成出来
一个比较高质量
不稳定性
比较好的一个数据
对
再就是说
经过这些以后
我们做了一些这个实验
是吧
就是说
再比方说
就是因为这个NR4OPT
这是Nips搞的一个
相当于一个
比较公开的数据集
你在上面测起来
比较容易
是吧
这是这个
就我们几个做的方法
就是Tingo
Export
这个应该是华为的
Optimus
这个斯坦福
后面是我们几个
根据这个问题
就是训练模型
大小
是吧
我们做了几个模型
你可以看到
我们还是明显好一些的
是吧
明显好一些的
就在这些问题上的表现
是吧
然后这里头也有几类别的
你像Industry OR
那就是我们现实中
我们提了70个
就是从我们的业务中
找了70个
比较复杂的业务问题
是吧
让它去建模
去测试
看能不能跑起来
是吧
就目前
当然你看到这个比率
也都不高
是吧
虽然目前我们还是最好的
但是说这个事
还有很大提升空间
是吧
就是这个事情
这儿也裂了
比方我们跟这个GPT去比
是吧
GPT-4去比
是吧
这个还是有明显优势的
是吧
就还是有明显优势
特别是这儿也裂了
你这些问题就是说
不管是简单
还是难的
是吧
对应的就是在
比方线性问题
这整数规划
是吧
就这些问题上
我们的建模
和求解成功率
是吧
NRP这个比较
这个主要是
你看这个都是0的
这个是因为我们
只有一个例子
都没解出来
是吧
所以不代表大家都很差
是吧
所以这目前这个东西
我们还在跟斯坦福合作
是吧
还在跟斯坦福那边合作
继续在弄
是吧
继续在弄
大家有兴趣的话
可以跟我们一起讨论
是吧
对
总的来讲就是从这个
商业上讲的话
这个东西有什么价值吧
这我也写了
就是说
像大量的这种
我们像我们这种
做这种复杂建模的问题
就是说
不管是我们作为乙方
是吧
去服务甲方
还有很多比方
是甲方的单位
就像刚才说的
电网 航空
就这些公司是吧
做这些任务的人呢
都是一个
所谓的水平比较高的
一些这种技术专家
是吧
技术专家
或者叫算法专家
那用这些人去做这些事情呢
它有很多问题
比方说这个
我在列了几个
从管理学的角度讲嘛
我在商学院嘛
说我们讨论
从管理学角度讲
你比如说知识传承与管理
是吧
一个牛人走了
你这个事可能就做不下去了
是吧
对吧
就人工依赖性也非常高
是吧
就
然后就是历史经验
你到底怎么传承新来人
怎么去学习这些东西
对吧
所以这些其实都是
很麻烦的一个事
这也是很多时候
为什么Consulting
这些公司
它必须得去顾
成本很高的一个原因
是吧
但这些东西
我们后来发现
在大模型里
你都可以解决
是吧
你比方说走了一个人
就是新来一个人
那你历史上
比方你做的所有项目经验
大模型它很大一个好处
就是它不光是说
我把数据拿过来
你这个
你写了
比方说这个
为了解决这个问题
你写了石板代码
这个代码
每一版的演进过程
它都能看得到
大模型都看得到
然后你在这个
做这个项目
你花了八个月
跟这个甲方做这个项目
这个项目中
你所有积累的document
每一次的meeting notes
什么的
这个项目的所有的东西
你全部都可以输入
大模型
它都能学习到
它都能学习到
是吧
然后它去给你分析
然后比方说产生一个
预测的模型
这个预测模型里
有哪些特征因子
它甚至会告诉你
这些特征因子少了
这个会造成什么影响
它都能干
是吧
所以我们发现
这还是很
对我们来说
对我们公司来说
很神奇的一件事情
或者说很省心的一件事情
是吧
你比如我举一些例子
你比如说这个东西
这个有一个某个
某个这个
这个珠宝厂商
是吧
就是很有名力
讲不能说哪一家
是吧
我们商场公司
做了两个月
两个商场公司
做了两个月
给它做到百分之八十五
是吧
做到百分之八十五
就是一上来
大概有百分之六十嘛
是吧
你调了两个月
调了百分之八十五
在我们把同类
的模型
就跑了
一会儿就跑出来
个百分之八十六
八十六点七
那就意味着
我们那些算法公司
对吧
花大家钱雇的
当时做这个事
应该还是两个小海龟
是吧
都名校毕业了
发现他们好像
都没啥用了
是吧
所以这个就是
当然我不能说
因为这个
我们就裁员了
是吧
确实裁员了
是吧
对
因为确实
这个事呢
确实很
你去想
这很吓人的
是吧
比如说这个东西
跑了百分之七十五
我那个大模型
跑了百分之七十二
正常情况
我是两个月干了活
是吧
干了百分之七十五
是吧
大模型的百分之七十二
说白了
我把前面
就八周的事情
我前六周都不用干了
前六周都不用干了
我只需要干两周
那就意味着
我还是有四分之三的人
是不需要了
所以从这点上讲
我发现这个
最先淘汰的是
高技术工种
是吧
高技术工程
以前我们说的
或者这两年
大家很多去做这种
数据分析师
是吧
实实在在的
是吧
所以这个东西
是很吓人的
很吓人的
是吧
这也是非常
这就是说
我把所有的这个历史
就是我们每一个项目
你比如说我们做了
快销我们做得特别多
是吧
做了三十家
那所有快销的东西
我全灌进去以后
我们做快销
就发现就特别准
是吧
特别准
只要三十家就够了
当然我们自己
刚才说了
我们用了很多合成数据
是吧
就是合成数据
你一定要想一些
我们刚才写的那些论文的
最大的一个创举
非常稀缺的数据
是吧
所以你要设计一些新的算法
所以这就是
我们在建模上
在大模型上
一些探索工作
是吧
就是建模和球解
是吧
两年事情
是吧
我今天基本上
就讲到这里
是吧
就谢谢大家
当然这个动画演示
叶老师演示了个片段
我就不演示了
是吧
好
谢谢大家
 Thank you
感谢葛院长的精彩分享
让我们了解到
领先团队
为复杂决策过程
提供的智能化支持
如果说
人工智能可以应用于
解决各种任务和问题
那么
生成式人工智能
作为其中的一个子集
专注于生成新内容
和模仿创造力
接下来
让我们有请
纽约大学斯特恩商学院
中生教授
计算机科学
和数学科学中心教授
陈希先生
为我们带来主题演讲
生成式人工智能
机遇和挑战
及在量化交易中的应用
掌声有请陈教授
好
谢谢大家
感谢大家
这么热的天过来
我给大家讲一点
希望比较轻松一点的
这个题目
就是我们讲一下
生成式人工智能的
我觉得一些挑战
和我最近做的一些工作
然后后面
我给大家讲一下
我觉得人工智能
在量化交易中的一些应用
当然这是我的一个
背景
然后一会我会讲到
我会结合我在亚马逊
广告组做首席科学家的
一些经历
这个会讲到
当然在讲之前
我给大家做一个
小小的自我宣传
这两本书
第一本书是讲
这都是相当于给MBA读的
比较科普性质
第一本是Beyond AI
然后我们讲了一些
关于AI在不同商业场景
落地下的一些想法
这些想法
会在今天的讲座中讲
这是由Splinger出版的
这个书正在翻译成中文的过程中
另外一本书就是还没有上市
希望今年下半年就能够出版
是讲一个区块链
web3相关的
这个书希望能成为一本web3相关的
一个MBA的教材
因为我看到这个市面上很多书
但是并没有一本商学院
是和MBA读的理论与实践
结合的一本教材
所以我们就和哈佛大学
商学院的朱峰教授
还有耶鲁大学计算机系的
他是做blockchain的专家张帆教授
然后一起写了一本书
希望大家希望今年下半年能出版
当然我不用多说
2023年3月14号
我觉得是一个值得纪念的日子
因为我们出了ChaiGPT-4
这个GPT-4在各种性能上
都吊打了以前的ChaiGPT
并且它实现了多模态的一个问答
比如说这边就给一幅图片
然后你就问它这幅图片
有什么不对的地方
它告诉你
你说你把一个电脑的接口
接到一个iPhone的手机上
它就能够对图片进行识别
从这个GPT-4诞生之后
我们就产生了整个的
声称是人工智能的浪潮
就开始掀开了
包括语言的 文本的
多模态的等等等等
我们今天就不赘述这个
我们想一想
我觉得人工智能
尤其是声称是人工智能
现在还有哪些挑战
我先讲一下它的局限和挑战
当然对在座的小伙伴来说
对在座的小伙伴
如果有感兴趣创业的
我觉得其中也会有些创业的点
可以跟大家分享
第一个我就讲一下
情感沟通和隐私保护
第二点我讲一下幻觉
第三点讲一下我最近的工作
主要是一个去中心化的验证技术
我们就讲一讲
当然我们给一些具体的例子
比如说大家可以看到
我这个比较胖是吧
是一个不爱锻炼的人
我就经常想问GPT说
你能不能劝服我多锻炼锻炼吗
GPT说可以
你多锻炼有什么好呢
可以增强体力
控制体重
提高心理健康
增进免疫系统
但我想问大家
你看了这样的回答
它能让你多锻炼吗
不可能啊
就是说这些回答
你们都无数遍
我不希望听到这样
说教的这个回答
那我们比如说
我们就会想一个
就是说你可以跟他进行一个
更好的一些对话
就有一些软件
我们尝试了
你就问他
那为什么阻止你去锻炼呢
你就回答
你就问
GPT可能会问你
说那什么东西阻止你去锻炼呢
你就说我的健康伙伴都被搬走了
然后他就说
这个社会支持非常重要
你可以加入一个跑步的俱乐部
然后你就说
没有时间
我确实没有时间给自己是很难的
然后就说
总而言之
就说即便是对话式的
这样的一些工具
它也很难的产生一个情感的沟通
那我理想中间的一个GPT
可能会是这样的
对吧
比如说
他会说你今天完成目标了没有
你说算了
我今天已经下班了
他说运动呢
我就提高你的能量水平
帮助你消除疲劳
然后你就会回答说
不要不要
明天再说吧
然后这时候GPT如果跟你说
那你先去走五分钟怎么样
你说这个我可能可以做到
所以我觉得
下一代的GPT应该更多的是一个
基于情感沟通和意图沟通的
这样一个东西
而不简简单单是一个
说教式的一个沟通
所以我觉得这块
其实是有机会的
当然了
这话我简单提一下
就是说这个GPT
通过这样的对话
它可能会泄露一些隐私的
问题
就比如说
他问你锻炼了吗
你说我经常去一个
24小时的健身房
然后如果他再问你
那他就知道这个健身房
是24小时去的
并且你可能经常去
这里头有一些隐私的问题
当然这不是我们今天
重点讨论的问题
总而言之
我的一个第一个想分享
就是说
我觉得情感沟通
可能是未来的
这个GPT的一个方面
第二个方面
我想大家都比较了解
就是GPT会非常自信的
发明很多东西
我们把它自信的
发明的东西
是不真实的
我们把它自信的
发明的不真实的东西
叫做幻觉
这里这个字比较小
但是就是说
它可以产生一些文献
比如说你用GPT写论文
然后你让它产生一些文献
它给你产生了很多文献
然后你在网上一搜
这些文献根本就是不存在的
就这头是个推特
就是说它说
一个教授说
你知道他2018年
在发表上的文章吗
他说我说了很多次了
他完全是在编造文献
听起来很普通
很不错
但是我可以保证
我从来没有写过这些文章
这个是一个
所以大家如果要用GPT生成
帮你进行文章写作
一定要小心
很容易将来会
就是你发表了之后
可能大家会发现
这个文章
你引用的文章压根就不存在
那么这个
现在有一些方法
来解决这个问题
其实我想跟大家分享的一个
就叫做检索增强生成
我不知道大家有多少
在座的小伙伴
可能在这个大会上
也都听说过了
它就是把搜索引擎
跟这个
这个GPT结合起来
就比如说我举个例子
这是GPT-4
你问他
What did the president say about justice prayer
这是美国的一个大法官
他就说我不知道
因为我这个
最多只能到2022年
我的信息只能到2022年的1月
我没有办法提供更多的信息了
那这个
这个搜索
这个新一代的这个检索增强生成
其实是这样做的一件事情
他把这个用户的这个问题
转变成了一个
这个项链
然后呢
他有个项链的数据库
在项链数据库中进行对比
这个项链数据库是随时联网
并且更新的
他把这个项链数据库中进行对比
找到项链数据库中的匹配的
这个比较相关的这些网上的信息
他把这个网上的信息
和你的问题呢
一起汇总成一个长的一个文本
这个长的文本呢
他一起丢到这个提示模板中
然后呢
让这个提示就当做prompt
然后把这个prompt丢给像GPT啊
丢给这样的大模型
然后大模型呢
提示到这个之后呢
他就会给你产生一个答案
这样呢
我给大家举一个例子啊
就是说
这个是一个NYU的一个
在美国挺火的
一个NYU的一个
就是我们的
这个一个
这个央乐控的一个学生
他做的一家公司
叫Perplexity AI
他这个就问你
同样的问题
他说What did the president say
about justice player
他就给了这样的答案
并且给了答案之后
他给了不断的引用
这可能看不出来
看不太清楚啊
这有123
上面就把这个
你搜索的这个网页
123全部都找到了
你可以通过这个引用呢
你就看一看这个网页
他甚至会帮你
标注哪里的这一段话
导致了这样的
这个文本的产生
这样的话呢
就可以从一定程度上呢
减少这个幻觉的发生啊
当然如何解决幻觉啊
这我觉得是一个
非常重要的问题
包括刚刚葛老师讲的
在运筹学中间呢
这个叶老师讲的
如果出现幻觉呢
可能会导致很严重的后果
对吧
那些问题你就不能通过
搜索隐形的方式
因为它是一个建模的问题
你也不可能在网上搜到
所以怎么样
减少那些问题的幻觉呢
我觉得当然是更困难的
但是呢
这个通过这个
这个Perplexity AI呢
我觉得我意识到一件事情啊
就说我觉得这个东西
会带来一个
这个数字广告的革命
我自己在2021年到2023年呢
在亚马逊广告组呢
作为首席科学家
其实工作了两年啊
就是说这个
那就说大家看到
现在这个谷歌的搜索
当然百度也是一样的
对吧
它这个主要
它这个赚钱的
方式啊
是来自于上面的
我们叫Sponsor Search
就是说你这个
一些商家可以在这
贴广告是吧
那现在问题你想过没有
如果你用了这样的
大模型的这种
检索的方式是吧
那你就没有办法
就说我也不看网页了
对吧
那我就根本就看不到
这些Sponsor Search的结果
我当然不会点开这些网页
那直接在这些网页上投告
投放的这个
这个广告商啊
他也就不能挣到
相应的这个钱了
所以我觉得这个
是对广告商是一个很
很严重的一个影响
那这个
那甚至我在想
谷歌为什么在这个
就是在这种搜索引擎上
这种RAG上做的
没有那么全力的去推是吧
那他可能就说
再往下推
可能会自己
革了自己的命
就说因为他这样
如果推的话
那么这个东西
就说那这样的话
这个广告商就不在
谷歌上投放了
因为我直接看答案就好了
对吧
所以我就没有这样的机会
那相反来说
可能未来的
广告的主战场
就会变到比如说
抖音
像TikTok
还是YouTube
像这样的方式
可能会变成
将来广告上的一个主战场
所以我觉得整个
这套RAG的模式
可能会对整个数字广告
包括数字广告投放的方式
数字广告的分析
会带来一个万亿美元以上的革命
那这头肯定也会有
很多创业的机会
就给大家分享一下
好
这是讲了一个
第一个是情感沟通
第二是幻觉
第三个我给大家讲一讲
是去中心化的人工智能
那这个呢
就说我们训练大模型
这个代价成本
是非常非常高的
大家可以看到
这头OpenAI
在GPT-4的训练中
就已经花了7800万美元
然后Google在Gemini的
这个计算生成中
花了将近1.91亿美元
这是一个海量的
一个天文数字
那么这个是一幅
就说我们说
能不能小公司
也能完成这样的训练呢
这是有希望的
比如说这是一个
分布式的计算
这是由Stanford
非常著名的篇文章
他就说如何训练大模型
在一个分布式的环境中
然后他做了一个
小的实验
有不同的美国
欧洲 亚洲的地方
把这些计算中心的
结合起来
做这样一个训练
但是我想讲的是
即便你能够在小
这种在不同的
通过分布式的训练的方式
来降低成本
但这头有一个核心的问题
就是说一个
像这个就是说
一个分布式训练的市场
这是一个Carweave
是美国一家公司
这家公司已经估值
10.5亿美元了
应该是Fidelity
像这个
以10.5亿美元
以10.5亿美元的估值
来支持来买
就是来投资这家公司
他就是说能够在
能够利用这些
网络上闲散的算力
把这些闲散的算力
拼接起来
来完成一个大模型的训练
如果不能做训练
至少可以做微调
我们叫Find Tuning
这样的工作
就是说他可以来做
这样一件事情
但是如果你用小公司
去做训练
这头有很多的问题
其中一个很严重的问题
就是可验证性
你怎么知道
他真正完成了
这样的工作
我来举几个可验证性的问题
我来举几个可验证性的一个
几个实例
第一个实例就是说
比如说客户说
你帮我用一个
175别令的参数的大模型
来产生图片
那这个厂商
他接到你这个任务
他用了一些闲散的算力
来完成这件事情
但他实际上可能
只用了7别令的大模型
来给你做推理
就给你产生了一张图片
你可能一时半会
你也分辨不出来
对于没有经验的
你也不能分辨出来
这张图片
是否是由7别令产生
还是由1别令产生
还是由175别令产生的
对于他就可以
在这时候造假
对吧
就是一个造假的问题
然后第二个
就是数据的可验证性
对吧
我们刚刚说了
这个数据到最后
都要做微调
甚至做reinforcement learning
就是做强化学习
到最后
比如说这里头
哪座山是最高的山
是吧
然后如果你回答
这是一个好问题
你就会达到一个difference
因为并没有
直接回答这个问题
但如果你的回答
是珠穆朗玛尔峰
你就会达到一个高分
这有个type
你会达到一个高分
这样的话
你就可能会
去形成一个正反馈
但是总而言之
你这个AI模型
比如说你把一堆数据
你是一个金融公司
或者你一个法律公司
你把一堆数据
交给了AI模型
那AI模型
如果擅自篡改了这些数据
你可能也很难
就是说抓到
甚至比如说
这个数据中
比如说我们说
有一些是违法的
有些是不违法的
然后你把这个数据
交给AI
然后交给一家公司
结果这个公司
如果有意的作恶
他把这个标签给改了
把违法的改成不违法
不违法的改成违法的
这个是一个
而且你很难去验证这件事
这是一个问题
那第三个是
整个训练过程的可验证性
这个是我做的一个研究
我们想象一个
这样的商业场景
假设你是一个律所
你有很多法律文件
你想训练一个大模型
帮你提起诉讼
写这个诉讼文书
这个很正常
有很多创创公司
都在做这样的研究
但是呢
你是一个律所
你都是一帮律师
你并没有
这样的AI的专家
于是你找到了一个
AI模型的训练商
你说
我给你提供这些数据
你训练一个大模型
然后呢
你把这个大模型返还给我
我可能拿一个
开源的模型给你
希望你在上面进行一些微调
然后给我一个新的大模型
这时候就有个问题了
他训练完大模型
他给
比如说你给他一个
7个别人的参数
他返回你7个别人的数
然后给你一个API
调用的接口
他就向你说了
说我这个训练成本
要100万美元
你说这100万美元
从哪里来的呢
你为什么要
收我100万美元呢
他给你一个账单
说你看
我一共用了
10万个GPU小时做的训练
所以我们按照律师的收费
一小时收费多少钱
所以我用了
10万个GPU小时
然后做这个训练
所以我就应该收你
比如说100万美元
这个问题是
你如何验证这件事
你说你用了
10万个GPU小时
你就用了10万个GPU小时吗
同样的
你也没有办法去验证这件事
所以
但如果大模型
分散在各个
小厂商中间
进行分布式的训练
其实呢
我们如何建立这种
信任的机制
这个是非常非常困难的
就是我们的数据的提供方
和这个服务的使用方
和这个模型训练的提供商之间
如何建立这种trust
建立这种信任机制
我觉得这个呢
其实是一个
将来大模型走向
就是一些
各个传统领域中间
也会面临的一个挑战
当然了
我这都举一个例子
就举一个例子
是我一个工作
当然我这个工作
就给大家简单的讲一讲
那其中呢
有一种方法呢
就是可以用我们这个
区块链的技术
用区块链的技术
我给大家简单的
介绍一下区块链
区块链其实非常简单
它就是一种
这个分布式的
不断增长的数据库
其中每个区块呢
都包含数据
当然大家常听的
我们所谓的比特币
就是说每个区块中
都包含了交易的数据
比如说我给你传了
这个这样的币
当然它其中可以包含
各种各样的数据
甚至包含图片
包含文本
包含各种这样的数据
然后从经济上呢
那怎么能完成这条链呢
就有一个东西叫矿工
矿工呢
就去为了这个上链
这个事情呢
进行比较难的计算问题
当你解决了这个
计算问题的时候
你就可以认为
我就有这个上链的权利了
那下一个是个
把这个下面的一个内容
存储到这个链上呢
就由我来写这么一个block
对
那其中呢
这个工作量证明呢
就是说
那怎么来设计
这个问题呢
其实呢
这个一直从比特币开始呢
其实大家就用了一个
用一个叫解哈希问题啊
其实是一个相当于一个
密码学上的一个问题
一会儿会简单的讲一讲
但是呢大家知道
哈希问题呢
实际上是一种计算上
完全的浪费
因为这个问题呢
算哈希
但算了哈希对这个人类啊
没有任何的帮助
其实它消耗了大量的能源
每年要消耗120太瓦
相当于一个中等规模的
国家的全部的能耗
都是用来干什么
就挖比特币
用挖比特币
那么
那为什么当时的
比特币的提出者
叫钟本聪
他会提出用哈希难题
为这个工作呢
当然我们到现在也不知道
钟本聪是谁啊
他只是当时写了一个白皮书
那大家要满足几个问题
什么叫这个工作量证明呢
它有这个问题
第一个是
这个函数相当于一个方程啊
是你很容易验证
就是告诉你答案
你很容易去
去验证这个是不是对的
但是呢你要反解这个函数啊
就是我告诉你这个方程
你要反解这个答案
这个是很难的
但是第三点呢
是要可控制难度
就是这个哈希函数呢
是很容易控制难度
他就说你前面有几个零
就你通过一个random的东西
通过这个哈希函数
前面有几个零
零越多呢
难度越大
所以我们听到什么比特币
就是其实前面多一个零
这样计算难度呢
就直接乘以二
自从这个工作量证明
提出了之后呢
其实大家都在想
怎么能让这件事情有用
其实刚刚跟这个
这个葛老师
耶利杰老师谈的呢
其实最简单的一个想法
是我们为什么不用
这个东西来做一些解方程
或者是举针求逆
因为你看呢
如果是解方程的话
是不是它首先
一个大的线性方程
它难以反解
但是易于验证
我告诉你答案
你就知道ax是不是等于b
我告诉你x
你很容易知道ax等于b
但是呢
如果你要告诉你ax等于b
你要解这个x
是非常困难的
但这头有一个问题
解方程做不到
就是控制难度
因为呢
你把这个矩阵ax等于b呀
你把这个a的行数增加
并不能保证
它这个计算的时间
是一个比如说
线性增加一倍
因为它这个东西
很多时候跟这个a
是这个结构
是有很大关系的
比如这个是系数
特定的结构
这都会导致呢
你这个难度控制非常复杂
所以其实从比特币提出
2010年开始呢
就有不断的人去想
我怎么能够
去把这个工作量证明
变成个有用的
这个工作量证明
但是都没有方案
就都没有一个合适的答案
但是呢
我最近就发现了
这个AI计算
其实是可以做到的
这为什么呢
首先AI计算呢
比如你训练一个大模型
是非常非常困难的
如果你把一个训练大模型
看作解方程的话
训练大模型的确是非常困难的
但是难度是可以控制的
为什么呢
我们训练大模型中间用的是
这个随机梯度下降的算法
我们这个每次呢
取一个batch of data
就是取一部分数据
当这个数据中呢
我们这个过数据多少遍
这个难度基本上是
随着你取多少个batch
线性增长的
就基本上是这样
所以它的难度是可以控制的
最后呢
就是说是否易于验证
这个就需要呢
我们做一些科研的工作了
就是是否去要验证
那我们通过理论的模型呢
尤其通过这个
我们都用了一些game theory
一些博弈论的方法呢
去证明它其实可以验证的
而验证起来并不困难
那这头呢
我再总结一下
我们通过AI的这个验证呢
去代替这个
就是以前比特币的这个
工作量证明呢
就这要满足三件事
我们叫做一个三角形
第一个是要安全性
第二是要计算效率
第三个呢
是要可
难度可以控制
如果同时能满足
这个三个东西
我们就等于说
我们可能提出一种
新的用AI的方式
来代替这个比特币
这个分布式
这个上链的过程
但是呢
它还能为人类产生价值
为人类产生价值
当然了这块
我们就没有时间
给大家细讲这篇论文了
我们其实这个想法
非常的简单
我们这个想法
是什么意思呢
就在你训练过程中
加入一些旗帜
加入一些flag
就是加入一些相当于水印
或者说一些寻宝游戏
然后呢
让这个验证
在训练的过程中
加入这些旗帜
然后让验证者呢
去找到这些旗帜
没找到一个呢
我就给你一些奖励
当你把这些旗帜
都找到了
就算你的这个验证成功了
但是我们证明了
这件事情的计算量
是非常的小的
假设你要训练
训练的时间是t
就你训练的这个时间是ot
你要经过t个epoch
或者t个minibash
那我们这个验证的成本呢
只是oe或者ologt
就可以了
当然了这头
我们也能证明呢
它的传输的
我们也有通过算法
导致这个传输的这个
这个communication cost呢
也会变小
这样呢
我们通过这个方式呢
这个论文在这里
我们今天当然就
做一个科普
就不给大家细讲了
但是呢
通过这样一个寻宝游戏的
这么一个验证方式
我们就能够
解决我们刚才的问题
我们就能够告诉大家说
哎
这个
这个你是否
就是说
是这样一个问题啊
就能解决
这样一个商业场景中的应用
就是说
我们能够
控制你
去验证你整个的
这个
这个训练过程啊
你到底用了多少个小时
你有没有用
合适的参数
你有没有篡改数据啊
这三点呢
都可以在这里头完成
这样的话呢
以后比如说
我让AI模型训练商去训练
他们告诉我
他有多少个小时
能够提出自己的定价
因为这时候
为什么是很难呢
就是说
大家知道这AI中间啊
我现在还是不能够通过
这个
你回答的答案的质量定价
比如说
我给你一个法律文件
对吧
你给我个大模型
我不能说
因为你这个
我让你生成合同
你出了错误
然后就不给你钱了
因为呢
我也不知道
你这个生成的合同好不好
这个需要专家去评判
而且
并且
如果你产生出来的合同不好
对吧
可能是我数据的问题
不一定是你训练的问题
所以呢
这个现在的定
合理的定价模式呢
第一的就是
按照计算的这个过程
你是否去完成了
整个计算过程
去定价
而我们通过
这个区块链的
这个一个想法呢
就给大家这个
这个
这个介绍了一种方式啊
这种方式呢
就是说
我们可以对整个的
这个训练过程
进行验证
而这个验证的计算成本呢
是比较低的
它呢
从另外一角度来说呢
它可以把
原来的这种工作量证明
区块链的工作量证明
变成了一种
有用的
区块链的工作量证明
好
那这时候
我分享了这个第一部分
给大家分享了
这个一些
我觉得这个
这个声称是人工智能中
一些痛点啊
就包括这个情感沟通
包括这个幻觉
和包括这个
可以验证的技术
那下面呢
我再
最后再占用大家
十分钟的时间
给大家讲一讲
这个
我觉得这个人工智能呢
在量化金融中的一些应用
我觉得这个也是一个
我觉得比较
让我觉得这个
比较exciting的一个领域吧
大家知道
这个量化投资的
这个兴起啊
就是前一段时间
有一位著名的
这个
数学家
这个
我相信可能
叶老师也认识
这个
叫
Simon
他给Berkeley也捐了一个
这个
这个很好的研究中心
他以前是
石西大学的一个数学教授
并且呢
他呢
跟我们这个
中国的著名的数学家
陈醒申
教授
他们一起合作了很多论文
后来呢
他就进入了量化领域
他就相信这个数学
能找到这个股市上的规律
通过这个东西去赚钱
然后成立一家公司
叫文艺复兴
也是世界上最成功的
这个
这个量化公司
他这个
就是说呢
在这个
这个复杂的资本市场环境中
他需要投资
能产生稳定的
回报
那基本上呢
当时他就提出了
他最早就提出了
我们通过
海量的数据
通过数据挖掘和AI呢
执行交易
并且这个交易呢
就会获得收益
他这样呢
不受人性的这个
弱点的这个影响
对吧
就是你不会看到股市跌了
你就非常恐慌
因为他这个
完全由这个计算机来执行
这样的交易
那么
最早呢
其实这个
在理论上呢
就是说Fama呢
就提出了一个
这个著名的
三因子的模型
就是说
他说这个
这个收益呢
能够通过这个证券
一个证券组合的收益呢
能通过一个
线性的方程呢
来表达这件事情
就是说
他把这个
上市公司的市值
账面市值比
和市盈率
来去
做一个
线性回归的方式
来表达这个股市的
这么一个
一个组合的收益
这是一个
简单的线性模型
当然人工智能的发生呢
就是说
我们可以
把这个模型呢
有两个方面
第一个是一个
线性的
我们可以把它
变成非线性的
第二点呢
这都其中呢
这个公司的市值
账面市值比
和市盈率
我们这个叫因子
就是叫factor
那我们这个factor
它是人为定好的
是吧
那我们可以去
通过自动的方式
去找寻
这个市场中间
那些关键的factor
通过这些factor
来解释
和预测股票的价格
那
那这个人工智能的兴起呢
就导致了很多
这个量化投资的应用
这当然是
美国的这个
很多公司
还有一些
这个国内的
可以进行多因子的
一些量化选股
包括深度学习
但另外呢
就是大语言模型的产生
让我们
微星摇杆和图像数据
都有了更加深刻的理解
而这些理解呢
会直接产生出
我们更好的一些策略
可以给大家介绍一下
其中呢
比如说
这又导致了2015年开始
这家公司
大家一定要
对量化感兴趣的朋友们
记住
叫xts market
现在最火的公司
这家公司
2015年建立的
它也是由俄罗斯的
当时一个纯数学家
做代码的
代数几何的教授
叫Alex
他这个
开个玩笑说
在俄罗斯做教授很穷
后来他就去了
德意志银行
他就发现
他通过人工智能的
能够做量化交易
2015年成立这家公司
我给大家讲一讲
这家公司有多么恐怖
首先Alex去年是
全部英国纳税人第一名
他这个资产
第二点
这家做外汇
他们是从高频外汇起家的
他们的外汇交易
交易量
超过了
剩下9家大银行的总和
他们是世界第一名
但为什么说人工智能
他们刚开始的这个理念
就是说
我们想通过这个暴力的方法
用算力去平推
这个一开始我们
如果对高频交易感兴趣的同学
可能知道
高频的理念就是说
我们一般讲
大家都认为高频
要在微秒级到毫秒级
做出交易决策
必须要用简单的模型
比如线性模型
他们的理念就是说
我们可以上非常复杂的
人工智能的深度学习
来做高频交易
这个在2015年
他们XCX Market之前
是没有人敢想的
他们对于开辟了这个新的范式
他们这个数字
大家可能读不清
我就给大家说一件事情
他们现在
即使去年为止
他们是世界上拥有显卡
排名第四的公司
前面三名是
应该是谷歌
OpenAI
和Facebook
甚至他们拥有卡的数量
比微软还要多
他们A100的卡
是全世界第二名
他们用了这么多的卡
去做这样的高频交易
导致了整个量化交易
新的范式的一个变革
当然这个公司非常的神秘
所以他们的人也很少
我们并不知道他们是怎么做的
这个并不知道怎么做
我给大家分享一点
我自己对量化交易
也是比较感兴趣
曾经这是以前在一篇
和清华大学李健教授
我们做过一些
通过集生学习的方式
就是把不同的强化学习的方式
结合起来
做一个量化交易的算法
当时我们做了一些工作
这个是发表在paper
大家感兴趣的可以看一下
当时也是在A股上
做了一些测试
取得了不错的效果
我们后来把AI的算法
也用在一些大宗商品的
CTA策略上
为什么做大宗商品
大家知道
国内的A股是不能做空的
但是大宗商品是可以做空的
我们对大宗商品做了一些
比如说高收益的策略
也可以做一些
能够回撤
能够把回撤能控制的一些策略
就做了一些这样的研究工作
大家感兴趣的可以具体
我们可以下面再聊
但是除了AI直接用来预测股
价格和做交易
另外的AI产生了更大的一个影响
是对于另类数据的分析和研究
AI会产生很重要的作用
什么叫另类数据
我给大家简单的介绍一下
我们把以前凡是你们做交易中间的
量价或者作为基本面的财报
或者价格这些东西
我们都叫传统金融数据
另类数据就是说它的来源不同
它的格式也不一样
大家可以理解比如说新闻
就是最常见的另类数据
但是我们还介绍一些别的另类数据
比如说首先大模型
很多公司都在尝试用大模型去
提取新闻的上下文的文本表示
看大家对什么样的公司的评论
因为这个评论可能代表了大家的名义
通过这个东西来预测收益率
然后通过上下文的捕捉文法的句法和语义
来更好的理解大家这个评论
因为有些人可能说反话
在以前的AI
以前的机器学习可能是没有捕捉到的
但通过现在的Transformer
和整个大模型做了理解
这头举一个例子
这是芝加哥大学他们发表的一篇文章
和美国AQR也是一个金融企业
他们发表了一篇文章
他们就说
我可以让这个
像以前把新闻分为正面和负面
现在他们分的就很细了
可以叫同意的
表达非常激动的
感激的
Enjoy的
他可以把情感分得非常细
负面新闻
同时他也把负面的新闻
分成了很多种不同的情感的品类
他们说在小股票和负面新闻
大模型可以在预测小股票和负面新闻
之后他们做了一些实验
结果更加的明显
他们说新闻报道对股票收益率
是有很好的预测能力的
尤其是对于这种中小型的股票
这是芝加哥大学他们最新的研究成果
大模型在最文本的理解的过程中
把它运用到金融市场
另外想跟大家讲一讲
除了文本之外
大模型对于图片
其实还有各种方面都有很重要的作用
比如说这个例子很有意思
大家知道2020年的时候
就是说发生了疫情
所以你知道公司每年
我们每年对于公司股价最重要的时刻
我们有开个玩笑说
叫赌财报
什么叫赌财报呢
比如说特斯拉或者英伟达
他要发布一个他今年的收益
他在之前华尔街的分析师
就会对他的收益进行一个预测
往往他这个收益
如果比华尔街预测的好
他的股价就会大涨
他如果比预测的差
即便他盈利了
他的股价也可能会大跌
所以一般讲在财报之前
华尔街的分析师
就各大分析师
就会对这个今年的收益做一个预测
但是到疫情的时候
就发现有很困难的一个问题
就比如说沃尔玛
我没有办法去预测
因为以前的历史经验都不工作了
就说我们不知道疫情的时候
大家对沃尔玛买东西的行为
会产生多大的影响
就多大的变化
当时这个另类数据和AI
就产生了巨大的作用
怎么办呢
他就通过卫星摇杆的数据
直接去拍24小时的监控
这个沃尔玛门口停车场的车的数量
然后通过车的数量来判断
大家有多少人去沃尔玛进行消费
然后通过这个消费
对当年沃尔玛的营收的状况
做了一个准确的估计
这就是一个另类数据
通过AI的方式
通过这个大模型
对于这个图片的识别
来去进行一个预测
这还有一个给大家讲一讲
很好玩的东西
在美国有一个债券
这个债券叫Catastrophic Bond
什么意思呢
叫聚灾债券
什么意思呢
你买了这个债券
如果比如说今年佛罗里达
没有发大水
你可以稳定地享受到
将近年化15%以上的收益
就等于你买了一个债券
如果佛罗里达没有发水
没有发洪水
大家知道佛罗里达
是一个比较爱发洪水的国家
你就买了一个债券
你就稳稳地收到了15%的收益
但是你如果佛罗里达
真的发了大水
你可能你的收益甚至是负的
就是说你要赔钱
它是通过这种方式
政府是通过这种方式
干了什么呢
就是说如果佛罗里达
没有发大水
我通过政府的钱
我给你一些回馈
一些分洪
但如果发了大水
这是你的责任
你买了这个债券
你就要承担相应的风险
这时候你的钱
就会用来进行灾后的重建
这个时候大家就想知道
如果你要不要买这个债券
很多时候你要对天气
做一个非常准确的评估
然后这个是当时它的一个收益图
这个是当时债券的一个收益图
大家可以看到
蓝色是这个债券
红色好像是一个指数
这个债券就收益很高
有意思的是
通过这个债券
大大推进了什么呢
推进了气象学的发展
就是因为以前
气象学的教授
可能工资也不是很高
就做研究
但是通过这个方式
各大金融机构
就请了很多气象专家
成立了小组
去研究
到底佛罗里达会不会发大水
然后它的研究成果
他们也乐意
跟当地的政府去分享
最后特别神奇的是
通过这个金融的一种机制的方式
市场的一种机制的方式
就导致
可能佛罗里达
或者美国那一些州
对灾害的预测能力
大大提高了
因为以前没有人做这件事
但自从发了这个债券
金融机构可能花了大价钱
请了一些科学家
请了AI的专家来做这件事
就反而导致了它整个带动了
就是
因为为民做了好事
最后气象学的预测
变得越来越准了
这是很有意思的一个事情
总而言之
我想说
当然了
AI用在金融学上
和我觉得用在运车学上
也是有一定的关系
其中最大的问题
可能还是一个可解释性
就是说
我们假设你有损失
你如何去解释
性能和可解释是一定要权衡
今天的苏老师
在最后会给大家讲讲
AI对整个经济学的一个影响
我这边只讲了个量化
算是经济学中
很小的一块
这给大家做一个抛砖引玉的功能
好
最后我就说
AIGC生成式人工智能的新时代
即将到来
这也切合大会的主题
谢谢大家
感谢陈教授的精彩分享
当前生成式人工智能的挑战
体现在情感沟通与隐私保护的局限性
甚至会带来幻觉的产生
在演讲中
我们特别了解到
利用区块链技术
来实现新AI时代的去中心化的算力市场
以及现代机器学习和AI模型
对量化教育行业产生的革命性影响
接下来
让我们继续探索
生成式人工智能领域
有请普林斯顿大学终身教授
AI创新中心主任王梦迪女士
为我们带来主题演讲
生成式人工智能的运用
面向生成优化的引导扩散模型
掌声有请王教授
大家好
今天我能做一个
更多还是从大模型本身的技术层面
来讨论现在的一些比较重要的问题
然后我想稍微的往几十年前
回溯一下历史
智能或者说怎么样去让一个机器
完成一个有智能的任务
这件事情不是从大模型
也不是从生理学习开始的
这件事情是从控制论开始的
控制论是诺贝尔·威纳
是美国的一个数学家
他提出的
在这个过程中
他其实和香农
在一起讨论信息的传输
如何从信息到决策
基本上控制论和信息论
差不多是同一个年代的
最重要的理论和方法论基础
他们也后面直接带来了信息时代
互联网时代和人工智能时代
控制论出版于1948年
一个非常基本的概念就是
其实控制论是要讨论智能
生物 人 动物是智能
机器也是智能
他们的共同点是什么呢
他们的共同点是
这样的系统都是一个控制系统
不管是一个生命体还是一个机械
他们都需要在一个复杂的环境里面
能够根据环境收集到的信息
做出反馈
这里面的计算可能是
通过物理和机械元件直接造成的
完全是物理上的
所以计算也可以是数字的
这是控制论
更现代
控制论就变成了强化学习
强化学习第一次就是让
家家户户都知道
这是2014年的AlphaGo
它是一个对抗式的博弈
但是它的解决方式是
让每一个博弈的单方
来自动地学习
如何去最大化他们的利益
所以它是一个对抗式的
强化学习算法
那么它的核心还是来自于
最早的控制论
强化学习还可以用于
多个智能体的
实时决策优化
还可以用于机器人
我们看到了很多很多巨神智能的
然后还
正在用于自动驾驶
也是马上就会出现在我们生活中的
然后另外一个强化学习非常有意思的应用
这个是
发表在Nature上
2022年
大家知道2022年
有哪些AI技术
产生了革命吗
对
XGPT就是2022年
但是2022年的AI技术里面
对人类产生最深刻的影响
有可能不是XGPT
有可能是这个用强化学习
去控制核聚变
reactor里面的等离子场
可控核聚变
是控制领域最难的问题
因为
这个核聚变的这个系统
本身是一个混沌的chaotic system
那么
传统的控制理论
经过复杂的模拟计算
依然不能解决控制问题
但是强化学习算法
基本上特别精准的控制在
任何一个我们想要的形态上面
那么这些都是强化学习
然而强化学习有非常强的去
在高维的系统中
去找到最优策略能力
但强化学习本身有很重要的弱点
就是强化学习
不是特别善于利用数据
那么我们今天要讨论的
不是强化学习
我们要讨论的是大模型
大模型是否可控
就是做互联网做技术的朋友
可能要了解
凯文·凯利是一个非常著名的作者
然后他有一本书
可能大家都读过
是凯文·凯利的一本书叫《失控》
这本书其实是一本整整30年前的书
他这本书里他又预测了
从控制论开始来讲
生命体和机器
在变得越来越像
机器越来越智能
生命体也越来越被工程化
这本书里预测了大量的
零散的
小的元件可以整合在一起
通过离散式的大规模计算
他们可能
会产生更新的智能
这本书预测了深度学习
大规模神经网络
这本书还预测了涌现
他说每一个神经元
是无意识的
但是它们整合在一起的时候
这个意识会自然而然地涌现出来
就是Emergence
Emergence这个词现在大家已经比较熟悉
当我们说大模型的时候
这个意识已经涌现了
但涌现这个词是来自于这本书
然后这本书的名字叫
失控
为什么叫失控呢
因为这本书它成功地预言了
从1994年到2023年
基本上所有人工智能的发展
但是最后它预言了
当智能体超过人类的时候
这时候会发生什么
会发生失控
这本书没有预言
后面再会发生什么
所以就是说
当智能体超越人类的时候
我们面临的这个
已经变成现实了
那么这个时候
在去年的7月份OpenAI
提出的一个问题就是
完全一样
这是我们现在的现实
超智能很有可能在未来几年内
或者我们如果悲观一点
未来十几年几十年内实现
但是当这件事情发生的时候
AI系统比每一个人都聪明
甚至是比我们全屋的人
加起来都聪明
那么我们如何保证
它还能够按照为人类的意志服务
那么这个问题就叫alignment
或者叫superalignment
超对齐
那么超对齐是个非常大的问题
现在所有的尝试都是很浅的
那么现在
最一个比较初等的
肯定未来会有很多很多新的发展
但现在一种超对齐的方式是
做用人工反馈的强化学习
它大概意思是这样
当我们有一个已经预训了好的大模型的时候
你可以想象
相当于我们来了一个
从来没有接触过世界的一个天才儿童
他知道很多信息
但他从来没有把这个信息灵活地梳理起来
也没有真正解决过任何问题
如果你跟这样一个
没有跟人说过话的天才儿童聊天
是有点痛苦的
所以最简单一件事情就是
你先要教这个天才儿童怎么好好说话
怎么好好跟人相处
之后再教他解决更复杂的问题
那么这一集在这里做到的作用就是说
它要不断地让大语言模型
和人类用户进行交互
收集人类的反馈
并且这个反馈是个很简单的反馈
就是说人对这段回答
是满意还是不满意
或者说我给你两段不同的回答
那么你更喜欢哪一段
然后用这样的数据去训练奖励函数
再用这样的奖励函数
把大语言模型的生成过程
当作一个控制策略
再用强化学习的方法进行微调
这是一个基本的基础思路
和各种不同的场景下
不同的应用
然后呢也就是说
为什么我们要从强化学习角度
来理解这件事情
因为token的生成
是一个控制过程
如果我们仅仅是模仿
那么它学不会推理
而是我们要把
如何生成变成一个策略
当我们自己在说话的时候
我们是有策略的
我们不是仅仅去像鹦鹉学者一样
所以这是为什么要用控制和强化学习
但是强化学习是有很多很多不足的
我们先不说大语言模型
我们光说机器人
这是我们组去年一个工作
就是说当我用很多离线的用户反馈数据
试图去对齐机器人的时候
这时候有很多问题
因为离线的数据
和我们理想中最优策略
对应的数据的分布不一样
这时候会造成一个distribution shift
也就是说数据不完全覆盖的时候
这里会有很多很多问题
比如现实中叫reward hacking
或者over optimization
我们看到最理想的一条红线
是理想中的performance
但实际能达到的和理想中有个很大的gap
对
然后为了解决这个问题
我们提出了一种双层强化学习算法
尼克利也是我们在对齐策略的时候
同时试图在对齐策略
然后用这种双层优化的思路
我们就可以大大的
逼近这个理论上最优
并且和这个没有做双层对齐的算法
实现了一个很大的
效果上的一个接约
然后这是一个
计算机器人
然后那个
最近我们组在
我们在这个大语言模型的对齐上
做了很多工作
这里面有很多具体的场景
和很多可以深入的方向
比如一个很具体的问题就是说
我们可能有很多不同的
不同的人类需求
有一些人喜欢这种风格
有的人喜欢那种风格
那么我想做一个更精细的对齐
而不是把少数人的需求
直接淹没在大量的数据里面
我们可以用一个
最高目标的强化学习的对齐方法
尤其用于帮助让大语言模型
能够注意到少数人的少数需求
然后同时我们最近还发布了
这种基于自我对抗的
更深度的
离线对齐算法
以及实时收集在线数据的
在线对齐算法
我们在线对齐算法比这个
现在的SOTA
应该提高了
我也读不出来数
这个30%到50%的样子
然后这是对齐
就是控制
对大语言模型不仅仅是
微调
我们另外可以做一件事情是
我们可以做
把一个小的大语言模型
和一个大的大语言模型结合起来
为什么要做这件事情呢
因为如果我们要用大的大语言模型
做生成的时候
这个大模型的成本是很高的
我们现在这个方法是
2023年有谷歌D1的第一次提出的
不是 我是我们第一次提出的
当我把小模型和大模型
组合在一起会发生什么呢
相当于你把小模型当成学生
然后大模型当成导师
然后这个学生去做生成
大模型只要去监督就可以了
但我们希望大模型就要
保证生成的结果
跟用大模型做是一样的
那么怎么去协调小模型和大模型之间
怎么让它们互相协调
达到一个最好的加速
这个也可以用强化学习来做
然后我们刚刚发布的
这个spec decoding++
就能够实现
大模型推理2.26倍的加速
然后更进一步
就是说当我们讨论对齐的时候
我们甚至可以
把对齐的奖励函数
变成数学证明的对错
或者说
自动编程的对错
从对齐的角度来讲
我们可以从一个
已经对齐的模型出发
当我们有一个新的奖励函数的时候
我们永远可以
再迁移到一个新的奖励函数上
然后在这种迁移任务里面
我们得到的最优模型
它的效果能够提升25%
甚至到超过100%
所以这里讲的都是
怎么让大语言模型可控
并且更好的为我们所用
然后接下来我们来换一个话题
我要讲的是可控大模型
大模型不光有大语言模型
生成式AI也是一种大模型
当我们想到生成式AI的时候
我们想到的都是
这个
图片 小视频
抖音 快手
但是生成式AI
同样也可以定点的
针对任何一个靶点去生成相应
能够结合的
这种蛋白质
这些看上去是不同的问题
但它们底层技术是一样的
那么先回顾一下
生成式AI的一个非常非常短的历史
生成式AI其实是一个副产品
最开始人们是在用
variational autoencoder试图把高维数据
压缩到低维数据
他们发现这个系统里面的
decoder可以把噪声
变成像模型一样的图片
那么这个副产品就非常有意思了
然后另外一个
曾经非常火的模型叫GAN
对抗式生成网络
它最早也不是为了生成
它是为了做预测
它是为了做classification和discrimination
但是这里面也有一个
因为为了对抗嘛有一个生成器
结果这个生成器就特别有意思
所以呢就是科学家发现
生成和压缩还要好玩
所以生成变成了一个单独的任务
所以当我们现在说生成的时候
就是说我们希望有一个模型
或者一个方法能够把噪音
变成我们想要的设计
我们想要的图像
甚至是其他的设计
然后如果我们去看这个VAE和GAN
这两个生成模型它有共同点
共同点在于
它的这个生成器
decoder或者generator
都是一个神经网络
相当于它一步就把噪音
变成一个新的数据点
但是
扩散模型完全改变了
生成是AI的逻辑
扩散模型本身就是
在控制一个过程
扩散模型是
从一个噪音开始解码
经过一系列非常多的timesteps
控制一个
从噪音作为出发点
终点是一张新的图片
这是一个控制过程
然后这里面
每一步
每一步的迭代
它都是由一个神经网络
来引导完成的
所以本质上我们现在训练的
这个神经网络
不管它是什么architecture
这个神经网络最终起到的作用
是一个控制器
然后多说两句
扩散模型是一个非常非常优美的
一个大模型
因为这个模型
它的出发点就是要找到一个
随机控制过程
我希望从噪音生成图片
非常难
但是如果给我一张图片
让我把它变成噪音
这个太简单了
所以这个过程是它有一个前向过程
是从图片变成噪音
我只要加噪行了
我可以设计一个特别简单的随机过程
我可以把它的VN方程写出来
那么我想做的事情是把这个过程取逆
然后概率论里面有这个非常优美的理论
可以告诉我们这个过程的逆过程
这个drift function应该长成什么样
然后就是基于这样的
随机过程的理论
扩散模型就是说
从一个加噪声的过程里面
进行试炼
最终学到了这个去噪声的控制过程
学到了去噪声的控制器
然后我们组
这个年份错了
我们组去年的一个理论工作
就是从这个统计理论上解释了
为什么这样一个加噪声去噪声的过程
能够去逼近一个有着latent
就是有一个低微流行结构的
复杂数据点
然后更进一步
就是说扩散模型
本来就是在求解一个控制过程
但是呢
我们是不是有可能
能够用它做更多的事情
比如我想求解一个优化问题
如果我们只做
传统的优化的话
我可以
我们会想象我们有一个
叫求解的一个优化函数的函数
我有一个landscape
比如我可以用
我可以做模拟退火
我可以做梯度法
它可能是非凸的也是非线性的
然后我们要在这个空间做搜索
我可能要设计一个很复杂的算法
如果我的算法恰好符合这个问题的
几何结构的话
我可能就会效率高
但是呢我没有利用数据的能力
所以我们想说的是
如果我们想优化一个蛋白质
优化一个电路设计
尤其是当它们特别复杂的时候
我们很有可能利用生成式AI
比如扩散模型
作为一个底座
然后在上面再把求解器搭上去
这样我们球可以又利用数据
又利用求解器
去直接生成更复杂的
任意的新目标函数的解
然后这就是我们去年到今年的一系列工作
然后这一系列工作
就是
是和这个业余老师
一起合作
并且我们还在不断地推进这个方向
比如我们做了一系列工作
来找到了一种
轻量级的把一个
已经预训练好的
扩散模型进行自适应的方式
使得它在
我们不需要改它的
甚至可能不需要改它的权重
我们只需要在这个
解码的过程
解码的过程其实是一个温文方程
我们只需要在解码的过程中
加一些额外的控制量
然后我们可以去设计这个控制量
让这个解码的过程最有效
最平滑能够生成任何一个
我们想要的目标函数的解
这说明什么呢
就是我们想做一种能指哪儿打哪儿的设计
然后最后一页就是说
当我们想用生成的方式
去
升级优化算法的时候
我们除了做视频和美图
我们还能做什么
比如啊
生成式模型应该大量用于机器人的控制
生成的是从以往的机器人轨迹数据里面
生成新场景里面
新的机器人的数据
然后我生成新的数据的时候
新的轨迹的时候还可以自动做优化
然后我们可以生成
蛋白质结构
然后我们可以生成DNA和RNA的分子
我们组今年年初有一个
自刊的论文
就是说如何用生成式的语言模型
来生成新的mRNA疫苗设计
然后同时
还有很多新的方向
比如去年还是谷歌D1的有一篇paper
是用生成式模型做材料开发
它在一篇论文里面
生成了超过220万种新的晶体结构
晶体结构是很复杂的
需要满足一些数学上的拓扑结构
然后这220个新的晶体结构
都是可以合成的
然后这篇论文里面
还估算了一下
如果是人来搜索这些晶体结构
所有人不是一个人
按照全人类原来的搜索速度
他们需要800年才能找到这一篇论文
生成的晶体结构
所以就是说当我们用扩散模型
我们讨论生成式AI的时候
我们能够更可控
我们能够越精确地控制扩散模型
我们就能够生成越复杂的设计
然后它的应用远远不止于小视频和美图
它可以生成新的材料
它可以生成新的电路设计
新的基因序列
还可以做机器人的控制
最后就是说
当我们已经有大模型的时候
如何让它可控为我们所用
这应该是通往AGI的一个必经之路
谢谢大家
感谢王教授的精彩分享
在演讲中
我们深入了解到了
扩散模型的统计特性
以及它们在优化问题中的潜在应用
扩散模型代表着生成式人工智能的重大突破
而在当今人工智能迅速崛起的时代
如何拥抱变革
把握机遇至关重要
接下来
我们有请宾夕法尼亚大学沃顿商学院中生教授
机器学习研究中心主任
苏韦杰先生
为我们带来主题演讲
人工智能和数据科学的经济展望
掌声有请苏教授
谢谢
以往我给报告一般都是
先做slide piece
做好以后
然后再起个标题
这个标题只要符合内容就行
这一次是我先起了个标题
然后再想
怎么样做一个slide
然后这样给我增加了
非常大的难度
我是今天上午才做完
然后
特别大的难度在于什么呢
这个展望
什么叫展望
因为这是预测未来发生的事情
这个是最难的
因为我设计到人工智能
数据科学 经济
其实特别是经济
我也不是特别懂经济
虽然我在商学
但不是特别懂
所以今天这个报告
更多是比较偏文科
就是更多是启发性的
我更多是一种
抛砖钻隐域的
一个期望
对 这是我本人
对
这个前面几位老师
已经讲过很多铺垫了
去年开始
是
生成是人工智能的一个
可以说是起点吧
然后突然
它之前有很多年的积累
但是去年开始
就突然大的爆发了
那么这个它已经成为了一种
军备竞赛
从一开始
开始需要
几千块GPU
所以门槛慢慢慢慢增加到
几万块
甚至最近看到新闻是
XAI
Elon Musk XAI他们准备购买
十万块H100
然后来训练他们的模型
就是已经这个是
这个需要的能量
可能是需要以
国家级别的能力
才能够驱动这样的
这样的训练了
那么
然后它的影响力
是什么样的
它是什么样的
从学术角度
它让我们以往比较公认的
图灵测试
可能没有那么重要了
因为图灵测试是计算机的一个
非常重要的一个假想实验
就是如果我们能够闭上眼睛
跟一个东西对话
发现它跟我们人自己
跟人直接说话
没什么区别那么我们觉得它已经
达到了人工智能
现在Language Model
大模型对话确实有种感
人的感觉是差不多
但是我们还不能说它达到了
通用人工智能
包括叶老师提到一个例子
就是一个简单的问题它都会出错
看起来很合理
但是错误总是在
这跟我们人还是不一样的
那说明图灵测试
这个图灵
在可能70年前提出了一个
假想实验
现在已经慢慢失去了它的
客观性吧
它比较擅长于
Coding
写作和知识的一些整合
更多还是一种整合吧
它并不是一种
完全新的知识的产生
然后它产生了
巨大的商业价值
当然商业价值
很多大家都在抱怨
它这种价值都归给
NVIDIA了
很多公司
AI本身
创造的价值
是在创造
但是怎么样把它
能够在一个垂直众生的领域中
产生
这需要精根细做
还需要
一段时间的积累
所以暂时只是让NVIDIA
赚了这个钱
那么从经济的角度
我们标题中
很重要的一个关键词就是经济
那么经济上
这个大模型跟经济什么关系
比较早期
它就已经有一个论文
这是会亮的吗
就GBT
第二个GBT
并不是另外一个缩写
这篇文章
在GBT4
刚出来的时候
就做了一个分析
然后分析它在
就业市场上对每个不同的
工种它会有什么影响
然后得出来的结论是
对一些比较
高精尖的工作的影响
可能会更大
对于一些比较相对我们可能看起来低端
可能对
体力要求高的工作可能影响反而
比较小
这个跟葛老师的观察
完全一致
确实他首先替代的其实是
我们这些人
所以我当时看到GBT
出来的时候我的第一个反应就是
我以前比较觉得自己
有点小小骄傲的一些技能
我觉得其实我可能
高估自己了确实
比如今年年初
年初有一个
Alpha Geometry
是吧就是一个Alpha Gold
DeepMind推出了一个工作
可以解决
IMO就是国际数学
奥林匹克几何
几何的
那种题目
这是以往我自己觉得
我是比较擅长的
我觉得我是偶尔
觉得还有一点点小自豪的
一些技能
但发现这些东西现在已经完全被自动化了
越是觉得相对
可能以前觉得抽象高端的能力
其实它解决得更快一点
反而那些体力
那些要真的动手去做的那些能力
其实是反而现在
替代可能是比较慢的
那么
那么它其实
现在
从经济角度而言
它现在产生了一种
计算机跟经济的
一种交融
那么从经济的角度
那么我们怎么样
数据成为了一种新的资源
怎么样
给数据定价
那么就是一个问题
这个陈老师也提到了
怎么定价
是一个非常重要的问题
因为根据完全根据推理的那个
时间
可以很好的反映它本身的这个价值
它价值来自于它
它是否解决了问题
还不在于它什么训练的时间有多长
那么怎么样能保证它的公平性
公平性在经济中也是个非常重要的问题
因为
我们不能只关注
51%的那个大多数
少数的49%
甚至更少的1%的
那些目标也是需要我们关注的
这也是
陈老师提到过的那个reg
那个信息增强
这个也是从经济角度
这是一个
online advertisement
一个非常大的一个价值
那么从更大的角度
从宏观的角度
这个可能更微观吧
微观经济
从宏观经济的角度来讲
那么AI的发展使得
它怎么样慢慢扩散到
我们的就业市场
那么它的速度有多快
这是一个不确定的问题
是一个非常值得研究的问题
然后怎么样它慢慢可能会替代
我们人类
这个也取决于我们
人类的工作的
这个复杂度
然后是不是
跟环境的
这个动
交互密不密切
还涉及到
两极化
因为现在有一种理论
是AI如果
再继续发展下去
中产阶级可能会消亡
因为中产阶级其实就是
最容易被替代的那些人
就是我们
底层的靠体力
其实暂时还不会受到威胁
然后资本更不会受到威胁
因为AI是不能替代资本的
所以这样的话
它把中产阶级给消灭了
那我们的人类的社会
最近工业革命以后
工业社会就不稳定了
可能是一个巨大改变
所以从
这个角度而言
它比第二次第三次
工业革命肯定影响力还要更大
还有
是美国的
巨大优势
因为AI
的
它对
如果通用人工智能实现
它的影响力是
远远超过前面两三次
因为它是
本质上是替代人
而不是光增强人
所以某些国家可能在这方面
会有极大的优势
它会让其他一些国家
在根本就
没法竞争
那么
这是我对AI和
经济的
比较粗浅的理解
有两边的理解
第一边理解就是AI怎么影响经济
在上面
我们怎么样根据我们的理解
能够更好的设计
AI的模型
使得它更好的有些经济的考量
那么我们先考虑
上面这个
上面这个
就怎么样AI会影响经济
我再次声明
开放的一些讨论
现在没有定论
那么它对
工作的影响呢
刚刚我也提到
它对工作的影响
与传统的理解稍微有些不太一样
那么我们可以引进
这么一个概念
叫做information complete
信息是不是完备
什么是信息完备呢
信息完备的意思是
这个工作它是不是像计算机
有个输出有个输入
它中间这个过程
它跟环境互动是比较少的
它是可以说是在一个封闭空间中
就可以完成的工作
越是这样的工作呢
首先这类工作有哪些呢
比如像程序员
会计啊
包括作家其实也是
相对比较容易替代
因为它输入输出是
比较确定
然后但是第二类呢
其实我觉得也是
相对可能会比较容易取代的
我相信是这样
就是最聪明的人
就图令奖得主
诺贝尔奖得主
费尔斯奖得主我觉得是最容易
工作的
所以它对我们人类的
替代这个程度是
跟我们普通
我们以往的想象可能是有点不太一致的
那么我们人类有很多很多种
能力啊
我这个只是随便写了几种啊
就是信息处理的能力
语言理解还有推荐
还有复杂问题的决策
还有
像我们做
research的也是一种能力
对然后那么它
AI什么时候会取代
哪些能力那么现在这是一个
非常讨论
非常激烈的问题
而且这个讨论过程中
我感受到一些
比较震撼的
一些一个方面
是原来最头顾的
那些人物他们
自己都相互
并不
同意对方
这个是比较少见的
因为以往大家的分歧
以往对历史上大量的问题的
不确定往往是来自于
两个不同的群体
他们是来自不同的
背景啊或者来自不同的
区域
什么的各种但是现在是什么
这三个图灵
对图灵讲得主啊
就是图灵讲得主深度学习的
三巨头啊三巨头
想必他们是应该现在是我们人类
中对AI理解最深刻的
这三个人至少是三个人之一吧
但是他们之间其实
对AI怎么样
会影响人类从长远
长远的宏观的角度
是理解很不一致的
耶勒昆觉得AI
还很遥远
从即时实现它对人
还是一个更多是一个
工具啊
但是Hinton包括Benjo
已经现在开始已经投入
很大的时间
去研究AI的risk
从长远
长远的角度
它对我们人类社会的破坏性
就那个失控包括
王老师刚刚提到的那个
失控那本书就是很危险
就是后面就没有故事了
那失控以后就是人类的文明终结吗
所以这个是Hinton和Benjo
现在比较关心的
关心的课题
所以他跟耶勒昆是完全是
是相同的
那么
从他们的讨论
他们相互还在激烈的讨论
那么我们能看出来是
这个是一个公开的
公开的问题
现在还没有定论
但是我们
我们不知道这个问题
并不等于我们什么都不知道
其实我们还知道一些的
这是我自己的总结
我的总结是
这不是我的
这并不是我的research
是我的个人体会
添加了这个
这个人类的
这个人类的
这个人类的
2010年
一个人称
那个人称
一个人称
是里面的
有一个人称
Skilling Law
当然我们接下来稍微会更多讲一点
Skilling Law本质上是说
随着你计算的资源数据增加
你的模型的能力是完全可预测的
是服从一个简单函数
一个密词函数
那么这种情况是我觉得
我个人觉得是一个比较
如果是有个上帝的话
它是一个比较nice的上帝
是我们可以
也许一定程度上
我们是能把握自己的命运的
另外一种是一个不可预测的世界
就是新的技能会不停地涌现
然后我们不知道什么时候会存在
也许就再努力一把
我们就可以有一种新的技能
但是也许因为我们不知道在哪里
我们就永远地失去这个机会了
所以这个一个代表
就是这个涌现
就是这个涌现能力
这个也是在大约模型中
现在观测到的一个现象
就是没法预测
前一秒觉得这个能力好像还遥遥无期
下一秒再努力一把
就直接就达到完美了
就是有这种
有个突变
那么有突变的话
那么我们就
其实我们人类的命运
未来很大程度上是要靠运气
我们不能完全自己把握自己的命运
所以这有两种可能性
我不知道是哪种
希望是第一种
对
Scaling Law和Emerging Ability
那么介绍一下吧
这个Scaling Law就是指
我们有很多的计算资源
然后函数
它的选择函数是服从了一个非常
可以说是曲线
一条直线
取了log以后就是一条直线了
这个有点像物理
因为物理中我们经常能看到这样的完美的预测
在计算机
在FG学习中几乎从来没见到过这样的预测
我心中就出现了
相当于如果有这个Scaling Law
Scaling Law能够继续下去
那么相当于我们有个水晶球
我们能够把握自己的命运
那么另外一种角度是
它是一个涌现
那个涌现的话
那么就是一个不确定的未来
什么时候出现我们是不知道的
这个就是诺贝尔奖物理得主
这个量子力学的Founding Father之一
那个波尔就提到的
预测未来永远是最困难的
这也许也是量子力学的本质吧
量子力学就是不可预测
当然从理论上其实这两者也是有联系的
这个也有工作
说Emerging Ability和Scaling Law并不矛盾
就是并不矛盾
但是它给我们的世界观是两种完全不一样的世界观
一种是非常可预测
另外一种听天由命
两种非常极端的情况
那么这个我讲完了
这是第一部分
这是我个人体会
就是AI对经济的影响
简单的说有两种可能性
一种是可预测
另外一种不可预测
但是具体哪一种没法预测
那么现在我们考虑第二种
就是从经济的角度
能不能我们对AI的设计做一些事情呢
那么这张图好像在之前好几位老师slide中出现了
特别是王梦迪老师刚刚也在他的报告中出现了
然后他也做了非常详细的介绍
那么也许我就可以过了
简单的说就是这个是大圆模型训练中微调的那一部分
怎么样让它更好的能够跟人交流
符合我们人类的预期
然后知道我们人类想要什么
不想要什么
那么从经济的角度
我们其实不光想知道
51%的人想做什么
我们永远要关心那些49%
甚至1%的人想要什么
我们需要知道整个世界的它的分布
而不是只知道最大的那部分
比如我们想知道现在有多少人喜欢咖啡
有多少人喜欢茶
这个关键是知道它这个比例
而不是只知道大多数人喜欢什么
那么这个不光是公平性
其实这个对经济非常有影响
因为我们做经济决策的时候
需要知道准确的比例
这个准确的比例有助于我们做经济上最完美的选择
那么比如我想抽象一个例子
我想现在开一个披萨店还是一个寿司店
那么我需要知道我这个区域中
喜欢披萨的人和寿司的人他们的比例
如果比例是80%对20%
那么也许我应该是披萨
但如果是10%跟90%
那么应该完全就不一样
那么我们怎么样能够模拟这种事情呢
我们就需要做一些简单的
一个模型
通过这个BTL模型来通过
来概率上来确定
多少人喜欢Apple
多少人喜欢苹果
多少人喜欢这个橙子
好
那么
但是在这个过程中
我们一定需要保证少数人他们的利益
能够他们的
我们要得到他们的有关注点
这个在
在OpenAI训练的数据中也有体现
他们的训练数据中
公开的instructivity中
他们有雇用了大量的人工标注数据
人工标注数据中也有百分之大概百分之二三十是不一致的
那说明
那说明什么
那说明这种不一致是一种天然的
这种天然它不光光是
它不是错误
它是体现了一种自由度
像茶和咖啡
本身一部分人就喜欢
一部分人就不喜欢
它并没有对错之分
这种没有对错之分的这种分布
它其实适应了是一种经济的一种考量
经济上我们要
要最大化我们的收益
我们就需要考虑它的整体分布
而不是只知道它最大的那个mode
好
那么
异地链小小的数学
我们近期的一个工作是这样
这个是
强化学习
对
这个
这个是强化学习中
最后有一个reward model以后
用强化学习然后希望
这个大模型能够更好地符合人类的预期
但是呢我们先提出加一个正则项
这个正则项呢就是
是一个函数
这个函数什么函数呢
是它这个分布的函数
这个probability
大概多少人喜欢
它有多少概率喜欢这个苹果
有多少概率喜欢橘子
就这么一个函数
我们想确定这个r这个函数的形式
是它能够完美地符合我们
它跟人类的这个语言
人类这个偏好
然后我们简单地
简单地一个计算
然后数学上证明了
它当且仅当
当且仅当这个r这个
这个损失
这个正则函数它符合
它一定是这个形式
这个形式
那比较重要的重点呢
是这个log
那这个log呢
本质上就是说什么呢
它本质上是说
我们是要对它
加一个相容的
一个商的一个惩罚项
商要大一些
商不能太小
什么是商
商就是一种不确定性
就是零一之间
我不要都是零
也不要都是一
我希望在中间 是吧
特别是二分之一的时候
商是最大的
所以这个商是entropy
它希望我们能够保持
能够保证它原来的分布
而不是把49%就设为零了
对
那么我们建议
在这个范式下
我们建议前面都是一样
就是先训练
做预训练
然后通过rlhf
满足人类偏好
但最后最后一步
我们通过
加这么一个preference matching
加一个log这么一个项
做一个微调
使得它
更好地符合我们人类的偏好
对
然后这个是我们的第一部分
经济上
那么总结一下
这部分是通过经济上的偏好的概率分布
然后我们有选择的
使得大元模型的损失函数
能够符合我们的这个预期
那么第二部分呢
我们讲一下这个数据
那么数据呢
是21世纪的石油
石油
这也是Elon Musk
他当时想买下
Twitter的一个动力
现在看来他这个决策是挺正确的
因为他现在同时拥有Twitter
现在叫X
和一个AI公司XAI
这两个公司其实是缺一不可
因为Twitter提供大量的数据
而且是实时的数据
海量的数据
然后XAI
现在它就可以直接用Twitter的数据来训练
然后它Twitter现在已经不允许外面的人爬虫了
所以Twitter成了它的私有数据
这方面是XAI
它那个公司现在以比较小的投入
但市值已经达到了
好像有个估计是预期一个估计
达到OpenAI的三分之一
所以OpenAI果然是
有这个很有眼光
它很早就是可能布局了
那么但是这个数据
重要的过程中大家发现
就是它引起了一个专利的问题
专业问题
因为它可以
有些有专利保护的数据
也在用于训练AI的模型
比如一个早期的例子
对这个扩散模型
大家直接通过
说
输入一个提示词
是一个人的名字
然后它就直接生成一个
原始训练数据中的一张图片
这张图片
基本上完全是一样的
只是这个
稍微像素点
稍微低一点
但其他就没什么区别
那如果这张图片是它不光
它的影响是非常深远的
它破坏了隐私
我们不希望有些数据
我个人的照片
直接就是让别人看到了
还有一点更严重
它如果是受专利保护的话
那么就是这个
它会引起法律上的一些纠纷
那么现在像
纽约时报已经正式起诉了
OpenAI和微软
然后起诉他们在侵权
他们训练他们的单量数据
像索尼已经禁止AI公司
训练他们的音乐
训练音乐
然后有各种
现在很多的起诉这方面
那么各个国家
各个国家的反应是不一样的
像日本
日本基本就放了
放弃了数据的保护
所以这也是OpenAI最近
它在除了三藩之外
它最近在东京开了一个分部
好像我不记得应该
因为OpenAI在其他地方
都没有分部吧
它在东京有一个分部
主要也是看中了
日本的这么一个政策
它在日本训练AI模型
数据不受任何保护
也能理解
因为日本基本上
就错失了前两代的信息技术
所以它可能想在这一波生成技术上
能够跟上
那要跟上的话
就是必须要非常手段
那非常手段就是说
随便训练
没有任何保护
好的
但是这个问题是
如果我们不保护专利
短期而言可能是痛快了
我们想训练是什么
随便训练
但长期以往
它会伤害我们人类的
作为一个智慧的物种
创新能力
会影响我们的创新能力
这个原理很简单
因为我们创新
我们都是需要有激励的
我们创新是因为
我们会能得到更大的回报
但是如果我们的作品
最后被AI学到了
然后它能够生成
跟我们差不多的风格的作品
那艺术家
我们人类中最优秀的那些创造型人物
有创造力的人群
他们怎么样能够获得一个
他们怎么样生存下去
这就是问题
那如果这样的人群消失了
那么未来我们在互联网上的那些数据
就充斥的
本身就是由AI生成的这些数据
所以这个就变成了
那个就是
garbage in garbage out
现在一个信仰就是
model collapse
已经有实验表明
如果AI模型用自己的
输出的数据来训练
它的效用就会逐渐下降
最终就是慢慢慢慢
慢慢变得越来越差
好的
那么我们这里想提出一个方案
就是我们希望引进
一个经济上的一个角度
把copyright呢
用经济的手段把它来解决
我们也不是完全保护copyright
但是专利
但是让有专利的
让有专利数据的
公司或者个人
能够得到相应的回报
那么经济
用经济或者金融的手段
解决这种问题
本质上其实还是overall
其实我们想达到
最高的整体效用
整体的效用
我们想是最大的
所以我们希望AI模型
还是用最好的数据来训练
它不受任何限制
因为我们希望它能达到
最好的性能
但是同时我们希望
人群中我们贡献了这些数据
贡献了这些专利数据的那些人群
它能够得到相应的回报
那这个问题是什么
回报
这个回报有多大
这就是一个重要的问题
怎么样我们平衡
平衡这个回报
那么一个例子呢就是
一个著名的音乐分享网站
分享平台Spotify
现在很多音乐家就是
就是在Spotify
然后售卖他们的音乐作品
在这个过程中
平台会收取一部分费用
但是如果音乐家这个歌手
他的作品非常非常非常流行
很多人听
那么他的回报也会比较多
所以跟音乐家本身的贡献也是成
造成正比
不是线性的正比
但是有这么一个趋势
那我们也想设计这么一个机制
然后能够达到这么一个效果
就本身上AI公司需要make an offer
就是要reasonable
至少reasonable
对
那么我们的这个想法呢
本质上是用了博弈论的这种想法
在博弈论中有一个sharply value
叫sharply
这个sharply它首先要明确一点什么呢
明确一点
现在考虑若干个人S
每一个人都有他们的数据
然后我现在只用他们的数据
来训练一个AI模型
那么我想知道这个模型呢
它的效用有多大
那么我们提出来这么一个东西
Log分子除以分母
那分子是什么呢
分子是我生成这个图片
只用S的数据的这个概率
分母呢就是
我什么都不用
我只用比如免费的数据
公开的数据来训练这个模型
然后生成那张图片的概率
那么如果这个分子
大于分母
那说明S的数据也非常有价值
非常有价值
那么去log以后也比较大
那么这个回报就会比较高
那么这就是他们这个S的这个coalition
这个组合的
它应该应该应用的价值
应用的价值
那么一个例子就是
我们现在有四个艺术家
比如梵高 莫奈等等
毕加索 伦伯朗
那么我们可以用他们之间的组合
比如我只用梵高和莫奈的数据来训练
那么训练一个模型
然后看看这个模型跟
不用他们的数据的模型
它使得效用提高了多少
这就是我们认为
梵高和莫奈这个组合
他们组合应该拿到了回报
那么现在我们只是讨论了每一个组合
我们并没有落实到
单独一个梵高或者一个莫奈
那么怎么样从整体的这个组合的这个收益
然后退到每一个个人艺术家
个体艺术家的这个回报
那么这个就涉及到了一个
诺贝尔经济学奖的一个贡献
就是这个叫做Shapley值
Shapley是为
他跟纳斯非常像
他们背景都是数学家
但是都获得了诺贝尔经济学奖
这个Shapley value是他的诺贝尔奖的贡献之一
这个贡献怎么说呢
他就是把每一个组合
就是比如梵高和莫奈
他们应该得到了回报
然后能够推导出每一个具体的
单个的艺术家
他应该得到的回报
而且他这个值以他自己名字秘密的这个值呢
可以在某种意义下是唯一的
因为他保证了这个有效性对称性等等
他是唯一的
他是唯一的
那么我们就是用这个Shapley value
然后就得出每一个艺术家应该
分享的这个比例
比如在这里
梵高他的比例是最高的38
然后其他稍微低一点这个比例
当然实际情况是
整体他应该是需要有一些沟通
有一些negotiations
就是在艺术家
整体艺术家和那个AI公司
比如AI公司保证
他把20%的利润分配给这些艺术家
然后这些20%的利润呢
然后这些20%的利润呢
总量下以这个比例
以这个38.5%啊等这些比例
然后再一次分配到这些单独艺术家身上
对
然后这个过程中
对
这个过程中
每个艺术家他当然也可以选择退出这个机制
他存在这么一个退出机制在这里面
这个就是我们的一个实验
简单地说
比如我们能够看到
这些非对角线上的一些
有些比较大
比如相对这个比较大一点
这个就说明什么呢
这说明莫奈和梵高
它们之间风格有一定的相似性
就是用梵高的作品
相对可以更容易地生成
莫奈的作品
好的
那最后我结束了
时间应该差不多是吧
然后
现在可能正在形成一种新的经济学
我不是经济学的这方面的专家
但是我能够体会到
因为生成是AI
或者说更大来讲AI
它是一种
真的是革命性的影响
它不光像以往
第一次第二次工业革命
前面几次工业革命
更多是让我们人跑得更快
飞得更高
是增强人
但是现在这一次AI
的
的
,的涌现
其实某种程度上是替代我们人类
或至少替代
至少让一部分人类
能够替代其他人类
所以在这个过程中
经济学的原来的假设
原来的一些机制
可能会有颠覆性的
颠覆性的一些变化
所以
有志于做
对经济学和
经济学和AI感兴趣的朋友
这是我非常建议的一个领域
因为AI
其实如果你不是
工科背景
想直接去设计它们这种架构
难得
但是
把AI作为一个工具应用到
应用到经济学中
那么一下子
它的自由度就会非常大
这是一个非常
相当于是个蓝海
是有很多很多机会的
那么最后这个是我的一张这么一张图
AI呢是这个霸王龙
它非常强大
但是我相信我们人类有机会
能够掌控它
应该不会失控的
我相信是
谢谢大家
感谢苏教授的精彩分享
数字经济浪潮席卷而来
催生了各行业技术
与应用的不断迭代
今天我们和大家相聚于此
共同见证了智能计算技术
推动数字经济增长的新征程
也探索了人工智能技术
不断发展促进数字经济产业创新的美好未来
尊敬的各位来宾
下面我宣布
AI加领航智慧未来
2024人工智能大会
智能计算与强化学习论坛
到此圆满结束
再次感谢出席本次分会的所有嘉宾和观众朋友们
最后祝大家工作顺利
万事如意
期待与您下次再会
谢谢大家