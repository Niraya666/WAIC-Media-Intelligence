 Hello everyone, welcome to my channel.
 Today I will show you how to make a simple and easy cake.
 Please subscribe to my channel and press the bell icon to receive notifications when I upload a new video.
 Let's get started.
 1 egg
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 1 tsp vanilla extract
 Thank you for watching!
 Please sit down as soon as possible and turn off mobile phones and other communication devices, or remain silent. Thank you for your cooperation.
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 Thank you for watching!
 中央网信办展示了人工智能治理的中国方案,就全球普遍关注的人工智能发展与治理问题,提出建设性解决思路,为相关国际讨论和规则制定提供了蓝本,也为开展人工智能安全治理工作提供了根本的遵循。
 积极响应并落实倡议,中央网信办正在组织研究人工智能安全治理框架,以推动政府、国际组织、企业、科研院所、民间机构和公民等各方就人工智能安全治理达成共识、协调一致。
 借此机会与大家分享几点关于人工智能安全治理的看法与思考。
 一是坚持包容审慎,确保安全的原则。
 对人工智能研发应用应采取包容的态度,鼓励发展创新。
 同时对危害组织。
 二是坚持国家安全、社会公共利益、公众合法权益的风险要及时采取措施。
 去年,中央网信办会从相关部门制定出台了生成式人工智能服务管理办法。
 本着促进创新和依法治理相结合的理念,在明确风险隐患防范责任和管理要求的同时,最大限度为技术和应用发展预留空间,推行包容审慎和分类分级的监管。
 二是坚持风险导向、敏捷治理的原则。
 目前,基于风险的治理理论,
 与取得一定共识,如何科学地认定、分类、感知、测评风险,并提出针对性的防范应对措施,是各方的研究热点。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险,也面临不当使用、滥用甚至恶意利用带来的安全风险。
 同时,随着人工智能技术快速发展,安全风险的表现形式、影响程度、认知、感知与随之不断变化,防范应对措施也要相应地动作。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险,也面临不当使用、滥用甚至恶意利用带来的安全风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险,也面临不当使用、滥用甚至恶意利用带来的安全风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 人工智能安全风险既包括自身的技术缺陷不足带来的风险。
 只是從頭開始。
 那麼我在學習研究這個東西呢,
 基本上所有的飲料,我沒有用,
 他們可能沒有用胎兒,
 也沒有用黃岩長的悟道,
 我主要是靠我自己積累。
 那當然這個代碼也很少用hug face的,
 因為四年以前的hug face還不是今天這麼好用,
 如果今天來做的話,我可能就要用hug face了。
 而且我還有一個,
 我來學習研究這個模型,
 我是個體戶,
 黃岩長你們在座的都有很多,
 菁英在這,自己本身就是菁英,
 我就是一個個體戶。
 所以這樣我更就大模型的,
 或者就女人模型的學習研究,
 中間的甜酸苦辣,
 能有不一樣的體會,
 別樣的感覺,
 所以我跟大家說說我的這個感覺。
 我想,
 或者第一個我覺得啊,
 我們用大模型,
 我講的大模型,
 都是來講的技術transformer的,
 這種女人模型。
 很多人告訴我,
 說現在的大模型基本上都是技術transformer的,
 那我覺得就,
 一致了。
 我覺得我們用大模型啊,
 要善於用其所長。
 那怎麼用其所長,
 我覺得呢?
 我在剛才我在思考,
 咱們這個主題,
 是叫可信大模型的創新運用。
 那首先,
 什麼是可信大模型?
 說實話,
 我也不知道這個概念,
 怎麼來衡量這個可信的能量。
 但我覺得有一條,
 我們講到可信大模型,
 我們是不是就要去琢磨,
 我們的模型有哪些東西,
 它還是不太可信的,
 或者還值得去再進一步來提高的。
 剛才博超局長在致詞中間提到了,
 要增加大模型的可解釋性,
 那就說明它現在還不太可解釋。
 那麼我們當然,
 這是我們覺得還不是特別可信的地方,
 我們要去學習,
 去研究。
 那這是其中之一啊。
 前兩天啊,
 我看到一個互聯網上的東西,
 是真是假,
 我無從考究。
 大家知道,
 因為27號,
 拜登和特朗普,
 搞了那麼首場辯論。
 那辯論以後,
 凱恩·麥克斯這個人,
 在座的很多都很熟悉,
 以向是對平等大模型,
 這是他的比較熱衷的一件事情。
 他就說了,
 兩位先生在辯論以後,
 麥克斯就說,
 他說,
 特朗普說謊像大模型一樣。
 這個我就覺得了,
 可能有點偏頗。
 大模型,
 我覺得他不會說謊,
 但是大模型,
 他可能說錯,
 也可能是大家說的,
 哈斯雷什,
 哈斯雷什,
 這些東西。
 那麼他為什麼會說錯這些東西?
 我覺得,
 從我看來,
 或者說,
 從純粹實現的角度來講,
 我們現在的語言模型,
 基於Transform的語言模型,
 無非就是語言空間的一種概略分布。
 我們要根據這個概略分布,
 給定的語言系列來判斷,
 以最大概率的方式,
 求定它的下一個語言型。
 既然是基於概略分布的,
 那當然它就不存在唯一性。
 或者說它存在唯一性,
 它就存在它的單調性。
 那麼把兩個合起來以後,
 它必然就存在它的一個不確定性。
 這可能就是,
 我們現在如果把大模型用來,
 做深沉,
 做寫詩,
 做畫,
 它可能,
 它的固有特性,
 當然我們在想很多,
 我們的科學家們在想很多辦法,
 來去調和它,
 去完善它,
 去改善它,
 確實起到了很多的進展。
 那我再想一件事情,
 這些問題都是我們在用語言模型,
 用Transformer,
 在深沉這個任務中間,
 來發現,
 來出現了。
 我們回想一下,
 2017年,
 瓦斯凡利他們八個人寫了一個,
 《Autism is all you need》這個文章的時候,
 它的主要出發點是幹什麼呢?
 它主要出發點是做翻譯。
 當然文章它也講到了,
 它的這個Transformer,
 還可以做很多其他的應對,
 但是畢竟它是什麼?
 那我從這個地方來講,
 我覺得我們的Transformer語言模型,
 它在索償,
 常在懶,
 它在常在分析,
 在判斷。
 那麼它用來做深沉,
 做推理,
 可能也是我們一個很好的嘗試。
 那麼用好大模型來做判斷,
 來做分析,
 來做分類,
 我們可能對我們的生態理念,
 對我們的工作,
 就可以減少我們講的不可信心。
 這麼一個,
 我就講,
 說的意思,
 要特別重視語言模型,
 或者說大模型,
 在專業領域,
 戲份領域,
 隨之領域的應用。
 當然,
 我們也不否定,
 我們大模型來進行創作,
 來進行聊天,
 來寫詩作畫,
 我覺得我們大模型還有一個優勢,
 但是大模型的這種思維方式,
 這種方法,
 這種形成的激勵和過程,
 值得我們加以學習和慰問。
 我覺得我們應該,
 這講的是創新應用,
 我們應該按照創新應用這個思路,
 用大模型的方法、激勵,
 甚至這個形成過程,
 來研究非語言模型。
 我們現在很多模型就是基於語言的模型,
 那麼如果我們去研究用這個思維的方法,
 去做非語言模型,
 那麼我們做音頻的模型,
 做視頻的模型,
 我們做音樂,
 做CT,
 做S光片的解讀模型,
 我們做我們自動駕駛的這一類的模型。
 我認為這一類模型,
 你們看看它有什麼,
 它主要是分析,
 主要是分類,
 主要是判斷,
 它少一些生成任務,
 所以我們存在的一些不確定性,
 我們可以不讓它回避。
 相反,它更有利於把我們的模型,
 大模型,
 變成實用的工具,
 變成生產工具,
 變成競爭力,
 變成發展力。
 我都想到了,
 說到了,
 我還在想,
 我覺得我們現在這個大模型,語言模型,
 也即待創新,
 有待創新。
 大家都很清楚,
 今天我參加我們這個論壇呢,
 說也有OpenAI的這個專家,
 當然是都是原專家。
 大家很清楚,
 OpenAI的2022年,
 已經推出了一個CHI GPT,
 的確,
 對推動人工智能的發展,
 起了非常非常重要的作用。
 它常以一個本來對普通老百姓來講,
 高深莫測,
 一個實驗室的高科技,
 高簡單的理論,
 一下子來到了老百姓,
 來到了市場。
 讓大家知道什麼是AI,
 同時不排除,
 也就是因為這個CHI GPT,
 我們讓更多的資金,
 更多的資本,
 來投到我們的AI,
 投到我們的大模型,
 也客觀上,
 推動了我們模型的發展。
 但是有一天,
 大家還有一件事情,
 大家可能注意的不是太多,
 2022年,
 推出CHI的GPT,
 同樣是OpenAI,
 大概是2020年,
 這個黃院長應該會有權威心。
 他們的CHI OpenAI的十位專家,
 發了一篇論文,
 這個論文叫做
 Scaling North for Neural Language Models,
 這個論文裡面,
 提出了一個scaling north,
 這個怎麼翻,
 擴張規則還是什麼東西,
 還不如把它叫一個openAI規則。
 那麼我們很多人看來,
 要根據這個scaling north,
 那麼我們在現在的,
 這個技術transform這個模型,
 只要我們在,
 模型規模,
 或者主要體驗模型參數,
 只要在我們的訓練數據規模,
 再加上我們的計算能力,
 它如果指數性的增長,
 它就能帶來我們模型性能的持續性的提升。
 當然這個論文本身,
 它並沒這麼說,
 論文本身它是講的,
 進入交叉上的loss,
 就cross-entropy loss,
 這個東西提出來的,
 而且它是用performance提出來的,
 但是我們現在,
 對我們的市場,
 對我們的一些地方來講,
 那可能就形成,
 只要增加訓練算力,
 只要增加飲料規模,
 只要增加算力,
 模型參數很快呀,
 從多少,
 幾億,
 幾十億,
 是不是現在到了幾萬億,
 我不是特別清楚,
 一直可以持續地分析,
 算力,
 大家都有幾多算力,
 那麼是不是它就一直,
 我覺得這個不一定,
 這個,
 這可能也是我們現在大家講的,
 大力出奇技,
 這麼一個說法,
 在去年九月份,
 國家網絡安全宣傳週,
 這個論壇上,
 我做了一個發言,
 也是關於人工智能的,
 我當時提到了,
 我說,
 大模型當然,
 這是非常好,
 但是我有點擔心,
 基於transforming的,
 這個大模型,
 是不是已經入上天花板,
 那麼我今天也有點擔心,
 大力,
 它會不會,
 就不一定出奇技,
 是跟您鬧,
 它在什麼樣的條件,
 它能成立,
 當然,
 OpenAI的專家也給,
 他是給出,
 他在七個數量級的時候,
 他說它是成立的,
 雖然他有一句話說,
 在更大數量級的時候,
 沒有發現它不成立的案例,
 這個本來是一個很嚴謹的東西,
 論文啊,
 這個有點弄得跟我們的體檢報告一樣,
 怎麼的呢,
 你安心做一個X光片,
 看你哪個未發現異常,
 這個未發現異常,
 這個未發現異常,
 不等於你沒有異常啊,
 所以他這個論文也來了一句,
 我沒有發現這更高,
 對,
 這個時候,
 它有這個不成立的案例,
 這個,
 我說的,
 大模型的發展,
 我們要提高散路,
 要不要再增加參數,
 也可以,
 也可以增加訓練的收集規模,
 但是,
 我們更應該要注重理論上的抗爭,
 突破,
 董事記,
 習近平董事長講啊,
 他說在人工智能這個重要領域,
 我們國家啊,
 理論研究上要走在前面,
 關鍵核心基礎要佔領最高點,
 但我們這個東西,
 要從機制理論上,
 理論上的事兒,
 我不是特別的明白,
 因為我這個,
 初中畢業就下鄉了,
 沒上個高中,
 沒上個本科,
 所以理論上我也說不清楚,
 但是從代碼角度的來講,
 我們現在這個transforming,
 這個東西,
 我們這個大模型,
 和這個separation這個東西,
 它最重要的,
 從代碼上來講,
 不就是鐵矩證,
 Q矩證,
 未矩證,
 我們的所謂自回歸,
 不就是這些矩證預算的多次重複,
 當然,
 中間還有很多,
 我們要,
 比如剛才我們的laus寒宋,
 比如我們的油化寒宋,
 我們有很多在裡面做,
 有很多東西,
 但是靠這些,
 它是不是都能產生智能,
 或者說特別是通用的智能,
 我覺得這個,
 我們都應該自己認真去研究,
 去思考,
 我們在大模型,
 在特定領域,
 我認為,
 現在,
 在特定的任務上,
 它可能都已經超過了人類,
 但是在更廣泛的領域上,
 在通用的領域上,
 它的理論基礎是什麼,
 這也許就是剛才說的,
 可解釋性,
 這也許就是一個大模型的暴雨中期,
 我也今天,
 還是剛才在想一件事情,
 剛才我們在休息室,
 進來的時候,
 大家都在談,
 上海昨天很熱,
 今天也不涼快,
 我就想一件事,
 上海已經很熱了,
 我們大模型的熱,
 可不一定,
 可別帶來我們天氣的熱,
 我想說的是,
 我們在大模型的暴雨中期,
 还要注意环境的理论,还要研究对环境的理论,还应该散散仗,散散投入铲除笔,我们要大力发展我们任意的理论,但是我们应该科学有效地去发展。
 比如说,我们背地就简单地按照那个Scalinar,来来来,这种模式来的。
 我昨天看了一个新闻,也是互联网上的,讲我们现在万卡集群已经是标配,而且是最低的标配,这个最低可是不低啊。
 万卡万屁,那么如果在后一个万加上去,你那个万屁,那就不一定是万卡了,那可能有两万卡,我们以A100来算,有两万卡。
 那么大家注意一下,如果以A100,E卡就是400瓦,H100就是700瓦,如果我们来用万卡,乘以一下,多少?
 所以在这个,我们...
 除了从我们的规模设定上,我们还是选了一个理论上的方法。
 也在这个问题上,让它更加科学,更加环境,更加有效地发展。
 我觉得这也是我们在研究大模型发展中应该值得注意的问题。
 好了,我就跟大家分享一些想法。
 不对的地方,请大家评论。
 谢谢大家。
 好的,谢谢。
 感谢赵理事长,请入座,谢谢。
 那刚刚呢,赵理事长为我们分享了,如何更好的使用和创新大模型,以促进新制生产力的发展,带来了分享。
 那同时呢,刚刚我们的赵理事长也提到了,ChatGDP呢,一经发布就成了颇炫热词。
 人工智能技术的迅速发展,也在深刻地影响着人们的生活环境,以及我们的社会进程。
 再一次感谢赵理事长为我们带来的深度思考,谢谢。
 可信呢,是人工智能的发展基石。
 大模型则是让人工智能技术实现了巨大的跨越。
 正在快速重塑数字时代的发展模式。
 蓬城实验室,作为国家战略科技力量的重要组成部分。
 在大模型方面做了积极探索。
 并且取得了大模型。
 并且取得了显著的成绩。
 接下来,让我们掌声欢迎,中国工程院院士,蓬城实验室主任,高文。
 做主题为,蓬城云脑与脑海系列大模型的主旨报告。
 让我们掌声欢迎。
 各位专家,大家好。
 因为会上,分会场的活动比较多。
 时间关系呢,
 不能跑来跑去,
 我就用这个,这种形式呢,
 把我要跟大家分享的内容介绍一下。
 今天我想跟大家分享的内容呢,
 是蓬城云脑和蓬城脑海大模型。
 大家知道这个,大模型这几年非常火。
 我们知道这个对大模型,对整个社会的这个,
 进步的推动,应该说是非常大的。
 就是它不仅仅改变了我们现在这些这个工作等等的方式,
 甚至将来有可能在生活上也会改变。
 当然更重要的在科学上也是改变。
 就是因为大模型呢,它使得科研和产业发展的范式都会发生变化。
 当然在大模型时代呢,就是我们总是希望,
 能发挥,把自己的作用发挥到极致,发挥到最大。
 那么我们知道最近这大模型呢,
 企业呢,在各个方面都发挥了比较重要的作用。
 高效呢,除了在算法以外,其他都比较弱一点。
 当然呢,是不是高效要再努力一点,
 其实就是高效要有调整好心态。
 因为现在要做,在这个时代呢,
 其实就是说一定要有规模,要有足够规模的数据,足够规模的算法。
 没有规模的东西呢,其实除了能写论以外,
 其实就其他方面都很难达到令人满意的结果。
 所以呢,高效呢,要尽量的算法上面可以自己多做一些创建和创造。
 但是数据方面还是呢,要多和这些同步的企业啊,
 或者多和研究,这个国有的研究机构合作。
 那么,高效呢,更重要的就是解决好重大的关键问题。
 去探索那些前沿和目前呢,还没有办法,就是说解决的一些难题。
 这个是高效最容易发挥作用的地方。
 那么我想跟大家分享的主要两件事。
 一件事呢,就是膨胀晕脑的智商平台。
 第二件事呢,就是膨胀脑海的系列大模型。
 首先我们先看看膨胀晕脑的智算平台。
 膨胀晕脑呢,这是膨胀实验室建立的整个的智算平台的一个系列。
 那么膨胀晕脑一呢,是基于英伟达的卡做的一台机器,
 接近一百匹的一个算力。
 膨胀晕脑二呢,
 是用这个华为的芯片,包括MPU和CPU,
 那么建立起的一台这个一千匹的算力的机器。
 那么膨胀晕脑三呢,现在正在建设中。
 今年年底呢,应该能够完成。
 完成以后呢,它的算力呢,是一万六千匹。
 那么比膨胀晕脑二呢,相当是膨胀晕脑二的十六倍。
 那么大概有两万多颗这个华为的芯片。
 膨胀晕脑呢,它是专门面向这个大模型训练的这样一个平台。
 比如说膨胀晕脑二呢,它已经连续八次,
 参加Top500的打榜。
 Top500大家知道是每半年一次的超级计算机的一个这个比赛的榜单。
 当然那里呢,既有比如说峰值计算速度Linpack,
 也有呢,
 比如说L500和其他的一些赛道。
 那么膨胀晕脑二参加的是L500的赛道。
 这个赛道呢,是测量评价一台机器它的存储和访问的性能。
 那么膨胀晕脑二从2020年下半年参加第一次,到现在已经连续八次了。
 那我们连续八次都是冠军,都是这方面的性能最好的一台机器。
 所以我们可以理直气壮地说,
 膨胀晕脑二是在计算平台里面世界最好的这样的一个机器。
 那膨胀晕脑二不仅它的这个硬件性能,
 或者说并行处理,并行文件系统的性能比较好。
 那么它实际上是有一个比较完整的计算基础软件在。
 那么最底层的这个AIECO的计算框架CAN,
 那么到这个MindSpore,
 到MindArt,
 那么再往上是我们一个开源平台,
 大规模用户的开源共享叫OpenEye,
 再往上还有一些生态的工具。
 所以它是一个完整的计算基础的软件在。
 那么有了膨胀晕脑硬件和软件的生态环境,
 其实我们膨胀晕脑也训练了一批模型。
 首先膨胀晕脑,
 自己训练了一大批模型。
 同时膨胀也用这个机器帮助国内的一些头部企业,
 华为,
 百度,
 北京智园,
 训练了一批他们的大模型。
 那么膨胀晕脑这台机器2020年上线以后,
 其实运行的效果非常好,
 基本上是百分之九十几的使用率。
 对于这种超算或大型计算机这是非常高的使用率。
 而且整个膨胀实验室自己用了不到百分之五十,
 用了差不多百分之四十六左右,
 其他的其实我们都开放出去,
 给其他的单位用,
 包括一些合作单位,
 包括一些工艺机构等等。
 膨胀晕脑的构建需要超级处理能力的人工智能专用加速硬件,
 开放的软件体系架构,
 以及完备的开源生态环境。
 膨胀晕脑二期达到了一级AI算力,
 是全球计算力度最高,
 算力规模最大,
 训练速度最快的AI技术,
 能为中国人工智能的发展能够提供最好的支持和服务。
 膨胀晕脑二期项目采用华为阿特纳斯周背AI机器,
 作为强大的算力组合。
 膨胀晕脑二期总共有四千零九十六颗,
 业界最强的AI工具,
 生成910组成。
 它提供一级的AI算力,
 相当于目前五十万台高性能的PC机的计算能力。
 基于超大规模AI模型训练与推力能力,
 膨胀晕脑大科学装置已在基础研究,
 重大应用赋能中发挥作用。
 那么正在建设的膨胀晕脑三呢,
 它实际上是把算力,
 存储能力和运力有机的结合在一起。
 高度结合的,
 其实它有三个技术上的特点。
 第一个是单颗芯片,
 性能基本上是业界比较好的性能,
 基本上接近于H100的性能。
 另外它在整个高载宽的网络方面,
 就是我们说叫,
 超级节点里头,
 它整个我们使用的背板交换的方式,
 使得整个它的验池带宽都做到业界最好。
 第三个就是大规模的组网技术,
 那么若干的超级节点,
 用这种大规模网络把它们连接起来,
 这样就使得整个它的,
 卡和卡之间的通信的验池,
 可以做到非常非常的短。
 那有了膨胀晕倒3呢,
 我们就可以做很多事,
 可以支持外籍大模型的训练,
 可以支持多模态的训练,
 那么既可以去做这种大模型的应用创新,
 同时也可以做各种各样的,
 面向基础研究的AI和Science方面的一些工作。
 这是关于第一个,
 关于膨胀这个一级计算平台。
 那么下面我们介绍第二个方面,
 就是关于这个膨胀脑海大模型,
 因为大模型出来以后呢,
 我们总是一开始我们是提供一个平台,
 帮大家来训练,
 后来我们想了那既然有这个平台,
 我们能不能也帮社会提供一些开源的东西呢?
 就是基于这样一个想法,
 其实我们就规划了一个
 膨胀脑海系列大模型,
 这个系列大模型里面到现在为止呢,
 是有三个成员,
 规模最小呢是7B模型,
 这是一个70亿才足规模的模型,
 中间这个呢是33B长窗口模型,
 那么就是330亿才足规模的一个模型,
 最大呢叫200B大模型,
 这个是呢,
 规模最大2000亿规模的这样的一个模型,
 这三个模型呢,
 我们当然就是说,
 因为它模型的复杂度不一样,
 所以训练需要的资源是不一样的,
 像200B这个模型呢,
 我们是花了差不多,
 接近7个月把它训练出来了,
 这个大模型呢,
 把它做成一个底座,
 这是一个开始是以中文为核心的稠密大模型,
 当然现在呢,
 英文和中文的这个操作的数量,
 其实是英文可能还更多一点,
 那么总而言之呢就是说,
 它是一个这个稠密的加一个文本的大模型,
 这个模型呢,
 一共呢是104层的一个网络,
 那么我们用云脑2,
 那么云脑2呢,
 有4096块卡,
 那其中呢我们用了3456块卡来进行训练,
 余下的卡呢去做测试,
 验证,
 数据的整备等等,
 所以这台机器呢,
 就是为了训练这个200B的模型,
 差不多花费了接近7个月的时间来训练这个模型,
 那训练过程中呢,
 我们怎么样能把这个训练做得更好,
 其实呢,
 这个训练算力的需求,
 这个训练能力优化,
 我们也做了很多工作,
 包括比如说集群,
 怎么样让它做得更稳定,
 算法怎么样更完健,
 训练这个故障恢复的时间更短,
 就是恢复优化做得更好等等,
 这个模型训练出来呢,
 我们也做了一些客观的测试比对,
 我发现这个模型确实,
 它和这些国内其他的一些大语言模型比较起来呢,
 性能还是相当不错的,
 在中文方面呢,
 是业界第一梯队,
 其他方面呢,
 也都是基本上还是可以的,
 当然训练大模型呢,
 是一个很花钱的事儿,
 我们知道像美国训练,
 比如说GPT3.5,
 GPT4,
 这个openAI了,
 包括谷歌,
 Facebook训练大模型都是很花钱的,
 基本上,
 从几千万美元到几个亿美元,
 在这个范围过程中,
 其实我们这个200枚大模型呢,
 训练如果算成本的话,
 大概也是将近五亿人民币的成本,
 所以训练大模型是非常花钱的一件事儿。
 本次发布成果,
 是蓬城脑海通用AI大模型进阶版,
 蓬城实验室联合中国外文局,
 华为,腾讯,
 共同发布,
 公众版本将面向全社会开源,
 与业界携手构建,
 基于中国算力网的AI大模型,
 创新应用生态,
 为全球人工智能创新,
 提供中国方案。
 就是这个大模型呢,
 应该说这个整体上呢,
 是对我们这个,
 做大模型的这些潜在的,
 这个接手的地方呢,
 是一个比较大的好处呢,
 就是它可以用这个模型呢,
 去做成它自己的底座,
 在上面做成自己的应用系统。
 这是两百币,
 因为两百币这个模型,
 两千亿参数呢,
 像刚才我说的,
 可能一千匹的机器,
 用华为的机器,
 我们差不多训练了九个月才训完。
 当然现在呢,
 我们在后面再训的时候呢,
 这个速度会快一些,
 效率会高一些,
 因为开始经常,
 因为这个地方有个错,
 那个地方有个错,
 这个有个故障,
 那个有个故障,
 越到后来呢,
 这些问题呢,
 就出现的越少,
 或者说有了故障,
 恢复的时间就越短,
 后面就得比较加速了。
 当然毕竟,
 两百币的大模型,
 需要的资源比较多,
 那么有的用户可能说,
 我没有这么多算力,
 去做推理,
 或者做这个东西的步骤,
 那怎么办呢?
 一个选项就是,
 我们提供一个33B的长窗口模型,
 330亿参数这个模型呢,
 应该说它刚好聚中,
 不大不小,
 这个模型呢,
 是我们和百川智能一起合作,
 来研究的这样的一个模型,
 这个模型为了训练呢,
 我们和百川做了各种尝试,
 包括底下的底座用它的,
 上面加我们的,
 底下的底座用它的,
 我们的上面加它的,
 我们的和他们的混合起来,
 一起训练等等,
 各种各样的尝试去看,
 效果更好。
 那么经过这个测试呢,
 经过这个验证呢,
 现在33B这个模型,
 应该说已经可以用了,
 这个是128K窗口的,
 这个窗口长度的一个模型,
 后续我们还会提供更长的窗口,
 这个19K的,
 或者更大,
 那么这个呢,
 就在规划实施过程中。
 比如这个模型呢,
 其实我们就把它可以去赋能了,
 所以我们通过开源的办法,
 去进行合作赋能。
 那为了这个合作赋能呢,
 我们和这个ATISA,
 和这个中国人工智能,
 这个产业技术联合组织呢,
 一起呢,
 来做这个开源的联合体。
 这里呢,
 我们通过人机合作啊,
 不同的模型,
 不同的这个领域啊等等。
 当然我们这个联合体呢,
 也包括一托CCF,
 就是中国计算机学会,
 开源发展委员会,
 以及中国人工智能学会的一些委员会呢,
 去联合把这个算力啊,
 数据啊,
 统到一起来做。
 那么这个模型呢,
 应该说它是一个全流程开源资源的一个工资。
 这上有个二维码,
 大家可以拍下来。
 其实这就是这个开源,
 这个脑海开源社区的一个入口,
 你可以进到里面去。
 如果你对这个模型有兴趣,
 不管是哪一个7B的,
 33B的,
 还是200B的,
 都可以去下载。
 那么这个是模型本身,
 当然你说光有模型,
 没有算力,
 你也没办法进行推理。
 所以我们现在也在鼓励呢,
 各地,
 有这个算力中心,
 算力分中心呢,
 用这个模型呢,
 去做各种各样的,
 它的可能的应用。
 所以我们,
 既从同层实验室这边参与,
 去做一些组织和赋能,
 我们也欢迎大家去做应用的,
 这个应用方,
 去和你所在地的算力中心,
 去联手,
 去把这个模型下载一下,
 去使用。
 那么这个旗帜社区呢,
 刚才说的这是一个开源的大模型,
 这种研究开发的这样的一个社区。
 这个社区呢,
 我们可以做很多很多的这种研究,
 很多开放的问题,
 可以在这里面去进行尝试和研究。
 那么这个大模型呢,
 这个我们也可以通过,
 彭城实验室的另外一个,
 这个国家计划,
 国家任务,
 叫做中国算力网。
 那么使得这个模型呢,
 能够在新的一个计算范式上面,
 得到这个展开。
 最后小结一下呢,
 就是彭城实验室呢,
 到现在为止,
 利用华为的芯片,
 已经建设了彭城云脑二。
 那么正在用华为的芯片,
 在建设彭城云脑三。
 这是一个云态智能的计算平台。
 那么它这个可以呢,
 做这个大模型的一些训练,
 赋能啊,
 而且是用开源的方式。
 那么中国呢,
 人工智能的发展,
 肯定需要有自己的大模型底座了。
 因为一方面,
 这个西方发达国家,
 对特别是美国,
 对中国的这个人工智能呢,
 可能施加了很多约束,
 比如说训练的卡,
 不让这个在中国销售。
 甚至呢,
 有一些比如说这个大模型,
 不管是开源的,
 还是服务,
 不像中国开放,
 等等。
 所以呢,
 中国要想人工智能顺畅发展,
 必须要有自己的大模型底座。
 当然我们并不排外,
 但是一方面要有自己的,
 同时呢,
 我们也可以对比着看,
 这个其他的模型做得好的,
 也可以呢,
 给我们做成一个标杆,
 参照系。
 有了这个东西呢,
 因为毕竟,
 我们要做这个大模型,
 中文是我们的看价的版权,
 是我们的看价的本领。
 如果中文不好呢,
 其实这个模型呢,
 就在中国就很难很好的使用。
 那么脑海这个系列大模型呢,
 其实它就是这样的一个尝试。
 那么通过这个脑海模型,
 我们希望能够对国产,
 这种大模型的生态发展,
 起到一些帮助。
 这个脑海模型啊,
 需要纵人食材才能火焰高。
 所以我最后这张照片呢,
 就是给了几个二维码。
 这几个二维码里面呢,
 你排下来呢,
 一个二维码是关于这个,
 这个启制的入口。
 一个二维码呢,
 是关于这个,
 这个膨胀实验室的入口。
 还有一个二维码呢,
 是前段时间我们写过一篇文章,
 在时事报告上面发了一篇文章,
 关于人工智能的发展,
 有一些我们的见解。
 如果大家对这些东西有兴趣呢,
 可以通过扫描这个码,
 最后呢,
 获取这些信息。
 好。
 好的,谢谢。
 感谢高文院士。
 大模型之路已经从通用语言大模型,
 向多模态大模型进行过渡。
 中国自己的大模型底座,
 对于促进技术创新和行业发展而言,
 至关重要。
 下面,
 我们进入到本次论坛的篇章二,
 与大家分享大模型技术,
 如何创新,
 以夯实加速应用服务产业的技术基础。
 让我们有请智源研究院理事长黄铁军,
 做大模型进展与思考的主题演讲。
 掌声欢迎。
 最近的赵部长,
 各位领导,
 各位专家,
 时间我看已经有点什么了。
 是十五分钟,
 所以我尽量不超时,
 能省一点更好,
 来谈一下关于大模型的一些思考。
 大模型这个技术过去这几年特别热,
 但是我们回过头来看,
 它这种技术路线或者这种思维方式,
 意味着什么?
 我想主要我从这个角度先谈一下看法。
 因为人工智能,
 传统的人工智能,
 像符号主义是很清楚的,
 因为整个的规则逻辑都是人设计的,
 所以当然可解释,
 它是一个本来就是人解释清楚之后执行的一个东西。
 但是今天讲的大模型是基于连接主义,
 是基于神经网络训练的一个东西。
 它的思维方式本来就是一个字体向上的,
 就是你先构造一个神经网络,
 然后用数据去训练它,
 产生智能。
 能产生什么智能?
 这件事本身在设计的时候是不清楚的,
 或者说从根本上讲就是一个开放问题,
 可以说是不能,
 无法去完全预测和控制的这么一个技术路线。
 当然这条技术路线经过了八十多年的探索,
 有各种各样的波折,
 但是最终还是在过去的十年左右取得了重大进展。
 大家都说transform,
 transform很重要,
 但是我觉得另外一个也很重要,
 就是十年之前的,
 十多年之前的,
 今天大模型都用的,
 无论是语言大模型还是今天做的多么的大模型,
 你总要把一个基本的单元,
 对于语言来说基本单元就是词,
 变成一个可计算的,
 语意可计算的,
 这样的一个向量,
 这是2013年的,
 当然之前也有类似的,
 自然运作力有很多进展,
 但是我想挑最重要的说,
 就是它不是一个词,
 词在大模型上不再是一个词,
 而是一个高维的向量,
 一般我们都会用1024维,
 当然还有用更多维的,
 这样的话每个词是一串数字,
 这串数字就是它的语意,
 或者换句话说,
 构造出来一个1024维的,
 高维的一个语空间,
 大模型算的就是我们的每个概念,
 每个词在这个语空间中的它的位置,
 有了它的位置,
 我们就知道词与词之间的关系,
 所以这很重要,
 不是说只有transform重要,
 你现在把数据,
 变成一个可计算的东西,
 然后才是transform,
 transform做的是通过计算,
 这些概念与概念之间的关系,
 来获得它的语意,
 这个一开始大家可能不是那么理解,
 后来我想我用一个最通俗的话说,
 词与词之间的关系,
 就是它的语意的最主要的来源,
 马克思说,
 人是一切社会关系的总和,
 怎么定义一个人,
 就是要你跟其他人的关系,
 那词也一样,
 语言也一样,
 语言有这么海量的语料,
 通过计算词与词之间的关系,
 是可以精确地获取每个概念,
 每个词的含义的,
 这是为什么大默认有智能的基本原因,
 它是真的算出来的,
 不是困运,
 是精确计算之后的一个结果,
 那GPT的重要贡献,
 尽管GPT没有像刚才说,
 神仙网络架构也不是它发明的,
 磁箱量也不是它发明的,
 它只不过是一种训练方法,
 但是这种训练方法是有它背后的,
 也可以说很深刻的一个对于智能的认识的,
 那就是所谓智能,
 其实就是根据历史预测未来,
 或者是用这个单词预测下一个,
 这个看似简单,
 但实际上它抓住了我们智能的一个,
 可以说一个根本性的这么一个问题,
 所以GPT的成功不是偶然的,
 它是,
 它是有自己的一个很清晰的这样的一个逻辑,
 所以才取得的成功,
 但是我刚才回顾这三个重要的点,
 目的是想说大模型这样的一个重大突破,
 就像这张图所显示的,
 它是一个构造出来的东西,
 它是在神经网络上用大量的数据,
 用预测下一个词的这种方法,
 构造出来的一个智能的系统,
 它的构造过程是很清楚的,
 就这么做,
 这就是我们说技术,
 这是方法论,
 但是这么构造的这个东西,
 它为什么会有这么强的能力,
 产生了各种各样的功能,
 这不是设计师的设计好的,
 这是这个复杂系统,
 自身表现出来的一种现象,
 一种功能,
 一种能力,
 所以呢,
 大家经常说这个不可解释,
 设计师本来就没有,
 不像不是经典的人工智能,
 设计的时候他很清楚是怎么回事,
 他也不清楚,
 这是一个技术,
 这个技术的一种自然的,
 或者一个现象,
 所以它不可解释,
 这是它的天性,
 我想过去几年大家通过图灵测试,
 甚至我们可以说人工智能突破了另外一个,
 长期以来,
 从上个世纪70年代,
 80年代,
 90年代一直在讨论的问题,
 就是一个符号系统,
 一个从数据里面进行计算的这么一个人工智能系统,
 是不是真的理解了,
 真正的有智能,
 那今天来看呢,
 这个经典认为甚至于不可能解决的问题,
 解决了,
 就是刚才说符号,
 符号本身的含义已经算出来了,
 所以这是一个重大的进步,
 但是这个进步背后的机理,
 像刚才说的,
 实际上是不清楚的,
 不清楚是,
 不清楚不是说这帮人有意的,
 也不是这帮人聪明和笨的问题,
 这就是一个自然现象,
 大家现在认清这个现实,
 我经常打比方,
 不打比方,
 指南针发明的时候,
 指南针为什么指南,
 不知道,
 但是我能做一个稳定指南的装置,
 飞机飞上天发明的时候,
 不知道为什么飞上天,
 没有昆尼动力学院,
 但是它能飞上天,
 能飞得越来越远,
 人工智能也一样,
 现在做出了一个有智能的,
 可以测试智能越来越强的系统,
 但不知道它为什么这些智能,
 那是另外一个问题,
 为什么的问题,
 需要我们后续更长的去研究,
 为什么要这么做,
 其实我想,
 这是对科学研究范式的一个理解问题,
 我们经典的传统的科学,
 总希望,
 这也没什么错,
 我们一个复杂的现象,
 复杂的是我们要知道的背后的,
 方程,
 知道它树里的模型,
 这是的,
 我们如果能知道的话,
 当然很好,
 但事实上,
 像智能,
 包括刚才我说的飞机,
 很多事物,
 我们现在没有这个规律,
 没有规律的时候,
 我们是不是就不发明了,
 不是的,
 我们照样会去探索这种可能性,
 所以用一个神经网络,
 这样的一个,
 不是那么优美,
 不是那么数学的一个东西,
 去构造一个体系,
 让它去刻画复杂,
 的现象,
 背后的规律,
 这是一个,
 这是一个现在,
 这个,
 可用的,
 一个很不错的这么一个方法,
 所以今天的神经网络呢,
 从这个百亿,
 千亿,
 万亿,
 后边还要做十万亿,
 百万亿,
 甚至更大的神经网络,
 这是一个可行的办法,
 尽管它背后,
 刚才说,
 没有我们原来经典的那些优美的东西,
 因为这是一种不同的思维方式,
 我们过去一百年呢,
 被科学的思维方式,
 某种意义上呢,
 这个,
 这个,
 这个,
 说洗脑有点那个什么啊,
 就是大家喜欢用科学的思维方式,
 什么事情呢,
 一定要说可解释,
 可信,
 包括今天讲的可信啊,
 你一定要清楚背后的这个,
 这个为什么,
 事实上就像我刚才说的,
 复杂现象,
 你清楚背后的为什么的这个难度,
 是,
 是可能超越目前这个时代的,
 但是技术呢,
 它就是要构造出越来越复杂的东西,
 咱们不说别的互联网,
 对吧,
 互联网的规则这个可以说很清楚,
 但是互联网发展到今天,
 你要理解互联网上的现象,
 那可就,
 那可就复杂了,
 是吧,
 人工智能也一样,
 如果说的再远一点,
 我们人,
 生命,
 智能,
 在地球上,
 这个,
 这样的一个发生过程,
 本来就是一个构造不断演化发展的过程,
 是吧,
 我们不,
 我们到现在为止无,
 无法知道这个,
 这个生命背后的所有的奥秘,
 尽管我们已经知道了一些,
 人工智能呢,
 其实,
 其实也是一样的,
 所以人工智能会往前发展,
 会发展得更强,
 会往这个通用人工智能,
 这个强人工智能,
 这样的一些方向,
 方向去发展,
 这里边呢,
 存在一个巨大的,
 可以说,
 巨大的机会,
 也存在一个巨大的风险,
 就是它的能力越来越强,
 但是我们又不知道这个背后的这些,
 这些,
 这些规律是什么,
 所以呢,
 在什么时候这个,
 这个,
 我们今天大家都投入的,
 花了很多资源,
 花了很多资源去做的这种,
 这种通用性越来越强的人工智能,
 会演化成一个,
 超越人类的AGI,
 不知道,
 但是我们就在往那个方向,
 这个发展,
 没有一个绝对的边界,
 说哪一天,
 达到什么这个,
 这个时候,
 哎,
 他就突然就是超过人类了,
 不知道,
 他是在一个,
 一个演化的过程中的,
 所以呢,
 关于可信这个词啊,
 我去年,
 那个腾讯,
 搞的这个,
 一个叫人工智能20年20问,
 当时呢,
 就有类似的一个问题,
 我也在思考这个问题,
 实际上,
 刚才我讲了这么多,
 什么意思呢,
 人类也好,
 人工智能也好,
 它是一个,
 刚才说的是一个复杂系统,
 这个复杂系统会产生各种各样的这种可能性,
 会,
 我们说它幻觉,
 或者说它想象,
 或者说它创造力,
 都是一个,
 从终极上讲,
 是一个不可理解的系统,
 人类也不可理解,
 我们所有人,
 大家说,
 最好的朋友,
 夫妻之间,
 你完全理解对方,
 那不可能,
 因为它是个大脑,
 它总会产生新的这个想法,
 那人类社会之间怎么可信呢,
 我们是要,
 你就是听其言观其行,
 对吧,
 我们要用时间去检验,
 所以你讲的,
 你做的,
 是不是符合这个现实的情况,
 所以我们要说,
 百分之百的信任,
 百分之百的可信是不可能的,
 因为它也不可能百分之百的被理解,
 它会越来越强大,
 但是呢,
 我们可以根据它的输出,
 根据交互,
 来构建一个共识,
 在这个共识中,
 我们形成了一个所谓的信任,
 对吧,
 所以比如科学,
 技术,
 知识,
 对吧,
 社会的规则,
 法律,
 这些东西呢,
 就是我们共识的东西,
 大家在这样的一个共同的体系里面,
 形成一定的这个可信,
 你不能绝对去相信一个智能体,
 无论它是人,
 还是一个AI,
 最后一页,
 关于目前的,
 我总结一下这个认识,
 到底今天,
 这个我们的人工智能,
 这个通用人工智能发展的什么阶段了,
 这是去年呢,
 OpenAI的一个分类啊,
 后来我看到之后呢,
 我觉得分的不好,
 为什么呢,
 它把这个AGI,
 就是咱们说的这个通用人工智能呢,
 划分成了五个级别,
 这个级别呢,
 什么叫差别,
 其实就是,
 跟人类的认知水平相比,
 大概达到了人类的百分之几十,
 对吧,
 那个百分之五十,
 百分之九十,
 百分之九十九,
 百分之一百,
 我觉得这个分没啥意义,
 因为你很难测试说,
 今天的一个,
 谁做了一个AI,
 摆的是五十分,
 还是九十分,
 对吧,
 我们也有很多很多的法,
 但是比这个东西呢,
 其实,
 对长远来说呢,
 这个不是最重要的,
 那我认为呢,
 这是今年,
 质变大会的这个安全论坛上,
 我给的一个分级啊,
 我也才简单的再给大家,
 这个讲几句呢,
 讲几句,
 马上时间就快到了,
 这是我的分级啊,
 因为我觉得这个可能才有利于,
 我们对越来越强大的人工智能,
 早点做出一个预判,
 我认为今天我们讲的这个,
 通用人工智能,
 就真的是general artificial intelligence,
 还不是artificial general intelligence,
 是一个这个认知水平低于人类,
 就像刚才说open AI的,
 这个前面的这个几集,
 四集啊,
 不管是什么,
 你是50分还是99分,
 总的来说认知水平低于人类,
 可以替代部分人类智能,
 这是我们今天面对的现实,
 这样的一个人工智能系统呢,
 我们希望善用它,
 但事实上呢,
 它也会被误用,
 会被滥用,
 会被恶用,
 对吧,
 这是我们今天面临的这个安全和风险问题,
 有可能这个,
 像open AI说大概两到五年,
 对吧,
 也有这个各种各样的说法吧,
 但总的来说在几年之内,
 有可能认知意义上,
 认知意义上,
 人工智能全面超越人类,
 它不是人,
 但是呢,
 它的知识的丰富程度,
 和它能够给出一些预测,
 一些预判的能力,
 比人类,
 几乎可以说,
 比我们所有人都强,
 这是有可能的,
 因为我们每个人掌握的数据,
 和我们分析这些数据,
 背后所允许的时间是有限的,
 而AI呢,
 它的数据的广度和时间,
 这个,
 这个计算的这个复杂度,
 要远高于我们,
 这个时候呢,
 我不认为呢,
 就是这叫第一级的,
 这个,
 这个,
 AGI啊,
 它一定是这个,
 在,
 可以说在知识水平上,
 全面超越人类了,
 这个时候呢,
 我们仍然可以跟它之间,
 建立一个理性信任,
 就像刚才说的,
 这样的一个关系,
 这个可信,
 是,
 是,
 仍然是可以做到的,
 尽管它已经是AGI了,
 但是呢,
 我担心的就是,
 我们大多数人类呢,
 可能因为自己努力,
 努力一生,
 都可能都不如这样的一个AI,
 这个,
 那,
 聪明,
 所以人类放弃了这个,
 这个,
 这个,
 这种,
 竞争的这种机会,
 躺平了,
 这是我担心的,
 这个,
 也可能是咱们,
 人生物质呢,
 越来越强之后,
 越强之后呢,
 会造成的一个,
 一个,
 一个社会现象,
 之后呢,
 才是这个,
 超越,
 这个,
 超越人类,
 甚至于不可控制的,
 几个级别,
 时间那个有限啊,
 我快速地说一下,
 一个呢,
 就是今天特别热门的,
 居身制的,
 因为为什么level一,
 我们能控制呢,
 因为它毕竟是一个,
 没有身体,
 没有这个,
 它自己的这么一个,
 它是,
 它是被动的,
 这么一个系统,
 但是如果它有了身体,
 它有了这个,
 那个运动能力,
 那就有一个,
 感知性能,
 和运动性能,
 超越人类的问题,
 感知和认知的结合,
 跟环境的互动,
 有可能产生意识,
 如果它这个,
 在这个神经网络复杂,
 达到一定程度之后,
 产生自我意识,
 这都是有可能的啊,
 我想,
 我说这个话呢,
 大家可能作为一个严谨的,
 科学研究者,
 他说你这个东西,
 有啥,
 有啥依据,
 对吧,
 这话呢,
 问得也对,
 但是我,
 我想刚才我已经讲了很多了,
 人工智能是在构造的一个系统,
 你不知道哪一天飞机会起飞,
 你不知道哪一天,
 飞机会起飞,
 你不知道哪一天,
 他的智能会达到一个什么水平,
 你不知道哪一天,
 这样的一个巨声系统,
 在这个,
 跟环境的互动过程中,
 就像动物一样的,
 它会产生了这个意识,
 就像这个少数动物一样的,
 对吧,
 它产生了自我意识,
 能够区分出自己跟环境,
 这种可能性都是存在的,
 我们没有任何,
 这个,
 这个,
 这个,
 绝对的证据说,
 这事儿都是有可能性的,
 我们没有任何,
 这个,
 这个,
 这个,
 绝对的证据说,
 这事儿都不可能,
 没有人能够给出这种,
 这种结论,
 所以我们就得考虑这种,
 这种可能性,
 当然最终呢,
 就是人工智能,
 就不再是人工智能了,
 它跟人也没啥关系了,
 它也不再用人类的数据去训练,
 它也不再仿照人类的大脑的神经网络,
 去,
 去这个架构,
 它自己会有自己的发展,
 那是更长远的事情了,
 但是我觉得呢,
 Level一,
 就是眼前的,
 但是我觉得呢,
 Level一,
 就是眼前的,
 几年的事儿,
 后面的,
 二三四,
 差不多是未来,
 十到二十年的事情,
 这是我们,
 至少,
 这个风险是存在的,
 我们应该做这方面的,
 思考。
 行,
 我今天呢,
 就给大家,
 报告这些,
 谢谢。
 好,
 谢谢,
 感谢黄理事长的精彩分享,
 请您入座,
 谢谢。
 在这方面,
 这些东西,
 每個人也有自己想想。
 你们每个小时都有,
 所显現的什么样,
 你要去哪里规律 Drops,
 没有什么都是 telling you pass的那一面,
 这 갑자기的一番,
 我都不会说,
 我YO informo 的。
 好你这么乐意,
 而且把自己说到房间 reply,
 那就是让你很有应用,
 那就是让你很ptioner。
 接下来让我们有请,
 Zhejiang大学,
 人工智能,
 研究所所长,
 求是特联教授,
 本 behavior 获得者无非,
 做置海系列,
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 致海系列垂直領域大模型
 我们把它称为垂直领域大模型。
 在2023年的时候,谷歌公司发表了一篇文章,
 说教科书就是你所需要的一切。
 在这篇文章里面,谷歌公司说,
 我们用教科书级别的高质量的语料,
 训练了一个13亿的transform的垂直领域的大模型。
 在某些垂域的任务上面,
 它战胜了1750亿参数的GPT-3.5。
 它显示了用高质量的语料来训练垂直领域大模型的重要性。
 我们就好比说让他喝咖啡,吃面包,
 可能他不是吃百家饭穿百家衣,
 就让他数月有专攻围绕某些领域的问题的话,
 用我们的垂域的高质量的语料去进行训练,
 可能我们只需要一个小模型。
 但大和小是相对的。
 谷歌公司,微软公司说,
 我们用了一个13亿的模型,
 完成了某些领域能够抗衡1750亿参数的大模型。
 我们国家自然科学基金委去年年底发布了
 叫做深层式人工智能基础研究的专项项目,
 就是希望去探讨深层式人工智能领域的话,
 有哪些基础科学研究的问题可以去解决。
 这个专项项目后来支持了六项,
 并成为了全部的推进。
 那我本人是在2021年承担了一个科技部,
 一个叫智能施法的重点研发计划的项目。
 这个项目是2021年启动的,
 正好有一个课题要做QA问答。
 传统的QA问答是把问题和答案写好,
 存入数据库,
 用户问什么问题的时候,
 把用户问的问题和数据库里面表示的问题进行匹配,
 然后把匹配成功的答案把它检索出来,
 说你不能问已经写好的问题以外的答案,
 因为它没办法做出这个回答。
 那我们做这个项目做到2023年的时候,
 预训练模型和产生式人工智能出来了。
 我们当时在想,
 能不能训练一个施法领域的垂直大模型,
 让它问任意的施法领域的问题呢?
 照浙江省的高院,
 在数字化方面走得非常的靠前。
 浙江省高院主管审判工作的朱新律副院长,
 浙江大学法学院的院长朱老师对人工智能持有拥抱和开放的态度。
 于是浙江省这个高院就把这个审判完毕的电子卷宗,
 给了我们浙江大学和阿尼巴巴达摩院,
 因为达摩院是承担了这个课题的一项研究任务。
 于是我们就在阿尼通一千问的六十亿这个小模型上面,
 用施法电子卷宗的这个数据去训练施法领域的单词,
 上下文出现,
 而进行预测的下一个单词,
 然后用法官、检察官、律师进行这一个法群辩论的这个任务来对它进行微调,
 然后把它开放出去,
 让法官、律师和检察官进行使用。
 于是我们就形成了一个六十亿参数的治海诺问的垂直领域大模型,
 之所以把它取名为诺问,
 因为宋代有个施法制度,
 叫做对犯人进行最终判刑的时候,
 王公贵族贤与诺问,
 就把犯人提审出来,
 据已经形成的这个卷宗一五一十的这个对照,
 如果有就把他没有任何的这个矛盾就判刑,
 如果有矛盾再发回从审,
 说我们希望这个诺问就像一个明察秋毫的法官一样,
 对里面的一些矛盾和蛛丝马迹进行这一个扫描,
 诺问现在已经在这个浙江省高院,
 浙江省司法厅和若干的一些检察院进行的这个使用,
 我们也在这个摩大社区把它进行了这个开源,
 收获了,
 很好的这个效果,
 就在诺问面对任何的施法命问题进行回答的时候,
 在那一时候我感到了all in one的这个巨大的这个魅力,
 以前我们做QA问答系统,
 写问题写答案写得多么的辛苦,
 以前我们做人工智能用一个模型只能解决一个问题,
 现在大元模型所有的问题都融合在一起,
 你可以去问他任何的问题,
 在这个基础之上,
 因为我本人承担了教育部101计划,
 人工智能议论这门核心课程的这个建设,
 所以我们这门课程的这个所对应的教材,
 6月16号已经正式这个出版,
 我和潘云鹤院士作为这个作者,
 那为了让全国高校更好地学习这本教材,
 我们又和高等教育出版社,
 安理云这一个公司以及华研计算,
 共同打造了一个叫自海三乐的人工智能这个教育的这个垂直大模型,
 它也是六十亿参数,
 我们希望学生们在学这门课的时候能够超越这本书,
 超越这本书里面这个四十三万字的这一个教材的内容,
 让教师创造性地教,
 让学生们个性化地这个学,
 所以自海论文的自海三乐现在已经在高校社的这一个云服务平台上面进行开放,
 让全国高校用这本教材的这个学生们进行这个使用,
 后来我们又形成了叫自海金盘和化合物合成,
 现在我们浙江大学是学科最为齐全的这个高校,
 总共有六十三个这个一级学科,
 我们想,
 如果每个学科都有自己的学科大模型,
 学科大模型再把它连接起来,
 不就成了一个像我们学校有个老师说,
 浙大先生是不是会出现,
 就把学科把它打通,
 然后让他问任何的学科问题,
 他都能进行这个回答,
 那大元模型是个大脑,
 你问他什么问题,
 他好像都能回答你的这个答案,
 如何把一个大脑装上手和脚,
 那么AI Agent就是一个很好的文件,
 当大元模型给出你答案的时候,
 之后要完成这个答案里面的编程计算,
 以及其他的这个功能,
 我们就可以打造一批一批的这个Agent,
 让大元模型形成手和脚,
 让它做更好的这个事情,
 这也是说为什么现在这个大元模型和Agent之间的这个结合,
 又成了人工智能的一个非常这个热点的这个研究的前沿方向,
 那我也要告诉大家,
 这个人工智能就像水和电一样,
 是我们的这一个通用目的的这个技术,
 我们现在这个正面临如何把我们的学生,
 武装成这一个人工智能的基本的概念和素质,
 今年3月份浙江大学成立了人工智能教育教学中心,
 从今年9月份开始,
 所有的本科生都要学习人工智能,
 人工智能已经成为我们浙江大学的通识课程,
 那今年9月份开始,
 浙江大学将面向6300名本科生教授人工智能,
 这一个通识课程由我们计算机学院来这个组抓,
 所以面向这样一个艰巨的这个任务,
 我们要求每个专业出一到两名老师,
 我们提供教材PPT和一些这个教学资源,
 有自己学院的老师去教自己学院的这个学生,
 你说我们把通识课程也分成了四个门类,
 叫做信息类,理工农医类,
 人文社科括号Python,
 人文社科括号无Python,
 我想在我们迈进人工智能时代的时候,
 我们的学生一定不能落伍,
 一定要用人工智能去改变,
 去撬动他们自己学科的这个变革,
 我记得教育部有个领导说,
 20年前我们正在思考把高等教育如何带进互联网时代,
 20年后我们真的在思考如何把高等教育带入人工智能时代,
 这是我们每个高等教育要做出的回答,
 和做出的这一个使命的这个行动,
 那浙江大学在6月16号,
 也联合全国大概30多所这个985高校吧,
 双运流高校发布了一个叫大学生人工智能素养红皮书,
 在红皮书里面我们希望学生们应该了解人工智能,
 使用人工智能,
 创新人工智能,
 隔手人与人造物之间的这个关系,
 全面的建立起人工智能的基本的这个素养,
 那今天我用15分钟呢就想简单的给大家刻画一下,
 如何从大圆模型到垂大模型,
 再把这个agent把它让大圆模型伸出手和脚,
 来赋能我们的实体经济和赋能我们社会的发展,
 谢谢大家。
 好的谢谢,
 感谢吴教授的精彩分享,
 请入座,
 谢谢。
 那刚刚吴教授的分享呢,
 让我们看到了浙大在大模型领域所进行的积极探索,
 同时呢也感受到了大模型,
 与司法金融教育文化相结合的无限可能,
 大模型作为人工智能技术的新范式,
 除了技术可信外,
 还需要解决可信应用的问题,
 进而加速其在金融医疗等严谨行业的规模化应用,
 接下来让我们掌声欢迎中国信息通信研究院人工智能研究所所长魏凯,
 做大模型可信应用架构的思考主题演讲,
 掌声欢迎。
 请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
 曾经的赵部长,
 王局长,
 各位专家,
 各位老师,
 上午好。
 那么刚才呢,
 黄老师和吴老师已经把人工智能大模型怎么在研发环节,
 在技术原理上做可信的保障讲得非常清楚了。
 那我这里呢,
 重点谈一下在应用端如何考虑人工智能大模型的这个可信的这个落地。
 大家都知道这样一个趋势,
 我就直接可以跳过啊,
 那么前景是非常乐观的。
 那么人工智能大模型在行业里的应用其实可以分成两大类,
 一类是基本上每个行业都在使用的场景,
 特别是这里头点出来这几个办公,
 知识管理,
 代码的编写,
 软件研发测试,
 这些环节其实是横跨任何一个行业,
 所有行业基本上都会对这些场景感兴趣。
 那么还有一些场景是领域专精的,
 那么它有特定的领域知识,
 所以需要深入的去跟行业的知识去结合。
 那么我们也非常欣喜的看到,
 其实我们的大模型的应用,
 正在从对于专业性要求低,
 容错性要求低的这样一些简单场景,
 像容错度要求高,
 复杂性要求高,
 非常专业的这些领域去延展,
 这个进展是非常快的。
 但是其实从用户角度,
 从应用端的角度来看,
 大模型在落地过程中仍然面临很多的问题,
 那么最后一公里如何去解决,
 是一个非常重要的问题。
 那么在技术研发端,
 在工程上,
 在应用开发上,
 在应用落地的各个环节上,
 大家都在采取很多的补丁。
 但是我觉得我们也越来越发现,
 需要一个系统化的方法论来指导,
 我们如何在应用侧保障大模型落地过程中的可信。
 那么可信人工智能实际上是个很广的概念,
 那么大家对于这个responsibility,
 其实讨论非常多了,
 但是从用户的角度来看,
 他们希望的人工智能在这个场景中的应用,
 其实有四个主要的特征,
 一个是专业性,
 因为如果从非专业场景到专业场景延伸,
 这个是自然而然的需求。
 那么还有就是可控性,
 因为transformer这个注意力机制,
 它是一种概率输出的模型,
 它天生就有不可控的机理存在,
 所以如何在使用场景中保障它的可控性,
 真实性也是个很大的问题,
 因为现在原理上大模型很难完全避免幻觉,
 所以在内容真实性的保障上,
 其实还是存在很大的挑战,
 那么安全就不用多说了,
 那么这里头既包括内容层面的安全,
 也包括信息数据和网络层面的安全,
 那么这个基本上能代表着用户对于大模型,
 在应用过程中的整体的一个诉求,
 那么如何去,
 保障这个大模型在应用环节的安全,
 可信这些需求能够得到满足呢,
 我们认识到其实就像刚才所说的,
 我们通过很多很多这个补丁可以解决部分问题,
 但是现在可能到了一个时候,
 需要我们系统化的思考,
 如何去在这个各个环节上去建立一套,
 这样的机制来体系化的保障大模型应用落地过程中的可信,
 那么大体上分成五个方面,
 一个方面是数据源头的问题,
 那么黄老师刚才讲了我们现在的大模型都是数据驱动的,
 那么保障可信最源头的是这个训练数据,
 微调数据的这个高质量的供给,
 那这个当然是非常非常重要的,
 那特别是对于千行百业的用户来说,
 他们可能不需要去做微调,
 不需要做预训练,
 但是微调的这个数据质量的管控,
 数据治理就显得非常重要了,
 那这方面其实很多还是一个比较短板的一个情况,
 那么第二个就是模型的这个专业增强,
 那这个主要靠把知识计算和模型的概率推理,
 放在一块来结合起来来看待,
 这个我们之前其实知识图谱还有很多的这个知识计算的技术也已经走了发展了很多年,
 那么现在越来越多公司其实是希望能够把这两个技术结合起来,
 来增强模型这个对于常识对于这个可控性的这个能力的增强,
 那么第三个方面就是内容生成的可控性,
 现在也有很多检索增强的检索生成增强的这些技术方案,
 但是问题就在于大模型往往不知道自己不知道什么,
 所以这个边界如何去很清晰的能够界定出来也是个很重要的问题,
 那同时呢这个现在就是裸的这个基座模型实际上在生产场景里头是很难成为生产力的,
 所以往往都需要把它封装成一个智能体,
 智能体就需要掌握这个调用工具做规划的这样的能力,
 所以这方面也是非常重要的一个增强的点,
 那么第五个方面就是这个持续的迭代,
 因为这个大模型就像一个实习生进入你们公司进入这个信息系统的这个服务里头去,
 那么他需要不断的去监测调优提升,
 所以持续的这个监测和提升是非常重要的,
 最后一个就是评测,
 因为现在很多大模型其实他的行为他的能力是一种现象学的这个表现,
 所以我们对他的这个解释性不强的时候就需要靠评测来掌握全生命周期里头的各种表现,
 那么由于时间关系我也不会特别详细的展开每一点,
 那么我们在这个研究里头也把这个如何在刚才说到的五个方面上提升可信水平做了一个详细的拆解,
 那么在数据级的这个供给上可能我们要做好面向大模型的数据治理数据工程的问题,
 这个是非常重要的,
 这个不仅是对于预训练数据而言,
 对于提示工程的研发,
 对于这个微调数据的研发,
 其实都非常重要,
 那么第二个方向就是这个知识增强,
 那么我们如何去在这个知识工程专业知识的这个注入和价值对齐上来保障模型输入输出内容的这个专业性,
 来满足我们越来越高的这个专业性的这种要求,
 那第三个方面呢是这个与这个专业,
 具体的这个知识库工具去结合起来,
 来强化模型生成内容的可控性,
 那这个可能主要的问题就是这个两个方面,
 一个是知识库的外挂,
 另外一个是工具的这个外挂,
 那么因为大圆模型其实自身能力是很强,
 但是它毕竟是一个这个只是一个agent的这个核心中枢,
 那么具体干活还需要知识库和专业工具去增强它的这个执行能力,
 那么第四个方面是这个智能体的这个开发,
 那么刚才也说到了我们要把它封装成智能体才能产生生产力,
 所以现在呢很多的这个应用场景其实都在探索如何在行业里开发领域的这个智能体,
 那么第五个方面就是刚才说我们要体系化的思考,
 要有一套机制来保障可信原则和需求的落地,
 在生命周期中管好这个大模型的开发和应用来保障我们的可信的要求,
 那这里头就包括了这个数据的飞轮的构建,
 这个模型领域的这个工程化的这个集成和这个场景拓展以及持续的评估和验证,
 那么第六个方面,
 就是这个因为刚才说了模型的表现实际上是它的边界是非常模糊的,
 我们如何评价一个大模型的能力以及它在应用场景中的这个表现实际上决定了我们如何去优化它,
 这个如果不能很好的度量就很难去优化,
 这是管理学上的一个原理决定了,
 那么这样其实在这个大模型或者基于大模型的应用落地过程中,
 其实在很多环节上大家都关心评测,
 那么大家经常看到榜单是吧,
 榜单实际上只是在研发环节对大模型的一个度量能力的度量,
 那么可能很重要的就是在场景中怎么去看待大模型的基本能力,
 那么这里头就包括了这个模块化的评测系统级的评测和端到端的评测,
 只有能够清晰的去做这个评测的这个工作,
 才能够指导我们应用测怎么去很好的来采取具体的措施,
 我们和蚂蚁和很多公司共同开展了很多的调研,
 那么围绕着如何在金融,
 如何在这个医疗,
 如何在政务领域来做好可信人工智能这个方法论的落地,
 大家开展了很多的实践,
 我们发现其实这方面的意识在这个大用户,
 特别是一些央企啊还有一些大的这个需求方在觉醒,
 那么我们的很多的大厂其实也越来越关注到在工程化层面如何保障人工智能可信应用的这样一些实践,
 那么金融跟钱相关,
 医疗跟生命相关,
 那么政府应用跟政府的威信权威,
 权威性相关,
 所以这几个行业是对大模型可信要求非常高的行业,
 那么我们这些案例的这个分析也有助于去很好的总结提炼未来我们人工智能大模型在行业应用中的这些方法论,
 最后呢也简单分享一下中国新通院在人工智能方面的一些实践,
 我们一方面在跟踪前沿技术的进展,
 我们每个季度会对全国国内外吧这个基座大模型做一个测试,
 我们已经积累了很多的测试的数据也清晰的能够看到我们国内的人大模型的这个技术进展的这个路径,
 同时我们也一直跟产业界紧密合作来推动在落地过程中的可信经验的这个这个总结提炼把它升华成方法论,
 我们也持续的去建设这个生态,
 我们牵头在网信办和这个工信部发展委科技部的指导下我们成立了中国人工智能产业发展联盟,
 那么在这个联盟平台上有一千多家会员单位来共同去产生一种协同的效应,
 那么围绕大模型人工智能如何去评测我们新通院作为第三方的评测机构,
 在性能安全还有基础设施的效率等等方面已经建立了相对比较完善的这个评测体系,
 当然这个体系也在不断的迭代要跟上这个前沿模型的这个进展,
 目的就是更好的服务于我们中国人工智能产业发展,
 那以上就是我的分享也是感谢各位领导和专家的聆听谢谢大家,
 好的谢谢感谢会所长的精彩分享谢谢请您入座,
 从刚刚会所长的分享当中呢我们可以看到的是人工智能可信内涵及外延已经非常的丰富,
 特别是在金融医疗政务等行业场景下,
 构筑专业可控真实安全的大模型可信应用框架是核心,
 而这需要产业上下游各方共同推动技术创新落地实施行业治理和生态合同行业,
 这也是我们期待能够在本次论坛上所达成的共识,
 蚂蚁集团作为大模型领域的代表性企业一直致力于大模型技术相关的研发和应用,
 2023年蚂蚁集团就推出百灵大模型并完成备案,
 那今天呢我们将看到蚂蚁百灵大模型在多模态领域最新的研发成果,
 接下来让我们掌声有请蚂蚁集团副总裁徐鹏和我们分享,
 蚂蚁百灵大模型升级多模态能力的分享,
 有请
 尊敬的赵部长,尊敬的各位来宾,各位朋友,大家上午好,
 我是蚂蚁集团的齐鹏,今天我代表蚂蚁给大家分享一下最近我们在百灵大模型多模态能力方面的一些升级,
 刚才赵部长讲的时候也提到,
 我们用Transformer这个模型一开始的时候只是文字文本,
 那能不能把它运用到图像还有视频更多的一些任务上去,
 那这些其实从过去一两年当中也是越来越多的发生了,
 那我们也是跟赵部长这个思路是非常接近,
 从去年开始也开展了更多的多模态这方面的一些研究,
 所以今天也是在这个场合用15分钟的时间跟大家做一个简单的一个分享,
 蚂蚁百灵大模型我们是去年第二批11月份完成了这个备案,
 在完成这个备案之后呢,我们继续沿着我们去年制定的这个布局和这个思路,
 来开展我们在大模型领域里的这个研发,
 其中我们在算力这个方面我们建成了万卡的这样一个集群,
 然后通过我们的持续的一个努力,
 我们在整个硬件的利用效率上面达到了接近60%的水平,
 然后我们整个训练的过程当中有效的训练时长已经达到了97%,
 这个是个什么概念呢,就是说我们在整个机器运行的过程当中,
 训练的过程当中只有3%的时间是没有做模型训练的前向后向这样的一个计算的,
 只有那个3%的时间是在做其他的一个处理,
 包括了checkpoint读写等等这些方面的一些工作,
 然后另外呢我们也持续的在数据方面投入了大量的这个精力,
 然后从数据本身的质量,数据本身的数量,
 以及数据本身的这个安全性方面做了非常多的这个实际的工作,
 然后也积累了万亿级别的这个训练语料,
 其中在多摩泰的就是图像还有视频语音等等,
 这些方面的数据也积累到了一定的水平,
 然后在整个这些算力以及我们的这个数据的支撑之上,
 我们的百灵大模型,包括我们的语言大模型,
 还有我们的多摩泰大模型,
 都在业界的这个一流的水位上面取得了相应的一个一流水位的一个水平,
 然后基于这些两个主要的大模型,
 我们呢就开展了各个领域的实际的这个应用,
 这些领域呢就包括刚才我们提到的很多严肃的应用,
 在金融方面,在政务方面,在医疗方面,
 这个待会儿张院长要讲的这个摇杆这个方面,
 我们都有很多的这个实际的这个应用,
 那这些应用呢从蚂蚁这个布局上来看,
 我们是一方面是要支持我们的C端的用户,
 我们在支付宝上面的用户,
 另外呢蚂蚁和植物宝有很强的生态,
 那我们要支持我们的生态的伙伴,
 这也就是我们B端的应用,
 那在支持我们的B端的用户的同时,
 因为我们B端用户有很多是这种严肃的应用,
 包括医疗和金融等等,
 这些领域里边有很多专业的一些人,
 这个人士他们是给用户提供服务的,
 我们呢通过我们大模型能力也会给他们提供他们的效率的一个提升,
 那接下去呢我就讲一下为什么我们要在多模态这个方向上面要持续的投入,
 以及我们在这个原生多模态这个模型上面做了那些具体的工作,
 去年我们在单独的语言大模型和多模态大模型的这个发展的过程当中呢,
 我们建设了刚才也提到就是万亿级别的文本的语料,
 同时也建立了百亿级别的图文,
 视频以及音频这些方面的一个数据,
 然后我们呢通过这个把图和文这两个就是在多模态这个模型上的一个结合,
 也创新的提出了一个跨模态的一个动态对齐的一个技术,
 然后把语言大模型以及图文这些数据的一个结合,
 也为我们带来一个实现千亿参数视觉语言模型的这样一个能力,
 那有了这些之后呢业界也在有单独的这个每个方向上都有一些发展,
 包括视频的理解,
 包括语音的理解和语音的识别,
 那在这个之上那我们去年的时候就定了这么一个目标,
 就是在2024年我们要突破原生多模态大模型这样的一个新的一个模型的一个架构,
 那这个架构有什么区别呢?
 在过往的这个图文多模态这个大模型里面,
 我们更多的是将这个语言大模型以及图像的这样的一个视觉模型这两个做一个桥接,
 各自分别去发展,
 发展之后呢再通过一个桥接的一个网络,
 把这两个模型合在一起来给大模型赋予一个图文理解以及图文问答的这样一个能力,
 但是随着这个各项技术的一个发展,
 然后这个所有的这个模型都在像Transformer这样一个架构来去点进的时候,
 我们也看到了这里面一个机会,
 这个呢就是我们用原生多模态一个架构,
 在图像视频语音以及文字等等这些方面都增加一个他们自己的这样的一个这个head,
 就是对他的一个这个语料和他的一个token的这样的一个表征,
 这样一个表征之上我们通过一个统一的一个网络然后呢去给这个大模型赋予一个生成文字图像视频语音这些方面的一个能力,
 把这些能力都结合在一起,
 之后那就就形成了我们的一个新的原生多模态一个架构,
 那这个模态这个拓展呢是可以进行动态一个拓展,
 如果有新的这样的一个数据的形式加入进来,
 我们也可以把它加入到这个网络里边进行一个动态拓展的一个训练,
 然后呢从桥接这样的一个网络就向原生的这个多模态的一个模型逐渐的去跨越,
 我们在这个例子里边大家可以看到,
 我们通过这样一个原生多模态一个架构,
 这个模型可以支持上下文的这样一个生成,
 比如说我们把这个图上里面的这个河流,
 然后和下面这个图上的一个山结合在一起,
 把这个河放在这个山下面,
 我们的模型就会生成后面那个雪山之下有一条河流的这样一个图像,
 然后这些例子呢其实都是通过这样的原生多模态一个模型才能这个达成的,
 这个例子呢刚才这个例子就是我们在这个图里面让它识别出来,
 有发出这样的叫声的一个物体并且把它框出来,
 然后我们模型就可以把这里面的这个狗然后给它框出来,
 然后在这样的一个原生多模态的一个基础之上,
 它就给我们带来了更多的一个更丰富的一个能力,
 有了这样的一些原生多模态的模型的加持之后,
 我们的模型就可以做到它能够看到,
 而且它能够听到,而且它能够说出来,它也能够画出来,
 那基于这样的一个多模态大模型呢,
 我们就可以在图文对话,视频理解,图像和视频的生成,
 以及语言的理解和生成等等这些方向都可以去做应用的一个落地和尝试,
 那这里面呢就是一些我们在蚂蚁里面具体落地的一些场景,
 包括我们智能助理啊,包括我们的这个创意生成,
 还有我们数字人对话等等,
 都是这个原生多模态在蚂蚁的实际业务当中的一些应用。
 那接下去呢,我就给大家看一下,
 就是有了这样的原生多模态之后,
 那未来的这个应用当中的一些可能的一些想象的一些场景和空间。
 在画面中看到你穿着白色衬衫,建议搭配一条深蓝色或灰色的牛仔裤,在约会中保持整洁清爽。
 另外,我查到今天杭州天气晴朗,紫外线较强,你可以戴一顶帽子,既能搭配造型,也能防晒哦。
 哈喽,我最近有点感冒发烧,你帮我看看这些药有什么我可以吃的吗?
 在画面中,我看到了古今丸胶囊,纸壳糖浆,蒙托石散等药品。
 对于感冒发烧,你可以尝试部落分缓式胶囊,画面中的红色盒子。
 不同药品的剂量会有差异,请按医生建议或说明书服用。
 那你看看这个药具体应该怎么吃呢?
 根据画面信息,成人一次一例,一天两次,请详细阅读说明书确认。
 哈喽,今天有朋友要来家里聚餐,我准备了这些东西,我能拿它们做点什么呢?
 你可以做清蒸鱼。
 第三鲜,炒西兰花和蔬菜沙拉。
 但是我不太喜欢蔬菜沙拉,还有其他的推荐吗?
 你可以做西红柿炒蛋。
 将西红柿切块,鸡蛋打散炒熟后撩出。
 然后炒西红柿,放点盐和糖。
 最后鸡蛋回锅跟西红柿一块儿炒匀,撒上葱花就好了。
 好了,谢谢你。
 不客气,希望你和你的朋友们喜欢这道菜。
 如果你还有其他问题,随时告诉我。
 请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
 这个就是我们近期在原生多模态大模型领域里面一个简单的一些进展的一个展示。
 那我们为什么要做这样的一个东西呢?
 我们从去年年底和今年年初就定了今年的一个目标。
 其中我们技术上面最主要的一个目标就是突破原生多模态这样的一个模型的一个研发。
 原生多模态在文本大模型的基础之上和单纯的多文维拿的大模型基础之上集成了这些能力之后,
 它能够做到看、听、说、画等等这一系列的这些能力。
 那有了这些能力之后,它实际上是对智能化的一个,就是从这几年以来大模型发展到现在大模型本身的一个很重要的一个进展。
 那以这样的一个进展为基础,我们认为实际上在蚂蚁的这个场景里面,我们有很多的可以应用的一个场景。
 这里边呢就举一个例子,就是举几个例子,是我们蚂蚁今年最重要的这个战略里面的这个三大管家的这个战略。
 那其中我们有这个智能生活管家,智能生活管家它的这个目的就是让大模型除了能跟你聊天之外,
 能够跟你实际的再办一些你要去比较的事情。
 那这里边呢,就是生活当中你可以通过猪脚上去干的很多事情,我们都可以通过这个大模型的能力的加持,以及agent这样能力的一个加持去帮你办到。
 这里边就包括了你去那个看一些你的政务的办事,你去出行的时候做一些规划,以及你去甚至是点餐等等这些,都可以简单的唤起大模型,这个让它来帮你去完成这些任务。
 那同时呢,因为蚂蚁是这个,
 有很强的这个生态,所以在我们在通过对这个生态的开放,把生态的能力通过这个大模型和agent紧密联系在一起,去让400万的商家和机构的小程序,以及8000多项数字生活的服务,可以很方便的在用户这端这个使用起来,能够让我们实现做11人的智能办事的一个助手。
 那在智能的这个金融管家这里边,当然就是一些财经资讯,
 然后投资的这个调研,以及在投资上面的一些陪伴过程当中,随着市场的企图,能给你更多的一些这个投资方面的一些陪伴和投资的这个教育,然后呢,希望是能够让每一个投资者都有一个专门的一个私人的一个理财专家。
 那现在呢,这个我们的这支销宝,这个也就是智能金融管家,已经累计有4300万的这个用户。
 然后呢,这个最后一个呢,就是我们的AI的就医生。
 现在就是大家就是去医院看病,要排队,要有很多的这个困难,去找到不同的地方,去做不同的检查,然后有了这样的一个就医助理呢,我们就可以在诊前,诊中,诊后,在全时段都可以做你的一个数字陪诊师,然后陪着你去做你的这个整个诊疗过程当中的每一步,然后告诉你每一步里面应该去哪里,做什么事情,并且把中间的一些节奏,
 结果能够适当的来给你一些解读,然后我们这个事情呢,也是结合了这个跟医疗行业的一些合作,等一下可能会有这方面的一些更详细的介绍,然后跟医疗行业的这个合作呢,就除了给个人提供这个就医助理之外,也可以给一些医生提供更多的可以触达用户的这个手段,把他们的知识更好的可以服务到更多的人身上去,那为了做到这些,这些都是一些非常严谨的一些产业,
 那我们还有很多的路要走,虽然我们有了一定的大模型的能力,也有了一定的原生多模态的模型的能力,但是呢,我们要这个在这个深耕这个产业的研究产业的这个时候呢,还需要做到更多的一些高质量的一些数据的语料,高质量的一些专家的一些知识,以及更多的这些人力的投入进来,才能够让这个模型呢,你更专业,更真实,更加可控,更加安全的这样的方式,来给更多的人力投入进来,
 让更多的人提供服务,来提供一个规模化的一个应用。
 那为了做好刚才这些严谨专业,这个要可信等等这些,我们一直都是很坚决的在投入在这个强化学习的这个领域,那除了前面这个可能大家都熟悉的人工反馈的强化学习呢,我们认为在这个基础之上,除了人类的反馈,我们要更多元的这个反馈的这个方式,
 因为人积累了很多的这个知识,这些知识呢,已经沉淀成了一些规则也好,一些这个工具也好,那基于这些规则,基于这些工具,都可以提供出来很多的这个反馈的一些这个信号,然后把这些信号收集在一起呢,我们就可以把我们的这个奖励模型去扩圆,去把它给调到一个更大的一个规模,然后更强的一个能力,
 通过这个奖励模型的一个扩展,
 然后反过来再用强化学习的机制,不管是这个TPU这个种模式也好,还是DPO这种模式也好,我们都可以让我们的模型学得更快,也学得更好,然后通过提供多样的这种强化学习的机制呢,就可以在那个我们不停的完善我们的这个框架以及模型能力的安全性的基础之上,也能够快速的支持下游的一些场景,快速去做一些优化,
 那我们在,
 在有用和安全这个方向上面,这个线线里面呢,是一直持续希望再往这个更安全,更有用的这个方向上面去努力。
 在未来,有了大模型,有了多模态大模型这样的一个强大的一个能力之后,我们希望的是通过一个强大的多模态大模型来支撑所有的这些下游的一些任务,
 在这些任务里面,这样的一个模型通过领域里面的一些模型来支撑所有的这些下游的一些任务,
 一些微调和领域里面一些适配,就可以达成这个帮助用户的一个能力,然后呢,也通过希望是能够通过不同的这个渠道,然后渗透在生活的方方面面,可以用不同的端,不同的这个方式来使用大模型提供这个能力,然后另外呢,就是对于每一个人来说,我们都希望能有一个,不管你是学生,你是程序员,还是你是一个这个白领文秘等等,都能够给你提供一个这种能力。
 这样的一个这个助手的这样的能力,那刚才呢,就是我讲的蚂蚁在过去的这个一年当中在原生多模态这个领域里面一些简单的进展,那除了这个蚂蚁自己在这个2C用户这样的一个领域里面多模态之外呢,我们也和武汉大学一起有一个联合实验室,在另一个维度,在摇杆这个领域里面,也从另外一个角度来看一下摇杆的里面的多模态,它有什么样一个挑战,
 然后在这个方面呢,我们也取得了非常好的一个进展,那接下来呢,就是有请这个张院长来帮我们来介绍一下在摇杆这方面的进展。
 有请武汉大学教授,摇杆信息工程学院院长张永军教授,有请。
 好,尊敬的张部长,各位专家,各位领导。
 大家上午好,非常荣幸代表武汉大学蚂蚁集团智能摇杆联合实验室向大家分享我们的多模态大模型SkySense,那么我的汇报呢,大概分成以下四个方面。
 首先是关于武汉大学蚂蚁集团智能摇杆联合实验室的一个大概的情况。
 那么武汉大学的摇杆学院呢,是集向摇杆测绘空间信息工程与一体的信息和技术力的学院。
 那么武汉大学的摇杆学科,在国际上面有一个排名机构,连续七年排名世界第一。
 那么最近呢,学科带头人李德仁院士,是荣获2023年度的国家最高科学技术奖。
 蚂蚁集团呢,那么具有丰富的摇杆应用的场景,在向群厚的技术实力以及先进的云计算的基础设施和人工智能的相关的技术。
 那么2023年的3月,联合实验室呢,正式揭牌成立。
 那么我们呢,也是两家学院。
 两家学院单位强强联合,希望呢,共同打造面向这个智能摇杆这个农业金融场景的第一家的联合实验室。
 那我们希望呢,是突破传统的摇杆应用,在这个向产业落地,技术创新,人才培养,社会责任等等方面都能够发挥比较积极的作用。
 接下来呢,我将分享摇杆大模型SkySense的基本的情况。
 那么大家知道,在这个传统的摇杆解译技术啊,
 往往是呢,针对单一模态、单一任务进行建模和分析。
 那么它呢,缺乏对多模态数据、时间序列数据,尤其是地理、鲜艳、知识这个方面的一些综合建模和利用。
 因此呢,在跨模态的大范围应用中,它是缺乏土石性的分割能力的。
 在这个状态下呢,那我们就提出来,是不是能够联合研发多模态的摇杆大模型。
 那么在这个为了加强预训练的效果,
 我们呢,在全球采集了大概分布超过2000万个样本。
 那么每一个样本呢,其实包含了高分的光学,多光谱的时序的光学,以及SAR等等这样一些场景的数据来进行训练。
 那么总的数据量呢,有17亿个瓦片数据,覆盖的范围是超过800万个平方公里。
 800万平方公里,有点接近于我们国家的这个陆地国土面积。
 那么包含了40个国家和地区。
 总的数据量,原始数据量啊,占到了30亿。
 那么这些数据呢,其实都是自动采集的,不需,没有经过人工的加工的训练标签。
 然后我们在这个构建了超过20亿参数的这个多模态的时序大模型。
 然后通过空间捷舞等等一些方式来融合高分的光学,时序的光学,时序SAR等等这样一些数据,
 来进行这个互接多次学习和深尺式学习。
 然后呢,能够充分的利用这个大模型的能力。
 这个过程呢,
 我们也提出了这个像时间感知切入,多力度对比学习等等一些新的机制来提升大模型的它的发化性能。
 同时呢,我们提出了这个地理上下文的这个相关的学习方法,
 可以对同一个地区大量的这个无标签的数据进行自适应的学习,
 来学习它这个地区特定的这个时空的表征,从而隐式的生成了地学敏感的这个时空知识。
 这一点是区别于传统的自然语言大模型。
 那么根据数据分析的显示,我们这个SkySense应该说是目前国际上参数规模最大,
 覆盖的任务最全,识别的精度最高的这个多模态的摇杆大模型。
 那么我们在包括像土地利用的监测,高分辨率目标的识别,第五变化的自动检测,以及农作物的监测等等,
 共七项这个摇杆领域的解疑任务上面。
 产用了全球公开的17个数据集,跟像包括IBM和NASA联合研发的Prisvy等等18个全球公开的这个同类的大模型进行了对比测试。
 那么在这个17个数据集上面,我们联合设施联合研发的这个SkySense全部都是名列第一的,这个应该说非常不容易的一个对比测试。
 那么接下来呢,我再分享一下就是SkySense这个大模型,它在应对一些复杂场景智能解疑方面的相关的一些应用的潜力。
 那么传统的这个高分辨率的卫星摇杆的分类技术呢,往往需要做什么呢,需要通过影像的裁切或者是缩小它的比例时来进行这个界模分析。
 那么这样的话就很难的兼顾到全局和局部这个语义的信息,因此呢,它在多尺度分类的时候,它的性能是不够足的。
 那么比如说像这个左上角这个图,我们只对这个小窗口的影像进行解疑的话,那么你很难分析它到底是何流。
 还是湖泊。而我们这个大模型呢,它会从不同的尺度上面去进行多力度的这个感知,而且呢,再加上这个相关的一些自适应的算法,能够解决这个挑战。
 我们来看例子。那么这个过程中呢,我们为了解决这个写层爆炸的问题,实际上采用了多力度的这个学习方法,就是说把影像我在不同的分辨率下面或者说叫不同的市场下面进行裁切。
 然后呢,每个图像块都要进行大模型的解决。
 这样的话,我们就能够采用最后的注意力机制,自适应的去多力度的多尺度的去学习它的时空的表达特征。
 然后呢,发现这个影像之间的,就是大幅面影像它们之间的这个长程的联系,从而既能够保留地物的完整性,同时呢,又能够实现地物的这个精细的类别的分割。
 这里呢,我们在这个多模态大模型基础上,用这个多式的注意力机制进行解决。
 那么,自学习的各种不同的地物,它在这个不同尺度上面的一些相关的一些重要的信息。
 那比如说,我们用这个小影像块作为特征的curry,然后呢,用大市场的影像呢,作为key和value。
 用这个curry呢,去查询,找到了key之后,那我们就计算它的注意力图,就是attention map。
 然后呢,再根据这个value呢,相结合,得到它在不同的这个比例式下面,或者说不同的视角下面,它的关键的信息。
 这个情况下,我们就能够。
 嗯。
 进而成功地实现这个细密度的分割和分类。
 这是一个比较有特色的地方。
 好。
 那么,基于以上面我所说的这个像多模态的特征的对齐,时间敏感的这个尺度的建模,信息建模,以及地理上项目的建模,多密度对比学习等等一些相关的机制。
 那么我们的这个ScanSense大模型呢,其实是具备多模态信息的数据的融合能力,和跨任务的通用的摇杆影像的解印能力。
 不仅在像我刚才说的学术界的这个公开数据级上面表现出了很强的能力,而且其实像在自然资源的调查监测,农作物的监测保护,视觉导航、制导,以及这个像陆地生态环境系统监测等等一些行业任务上面,其实也表现出了优秀的性能和巨大的一个应用的潜力。
 那么最后呢,我简要地向大家分享一下就是ScanSense它的这个开源的计划和主要的申请方式。
 嗯。
 目前呢,ScanSense是处于一个定向开源阶段,那我们已经分享给了国内的一些研究机构供大家来使用。
 那么未来呢,我们希望经过一段时间的进一步的打磨之后,能够全部开源面向学术界来广泛使用。
 那么近期如果各位在座的专家学者,大家如果对这个ScanSense的使用和测试感兴趣,可以发邮件给我们联合实验室的联系人李延胜教授,我们会第一时间处理大家的申请。
 那么这里呢,我列出了这个李教授他的email地址。
 大家感兴趣可以拍个照。
 好,以上呢就是我的解药的分享。
 好,谢谢大家。
 好的,谢谢。
 感谢张教授的精彩分享。
 谢谢,请您入座。
 那刚刚许总和张教授的精彩分享呢,也让我们看到了蚂蚁百灵大模型能力从规模突破、模态扩展到应用多样化的快速发展。
 和积极探索。
 而蚂蚁集团也通过与五大的肖启合作,在多模态、摇杆大模型技术创新的应用方面取得了很多的突破。
 TreadGPT的横空出世,在给大家带来震撼的同时,也带来了很多的思考。
 那接下来,让我们有请OpenAI原研究员、人工智能科学家肯尼斯斯坦利,做从TreadGPT发展和大模型技术创新的实践、思考与展望线上的介绍。
 请看大屏幕。
 Hi everybody.
 It is a real honor to be able to speak to you today at the World Artificial Intelligence Conference.
 I'm really happy to have this opportunity to tell you a little bit about myself and my views in the field of AI, in particular focusing on new opportunities for AI development.
 Some of my background.
 For those who don't know me, I actually have a very extensive and diverse background in the field.
 I started as a professor.
 I started a company called Geometric Intelligence.
 I was a co-founder of that company.
 That company was eventually sold to Uber and became Uber AI Labs, where I was leading core or basic AI research for a couple of years.
 And then I also moved on to OpenAI, where I led a team called the OpenEndiness team.
 And currently I'm the CEO of a company called Maven, which is trying to bring artificial intelligence into the realm of social networking.
 You may know me better from my book.
 It's called Why Greatness Cannot Be Planned.
 It was co-authored by Joel Lehman.
 It has both an English version and also a Chinese version, which came out last year.
 So some people may be more familiar with the Chinese version, which is newer.
 And has been, as I understand it, popular recently in China.
 And one of the things I wanted to tell you about today was some of my own work with large language models.
 Because I know that there's enormous interest in large language models right now and probably at this conference as well.
 And I personally have a considerable amount of experience with large language models, both from my time at OpenAI and later.
 At Maven, where I am currently.
 And at OpenAI, my focus was on creativity and open-endedness.
 I was actually interested in, in general, I mean, by in general, I mean not just with LLMs, but in general in the field of AI.
 How we can get artificial intelligence algorithms to exhibit genuine creativity.
 And open-endedness, which means continual creativity.
 Which, the longer it's allowed to go, the more interesting it gets.
 And, you know, open-ended processes are very common for humans.
 So, for example, civilization itself is an open-ended process.
 And I've always been interested in cracking the code of how does open-endedness actually work.
 And at Maven, I turned my attention, and still working with large language models,
 but to trying more to focus on how to identify interests.
 Inside of text.
 And eventually could be extended to other modalities.
 But we've been focusing on text to understand who might be interested in a particular passage of text.
 And LLMs actually turn out to be very useful at these ideas.
 So, I'm going to tell you a little bit more in depth about these two areas of work that I've been involved in.
 So, at OpenAI, I was working on exploring a space of designs.
 This is a creative space.
 With large language models.
 And, actually, we did publish a paper.
 So, this is in the public domain.
 It was called Evolution Through Large Models.
 Which describes this work.
 And it's really based on the idea that, you know, it can be very hard for a large language model to propose an entirely new design or idea from scratch.
 By design, I mean like a new invention.
 Or an entirely new concept.
 Or, say, a concept of a program.
 Or an entirely new concept of an AI model.
 Or maybe a new kind of literature.
 A new kind of art.
 I'm not talking about derivative ideas.
 Like, you know, it obviously can write a story.
 It can write a new story.
 But can it invent a genuinely new, conceptually new artifact into the world?
 And that, I believe, is still a challenge for today's models.
 And so, we were interested in what we can do, nevertheless, to facilitate that.
 And so, I think it's really important to facilitate the exploration of the space of possibilities with LLMs.
 Because, obviously, they're powerful.
 Despite that they're not quite ready to do fundamental creativity from scratch on their own.
 And so, one of the interesting opportunities that exists even now, which we explored, was what if we just exploit the fact that a large language model can propose modifications to existing designs?
 It's very difficult today to get a genuinely new invention, whole cloth, from scratch, from a large language model.
 But they are able to propose modifications, changes to something that already exists.
 And you see, what's really interesting, if you think about it, is that a sequence of modifications ultimately leads to potentially a genuinely useful new idea.
 And so, it's possible that we could try to guide the language model.
 Step by step by step.
 Towards a sequence of changes that leads to something that's carefully propositioned to be something new and interesting.
 But the thing about that is when you're talking about sequences of changes, sequences of proposed changes.
 So, iteration. Not a single output, but an iterative process.
 You need some kind of outer algorithm.
 And that's kind of what the paper addresses to some extent.
 Is that the large language model on its own.
 Won't necessarily be able to judge and test all of its proposals in the way that we might want it to.
 And so, what we can do is have an outer algorithm where the large language model is just a component.
 But the outer algorithm is deciding what to do with the proposals of the LLM and the inner loop.
 And which proposals to modify further.
 To look further down that road of possibilities.
 And which to just abandon.
 And so, it's the outer algorithm that really is very important here to make this work.
 But when you combine them together, you get actually really interesting new creative mechanisms.
 And we tested this idea.
 And basically this is, as far as I know, one of the first, maybe the first paper to test this idea.
 Of putting in effect an evolutionary algorithm around a large language model.
 You can think of it as the large language model becomes the main language model.
 It becomes a mutation operator searching through a design space.
 And so, it's like an intelligent mutation operator.
 It's more like the way we think.
 You know, people think in terms of, well, I have this idea, but it's not good enough.
 So, I need to modify it.
 What if I modify it this way?
 How good will it be?
 And it's basically, we're effectively causing that kind of a process to happen artificially.
 And so, we decided to test it initially in a constrained space.
 You could call it a toy domain.
 Where the objective is to design two-dimensional simulated robots for different terrains.
 And so, the idea was that, you know, we would say, let's explore the space of designs of these 2D robots.
 Which is inside of a simulator.
 With this specialized algorithm.
 It's called a quality diversity algorithm.
 Wrapped around a language model.
 And we try different models.
 And we would look at how they do.
 And then it would propose modifications.
 It's like a person having ideas.
 And it could create entirely new designs.
 What's interesting here is, the ultimate designs that are output by this system are designs that the large language model would never output on its own.
 That's what's so interesting.
 Even though it was involved in their creation.
 A priori, if you just queried it and asked it for proposed designs, it could never do this.
 It was only possible because we were looking at each change it proposed.
 And testing them.
 To see whether those were leading in directions that were interesting.
 And therefore, we were able to assess the directions that were most promising.
 Using the model itself.
 And so, this is really interesting because it was able to come out with a huge repertoire.
 A collection of many designs.
 And that large repertoire was then useful.
 Because we could look inside that repertoire.
 And see which ones might be good for different terrains.
 And in fact, we even went farther.
 And we later fine-tuned these language models.
 To output designs that are conditioned on different terrains.
 Using the ideas that had been generated in the initial phase.
 Like all of this huge repertoire of robot designs.
 And so, ultimately what you have is.
 You have the ability to fill a space of possibilities.
 That does not exist at all in the training data.
 I think this is what was really interesting about this.
 Is that the form of the design of these models.
 Which were called Soda Racers.
 Didn't exist in the training data at all.
 We invented our own formalism for it.
 So, it's not possible that it could be in the training data.
 And so, you might say.
 Well, if language models have never seen this kind of formalism.
 They can't actually work with it.
 But this work shows that they can.
 Because we give them a starting point.
 And then they just propose modifications.
 And it actually leads to covering the space of interesting robot models.
 And so, that was very interesting.
 But I think the more interesting take home here.
 Is that you can generalize this process across many domains.
 Where designing things is the aim of the system.
 And so, it gives some hope that we could use LLMs.
 For creative exploration.
 Even though on their own.
 They might not yet be capable of doing something like that.
 With current technology.
 The current versions.
 Current cutting edge versions.
 So, I thought this is really interesting.
 And a really interesting open possibility.
 And indeed.
 Since the publication of this work.
 Already within the last couple of years.
 There's been dozens of papers written on this topic.
 And I think.
 I'm guessing it will be a whole field.
 Because it makes a lot of sense.
 To use an LLM to search through a design space.
 Now, later on.
 When I worked at Maven.
 And started this new company.
 Which was about social networking.
 We were interested in this question.
 Of how to know what would someone be interested in seeing.
 Without having to fall back on things like likes.
 Or follows.
 Or upvotes.
 We wanted to use AI to figure out.
 What would you be interested in?
 And what's interesting is that.
 That requires a real holistic analysis of a piece of text.
 Like to actually understand it truly.
 So that you can then think about.
 Would someone like to read this piece of text?
 What are the interests that are associated with this text?
 And this would have been really hard to do five years ago.
 I mean, it probably would be impossible to do.
 You know, the best thing we would have had.
 Were primitive embeddings.
 But I don't think they're good enough to do what we want to do.
 To really be able to extract.
 Genuinely the interests that relate to a passage of text.
 But LLMs make it easy.
 So this is another use of LLMs.
 Is to extract interests.
 You can see in the example.
 In the slide that I provide.
 That like if there's three tags that have been extracted here.
 This is extracted by the LM.
 To decide what are the interests.
 The specific discrete interests that might intersect.
 With this passage of text.
 And the LM is just very good for doing that.
 It sort of, I think, points to the fact that.
 You know, some things are challenging for LLMs.
 Today.
 With today's technology.
 You know, it can kind of do them.
 You know, it can kind of on its own.
 Do some, a large project.
 Like write up a legal document or something like that.
 But it's still, it's still unreliable enough.
 That it needs human oversight.
 You know, it still makes mistakes.
 It still hallucinates.
 It still struggles with creativity.
 Like there's still problems.
 There.
 You'll get misinformation can come up.
 But just extracting interest is, is very, very good at that.
 And so one thing to think about here is, you know, when you think about applications of LLMs is.
 There are things that are currently at the edge of possible.
 But there are also things that are really, really well aligned.
 Which could be the killer applications of today's.
 Large language models.
 Because they already work really well.
 And I think interest extraction.
 And interest matching is one of those things.
 So what are some of the.
 What is some of the future outlook for large models?
 Well, I think.
 One of the big questions that we're facing is whether.
 More data with the same architecture is enough.
 You know, we're going to find out.
 Whether the scaling hypothesis holds.
 As we get to bigger and bigger models and more and more data.
 And some people believe right now that it is.
 Some people believe that.
 You know, we just.
 Make the models bigger.
 Collect more data.
 We will achieve a GI in effect or artificial general intelligence.
 Other people are more skeptical and think that probably more new ideas are going to be needed.
 And so another problem that might happen.
 You know, and so if you're.
 If you're.
 If you're using a.
 So if we needed.
 You know that we might need.
 New kinds of architect.
 That's a possibility.
 Or another kind of problem could be that we run out of enough data to keep scaling with.
 In which case we'll need to make more data and the generation of new data.
 You could probably see is related to this question of open.
 How do we get new ideas to come out of something.
 So that might turn out to be part of the recipe that we need
 to move forward and to get more advanced models.
 You know, and there are some things, it's still possible,
 there are some things that don't even exist in the data,
 which is another problem.
 Like some intuitions that we have
 that can't be expressed through words.
 For example, I have an intuition about when I have to stop.
 Like when I don't know anything more,
 can't do anything more, when I'm stuck.
 That's actually a really useful intuition
 to think about with respect to something like hallucination.
 Knowing when I just can't go any further is really useful
 because it stops me from saying things that aren't true.
 And maybe some intuitions of this type
 are not well encoded in text or expressed with words
 and therefore it would be hard for us to use only data to achieve,
 which would mean there might need to be architectural changes.
 Some other things that aren't necessarily in data
 includes chronology.
 Chronology, the order in which things occurred in history,
 that's related to the idea of novelty or interestingness
 and ultimately to creativity
 because the idea that something is interesting
 is related to when it occurred.
 You know, the idea of a car,
 like a box on four wheels that can go from A to B,
 is actually not interesting today
 because it's been around for more than 100 years.
 But 100 years ago, it's actually something interesting
 and might be worth talking about at a party.
 And so chronology is related,
 it's related to understanding interestingness and novelty
 and chronology tends to not really be captured
 in the way that we train current models.
 If they see everything all at once in a batch,
 and so it's possible that we need to do some changes
 or maybe even need new architectures
 to be able to capture that kind of information.
 Of course, like even short of AGI
 or artificial and general intelligence,
 there's still opportunities, for example,
 in amplifying human expression,
 and in multi-modality, like in GPT-4,
 we see many modalities in this,
 like we see visual modality
 and the text modality in the same model.
 And these kinds of advances are interesting,
 even short of full AGI,
 and to some extent will allow humans to be more expressive,
 even if the model still needs a human
 to push it in the right direction.
 That's still really valuable
 and presents a lot of opportunities.
 So, in terms of what industries are going to be affected,
 I kind of give a little injury,
 like that's probably not going to happen.
 Being right or being wrong isn't so important
 in artistic domains, video, music.
 And so they're ripe for disruption because of that,
 and we're already seeing this starting to happen.
 I think maybe next down the list would be complex routine tasks,
 stuff like contract writing, legal advice, medical diagnosis.
 These might be,
 but I think they still need human oversight
 because they're too risky to leave alone to a machine currently.
 A machine makes too many mistakes,
 has too many hallucinations presently
 to allow this to be autonomous,
 but it could still help a human to accelerate
 and supplement what they're doing.
 But we ultimately need human oversight currently
 for those kinds of tasks to work.
 So that's something to consider if you're thinking
 entrepreneurially about, you know,
 what's actually feasible today and what's realistic today.
 And, you know, finally, I think, you know,
 there's creative types of thinking,
 which is farther off, like new scientific theories,
 ideas for companies, movie plots, new inventions,
 like this kind of like fundamental creativity.
 Like I said, at least my opinion is,
 based on using these models in their recent iterations,
 is that they're not really ready yet
 to think fundamentally, creatively,
 on their own, like without any human oversight.
 So probably those kinds of tasks are still farther off.
 And though maybe at some point innovation will allow them.
 And then of course, there's one other thing
 that's worth mentioning, which is robotics.
 People are talking about foundation models for robotics.
 It's hard to predict what the direction is of that research,
 you know, partly because robotics does involve some risk to
 people.
 And so when it's ready for prime time is hard to predict,
 but it's certainly a promising direction
 and can certainly contribute to some level of disruption
 and, you know, things like factories and other places.
 And so I see a lot of possible disruption coming
 in the future.
 And of course, we should remember that technology continues
 to progress as well.
 So in the future, there'll be even more opportunities.
 And I'm very happy that I had this chance to tell you,
 some of these views, hope you have a great conference
 and hope to meet everyone here at some future date.
 Okay, goodbye.
 Thank you.
 So the next panel will be the third panel of this forum.
 We'll explore the industrial applications and innovation practices
 of big models.
 The innovation of big model technology has brought
 a lot of surprises to the industry.
 At present, big models have started to infiltrate
 from simple tasks with high accuracy in the industrial
 world to complex tasks with low accuracy in the field.
 This trend is based on the improvement of basic technology
 and the exploration of innovation practice,
 and is also further promoting the evolution of technical
 variations and application practices.
 I think that everyone here has the opportunity to learn more about the new technology,
 大模型未来将有哪些爆款 行业龙头企业都在深耕哪些领域
 而最终我们的生活又将与大模型产生哪些联系呢
 那么接下来是高峰对话环节
 将由CSDN创始人董事长蒋涛主持
 对话嘉宾蚂蚁集团副总裁徐鹏
 智普AI董事长刘德斌
 华为公司人工智能战略与产业发展副总裁秦瑶
 深处科技董事长CEO唐嘉瑜
 百川智能副总裁邓江
 来共同探讨大模型爆款应用的N种可能
 让我们掌声有请各位嘉宾
 谢谢
 时间稍微有点多
 但是这个话题还是大家非常感兴趣的
 我们就抓紧进入
 先各位要不然还简单介绍一下自己
 咱们从邓江开始
 大家好
 我是来自于百川智能的邓江
 百川智能是去年最晚的成立的一家
 从事机座大模型研发的公司
 目前我们在
 百川智能是最晚的成立的一家
 五月份刚刚发布了
 我们百川寺最新的大模型
 同时发布了我们面向C端的APP白小硬
 目前我们在B端和C端
 都在跟生态伙伴一起
 然后来拓展大模型应用落地的边界
 秦总
 来自华为
 今天线上线下有很多我们的伙伴
 我在华为负责集团的人工智能的战略
 与产业发展工作
 同时也负责我们中端BG的相关的产业发展工作
 大家好
 我是徐鹏
 来自蚂蚁集团
 负责基础智能技术部
 NextEvo
 大家好
 我是来自生数科技的唐嘉瑜
 生数科技是去年三月份成立的一家多模态的大模型的公司
 我们致力于像图像3D视频
 包括最近我们视频可以同时生成音频
 这样的多模态生成相关的一个研究
 然后我们也在华为购买了一家大模型的公司
 简要的介绍是这样
 大家好
 我是智普发展刘德斌
 智普公司做大模型比较早
 现在在大模型的机座模型
 代码模型
 多模态模型
 还有对话模型等各个领域都有一些布局
 然后在我们今年一月份发布了最新的GM4的模型
 基本上能够对标到国际前沿GPT-4
 然后在今年五月份
 我们也新的开源了我们的9B模型
 相当于我们前面开源的6B模型
 现在也有一个新的6B模型
 也有一个比较大的提升
 也欢迎各位业界同仁来使用测试
 谢谢大家
 谢谢五位嘉宾
 我是主持人蒋涛
 我们CISDN是最大的程序员社区
 程序员就关心一个问题
 现在处于一个什么阶段
 大模型如果是一个新的操作系统
 或者我们开发人员的一个底座的话
 它到了什么阶段
 然后我们现在应用开发
 大模型的应用开发
 应用
 出现了一个大模型的应用开发
 处于一个什么阶段
 要不从咱们的开始
 百川认为
 好
 我觉得从一个可喜的角度来看
 在过去一年
 特别是国内的大模型
 基座模型的能力在持续的提升
 也基本上能赶到
 世界一些先进的模型的一些水平
 但是我觉得更令人兴奋的
 就是它的进化迭代的速度是非常快
 所以在这个基础上
 实际上我们能够看到
 模型的这种智能化的水平
 其实在不断的提高
 所以呢在今年实际上呢
 我们能看到有很多好的
 应用场景的一个落地
 然后模型能够作为一个智能体
 然后真的嵌入到场景中
 产生巨大的生产力的价值
 这个我觉得是
 模型能看到的一个东西
 那当然在这个过程中呢
 实际上我们看到各家
 实际上在不同的场景和领域
 其实是在不同的场景和领域
 其实也在做垂直的一些能力的一个提升
 包括百川智能一直尝试在
 医疗金融等一些知识密集的行业吧
 做这种相关的技术的迭代
 然后我们也跟很多的伙伴一起吧
 然后非常期待着这个
 随着模型能力的提升
 能够创造出更大的一些业务价值
 我们可以再具体一点
 下面请总
 就是比如说移动互联网的阶段
 和现在类比我们到什么阶段
 或者云计算也可以相比一下
 现在成熟吗
 应用成熟吗
 底座成熟吗
 我第一个感觉就是
 我觉得大模型可能跟云计算
 和这个移动互联网还不能完全对比
 因为大模型呢
 本质上是个技术
 我个人认为它可能还不是个产业
 从这个技术方面来说呢
 我觉得它可能还属于一个非常早期
 如果相比于
 早期什么程度
 就如果说我们把这一个赛道
 分成上半场下半场的话
 现在可能还属于上半场的
 很不好的阶段
 因为我觉得现在技术呢
 刚刚从前年是吧
 发展发展之后呢
 其实发展很快
 但实际上呢
 还属于很多技术的概念的讨论啊
 研讨啊
 包括还有一些可信安全的问题
 现在呢
 我觉得从关键的应用场景
 商业模式上面
 还有很多路要走
 所以我个人判断呢
 这个大模型技术也好啊
 产业也好
 还属于非常早期的阶段
 OK
 徐峰同意他的观点吗
 我基本同意啊
 我也认为
 它是属于一个比较早期的一个阶段
 因为本身大模型的能力
 还在不断的提升
 离人对它的期待
 我觉得还是有一点距离的
 你们也做了一些演示
 刚才看的
 你认为那个是未来应用的方向吗
 或者到现在应用到了一个
 可以实际落地的程度吗
 包括你刚才讲
 你们那个金融有四千万用户
 我觉得在一些有限的应用场景之下
 是确实是可以有落地的
 但是这个大模型呢
 可以
 对比一下
 包括云计算
 包括其他的这个互联网
 就移动互联网这个
 它的出现
 其实都是有一个非常开放的一个生态
 在背后这个支撑的
 然后大模型现在的开源
 实际上还不是真正的开源
 所以它很难去生长出这么繁荣的生态
 这个我觉得这个还需要大模型进步的开放
 如果内比安卓能内比一下吗
 到几点点现在
 我觉得安卓本身
 它从一开始就是一个完全开放的生态
 然后大模型今天的开源只是模型权重和代码的这个开放
 它其实不是一个真正的本质上的一个开源
 所以它跟这个技术上是不能比的
 我说就阶段上内比一下
 阶段内比
 因为它两个并不是同样的一个开源
 所以我觉得现在的这个还没有办法跟安卓的开源完全相比
 好
 申诉算应用代表了
 是是
 其实我非常同意这个秦总和徐总的这个观点
 就是它真的是一个非常前期的一个阶段
 就是我们从数字上可以看到
 比如说像国内的现在这种大模型的应用
 那比如说C端应用其实加起来的一个月火的话
 估计现在大家一个统计的话
 大概还是千万级的
 那你真正的一个国民级的
 而且是多个国民级的应用的话
 其实还是有很大的一个距离要走的
 然后从这个B端来讲的话
 我相信这个在座的几位的话
 都是在这个B端领域有不同程度的一个深耕的
 那真正的在这个B端的企业呢
 很深入的去用起来
 然后呢去做到非常好的一个降本增效
 或者是说有一个非常好的一个体验的提升的话
 确实还是有一个比较较大距离的
 像我们本身自己做这个多模态模型
 比如说我们最近发布的进展的话
 是像在这个4月份中关村论坛
 发布了这个对标SORA的V2这样的模型
 然后在6月份也来到一个这个更长的时长
 包括生成声音等等
 就是从技术这本身层面来讲的话
 好像是做了一个非常大的提升
 但是我们在落地的这种过程中
 无论是跟饮食机构
 然后游戏产业
 然后或者是在这个
 这种C端的创作者来说
 它总体上来讲
 比如说它在这个生成的成功率方面
 包括推理的成本方面的话
 其实都还是有非常大的这个提升的这个空间的
 所以我们觉得整体来讲的话
 还是一个相对比较前期的一个状态
 所以是底座能力还需要提升是吗
 对 底层能力其实还是有比较大提升的空间的
 智普这边能讲一下吗
 你们做的
 我认为这个大模型
 现在应该确实是一个飞速发展的阶段
 如果我们前面其实也看到很多人有这个理论
 说现在大模型启动了第四次的工业革命
 如果认为第四次工业革命会是一个未来50年
 一个高速的发展期的话
 你可以想象最近的这几年
 其实只能算是它的一个非常早的前期
 但同时我们也看到就是大模型的应用
 尤其是在今年
 其实应用我们接触到的非常非常多的人
 有兴趣来做这个事
 所以说我认为它会是一个应用的爆发前夕
 我就可能再等个一年
 很多应用
 比如说我们现在说的一些幻觉问题
 或者是在这个时代
 应用过程中要花大量的时间去定制的一些问题
 估计都能得到解决
 这个时候应用的爆发就会比较可期
 现在应该说有很多人在做
 但是做得多么好还不是一定那么确定
 对 你讲的工业革命
 我们再回来
 我们今天不是讲大模型的爆款应用吗
 现在其实有两条路
 一条路就是比如说ChatGPT在走的
 它做一个C端的一个对话
 也吸非常多的人
 咱们各家也都有自己的那个对话助手
 另外一个就是
 我们现在在做一个C端的一个对话
 微软的代表
 微软就是把大模型的能力
 集成到它的各个产品线里面去
 有点偏to be吧
 我们可以这么说
 或者偏已有的场景的增强
 就是你怎么看这两条路的发展
 而且昨天李延红还讲了
 就是说以后没有
 大模型时代没有超级APP
 只有这个应用
 大家可以看看
 这个路径会是什么样子
 就是这个我们
 我们不讲爆款应用的可能性
 中国C端还有B端
 还有所谓的资源体端
 就是李延红讲的那个
 大家怎么看这个
 可以赞成C端的先发言好吧
 没有有吗
 你赞成吗
 我还是我来分享一下
 就是说我觉得作为像微软
 苹果这样的大企业来说
 然后他们有自己的应用场景
 我觉得至少能够证明
 大模型在它的那个场景中
 能够创造出巨大的业务价值
 就是能够让客户去使用
 或者是买单
 然后同时通过这种应用的深度嵌入
 其实能够建立起
 我们叫数据的飞轮
 从于这大量的客户的使用
 积累更多的数据
 来进一步提升模型的能力
 所以我觉得如果能找到这样的场景
 让模型落地
 我觉得这个肯定是我们每一家模型公司
 愿意去做的一件事情
 当然呢
 它会带来另外一个问题
 就是我们看到有更多的场景
 其实模型还不能够完全胜任
 或者是发挥出应有的一个能力
 所以这也是我们这些
 做机座模型公司要去做的事情
 就是不断地去提升模型的一些基础能力
 比如说推理的能力
 生成的能力等等这些能力
 然后去满足模型公司的能力
 去满足那个场景的那个需求
 这个是我的基本观点
 秦总
 你们又有C又有B
 你先讲C吧
 手机跟大方形结合能爆发吗
 我先说我的观点吧
 我就说这个
 你的爆款应用
 这个词其实就有导向性
 因为我们说的爆款呢
 本质上就是指C端
 会多一点是吧
 我们说的B端里面
 你现在用比较多的
 比如OCR啊
 或者说质量检测呀
 制造里面
 这些已经用很多了
 所以说呢
 我想说的就是说
 但是呢
 我们不得不承认是吧
 这个B端的
 特别面向工业里面的很多场景
 因为华为也做这块是吧
 我们给客户提了很多
 这种方案和服务
 包括气象测的很多东西是吧
 这块呢
 的确不太容易进行爆款
 因为爆款的前提就是说
 因为毕竟没法跟个人用户来比
 是吧
 他也可以讲行业渗透嘛
 你改革了这个行业
 比如刚才讲律师
 律师以后都用AI来干了
 是吧
 这也是爆款
 这也是律所全部都改成
 这个AI辅助了
 我只是举个例子
 对
 这也能不能成为爆款
 咱们可以继续来讨论
 或者哪个行业能爆也行
 或者哪个应用场景能爆也行
 对
 第二个我想说的就是说
 如果说要这样说的
 这个爆款
 我觉得的确应该在C端
 会快速影响出来
 是吧
 比如现在可能比较多的
 比如面向这种对话类的
 是吧
 或者说这种图片生成类的
 甚至再往后走的一些
 什么的
 跟消费相关的
 是吧
 我觉得这些都会慢慢影响出来
 所以说C端
 我个人觉得它发展会更快
 而且它的整个的用户
 也会更普遍
 我觉得应该会快速影响出来
 这是我想说的一个
 另外一个
 我觉得说
 因为您刚刚提到了
 包括微软的很多应用
 我觉得这个可能跟各公司的路径有关系
 但是我一直认为
 就是一个公司大模型
 你要做得好的话
 还是要找准一个
 你自己想办法
 做得好的地方
 是吧
 就真正把自己能够
 你们公司的一个能力的东西
 把它做透做深
 这可能是真正的一个关键
 另外呢
 我觉得刚才数据这个事情也很关键
 是吧
 因为我们现在谈的很多都是算法
 和算力的问题
 Transformer这些事
 但其实背后还是数据
 和真正的科学
 和知识
 这个其实是最关键的
 而这个公司呢
 你像微软也好
 或者别的公司也好
 它在长期的积累里边
 它有这份能力
 它就应该把它能够进行变现
 或者优先进行变现
 这样才能催促这个产业的爆款
 我觉得这个闭环呢
 其实也很重要
 大模型加持支付宝会有什么变化吗
 希望能做出一个爆款应用
 但是我刚才提到的这个
 不管苹果也好
 还是微软也好
 它把大模型应用到自己的这个生态里面去
 如果做得好
 比如说像Windows Copilot这样的东西
 如果能做得好
 它其实就已经是一个大模型的爆款应用了
 如果爆款的定义是用户量的话
 它可能就已经很容易做成一个爆款应用
 包括谷歌的搜索
 它也很容易可以做成一个爆款应用
 但是我觉得我们大家可能一直期待的
 都是这种从来没有出现过的一个新的应用
 突然之间形成了一个爆款
 这个可能是大家经常期待的这种爆款应用
 但是这个爆款应用
 我自己对这个爆款应用的理解是
 它一定是解决了人的一些
 之前没有能够解决的很好的一些
 需求才能形成一个爆款应用
 那现在的这个大模型的应用呢
 现在目前没有看到特别明确的
 能够形成爆款应用的这个产品的尝试
 那当作是我觉得这是一个好
 很好的一个事情
 但是现在还没有看到特别清楚的
 不讲C了讲B好了
 我们其实主要做C
 大家讲C
 但其实我觉得这个问题跟刚才那个回答比较类似
 就是其实还是因为它这个大模型
 能力在起步的阶段
 然后还有非常大的上升的空间
 那在这个落地的应用中的话
 其实最直接的就是结合
 像比如说刚才提到的微软苹果
 结合以后的场景
 在这个场景中去做一些
 加AI的一些落地
 然后包括是说
 它可以去在这个落地场景中
 去做一个能力的一个很好的打磨
 因为我们发现
 现在AI的所谓的这个general的这个能力的话
 其实是比以前的AI是来到一个新的台阶
 但是在无论在B端还是C端落地的话
 其实还是有非常多的能力的
 一些这种垂直化的
 一些领域化的工作要去做的
 所以我觉得它在这个领域场景
 比如说像这个Office这样的场景
 你去打磨的话
 实际上非常必要的
 然后回到这个说报款应用
 或C端应用这一块的话
 我们是觉得是说
 拿真的你的这个AI的能力
 可以给大家带来一个这种
 几十倍的一个这个效率的提升
 或者几十倍的一个这个体验的提升
 但这个体验很难量化
 但是肯定是一个非常大的一个体验
 提升的时候的话
 它是能带来
 报款的这个能力的
 这个可能性的
 就比如说像这个我们觉得
 比如说我们一直探索的
 觉得是说大家在这种
 创作的一些方面
 这种创造力的方面
 实际上是有非常多的一些这种
 想象力或者是说这种意愿吧
 没有被这个激发出来的
 这个我觉得是要先有这个东西出来
 就有点像是说之前
 比如说像我自己是经历了
 交片数码
 然后到这么一个过程的
 拍照的一个过程的
 那真正当你的手机摄像头
 出现的时候的话
 才是来到一个人人都可以去拍
 然后我们以前觉得说
 也好像这个爷爷奶奶爸爸妈妈
 是没有这种拍照的需求的
 没有这种的这种欲望的
 但实际上你把这个东西
 变得非常简单以后
 你用你的AI可以让大家的
 这个想象力做到一个
 特别好的一个释放以后的话
 我们觉得这种
 随端爆发的可能性的话
 是存在的而且是
 你看到什么有趣的应用吗
 在你们包括应用你们的一个技术
 我们现在比如说在
 比如说创造力这一块
 其实大家可以看到的很多的
 就是说比如说最直接的
 现在这种图像生成的一些应用
 已经有非常多了
 比如说现在这种
 然后但是它其实为什么
 我们觉得没有来到一个
 就是大规模爆发的一个实际
 其实上它还是底层
 有很多东西没有解决
 比如说图像的可控性
 现在我们能生成
 特别好看的一些图像
 但是比如说最简单的
 控制不了
 对控制不了
 对我想生成一个
 比如说一个漫画
 然后就是这么最简单的
 想起来一个图像生成
 很基本的应用
 它里面的主角或者这个背景
 什么的一致性就很难保持
 那这些在底层层面的话
 确实还有非常多的一些关键点
 还要去突破的
 嗯
 对正好我要问一个问题
 就他讲的这个刘总
 我有个朋友他就说
 生成一个图片
 他就说我就要四个人去舞龙
 结果出来的就没有四个人
 老是三个人
 搞得他很郁闷
 就大模型
 大模型为什么就他说的
 还有一些能力还不够呢
 或者什么时候才能够啊
 就现在应用的在抱怨
 这个问题应该说是
 应该在快速迭代过程中间
 是能够解决
 然后回到刚才说的那个问题
 我倒是觉得
 抱怨应用这一块
 我倒是觉得
 其实我挺推荐
 就是智能体的这一个应用
 我觉得可能是一个
 未来的抱怨应用
 为什么这么讲呢
 就是大家都在担心说
 智能那个大模型出来了以后
 取代人还是怎么怎么样的
 但是人一定和那个大模型之间
 会有一个交流
 就怎么把人和大模型之间连接起来
 能解决人的问题
 这是将来的一个关键
 我们刚才提到的
 像CHATGPT或微软的结合这种呢
 是在做的一个问题
 在2B行业里边
 比如说已经有的龙头行业里边
 他们去做的
 这个是很靠谱的一种方式
 那个方式挺好的
 但是如果要到2C领域里边
 智能体就是一个很好的方式
 它可以让
 你看就像我们现在
 大家熟悉的快手啊
 抖音这种应用
 其实有很多人在里边去做创作
 而且要的那个
 对这个人的那个要求
 不会特别高
 当然现在其实那个
 也不算太低啊
 但是智能体这个方式呢
 将来对于很多人
 与智能体交互的时候
 它对人的要求会更低
 但同时如果你
 你特别特别的那个有经验
 或者说你自己特别有创造力
 那么你的智能体
 做出来的影响力会更大
 就是说你的
 那个智能体可以做到
 非常非常高
 所以它是可以把所有人
 都集成到这个
 这个应用里边去
 然后都能发挥作用
 但同时能够发挥的
 特别好的作用的人呢
 又能凸显出来
 那么智能体的这种结合
 就可能会是一个爆款应用
 你们不是已经发布了那个吗
 反响怎么样
 或者用户使用起来
 有什么
 跌到了以后
 对你们有什么启发吗
 就有了用户量以后
 对
 我的感受就是确实
 就是我刚才说的
 我觉得智能体非常有价值
 然后我们现在呢
 大概是有
 四十多万的一个智能体
 就是发不起来
 很快就产生了
 大概四十多万的智能体
 有很多人在里边
 建自己的智能体
 而且有的智能体
 建的确实还非常好
 就是靠建的那个人
 自己在里边设规则
 加工具
 然后加知识库
 如果能加得非常好的话
 这个智能体用的人就特别多
 具体例子是什么样的应用
 特别多
 它各种各样的都有
 比如说很典型
 大家熟知的
 写公文啊
 猜谜啊
 做游戏啊
 然后写法律文书啊
 什么东西都可以
 就相当于你自己
 有一个自己的想法
 我想做一个什么事
 然后我有我自己的一些知识
 我把它与大模型结合起来
 然后形成我自己的一个特色应用
 然后可以开放去给别人用
 这样的一种模式呢
 它就把人和大模型结合起来了
 然后这种东西
 它有一个特别大的要点
 就是要求这个机座大模型的
 通识知识能力特别强
 就是它对所有人都能结合起来
 而且还能结合得很好
 那这个机座模型的
 通识知识的要求就非常高
 如果这个东西做得足够强的时候
 比如说我猜啊
 就可能到GPD-5这个水平的时候
 很有可能这个智能体就能形成爆发
 现在呢
 大家更多的是在尝试性的用
 尝试性的用
 用起来还挺好玩的
 但中间可能也中会碰到
 各种各样的小问题
 就会发现
 它不是按我想的那个方向在走
 就会有这样的问题
 但是这个模式
 我认为它还是非常有前途的
 对
 有点像昨天李永宏也讲的
 能够做网站还要容易
 因为我们曾经经历过战长时代
 以后可能要有个大智能的应用组时代
 咱们C端一趴就到这里
 我们还是回到这个B端
 我也知道这个
 其实咱们大模型公司
 都有做行业的落地和解决方案
 在行业和落地的时候
 哪个行业接触
 和哪个场景的接触度最高
 能讲一下吗
 好
 嗯
 是这样的
 就是我们老讲大模型
 其实忽略了两个最重要的字
 叫大语言模型
 这一代大模型实际上
 它是承载了人类的所有的语言
 以及背后对应的知识
 这么一个能力
 所以我觉得要围绕着这个
 来回答您刚才的问题
 就是说我们看到现在大模型应用
 我觉得最有价值的应该是
 我们讲叫知识密集的行业
 知识密集
 知识密集
 比方说我要培养一个
 医生
 可能我要花十年二十年的时间
 律师
 对
 比如说律师
 比如说金融的这些专家
 它是知识密集的行业
 所以呢
 我们看到就是在知识密集的行业里
 然后我们能够通过大语言模型
 来提供智能体
 提供心智生产力
 比如我给大家举一个例子
 比如说医生
 我们看到医生每天大量在处理的
 其实不是疑难大症
 而是普通的
 最基础的一些病
 然后呢
 他挂号一天
 他看的病人
 大多数都是基于病人的症状
 再给他开检查单
 说你嗓子疼
 问几句
 两分钟搞定的
 对
 然后呢
 这个事呢
 实际上对于目前的大模型来说
 你让他掌握基础的医疗知识
 然后建立他的问答能力
 逻辑推理能力
 多模态的识别能力
 实际上他是可以
 做到对一些基础的病的问诊
 排查
 包括一些检查单的这个读取
 等等这些能力的
 然后我们看到在法律行业也是这样的
 就是比如说检察官
 检察官处理的大量的案件
 其实是比如像酒驾
 标准性的
 或者是酒驾等等
 特别轻微的刑事犯罪
 那这些东西其实也是非常可以
 用智能体
 用大模型来做标准化的处理的
 比方说你喝了多少酒
 是不是被警察抓住了
 是不是手犯
 然后有没有造成伤害
 这些标准情况下
 其实很容易就能把它抽象出来
 用大模型
 对所以我们看到现在
 其实真正在大模型应用落地
 有广阔空间的
 其实我们讲的就是提供新制生产力
 那这个生产力背后
 其实就是大模型对于知识的
 这种快速的掌握
 然后当然要结合着
 比如说搜索增强
 知库等等这些配套的
 这些工程化的能力
 然后能够帮助企业
 然后来我们叫造人
 造出更多的医生
 更多的员工
 更多的律师
 是这样
 好这个问题挺好
 秦董怎么
 对邓总讲的很好
 我就因为时间关系
 我就讲就讲一点
 我觉得除了知识以外
 其实数据也很重要
 我们华为做了很多这个行业
 当时遇到很大问题
 矿山大模型
 矿山气象
 油田
 其实很多
 我们做了很多case
 但是到最后
 其实我们都归结到
 除了知识以外
 数据也很重要
 这个数据又分成很多类
 比如说数据的可获取性
 因为很多行业的数据
 是不可获取的
 或者很难获取的
 这数据打开看
 还有说的版权的问题
 定价的问题
 在中国都是一个空白
 比如我这个数据卖给你
 或者在一块训练
 多少钱
 这是很难去定义的
 所以这是一类
 还有一类就是数据的
 是不是我们说叫干净
 是吧
 因为我们做数据训练
 质量
 高效质量也很重要
 我们经常爬了很多数据
 到最后用了之后
 大模型不但没训好
 然后还训得更差了
 那也有可能
 这在很多行业它也存在
 所以我认为除了知识以外
 数据也很重要
 所以我们现在
 也是把很多重点
 放到了这些数据
 相对来说容易获取
 是吧
 或者说数据质量比较高的
 就这些行业
 可能更容易突破
 好 这个补充也很好
 对 我换一个角度
 就简单补充一个点
 我觉得B端的应用的
 爆发和C端的需求
 和C端应用的爆发
 是联系在一起的
 现在就是有很多行业里边
 包括医疗
 包括教育
 包括刚才也提到过的
 这个金融
 其实有很多的人
 是需要得到更好的服务
 但是是苦于得不到资源
 是拿不到的
 那如果是能够
 通过大模型的能力
 去帮助这个医院的医生
 帮助金融理财的理财师
 帮助这个教育行业的
 这些这个从业者
 可以把一个人的这个力量
 通过大模型的加持
 可以乘以十乘以一百
 那这样可以有更多的人
 得到这方面的高质量的一个服务
 我觉得就可以爆发
 好 刚才有讲到说
 我们更多的经济是在C端
 但是现在其实真正商业化落地的话
 更多是在B端层面
 因为B端的话
 其实像我们在做的一些
 比如说跟这种广告行业相关
 游戏行业相关
 去做一些
 内容创作的相关的事情的话
 它因为在一些特定的领域下
 包括是说有一些特定限制条件下的话
 我们可以在这个垂直领域下
 把模型的表现做一个更好的应用
 所以我们会觉得是说
 它会有一个B和C
 是一个相辅相成一个阶段
 就类似于在B端的场景里面
 去打模拟的这个模型的能力
 然后延伸出来
 这个模型能力的增长以后的话
 可以去外移到
 或者是说在这个C端的场景下的话
 做一个更好的一个支撑
 这也是我们实践的一个路径吧
 等一下 刘总
 那个落地能收到钱吗
 现在B端
 还是能收到钱的
 只不过其实
 会能帮助他们实际解决问题
 创造价值了
 对 其实销售还可以
 而且我知道有一些
 有一些应用单位
 就是他就不做机座大模型
 他就纯做应用的
 其实销售还挺高的
 达到四五亿这个量级
 就是说一年销售
 四五亿这个量级
 就是用大模型来
 对 就是大模型做应用
 其实说的挺好的
 我们反而还没有他们
 做的这么大的销售量
 但是呢
 我的总的感受就是
 现在应用还是挺广泛的
 像我们最直接的
 我们的那个API调用平台
 四十多万用户
 然后一万多家的企业在使用
 大概每天的Token消耗量
 六百多亿
 然后覆盖了呢
 我看了一下
 大概二十多个主流的行业
 所以说其实在各个行业里边
 应用都还是可以的
 但是真正把它用得特别大
 我的最大感受是说
 其实是需要有行业的用户
 他本身自己也有一定的
 对这个事有一定的理解
 大家结合起来做
 就能把这个行业
 做得比较透 做得比较好
 而且呢
 这个行业的应用呢
 不只限于我们现在的对话
 然后多模态 语言
 其实还有很多
 像那个时空的数据
 然后时序的一些数据
 这个东西其实放进去
 也一样能产生效果
 比如说我知道的
 像什么在机器人里边
 在那个自动驾驶里边
 还有在那个天气预测里边
 这些东西我们都做过一些吧
 做过一些
 还有工业制造里边做过
 就是它都是有机会
 而且能做出效果来的
 但是能把它做得多么好
 是一定要与一个行业的用户之间
 做一些深度的共创
 然后去做一些
 把行业的一些场景
 行业的数据结合进来
 而且要实时的想一些办法
 不是简单的把这个数据
 放到机座大模型上去
 加一下就可以
 可能没到那个程度
 还要做得更深一点
 这是能做通的
 我们觉得是能做通的
 好 就看起来是能赋能千行百业
 但是也会带来一些冲击和挑战
 特别现在也是高考季
 大家是关心
 以后学习会怎么样
 还有刚才咱们邓总讲的
 你把医生的工作都干掉了
 医生会失业
 就职业会
 我们职业会发生什么样的变化
 学习或者给大家一点建议
 因为每个人都在职场
 面对大模型应该怎么办
 其实我觉得
 大家不用去担心这个问题
 就是说目前
 如果我们把大模型比作一个人
 它可能也仅仅是一个
 比如说二本
 或者一本的这么一个水平
 那它迟早会变成博士
 对
 然后我们实际上
 从心智生产力的角度来讲
 我们不是让它去取代谁
 而是提高供给
 比如说全国有几十万的医生
 那它显然医疗资源是不足的
 那我们能不能通过AI的
 大模型的能力
 然后创造出几百万个医生
 然后服务更多的人
 所以我觉得第一步是这个
 那当然在未来
 很多细分场景
 比如说像无人驾驶出来以后
 可能确实很多司机
 它就不需要了
 对
 所以我是觉得这个是一个
 就是还是需要有一段时间的
 就是它的整体能力上取代一个人
 但是在局部
 刚才我提到的
 比如像问诊
 它是可以取代的
 但是做手术
 比如说处理那些复杂的病症
 那还是要靠医生的
 所以但是有一点
 我觉得可能我们内部
 跟一些企业聊
 就是说基础的大模型的应用
 可能就会像PPT
 像一个SIR一样
 是每一个人都得掌握的一个能力
 基本能力
 对基本能力
 然后它是你的工具
 是你的助手
 然后你是必须得掌握的
 然后你才能够胜任
 未来的一个工作
 是这样
 秦董
 对哪个职业有什么建议
 我分享两个点
 我觉得对于整个社会学来说
 我觉得大家对这个问题
 不用过于担心
 因为你看我们看美国
 是吧
 过去100年的失业率
 它都是维持在
 4%的6%之间
 只有一两年例外
 就是因为前两年疫情的时候
 那个是例外
 包括你看我们这个
 比如说这个电灯发明出来之后
 这个做油灯的人
 其实他也没有完全
 是吧
 就彻底找不到工作
 红冠来看是不会有影响的
 从历史周期来看
 一个技术的发展
 会带来一些工作挑战
 但是呢
 从长周期来看
 还会找到新的工作
 这我想说的第一点
 从社会学来
 但是从对个人来说呢
 其实我刚才那个
 上一个那个
 我们那个OpenAI那个成员
 我觉得他列那个
 还是比较好的是吧
 现在我们大家看到的
 比如刚才我提到的
 像这种智能语音
 然后还有这个
 什么图片生成
 这种工作
 还有代码编辑类的工作
 还有文档拆了那类的工作
 这一类我觉得短期内
 会受到比较大的冲击
 对个人来说
 大家要小心这类的工作
 好
 我知道这个徐鹏
 原来搞翻译
 这个翻译
 这个好到应该会消失了
 这个是
 很有可能
 这个但是从一个
 学习的这个角度
 我也觉得
 这个大家不用太担心
 因为现在的学习
 很多人在学习过程当中
 是在死记硬背一些东西
 那这样的事情
 可能以后就不用做了
 是不是大学要变化了以后
 就是教育的方式
 可能要发生一些变化
 然后呢
 我觉得人的特点就是
 其实人是闲不住的
 这个不存在说
 大批的人都躺平这个问题
 大家闲不住的时候
 就会做一些
 更有创造性的东西
 可能就是刚才说的
 做自然体制了
 这个做一些有创造性的东西
 可以把一些事情做得更好
 我觉得这个
 我觉得前途还是光明的
 好
 深宿要玩
 对高考学生搞点建议
 我觉得他跟前面嘉宾观点
 比较类似吧
 我觉得未来的话
 肯定是一个共生的一个关系的
 我觉得不用太担心
 是说会被淘汰掉
 这就像比如说眼下的事情的话
 就像是说
 这个AI画图
 我已经画得很好了
 画得很精美了
 但是它的一些审美
 或者
 一些评价的话
 其实还是要人去参与
 然后去人去引导的
 然后再往前我们去推演的话
 比如说
 以前还有打字员
 这样的一些工种
 然后他还专门为你去
 发一些这种打的文字啊
 等等
 那现在的话
 其实人人都会去
 比如说发微信
 或者说哪怕我不识字
 我可以去发语音
 那已经变成这个工具
 成为你生活的一部分了
 所以我觉得未来
 AI其实是一个类似的一个关系
 就是人们生活中的一部分
 然后大家去
 这个第一阶段
 可能是家喻
 AI第二阶段
 就像刚才那个黄老师讲的
 后续可能是一个
 AI比人更强以后
 那我们其实就是一个
 伴随或者共生的一个关系
 那我觉得这是一个
 详细来讲的话
 不用太担心这一点的
 就是有两个点吧
 首先我觉得就是
 我们现在看到的很多东西
 这个整个发展趋势
 都是这样的
 当你发现的特别多
 其实跟你会发现
 未知的空间反而越来越大
 就是未来还有很多很多
 我们不知道的事情
 AGI也不会是顶点
 就是我们
 做到了一个事儿
 往往它给我们展开的是
 一个更大的世界
 需要我们更多的人
 去做更多的事情
 我认为它其实
 给我们提供了更多的机会
 然后对于我们个人来说
 我觉得更多的是
 要保持一个开放的心态
 其实我们历史上
 比如像国企改革
 这各种事儿
 其实都有过一阵阵痛
 但是最后发现
 都是好的
 对大多数人来说
 应该都是好的
 其实我们应该确实
 可以享受到更好的生活
 然后未来
 也有更多的可能性
 然后每个个人
 最好是保持一个
 开放接收的一个态度
 然后去拥抱这个变化
 因为这个变化
 基本上是不可逆的
 大家也没办法说
 我怎么就把它给停止掉
 是吧
 所以说我们就想着
 怎么样拥抱变化
 然后自己去适应这个变化
 那么其实我们
 应该可以收获更多
 好 谢谢
 我们最后一个问题
 因为时间也到了
 就是预测一下明年吧
 如果前面预测完了明年
 你们可以说
 后年和大后年
 会出现的一个
 重大的应用的可能性在哪
 嗯
 嗯
 嗯
 先从第一年开始
 明年
 你就讲明年就好
 我觉得是这样的
 就是从B端看
 我觉得明年
 还是有非常大机会的
 今年其实我们看到
 有很多的企业
 已经在尝试着
 大模型的落地
 我相信呢
 它会为明年
 打下特别好的基础
 包括做很多的预算
 所以我觉得明年B端
 会有很多机会
 然后它的机会点在于
 还是我刚才说的
 就是能够为企业
 提供更多的
 新制的生产力
 然后在知识密集的岗位
 然后用大模型
 来提供供给
 那C端呢
 实际上我们看到
 就是在垂直领域
 实际上随着模型能力的
 一个进步
 然后呢
 满足大家在某一个领域的
 专业的需求
 特别是14亿人都需要
 比如说医疗
 金融
 教育
 情感陪伴
 法律
 等等等等这些
 你不能讲完了
 后面还有
 我觉得纯C的话
 应该是百花齐放
 明年会越来越多
 对于面相2B的
 那些人
 那些政府侧的
 可能Copilot
 应该是个非常大的应用
 面向真正的处理行业
 制造这一类的
 我认为很多的
 大规模的应用
 会越来越多
 特别是面向
 我们现在流程行业的
 可能会
 面向什么
 流程行业的会多一点
 好
 我同意刚才的说法
 C端应该是会百花齐放的
 所以不会出现一个
 超级应用
 或者AI native应用
 不会出现
 现在还没有
 看到这个特别特殊
 首先
 C端百花齐放
 这个事情我是同意的
 然后另外的话
 那从我们自身来说的话
 我们还是致力于是说
 去释放大家的创造力
 这个事情
 所以我们在当下
 其实比如说
 如果预估到明年的话
 我们觉得是说
 AI能力可以去进一步的
 把大家的这个
 所思所想
 进一步的从画面的形式
 声音的这种多模态的形式
 去呈现出来
 然后去
 创作视频明年会有大变化
 应该这么说
 创作视频
 它是一个内容形态
 但是更多的
 其实是释放
 它大家的一个
 内心的创作的热情
 和创作后交流的
 一个欲望
 我觉得B端上边
 对有一些应用成熟
 然后能够产生
 提示征税的效果
 这个基本上是必然的
 但是我看的
 更期待的是说
 B端能够出现一些应用
 它能够对这个行业
 有颠覆性的一些影响
 比如说把行业
 比如说工业制造里边
 原有的一些工作流程
 都能改变
 然后原有的一些机械控制
 都能改变
 这样的一些应用
 我觉得是有可能能出来
 它可能稍晚一点
 比如说两年到三年
 然后在C端这边
 我更期待的就是一个
 完全的个人助理
 比如说自己的一个数字分身
 代替你能做
 各种各样的事情
 这样的东西
 我认为也是可以期待的
 它可能也可以稍晚一点
 但是是完全可以期待的
 好的 谢谢
 谢谢各位分享
 咱们今天这个论坛
 就到这里
 好
 好的 谢谢
 再一次感谢
 各位对话的嘉宾
 请入座
 谢谢
 那刚刚呢
 我们几位专家与嘉宾
 从多方面多角度
 为我们分享了
 自己对于大模型
 规模化应用的思考
 也是让我们看到了
 大模型在驱动产业创新
 实现更多前所未有的突破上
 具有的无限可能
 科技普惠
 一直是蚂蚁集团
 坚持的核心理念
 而医疗与人工智能的结合
 也就是一种
 将进一步加速医疗普惠
 从2023年开始
 在百灵大模型能力的支持下
 支付宝向医疗行业
 开放了AI就医助理解决方案
 整合数字人
 就医全流程架构等技术
 可以为每个城市
 医院
 定制专属就医助理
 为用户提供全流程
 可江户智能化的便捷就医体验
 那此次呢
 支付宝也将发布
 其AI技术
 在医疗领域布局的最新进展
 接下来呢
 让我们有请
 蚂蚁集团大模型应用部总经理
 顾敬杰上台
 与我们进行分享
 掌声有请
 各位嘉宾
 现场的今天来参会的
 所有大家同学好
 今天我代表支付宝的
 医疗健康事业部
 和大家分享一下
 我们在医疗方面
 取得的一些最新的进展
 首先
 先跟大家同步一下
 介绍一下支付宝的医疗健康频道
 我们从第一笔的这个挂号的缴费
 到今年我们跟众多的这个合作伙伴
 一起推动了第一个AI就医助理
 那么支付宝的始终在坚持助力
 整个医疗服务行业做AI的创新
 我们现在已经在推出了
 我们整个数字医保支付的方案
 到医疗的数字化
 到现在我们已经跟很多医院
 以及浙江省推出了
 很多医疗助手的解决方案
 目前呢整个支付宝的
 医疗健康频道
 已经有8亿家的这个年活的用户
 另外我们也跟3600多家医院
 入驻了我们整个医疗健康频道
 那么接下来我们就要通过AI的方式
 和我们这么多合作伙伴
 一起来共同塑造
 在智能化时代下的医疗体验
 我也简单给大家介绍一下
 在过去的这个一年的时间里面
 我们百灵大模型和医疗
 从底层的算力
 数据安全力方面
 做了大量的工作
 同时呢我们在去年
 也结合百灵大模型的语言能力
 和多模态能力
 共同在我们的医院的
 五家场景里面
 包括医疗的场景
 患者的场景
 医生的场景
 然后同时我们也提供了
 大量的生成式AI的解决方案
 包括这个医疗问答
 包括这个电子病例等等
 那么在过去的一年
 我们通过百灵和医疗行业的
 持续的这个深耕
 我们已经加速让AI
 渗透到智慧医疗的各个角落
 那么在这一年
 我们对整个百灵大模型的
 这个基座能力
 包括医疗的能力
 做了一个全面的升级
 在前面我们也介绍了
 我们整个百灵大模型
 今年已经推出了
 多模态的解决方案
 同时我们能够支撑
 接近千亿级别的
 这种多模态医疗的能力
 另外呢我们也通过
 我们的技术研发
 能够通过多模态
 像这种原生多模态的架构
 做了一个演进
 那么今年呢
 我们医疗大模型
 底层的安全能力
 又做了进一步的升级
 众所周知
 我们现在很多医院
 或者很多机构的
 这个使用场景下
 其实不太需要
 千亿级别的大模型
 它其实不太需要
 这个大模型
 也能讲笑话或什么
 反而是能够支撑好
 我们医疗场景里面的
 这个很多的能力
 所以我们今年也升级了
 我们整个医疗
 底层的解决方案
 我们提供了
 蚂蚁的可信一体肌的方案
 同时我们在很多
 高并发的场景下
 我们还提供了
 可信云的医疗解决方案
 那么随着这一系列的升级
 今年我们跟我们的
 合作伙伴共同推出了
 很多的医疗里面的
 应用的最佳实践
 包括我们说的
 我们推出了
 全国首个城市级别的
 健康数字人安整儿
 这个是我们和
 浙江省卫健委一起
 在去年年底的时候
 就推出了这样的
 一套能力
 同时我们也推出了
 全国首个医保数字智能体
 杭州医保小智
 另外我们今年上海
 师医的合作伙伴
 也到了现场
 我们跟上海师医
 推出了上海
 首个AI数字配等师
 同时我们在
 去年很早的时候
 我们就已经研发
 首个深层市的电子病例
 通过深层市的电子病例
 我们其实极大的降低了
 我们在很多科室里面
 医生书写电子病例的时间
 接下来我简单给大家介绍一下
 我们这次重磅发布的
 多模态医疗大模型
 我们也是全国首批发布
 多模态能力
 在医疗行业的应用
 那么我们整个
 多模态的医疗大模型
 都是全站自研
 并且我们的整个参数
 能够支持到千亿级别的
 医疗视觉语言的这种能力
 同时我们也通过
 模态扩展的方式
 通过从桥接架构
 到原生架构的眼镜
 我们能够支持很多
 在GBT4O这种原生语言
 视觉等多种输入模式的
 这种联合架构
 那么在这种方式下
 我们结合了
 跟我们合作伙伴一起推动的
 包括百亿级别的
 中英文的
 包括图文的这种训练语料
 包括我们也融入了
 千亿级别的医疗的
 专业的这种文本的信息
 最后我们还构造了
 千万级别高质量的
 医疗知识图谱
 那么通过这样的方式
 我们共同打磨了
 百灵多模态医疗大模型
 我简单给大家介绍一下
 我们首批就是
 在这样多模态能力之下
 我们首批实现了
 四种交互的能力
 包括毛发的
 包括体检报告
 包括
 药物的翻译
 包括识别药盒等等
 这也是跟我们的
 很多合作伙伴
 一起来建立的
 在我们很多的
 这个多模态的场景里面
 我们基本上的
 这个识别的准确率
 都是超过90%以上
 目前在行业里面
 大家能够应用到
 通用的这种
 多模态的能力
 是很难达到
 这样的一个水平的
 我简单给大家演示一下
 在这种多模态
 和原生桥接下
 未来可以实现的
 这种交互模式
 这是一个在
 体检报告相关的
 一个场景
 请您看看
 有什么问题吗
 好的
 我来看一下检查报告
 将相机拉近一点
 我好看清晰
 好的
 你看清晰
 大家知道我们以前的
 阅读这个体检报告的时候
 需要拍很多照片
 但是在这种
 视频的这种交互情况下
 其实你只要把
 报告单给它看
 可能是一张
 两张
 三张
 四张
 五张都可以
 那通过这种
 语音加视频的
 这种交互模式
 其实能够大大降低
 在这种
 场景里面
 这个交互门槛
 同时呢
 我们其实也在
 在刚刚过去六月份
 我们也在头皮
 毛发相关的
 也做了一些工作
 所以我们把这样的能力
 也集成到我们这种
 新的大模型能力里面来
 我简单给大家演示一下
 我是您的健康管家
 有任何问题尽管问我吧
 我有点担心
 最近掉头发有点多
 让我仔细看看你的头发
 请正对着我
 对就是这样
 我们在正常的交互模式
 里面我们可能得
 正着拍一张
 侧着拍一张
 可能甚至在其他地方
 拍好几张照片
 但是在视频的这种情况下
 你其实只要跟他
 就像在打一个视频电话一样
 那么他看了你的
 这个各种情况之后呢
 结合你语音给他输入的信息
 最近你有点掉头发
 包括我们刚看了他头
 中间可能有些拖把
 那么通过这种方式呢
 我们就可以很轻松的
 去完成这样的一个检测
 那么在这种多模态
 加上原生多模态
 这种情况下
 未来我们整个医疗的交互
 体验可以会变得越来越好
 当然今天我们才只实现了
 四个场景的这种
 一个小的一个demo
 但是未来我们也希望
 跟我们的合作伙伴
 一起能够在更多的场景
 去推广这样的一个体验
 说了原生多模态
 的一些体验之后
 我简单给大家讲一下
 我们医疗可信一体机
 和这个云的解决方案
 众所周知我们很多机构
 其实在部署医疗的
 这个AI的方案的时候
 都是非常非常担心的
 其中最大的两个点
 就是第一个
 就是它需要隐私安全
 因为医疗里面
 中间大量的数据
 都是跟个人相关的
 另外一点就是
 很重要的就是机构
 其实很难支撑
 特别大的这个计算量
 可能往往只有几张卡
 那么这个时候
 你自己要去采买芯片
 实际上是非常非常难的
 所以我们跟我们整个
 百灵包括隐私的
 这个密算云的一体方案之后
 我们打磨了一个
 在医疗情况下
 医疗场景下的
 医疗可信一体机
 那么通过这个
 百灵医疗可信一体机
 我们能够非常快速地
 加速我们在机构的
 这个解决方案的交付
 首先我们整个这个一体机
 是支持整个国产化的
 训推一体的
 是能够支持训练
 也能够支持推理
 那么我们通过
 这个医疗一体机的方案
 我们在很多的这个场景里面
 可以加速90%以上的这个速度
 只要原来的10%的时间
 我们就可以把我们的
 解决方案交付
 所以这个能大大加速
 我们在很多机构里面
 这个推广
 另外一块呢
 它是整个都是基于
 密态计算的
 所以你可以非常大胆
 放心地去
 把你的这个隐私数据
 交给我们这个密态一体机
 包括它是防撬的
 所以你机器部署在那
 你也不用担心
 别人会来攻击你的这个服务
 最后呢
 我们其实还通过
 这个一体机的方案
 我们还把百灵的这个模型
 从最小的一臂的
 一直到最大的
 可能接近千亿的这个模型
 都可以通过这个方式
 来做交付
 那么我们今天也
 给大家简单演示一下
 我们在特别小的
 这种轻量化场景里面
 比如说我们写这个定力
 那么我们通过剪裁
 我们可以把整个模型
 缩小只有一臂
 那么这个模型呢
 可能甚至能跑在
 这种消费级的显卡上面
 那么它的速度呢
 也是比我们整个
 目前行业里面
 开源的那种小模型
 要快很多
 我简单给大家看一下
 右边呢
 是我们在后台里面
 输入了一个这个
 电子并列的这个prompt
 这个prompt还是比较长的
 那么左半边呢
 是我们百灵的
 这个一个解决方案
 大家可以看得见
 我们百灵的整个解决方案
 比目前整个
 在开源方案
 大概能快1.5倍到2倍
 那么它很快就把
 这样的一个电子并列
 给生成了
 那么这样子
 能跑在消费级显卡上
 再加上一体系的方案
 我们可以非常快速的
 去支持我们在
 机构侧的应用落地
 最后呢
 其实今天百灵
 整个百灵大模型
 包括我们动物派大模型的
 这个场景的开放
 非常非常依赖
 我们跟很多
 生态的合作伙伴
 跟我们的机构
 和我们政府
 包括我们今天
 很多大量的
 这个专业机构的参与
 我们在今年呢
 也跟我们很多
 生态的合作伙伴
 建立了非常好的连接
 未来我们这些
 多模态能力
 我们这些场景能力
 一体系的能力
 都希望跟我们的
 合作伙伴
 能够一起推到
 更多的这个医疗的
 这个场景里面
 所以接下来
 我们会继续坚持
 AI能力的开放
 携手我们整个产业伙伴
 共建整个医疗行业
 那么我们接下来
 就邀请我们
 今天我们很多的
 这个产业的伙伴
 都来到现场
 接下来我们邀请大家
 一起来共同开启
 医疗AI的生态共建计划
 接下来进入到
 今天最激动人心的环节
 致富宝多模态
 医疗大模型发布
 即合作伙伴
 AI共建计划启动仪式
 让我们有请
 启动嘉宾上台
 他们是
 宁布市尹州区
 卫健局党委委员
 副局长朱宇
 厦门卫健信息处
 陈彬彬
 北京大学医学部
 医学技术研究院院长
 教授韩红冰
 复旦中山大数据中心主任
 钱坤
 蚂蚁集团
 平台技术事业群总裁
 曹凯
 北京人为智术科技总经理
 贾晓薇
 北大人民医院主任医师
 教授张涛
 上海人气医院
 分院门办主任
 池晨斐
 复旦附属肿瘤医院
 大数据中心主任
 王毅
 上海市医院信息科主任
 傅春瑜
 深大总医院
 信息技术部主任
 张啸
 浙江省人民医院
 信息科副主任
 李祥杰
 让我们有请各位嘉宾
 共同来到舞台上方
 让我们见证此刻
 请各位嘉宾将您的手
 放在屏幕或启动柱上的
 手掌印之上
 请我们各位嘉宾
 可以将您的手
 放置在我们大屏幕的
 手掌印之上
 让我们在倒计时结束之后
 来共同地进行启动
 朋友们
 让我们一起倒数
 三
 二
 一
 支付宝多模态
 医疗大模型发布
 即合作伙伴
 AI共建计划
 正式启动
 请各位领导嘉宾
 来到我们的舞台前方
 共同合影留念
 请后一排嘉宾
 向前一步
 请入座
 谢谢
 好 谢谢
 相信今天的启动
 将会为我们未来
 共同的产业升级发展
 提供更多的可能性
 谢谢
 再一次感谢各位领导嘉宾
 请入座
 谢谢
 感谢各位领导嘉宾
 感谢今天上午
 所有演讲嘉宾的精彩分享
 女士们 先生们
 本次论坛到此结束
 谢谢
谢谢
 先来讲一下
 让我们先紧接上进
 海外国家との会见
 本日节目的活动
 是中美国国家习校
 在平台宣传中
 在附近的文明
 美国国家剧 second wing
 我是少数人
 在美元球职
 在最上级和中文公民 stands
 但是但因为
 在美国留在来自明国
 大规模的hr� bullshit
 一句王员就看出
 在画面和主题
 在墨西华的文法
 在视光中
 在小学生
 在世界 Jong Mall
 在海外宣传 Kin Firstly
 在秘密联合观了
 在海外检查临
 Teksting av Nicolai Winther