请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
明镜需要您的支持 欢迎订阅明镜
明镜需要您的支持 欢迎订阅明镜
明镜需要您的支持 欢迎订阅明镜
尊敬的各位领导 各位专家学者 女士们 先生们 大家上午好
盛夏七月黄浦江畔 加克云集
由同济大学上海市杨浦区人民政府联合举办的
2024世界人工智能大会智能社会论坛隆重举行
本次论坛以智能社会与全球治理框架
为主题 旨在促进人工智能向善发展
造福智能社会 人类美好生活
接下来请允许我介绍出席今天论坛的各位领导和嘉宾
他们是同济大学党委书记方守恩
杨浦区委副书记区长周海英
上海市委网信办副主任杨新
上海市教育委员会副主任王浩
同济大学常务副校长吕培宁
杨浦区委常委常务副区长倪斌
杨浦区副区长刘静元
同济大学党委常委宣传部部长端木怡文
出席今天论坛的还有十余位人工智能领域的国内外知名的专家学者
同济大学杨浦区相关部门负责人及企业嘉宾等
让我们用热烈的掌声对各位领导和嘉宾的到来
表示热烈的欢迎和衷心的感谢
接下来我们进入论坛的开幕致辞环节
首先让我们掌声有请上海市委网信办副主任杨新致辞
杨新致辞
尊敬的方书记周区长各位嘉宾
大家上午好
很高兴参加由同济大学和上海市杨浦区人民政府
共同主办的2024世界人工智能大会智能社会论坛
我仅代表世卫网信办向论坛的举办人们
表示热烈的祝贺
向出席论坛的各位嘉宾表示诚挚的欢迎
向长期支持上海智能社会治理工作的各位同仁
表示衷心的感谢
中国高度重视人工智能发展和全球治理
去年10月习近平主席在第三届一带一路国际合作高峰论坛
开幕式主旨演讲中提出了
全球人工智能治理倡议
主张坚持以人为本
智能向善
支持形成具有广泛共识的全球人工智能治理框架和标准规范
今年5月习近平主席在法国进行国事访问期间
中法两国发表了关于人工智能与全球治理的联合声明
在昨天的开幕式上
李强总理指出
人工智能发展迫切需要各国深入探讨
凝聚共识
共抓机遇
共克挑战
中国愿与各国一道推动人工智能
更好服务全球发展
增进人类福祉
共同走向更加美好的智能未来
人工智能全球治理上海宣言也强调
只有在全球范围内的合作与努力下
我们才能充分发挥人工智能的潜力
为人类带来更大的福祉
人工智能问题正超越单纯的科学技术
成为国际社会的重要一程
也是中国
积极参与完善全球治理体系改革和建设的重要领域
由同济大学和杨浦区共同举办的智能社会论坛
今年已是第三届
今年的主题是智能社会与全球治理框架
相信通过政府高校的久久为公
持续合作发力
将为我国智能社会建设和参与人工智能全球治理
贡献更多理论与实践相容的路线图
杨浦区是国家创新型城区
人民城市重要理念的首提地
也是全国唯一由政校联合申报的
国家智能社会治理实验综合基地
自2021年基地获批以来
杨浦区联合同济大学通过聚合多主体参与
整合多学科力量
共同致力于智能社会治理的探索与实践
取得了丰富的研究与实践成果
在国家网信办等八部门口中
联合组织的基地中期评估中
杨浦区入选工作进展明显成效突出的综合基地名单
在全国基地中名列前茅
期待杨浦基地能继续紧跟前沿方向
丰富场景建设
在超前探索智能社会治理的实践道路和运行模式上
取得更大进步
那么借此机会
就国家智能社会治理实验基地建设
谈几点想法与大家讨论
一是加快推出服务治国理政的实验成果
强化研究主体力量
围绕大模型等人工智能前沿技术应用
挖掘典型场景提炼经验成果
总结共性问题
研究社会影响探索标准法规提出政策举措
二是加快落地人工智能前沿技术应用
充分调动实验基地技术主体
应用主体的积极性
强化政效
及联动结合地方实际
在城市管理教育养老
卫生健康体育等特色领域
开展人工智能前沿技术的应用
形成一批特色应用场景
三是强化成果交流和国际合作
加强智能社会建设宣传
营造良好社会氛围
鼓励民众参与治理实践
积极推动国际合作
推动建立多边协同共治的机制
把伦理准则
行业规则
技术标准和治理技术等
纳入国际治理框架
向国际社会传播好中国方案
那么最后
我预祝论坛取得圆满成功
谢谢
谢谢
请入座
再一次感谢杨新副主任的精彩致辞
接下来让我们有请
上海市教育委员会副主任
王浩致辞
有请
好 尊敬的方书记 周区长
各位嘉宾 大家上午好
能工智能必然融入社会
赋能千行百业
能工智能也是我们上海
着力发展的三大先导产业之一
目前全社会正在重算力
数据等方面
重新发展
促进人工智能
科技研发和产业发展
刚刚闭幕的全国科技大会
国家科学技术奖励大会
两院院士大会上
习近平总书记指出
加派新一代信息技术
人工智能 量子科技
生物科技 新能源 新材料
等领域的科技创新
教育也积极融入
人工智能应用的时代潮流
怀静平部长
强调教育要主动拥抱智能时代
把人工智能技术
深入到教育教学和管理的
全过程各环节
作为一种具有社会属性的技术
在给经济社会发展
带来巨大红利的同时
人工智能也承载着
诸多风险挑战
人工智能自理成为世界各国
共同面临的重大课题
继续通过对话合作凝聚共识
推动人工智能朝着
科技向上的方向合规发展
去年10月
中国国家主席习近平宣布
全球人工智能自理倡议
围牢人工智能发展安全
治理三方面系统阐述
人工智能治理的中国方案
得到国际社会的高度评价
早在2021年
上海市教委就委托同济大学
成立了上海人工智能社会治理协同协议
成立了上海人工智能社会治理协同协议
创新中心
经过近三年的建设
协同中心立足于国家战略需求
积极惩罚上海事件
充分协同创新
开展了人工智能相关的法律
伦理和社会治理问题研究和社会服务
为国家和我市
为国家和我市
人工智能可信向善发展
贡献智慧
中心作为同济大学校内
人工智能
人工智能
新平台
参与了国家智能社会治理综合实验基地的申报和建设
在区校协同方面
进行了更为紧密的探索
成绩斐然
在论坛稍后的发布环节
我们会看到相关的技术系统
系列从书和研究报告的重磅发布
这些努力
为人工智能上海高地
尤其是
规则供给高地的建设
贡献了力量
在大模型研发和应用加速推进的背景下
如何有效开展智能社会治理
以善治促进善治
这里提供三点建议
供大家一起来探讨
第一
妥善平衡
治理和发展
全面深入讨论
人工智能发展安全和治理问题
首先
科学认识人工智能的风险特点
探索更科学的风险管理体系
其次
更新治理理念
落实敏捷治理
开展成效评价
与社会实验活动
为推动人工智能的产业发展
及其社会应用
贡献智慧
第二
深入应用场景
探索治理规则
首先
要关心人民的真实需求
深入具体的应用场景
我们拥有全世界最为丰富的应用场景
为提炼治理路径和经验
提供了可能
其次
人工智能技术治理需要国际规则
搭建开放包容
平等参与的国际学术交流合作平台
积极参与人工智能全球治理进程
第三
百年大计
教育为本
人工智能科技和智力人才的培养
是支撑人工智能发展的根本力量
首先
人工智能的教育需要从孩子抓起
2024年2月20日
教育部办公厅的正式公布了全国首批中小学人工智能教育基地名单
上海的也有六所学校入围其中
在整个全市中小学
人工智能教育的推进过程当中
我们也在做一些整体布局
下阶段
我们会根据现在面上一批四点校
探索研究的基础上
会尽快的普及中小学人工智能的课程教学
其次
发挥高校的学科优势和育能功能
在政府高校和企业更大范围协同创新
联合培养卓越的人工智能教育
人工智能人才
各位嘉宾
人工智能社会治理议题宏大
影响深远
我们大家共同责任在间
让我们一起努力
为推进智能社会治理事业的发展
贡献更大的力量
最后感谢本次论坛为我们提供了宝贵的交流机会
祝各位嘉宾在乎工作愉快身体健康
祝大会圆满成功
谢谢大家
谢谢 请入座
再次感谢王浩副主任的精彩致辞
下面让我们掌声有请
同济大学党委书记方守恩致辞
有请
尊敬的海营区长
王浩主任
杨新主任
各位领导
各位参加
女士们 先生们
大家上午好
今天同济大学与杨浦区人民政府联合主办的
2024年世界人工智能大会
智能社会与全球治理框架论坛
在此举行
我仅代表同济大学
对各位的到来
表示最热烈的欢迎
也借此机会
对各位长期以来
给予同济大学的支持
关心 帮助
表示最衷心的感谢
当前人工智能技术的快速发展
对全球经济社会发展和人类文明进步
产生深远的影响
同时也将带来难以预见的各种风险
和治理的挑战
去年10月18日
习近平主席在
第三届一带一路国际合作高峰论坛开幕时
主旨演讲中
提出了全球人工智能治理倡议
就各方普遍关切的人工智能发展和治理问题
提出了建设性的解决思路
贡献了中国智慧和中国方案
今年3月21日
联合国大会通过了首个
关于人工智能的全球决议的题目是
抓住安全 可靠和值得信赖的人工智能系统
带来的机遇促进可持续发展
这项决议汇聚全球的智慧
为人工智能的治理
确立了全球的共识
具有里程碑的意义
在过去的两年里
同济大学与杨浦区人民政府
连续两年举办世界人工智能大会
智能社会论坛
邀请了众多国内外专家
报告人工智能治理前沿
发布了一系列重要的研究成果
受到了联合国教科文组织的关注
并取得了广泛的社会影响
学校与杨浦区
共同打造的
国家智能社会治理实验综合基地
是上海唯一入选
中央网信办等八部门公布的
十家国家智能社会治理实验基地名单的
综合实验基地
也是全国唯一的
政校企联合建设的实验基地
经过近三年的建设
实验基地建设成效
在中期考核中
名列前茅
打造了上海市
智能社会治理的示范和样板
为人工智能辅能国家治理体系
和智能现代化建设
提供了生动的场景
近年来
学校将人工智能辅能战略
作为学校高质量发展的重要战略举措
一系列国内外
一流人工智能重大平台
接连落后了
同济大学
我们依托同济大学建设的
上海自主智能无人系统科学中心
是国家人工智能上海方案的重要内容
在此基础上
学校实现了首批标杆
自主智能无人系统全国重点实验室
自主智能无人系统前沿科学中心
自主智能系统基础科学中心
人工智能国家产教融合平台等一批
国家级的研究和产教研的平台
可以说我们基本上
把全国的各个领域的各个部门
相关的平台拿全了
这个是推进了这些平台的建立
推进了学校人工智能
赋能教育科研的一个建设
在加强人工智能基础研究
和前沿科学攻坚的同时
学校也加强了人工智能赋能
城市建设和社会治理的应用研究
有同济大学牵头建设的
中国上海数字城市研究院
上海新城建设研究中心
上海指数研究院等
将目光聚焦在超大型城市
在数字化转型中的理论问题和技术问题
为城市数字化夯实数字底座
标准规范
助力上海打造国际数字之都
依托同济大学建设的上海市
人工智能社会治理协同状况中心
也紧密围绕人工智能国家重大战略需求
和上海市重点产业的布局
来开展人工智能相关法律伦理
和社会问题的研究
打造人工智能治理的上海模式
今年5月为加快和加强
人工智能辅能力度和步伐
学校进一步发布了全面实施
人工智能辅能学科创新发展的行动计划
全面的推进智能技术辅能教育教学
科学研究工程技术管理服务等创新的实践
今年我们学校9月份即将入学的所有的新生
将全部接受人工智能必修课程的学习
在学校未毕业的学生
也将在他们毕业之前
根据需要提供相应的选修课
来补人工智能的课程
学校将全面加快构建人工智能家
未来教育教学的一个新形态
未来同济大学也将继续发挥
在人工智能社会治理领域的
先发研究优势和平台的优势
加强于上海市杨浦区政府
以及其他相关产学员资源的协同
立足上海服务全国面向世界
聚焦智能社会高质量发展
与人工智能全球治理框架的建设
打造具有全球影响力的
智能社会的协同治理智库
智力在研究和构建
智能社会治理理论 方案和技术的体系
夯实人工智能应用的标准 规范
形成创新性的政策和制度建议
建设智能社会治理人才高低等方面
发挥积极的作用
希望通过本次来临的
论坛 各位专家和学者
能够分享真知灼见
碰撞思想火花
共同探讨人工智能技术的
应用与治理之道
为构建更加美好和谐的
智能社会建议现策
进一步深化人工智能治理的
国际合作与交流
为推动人工智能全球治理框架
贡献我们的智慧和力量
最后
预祝我们本次论坛圆满成功
祝各位身体健康 学术长青
谢谢大家
谢谢 请入座
再次感谢方书记的精彩致辞
也让我们了解到了
同济大学在人工智能领域的
成就和成果
接下来让我们掌声有请
杨浦区委副书记
区长周海英致辞
有请
尊敬的首文书记杨鑫主任
王浩主任 裴明校长 宜文部长
尊敬的耀初院士 志强院士
苏军院长 各位领导
各位专家 朋友们
大家上午好
很高兴与大家相聚在
2024世界人工智能大会
智能社会论坛
共划人工智能发展
共商智能社会治理
首先
我代表中共杨浦区委
杨浦区人民政府
向出席今天论坛的
各位领导和嘉宾
表示热烈的欢迎
向一直以来
关心和支持杨浦发展的
各界朋友们
表示衷心的感谢
当前
人工智能已经成为
新一轮科技革命
和产业变革的重要驱动力量
请大家多多关注
请大家多多关注
新一代人工智能的
发展机遇
加快打造世界级产业集群
是以习近平统治为
核心的党中央
交给上海的重大战略任务
杨浦主动服务全国
杨浦主动服务全国
上海发展大局
充分发挥区内
科教资源优势
创新氛围活跃的
特色优势
统筹发展与安全
积极推动人工智能发展
统筹发展与安全积极推动人工智能发展
行稳致远
一方面
我们加快构建
以数字经济为核心的
创新型现代化产业体系
重点布局
人工智能等新兴赛道
大力营造充满生机活力的产业生态
目前区内集聚了
抖音 美团 B站 千寻位置
复旦微电子 新思科技等代表企业
以及上海数学与交叉学科研究院
中国上海数字城市研究院
等功能性平台
洋普人工智能产业
正驶向蓬勃发展的快车道
另一方面
我们积极应对
人工智能对城市管理
社会治理带来的潜在挑战
与同济大学合作
共同打造全市唯一的
国家智能社会治理实验
综合基地
朝前探索面向未来的
智能社会治理体系
推出了一批基层治理典型案例
城区智能场景建设
及数字化转型取得新发展新突破
面向未来
洋普将着力打造
人工智能产业新高地
坚持大学校区 科技园区
公共社区三区联动的核心理念
聚焦全球的智能社会
最大模型 芯片设计
智能算力 巨声智能等前沿领域
不断优化政策服务
开放更多应用场景
促进产业需求与基础研究的精准对接
让更多科研之华结出产业之果
洋普将用心开拓智能社会治理实验田
秉持科技向上理念
与同济大学进一步深化合作
在合规服务上
数据交易 人才培养
社会服务 基层治理等方面
开展更多社会实验和探索事件
努力为上海乃至全国
提供更多智能社会治理新样板 新经验
各位领导 各位专家 各位朋友
在大家的共同努力下
我们已成功举办两届智能社会论坛
更多国内外专家在此分享真知灼见
开展跨界对话
贡献了一场场思想盛宴
期待大家围绕智能社会与全球治理框架的主题
在浦江之畔再次实现思想的碰撞
迸发智慧的火花
最后预祝本次论坛取得圆满成功
祝愿大家身体健康 工作顺利
谢谢大家
谢谢
请入座
谢谢
再次感谢周学长的精彩致辞
也希望能够让各位了解
杨浦在人工智能领域所做的努力
以及未来的发展前景
尊敬的各位领导 各位嘉宾
本次论坛的开幕致辞环节就到这里
接下来让我们有请
同济大学法学院副院长
上海市人工智能社会治理协同创新中心秘书长
徐刚主持专题发布
有请
各位来宾好
下面进行专题发布
首先发布
统计大学自主研发的数字沉底座
IS-3基础设施智慧服务系统
有请统计大学特聘教授
土木信息技术教育部工程研究中心主任
李小军上台介绍成果
有请
好 尊敬的各位领导 各位嘉宾
我今天给大家发布的是
我们IS-3基础设施数字底座
这个
诶 这个视频
诶 这个视频
这个数字底座呢
是我们统计大学
诶 诶 朱厚华院士团队
经过
有没有
PPT是
是我放还是
这个放
这个数字底座是统计大学
我们这个二十余年的工程
数字化实践的这个
积累研发的这个
一个自主的一个数字底座
那么这个数字底座的目的呢
是为了能够支撑传统的物理的基础设施
能够快速的改造成为数字的基础设施
在这个数字基础设施之上
我们可以构建各类插拔式的应用
来支撑数字治理
数字经济和数字生活的各类的应用
那么这个数字底座的主要的特点呢
是它基于的是我们采集处理
呃表达分析的设施的设施
决策的信息流的第一的原理
具有通用性专业性和生态性的
三大创新的这个特色
那么这个数字层的这个底座呢
是我们同济大学联手
我们上海数字城市研究院
那么它主要的这个特点呢
就是说我们这个数字的这个底座呢
能够把我们的基础设施
变成了数字的一个版本之后呢
能够在上面服务于我们高校的这种
城市的数字的治理
城市的数字的治理
城市的数字的经济
以及城市的数字的生活
那么接下来呢
举几个典型的案例
第一个案例呢
就是说上海的这个地铁的这个建设的风险管控
那么基于这个数字底座呢
可以把它快速的搬到网上
能够进行这个风险的
即时的这个管控和智能的数据的挖掘和分析
还有呢基于这样的一个数字底座呢
可以实现我们整个城市的地下空间的
精细化的评价
帮助我们来发现城市的风险管控
是哪里有风险
哪里建设的时候风险比较高
要进行及时的这个规避
为我们规划提供决策的支撑
那么这个数字底座呢
第三个案例呢
就是可以帮助我们城市的这个风险管控
比如说我们的城市的这个
这个韧性
这个地震来了
这个韧性呢
在哪里还有一些缺陷
可以帮助我们来做城市的
这个灾害的这个模拟和韧性的评价
那么同样的
这个数字底座呢
也可以帮助我们来做这种
高速公路的这个主动的这种
孪生的管控
还有呢
能够在我们的生活方面呢
比如说我们的公园
它的舒适性
它的油气的这个指数
可以随时的来告诉我们
那么我们最近呢
也在用这个数字底座呢
来打造一个我们同级的这个数字的校园
这个校园呢
是构建了一个三维的一个实景的
一个场景
然后联合了我们学校的土木建筑
测绘 交通 电信各个专业
来打造学在同级 吃在同级
数字防灾以及绿色同级
这样的一个应用
那么这个应用呢
能够为我们学校的这个精细化的治理呢
提供技术支撑
为我们高质量的人才培养呢
提供一个创新的一个载体
那我的介绍就到这里
谢谢大家
好 谢谢李教授
谢谢李教授的介绍
下面发布的是
爱生者和同济大学联合编制的
负责任人工智能风险管理指南
有请爱生者大中华区法务及政府事务总裁高文胜
和同济大学上海市人工智能社会治理协同创新中心研究员朱悦
一同上台介绍成果
有请
促进人工智能向善发展
接下来发布
爱生者与同济大学联合编制的负责任人工智能风险管理指南
感谢大家
非常荣幸今天可以一起发布指南
正如昨天发布的
凝聚全球共识的人工智能全球治理上海宣言所说
企业研究机构社会主体个人
要根据自身的角色去发挥各自的定位和作用
要加强人工智能的监管和问责机制的建设
要促进人工智能的合规使用和责任承担
那也就是说
今天来发布负责任的人工智能风险指南
是在最合适的时间最合适的地点
我想也是前瞻到了一个最合适的题目
那接下来我也将时间和舞台交给高总
感谢
有您来详细展开
谢谢朱老师
各位好
很高兴今天有机会在这边跟大家进行一个分享
那么
我们知道这个
从这个
什么是负责任人工智能
我们要先从这个话题再讲起
那么
艾森哲认为我们负责任的人工智能
它不仅仅是一个技术的应用
那么它也是一种涵盖了应用设计模型适配跟使用
部署跟维护的端到端的这么一个实践
那么负责任的人工智能
绝不是一个单一的技术问题
或者是道德伦理问题
更不是单一的企业的法务的合规问题
而是一个系统性的涉及到企业每个人
未来如何看待和应用人工智能的问题
用好了它可以帮助企业合规
促进对于技术的信任
带来业务的创新
但是用不好的话
则有可能给企业
给个人都带来伤害
那本质是促进人跟机器之间的协作和信任
那么了解了这个
什么是负责任的人工智能以后呢
接下来我们就需要非常精准的去理解
人工智能风险的分类和分级
并有针对性的对其进行管理
那么这两个内容
也是我们这一份指南的重要的组成部分
那么艾森哲的全球的最新的调研显示
97%的受访的高管
认为自身的企业将受到AI相关监管法规的
影响
77%这些高管是将AI的监管
列为这个优先的事项
另外还有80%的受访者认为
他们将投入10%或者更多的AI的总预算
以满足未来的监管的要求
那么在指南中呢
我们就将这个人工智能风险的影响
分为了三个层面
包括对人的影响
对组织的影响
以及对生态的影响
那么为了更好的去管理这些风险呢
我们会建议企业
就像这个PPT显示的
用四个维度去负责任地
进行人工智能风险的管理
首先企业应该确保
本身要合法合规
遵循相关的这些法律的规定
其次呢
企业也应该明确负责任的
这个人工智能的这个原则
并且将其嵌入到
人工智能系统和开发流程中
第三
企业应推动领导层
将负责任的人工智能
提升为其关键的业务的要求
并且为所有的员工提供这个培训
那么最后
企业应该建立透明的
健全的
可持续的人工智能的文化
确保每一位员工都能够理解
并实践
负责任的人工智能的原则
那从这四个维度入手的话呢
我们认为企业就可以更加全面的
识别与管理人工智能的风险
使人工智能的技术应用
更加的负责任
那么在具体的实践中呢
我们是根据企业应用人工智能的成熟度
将这个企业化成了三类
大家可以看到
从这个AI的领军探索者
还有一类是这个AI的创新技术
以及另外一类是AI的实践的起步者
那么在指南中间
我们对于每一类的企业
都提出了相应的建议和行动方案
那么比如说AI的领军探索者
他应该全面的
遵守当地的法律法规
积极的参与推动AI的合规标准的制定
并建立完善的AI的治理的体制
而AI的实践起步者
那从另外一方面
则应该初步的制定负责任的AI的企业的原则
并且进行相应的风险评估
女士们 先生们
人工智能的发展离不开我们的共同的努力
负责任的AI不仅是企业的责任
政府也需要加强监管和创新的支持
那么学界的话
应该是生化 化学科的研究和人才的培养
社会组织要激发公众的参与和监督
专业服务机构则应该提供专业的咨询和技术支持
通过这种多方协同治理
才能够有效的应对AI带来的挑战
实现科技向上的未来
那么最后也是感谢各位的聆听和支持
让我们携手并肩
共同迎接人工智能的时代的到来
推动科技向上的未来
祝福人类社会
谢谢大家
好 也感谢两位的介绍
那么下面发布
统计大学开发建设的
全球人工智能治理数据库
有请上海市教委副主任王浩
统计大学党委常委常务副校长吕培明
一起上台共同启用数据库
有请两位
请两位领导把手放在屏幕上
启动
也祝福数据库的正式的上线启用
请入座
谢谢
接下来要发布的是
统计大学上海市杨浦区
国家智能社会治理实验综合基地等单位
策划出版的
关于人工智能伦理法律
和智能社会治理领域的系列重书
有12本
我们一次性发布
有请统计大学党委常委常务副校长吕培明
杨浦区委常委常务副校长吕培明
杨浦区委常委常务副区长倪斌
一起上台为新书揭幕发布
一起上台为新书揭幕发布
有请
请两位领导为新书揭幕
请两位领导为新书揭幕
请两位领导为新书揭幕
我们也祝福这些新书的出版
请入座
请入座
请入座
请入座
请入座
请入座
最后发布上海市杨浦区十大锤类大模型应用场景需求榜单
请看大屏幕介绍
2024年人工智能发展迈向强应用阶段
发力点逐渐由通用大模型转向行业大模型
杨浦区积极抢抓新一代人工智能发展机遇
以人工智能驱动形成新制生产力
全力打响杨树浦品牌
为推动人工智能大模型赋能千行百业
日日催生未来产业新模式新业态
杨浦区先发布垂直行业大模型应用场景需求榜单
向全社会接榜挂帅
面向海量影音内容的精准分析和高质量生成需求
争取文化娱乐场景大模型落地方案
面向传统制造行业的智能化升级专行需求
争取智能制造场景大模型落地方案
面向教育行业的智能化教学和个性化学习需求
争取智能教育场景大模型落地方案
面向医疗服务行业的智能化升级转型需求
争取智慧医疗场景大模型落地方案
面向生活服务领域的大模型精准营销需求
面向生活服务领域的大模型精准营销需求
争取生活服务场景大模型与建筑设计与审图效率低
建筑管理成本高等问题
争取建筑设计场景大模型落地方案
针对法律信息获取难、案件分析耗时长等问题
争取法律服务场景大模型落地方案
面向金融领域的交互服务与风控需求
争取金融风控场景大模型落地方案
面向跨界市场的大模型落地方案
面向经济贸易中海量通关文件种类多、时效高等需求
争取智慧物流场景大模型落地方案
为解决时空智能分析精确性与适应性等难点
争取智慧交通场景大模型落地方案
促进人工智能和实体经济深度融合
为高质量发展注入强劲动力
未来无限 等您接棒
从这个介绍当中我们注意到
这十大应用场景涉及的领域非常广泛
这也是得益于杨浦区有着丰富的科教资源
良好的创新生态
以及多元的数字经济和城市数字化转型的实践
下面有请上海市委网信办副主任杨新
杨浦区副区长刘静元
统计大学党委常委宣传部部长端木怡文
一起上台正式发布需求榜单
有请各位
请各位领导把手放在灯光柱上
启动
感谢各位领导请入座
我们也欢迎大家能够持续地关注统计大学和杨浦区
在智能社会建设领域当中的很多的努力和活动
那么专题发布的环节到此结束
下面有请统计大学法学院院长
上海市人工智能社会治理协同创新中心主任
蒋惠领教授主持主子演讲环节
有请
尊敬的方书记周区长
各位领导
各位嘉宾
女士们先生们朋友们
大家上午好
今天上午的智能社会论坛
我们是邀请到了六位重量级的嘉宾
为了节约时间
我在这就不显一一的介绍
各位嘉宾的简历情况
在会议中
以及手册里面都有
大家可以查阅
而且因为为了节省时间
我在中间就不做过渡性的评论
那么最后有时间的话
我再做两句点评
如果没有时间
我们就后面就转到后面的圆桌对话
纪伟东老师主持的环节
因为今天时间上午非常的紧张
我们的这个主旨发言阶段
主旨演讲阶段是90分钟
我们有六位嘉宾
这样每位嘉宾
平均时间是15分钟
时间差不多的时候
我们会有那边的工作人员
会有请提示
大概剩三分钟剩一分钟
好
下面我们就有请今天发言的第一位嘉宾
他是欧洲科学院院士
国际电气与电子工程师学会会士
西湖大学人工智能讲习教授
金耀初教授
有请金教授
好
那么各位
尊敬的各位领导
各位专家
各位与会者
我叫金耀初
是西湖大学人工智能的讲习教授
那么很高兴有这个机会来参加这个会议
那我是从这个
就去年11分才加入西湖大学的
那么之前是在德国比勒菲特大学
做这个红宝人工智能这个讲习教授
我们从2017年开始呢
就从事一些有关隐私保护和安全的这个方面的研究
那么后来呢
也很偶然
去年的4月份
在比勒菲特大学的时候呢
就代表这个德国的这个中小型企业
在柏林参与了一次这个
这个AI Act这个在
就在讨论过程当中的一个研讨会
所以呢就是我今天呢
给大家呢来分享一下我的一些有关
人工智能方面的一些这个见解
个人的一些看法
但是呢首先我不是人工智能智力的专家
所以讲的有什么不对的地方呢
请多批评指正
那么这个是我大概今天的这个汇报的这个内容啊
就先稍微简单地讲一下人工智能历史
然后呢我们再探讨一下
人工智能到底哪些风险
和目前已有的一些技术上的一些
对付的方法是吧
然后呢再简单讲一下呢
就我们目前世界上主要的一些国家
特别是欧美中三国家
对人工智能治理方面的一些
目前已有的法规
那么大概比较一下
它们有什么相同点和不同点
那最后呢我讲一些自己的一些这个建议
人工智能其实大家都可能现在是非常
这个可以说是家喻户晓是吧
它的历史可能可以追溯一下
可以说到这个上个世纪的
十七世纪的这个中期啊
那么它经历了三起两落是吧
三起两落
有两个所谓的冬天
那么大家都可能听说了是
一开始正式提出人工智能
这概念是在五五年
那么是为了五六年的一个人工智能的研讨会
就在美国
那么我们也看一下这个
就是五五年提出以后呢
这个人工智能就是很热了啊
那么马上啊就是
这是一九五六年提出的是吧
那么到了一九七零年左右呢
就经历了所谓的一个第一个冬天
其实这个冬天的原因是哪
也是非常简单
当时最流行的人工智能的模型啊
叫感知器
它只能解决一些比较简单的问题
就这本书分析的啊
所谓的简单问题就是所谓的线性可分问题
大家看右下角
如果两个不同的东西
两类不同东西能用一条直线就能分开来的
那就是线性可分
那最早人工智能模型只能解决这样的问题
所以当然
被这本书指出来以后就说这不行
所以呢就
马上进入冬天了是吧
那么一九八六年的时候呢
迎来了人工智能第二个春天
那当时主要就是
主要的原因呢就是我们把这个最简单的感知器呢
中间加了几层啊加了一两层
那就叫多层感知器
那这个也是啊有我们现在非常热的
是图灵奖获得者包括
Hinton在内的几位专家提出来的
虽然之前已经有人
曾经提出来过只是没引起注意
好那么
我们
这没多少年啊
一九九五年左右
又来了一个第二个冬天啊
这个也是刚刚我在这大开始读博士的时候
我们在用神经网络来做一些解决一些控制问题
建模问题
没多久就发现这个是人工智能没人喜欢做了
那么这个原因是什么呢
因为
当时的统计学习方法
就我们这样比如像和所谓的叫和函数方法
或者支持向来这样的一类
统计学习方法呢
在性能上
呃
完全压倒了这个当时的有一层或两层
这个隐含层的神经元的模型啊
所以那就
又神经网络又没人住了
呃那么呃
直到一二零零七年啊
Hinton又
在这个
一本期刊上啊就发表了这个所谓的深度学习的网络
那么这深度学习其实就是前面这个
从一层两层开始他中间加了很多层是吧
所谓的深度就这个意思
呃但是他当时发表这个文章以后并没有引起太多的注意啊
直到二零
直到这个二零一二年
一个深度学习模型的一个变形叫Alex Knight
他在这个
一个一次竞赛当中啊
完全打败了这个统计学习的方法
才又在学界
在人工智能学界
引起了
重视啊
从那个时候开始呢
我们基于人工
就是神经网络的方法呢又
又开始获得重视
好那么真正在社会上引起人工智能对大家
特别影响大的就是可能大家有回忆起来的话
就是二零一六年是吧
谷歌提出来的
这个
一个算法
他能够战胜当时的一个韩国的这个围棋高手啊
那么到二零一七年他又提出了一个新的版本
就是
前面这个版本是要
为他很多很多的棋谱可能上一盘棋谱
但到后来这个所谓叫
AlphaZero的话他不需要为他棋谱了
就不需要为数据了
而是让两个这个算法自己相互博弈
哎最后他这个
性能的话比为棋谱的还更好
是吧所以这是一个很大的这个进步
那么第二次的大的冲击是吧
我们第三次人工智能的这个高手
第二次大冲击可能就是这个ChatGPT了
可能大家都非常清楚了
那么他的这个
之所以让我们惊奇的原因呢
就是他的对话的流畅性
因为这个对话
这种软件本身70年代就有
没有引起我们太多注意
但是呢ChatGPT呢
彻底让我们
感到很震惊啊
因为是
他的流畅性非常好
很像人在对话
那么从此以后呢这个大模型大家也知道就是
飞速发展
有无数多的大模型
那么另外一个很重要的事情可能今年
年初是吧
大家都知道这个Sora是吧
我不知道这个能播放吗
哎哟好像不行
怎么样才能播放这个东西不太清楚
因为我想播放的原因实际上其实
这个Sora这个出现的这个视频啊
虽然是非常的惊艳是吧
但其实如果你仔细看你如果不要只是看他的脸啊
你仔细看的话
其实下面是有很多这个
这个这个这个
问题在里面的但是很可惜这个放不出来
这也是就是
对我们在这个人工智能发展一个很简短的历史啊
那么现在这个大模型出来以后
可以说大家每个人
都谈大模型
做人工智能如果不做大模型觉得你已经不做人工智能了
那么大模型的话也有很多很多的探讨
那也有很多呢很乐观的说哎马上我们
这个这个通用人工智能出来了
这个我们有非常就是甚至比人也要聪明的是吧
这是乐观的一种想法
那么又有一些悲观的想法就是他人工智能会不会
统治人类
会不会取代人类
有这样两种不同的观点
那不管怎样呢就是我们需要对人工智能因为高速它的高
高速发展
所带来的一些
社会经济的重大的影响
因为它几乎涉及到所有的领域
所有的领域
那么目前的话如果我们要总结人工智能有什么风险的话
大概有这么几类一个就是安全性
第二个呢隐私保护
隐私的话因为我们人工智能是依赖于很多很多的数据
还有一个就是公平性
另外呢像透明性以及可解释性
还有呢就是鲁邦性和可靠性
最后呢就是责任性和可问责性
我后面稍微再探讨一下
那么为什么要讨论这个人工智能模型的安全性
深度学习模型非常强大
大家可能知道就是说有的时候两张人脸人都分不清楚
他能够分清楚
同时呢他又非常的脆弱
也就是说你人不会犯那些错误
绝对一看就知道的问题
他可能就会犯错误
这是一个经常用到的一个例子是
就主编大家看到这个大熊猫是吧
然后呢如果你在这个图片上加上一点噪声
那么变成右边的图像
那我们人眼一看还是个大熊猫对吧
但是深度学习模型可能是完全把它当作另外一个动物来判断
所以就是说深度学习的模型很脆弱
那么怎么来对付这个它的脆弱性
当然有很多研究现在有很多就是说如何来设计好的深度学习模型
来避免呢
他这个
这种对一些很小的变化就能犯大错的一个方法
那么第二个呢就是说风险就是隐私了
那么隐私的话因为我们依赖大量数据
所以呢这个数据里面的往往会有很多这个个人信息也好
或者企业的一些重要的经营信息也好
那么这些信息的话如果你给泄露出来的话
当然就会造成很大的风险
那么隐私计算的话就如何来保护隐私要用到这些数据是吧
那么有很多方法
这个传统的
空间安全的一些方法像
独方安全计算
或者差分隐私以及加密等等
那么现在也比较流行的叫做叫做这个
联邦学习
那么这些都是一些技术性的方案
来保护数据的隐私
同时呢又能够充分利用这些数据的这个
价值就是又既能打破这个数据孤岛
又能够这个
来
保护这些数据的这个隐私
那么第三个方面的就是
它的所谓的叫鲁邦性或者可靠性
为什么呢就因为人工智能模型呢
有时呢也对这些
一些不确定性或者噪声啊输入的
信息的噪声
比如传感器信息的噪声非常敏感
那么怎么来处理这些已有很多的技术方案是吧
比如说我们来
把这个数据质量
那个清晰数据那么提高数据质量
或者呢在机器学习的方法上
进行一些
这个改变
使得呢这个模型的不对这些噪声的特别的敏感
那么我呢就不详细探讨这些技术的方案
还有一个很重要的
问题呢是就是
所谓的公平性
由于这个多方面的原因
人的一些我们人有些天然会有些可能一些偏见
然后在数据上的也有些偏见
那么这样的造成或者是模型训练上一些偏见的
会造成这个
我们人工智能模型啊
如果你要记得它做一个决策的话它可能也会有偏见
那么如何来保证
这些人工智能模型在决策过程当中
能尽量的公平
有很多很多的方法
那么在我们数据的处理也好或者是模型训练也好
后处理也好等等
那么其实这公平性其实非常难的
我举一个简单的例子
一方面它涉及到多方面的不只是一个技术的问题
因为你的公平性怎么来定义
其实涉及到很多
文化社会等等各方面的这个学术等各方面的这个
因素
另外呢
有一个很简单的例子比如说我们这两类这个
是表示男性和女性然后呢
这个是这个就是说有两种肤色的假设
那么它有多少人被聘用了
那么如果你
你只是去看单纯某一类的话
就只看男性和女性
或者只看肤色觉得很公平吗都招了三个是吧
但如果你把这两个合在一起看的话
其实还是有很多这个偏见在里面
第四个要探讨的就是我们这个叫人工智能模型的这个
叫可解释性或者叫透明度
那么这个可能大家也都听说过
有一个很有趣的现象就是说人工智能学习学得很好
但到底我们不知道他在学什么是吧
他学的是这个因果关系
还是学的是相关性
还是一种完全是一种假象
或者是一种很偶然的现象
那么有时也非常有意思
在这个
这个实际是20世纪初
有个叫
叫做聪明的汉斯就是这匹马
所以他会做四指硬算
后来发现其实并不是他只是会
察言观色而已
那么还有很多一些其他的这个技术方案因为时间原因的我也不是讲了这就是一个
因果关系和
相关性的一些区别就是同样
冰淇淋消瘦很厉害
很多啊
但是那另外一方面你可能被晒黑了
那么这样的话就是说天气热跟
冰淇淋的消瘦量增加
和天气热跟被晒黑
这是因果关系
但是呢
冰淇淋的销量的增加和被晒黑这两者之间
不一定有因果关系只是一个相关关系
那么为了
对付啊上面这么多的这个
可能的风险
其实欧盟在很早啊 2017年就
GDPR就出来了
所以很多方面的规定
那么对
其实这是一个最后
第六个方面
就是所谓的responsibility
就谁来负责任
那么这里我把它列了一些不同的
有可能是用户方
用户经理等等
用户单位
开发方 销售方等等
有很多
都有可能
如果出了什么事情
你可能都去会找这些人
到底是谁的责任
那么目前的话
针对所谓的上面这些风险
其实各国政府
已经出台了很多的规范 法规
从2017年欧盟出台的GDPR开始
它就提了很多
对人工智能的一些要求
包括像要受人类监控
技术的鲁邦性 安全性
隐私保护
透明度 东洋性等等
还有一个问责制
最近
就是今年的6月份
弗吉尼亚Tech和哈佛大学
MIT等等一些学校
就发了一篇文章
这个文章
把所有不同的风险
做了非常仔细的分类
总共有三百二十几个不同的分类
非常仔细
那这不同的分类
可以分成四个大的类
大概有这么四个
就是系统和操作风险
内容安全风险
社会风险
以及法律的一些权责风险
那么这个分类的目的是为什么呢
主要是它想分析
中欧美三国目前已有的人工智能的法规
对到底cover了哪些
就涉及到其中哪些
所以分析得非常详细
大家如果有兴趣可以去看看
那么比如像这是欧盟
欧盟大家都知道
2017年GDPR和今年刚刚通过的
这个法规
那么它当然有一些特殊的地方
而我们如果回顾一下
看看三个国家
这些不同的法规既有共同性
也有一些不同的侧重点
那么这是美国和中国的
也是这样
就是有些共同的观点
也有一些特殊的自己关心的
这是三个国家的法规所共同的地方
那么我最后的话
利用可能一分钟左右的时间
就是来探讨一些我自己的一些看法
首先就是说到底要我们规范什么东西
什么是人工智能
其实这个定义不是很清楚
特别是在一开始
欧盟这个法规刚出来的时候
把几乎所有的传统的
像控制 优化等等技术
都把它归到人工智能里面去
那么其实它的影响的面积非常大
那么如果我们在这边的法规上
那么如果我们在这边的法规上
那么如果我们在这边的法规上
那么如果我们在这边的法规上
如果我们在法规在设计方面太广之后
那么就会影响一些中小企业
对人工智能的发展
第二个呢
不好意思
稍微用半分钟时间
第二个呢
就是说我们到底要规范什么东西
我个人觉得
就是应该规范人工智能的产品
以及应用
而不是规范人工智能的技术
最后的话呢
就是我们其实对人工智能技术
其实还要分层分类
特别是一些
高峰性的技术
高风险的
包括像生成式模型
或者是非常高度的
自主的人工智能算法
以及一些通用人工智能
这方面呢
可能带来的风险会比较大
我们可能是
因为我们需要规范的一个重点
那么我今天就分享这些
谢谢大家
还有一些因为时间关系
我就不多说了
以后如果有哪位参议会者有兴趣的话
我们可以在线下讨论
谢谢大家
好
非常感谢大家
谢谢金教授的精彩演讲
高度浓缩
时间不太够了
我们下了以后再跟金老师请教
好
因为我们议程做了一点小小的调整
那么第二位发言的嘉宾呢
是中国工程院院士
德国国家工程科学院外籍院士
瑞典皇家工程科学院外籍院士
同济大学原副校长吴志强教授
有请吴院士
好
这个因为后面全国的那个
我们城市规划的专家也在聚在上海
我一定要过去
我是主持人
所以我把会议做一个调整
我先讲掉
非常重要这件事情
这个我们同学们
同济和杨浦专门做这个社会治理这块内容的
这么一块探索吧
我觉得特别重要
所以我呢
把自己的研究啊
在为今天的那个会议
专门做了一个特别的powerpoint
这个报告呢
就叫社会智能
关于哈尔主义的破题
实际上是做了那么多年
实际上在2014年
这个全盘的这个
把城市规划导入这个AI的推进
也就是那一波的时候呢
我们的世博会就在这块场地上
实际上当时有了解释
我们当时呢
世博会一天要进一百万人
所以说这个压力是非常非常大的
这个密度啊
这个温度啊
都是非常挑战大
所以作为世博会总规划师呢
我就把整个世博会的每一张票
全部定位的
所以说为了踩踏世界的房子呢
是全部的每一个人进来
这个说一件事情
大家都可能会觉得很荒唐的
这个觉得这世博会
怎么会有那么大的经历呢
就是因为有人说
这个超过了一个平方米
只要一点三人
不要踩踏世界
而我们世博会这块场地上
一天要进一百万人
就是说一个平方公米
要占六个人
你们知道六个人意味着什么
只要有任何事件
那就是超过了
这个世界纪录的
你必须要超标
不超标就没有那么多人
答应世界要破这个世界纪录的
但是呢
用这么高的密度
又是破了中国国家的规范了
国家规范一个平方米
必须只能占一点三个人
假如要国家规范
又是要用的话
那就是这块世博场地呢
要扩大六倍
我们不可能再扩大六倍
来做这个世博场地
所以必须要高密度要完成
在这么一个条件下
我们做了每一平方米的
这个精准的模拟
每一张票的精准模拟
为了不踩踏事件的诞生
这么样子我们就进行了
大规模的数据的动态
世博会结束以后
一二年大家说
你这套办法现在有名字了
叫大数据
叫Big Data
现在有名字了
即使的用电
即使的能流
即使的每一个数据的统计
每一间房间的用电量
那么这个时候呢
把这套内容呢
也就是中国
工程员呢
大规模来支持这套系统
就是我们的城市管理
城市的治理
开始用作为我们的
这个这套内容
那么很高兴的是
做了一四年开始
全部到今天正好十年
我们特别高兴的是
实际上好多好多的数据
我们碰到了很大的问题
刚才金教授在谈这个问题
实际上是我们是
真正的碰到了
这些实实在在的国内的问题
那么很高兴的是
我们中国工程院
在14年成立这个课题
我在这里面
16年我们给总书记写报告
中国一定要注重人工智能
在我们的社会经济
各个方面的推进的时候呢
总书记实际上是
两个星期就改了很长的一个批示
让我们工程院呢
就落实这个姿势吧
包括我们的老校长
万刚校长
也是在这个中间起了很大的作用
所以我们的这个计划
中国人工智能这个发展报告
发展规划
Strategy Planning
战略规划呢
在16年的年底全部变完
这是在中国是这件事情上
推进上和全世界完全平行
这16年同时我们推出来的时候
美国推出来了
欧盟推出来了
所以说刚才金教授说的
这个三波基本上是
全世界最平行的三波
像日本了什么
都还没有到这么快
那么在这个过程中间呢
实际上事业啊
经济啊
这些问题啊
都会有很多很多的担心的
那么我们工程院呢
从头开始就同时成立了
从技术推进十个方面
我待会会说到
另外一个方面呢
就是我们的社会的问题的
同时的这个内容的
全部同时来
这个小组呢
当时是放在我们的上海大学的
原来这个小组
那么这个小组呢
因为后来上海大学的校长
到了天大去了
当校长去了
所以这个小组呢
又被拉到那边去了
实际上这是都跟着人在走
那么这块的内容呢
我今天呢就是说
一直说AI
说了那么多年
这个从17年
我们在全上海组织了4000人
成立了AI城市规划联盟
这个在徐汇区
然后18年就在我们这个场地开始做
做到今天
实际上这个AI
这个大家呢
当时呢就都压了
这个AI特别好
就觉得它是一个很正式的
一个很重要的内容
到今天呢
我就想给大家把那个H加上去
这个H什么呢
就是Human
实际上是能与AI的深度的合作
这是一定要很清楚的
实际上不是AI一个人可以完成的
这个事情
做了10年的实践啊
最后得出来的结论
今天给大家说
第一句话就是
人和AI的深度合作
这才是未来的社会
我们要做的事情
是人与AI的共同的智慧
相互之间摻在一起
可以完成的
是人的智慧和AI的智慧的共生和共创
这是今天我们特别要说的
所以我今天呢
就把这个报告称为叫
嗨主义
Human和AI合作
才是人类的明天
所以呢
我就讲
今天就讲
嗨主义的几条原则
讲五条原则
第一条原则就是
人本互动的
互助的
这非常非常重要的
什么意思呢
就是什么事做的时候呢
所有的事情
AI的所有推进
都必须围绕着人本身的渴望
这是所有的起步
你假如说AI的本身的技术的进步
你就脱离了人本身的渴望
好
所以说
这点呢
大家可以说
我们是大规模在运用了城市规划里面
我举个例子给大家看
我们可以用大规模的来完成人的需求
每一个治理
包括我们做了这个
深圳的所有的每个平方公里的治理的数据
都完全不一样
这是我们做厦门
做厦门的治理
过去我们城市规划是走上来
就是说功能怎么样
道路怎么样
哪里布局怎么样
这是我们是挖了几十万人
大家可以看
很快的数据全部收集上来以后
发现厦门人最最喜爱的是沙茶面
提高心情最快的提升是沙茶面
我们规划是过去
怎么会想到沙茶面那么重要呢
我们做了六个地铁站
做个地铁站的时候
第一件事情就想到了
沙茶面要落实
不落实的话不行
深圳人
厦门人最不喜欢的事情
我们大部分建筑师过去不知道的
最不喜欢的是奢靡
我们过去一下子就
要做新的地铁站
大理是铺好
做得最最漂亮
根本就不是
人家根本就不喜欢这样东西
所以说对我们的所有的AI的推进
直接导向了人心所向
这是非常重要
帮助我们
大家可以看绍兴人臭豆腐心情最快
你们知道吗
你们知道吗
你们不会想到的
大家一想到
做绍兴的老城的保护
规划
什么什么
怎么做得很精致精美
这对的
但是人家心情最快乐的是臭豆腐
黄酒
和快乐老家
所以说你就倒回去想
什么是载体
做什么事情最最重要
绍兴人最最吐槽的是宁波
修路
等等
你知道啊
原来绍兴人想这些东西
想这些东西
你在做设计的时候是完全不一样的
人心所向
我可以举很多很多这个例子
正向清去
负向清去
现在我们远远
就所有的把大量的人工智能
用到了人心所向
知道每个地方人在想什么
我们做到了什么程度呢
我们给深圳做的是每一平方公里
每一小时人的变化
就是刚才做的只是给大家看
一件事情实际上它是动态的
什么时候变化的
我告诉大家我们做了全中国的
369个城市的每周的报告动态
全中国人的心情变化是非常非常有规律的在波动的
这个疫情的时候
疫情之前
2020年之前
武汉人是整个中国中间
所以最最乐观的一群
但是一封城以后
一下子掉下去20个点
清清楚楚
上海封城掉下去了18个点
非常非常清晰的波动
然后呢
疫情波波打开
慢慢慢慢慢慢恢复
基本上到了2023年的中期
全中国人民都起来了
都超过了2020年的时候
唯独武汉人还没有克服
上海人还没有克服
全中国只有武汉人和上海人
还没有恢复到疫情之前
其他地方都恢复了
可以看到整个的心情的波动
这才是我们所有的内容
这个实际上数据
是我们所有社会自己的根本
这件事情我说掉
第二个海主义的
我也可以把它用中文上海话说的
就是海大海的海
海主义的第二条
就是要透明互信
刚才说了
transparency是非常重要的
讲了不能transparency
你是没有办法相信AI的
AI的过程
你要让人知道为什么是这样
不能说你它做出来结果就这样
就这样
不对的
这个要transparency
这个就是我们现在做了大规模的
这个里面为什么
你要让领导知道
为什么它是这样的分布的
这个老年 中年 青年各个时段
他们为什么出来
这个为什么这样
这是大量的东西
比方说我们这里
当然一代代做了很快
我们已经做到第四代了
当时
就是说
你可以看到原来的城市是这样的
我们不仅仅是做到未来的城市应该怎么样
而且未来的城市的每一栋房子里面的人
手机数量全部推演出来
已经做到这样
但是为什么呢
你假如老不说为什么的话
这是有问题的
这个就是AI的很大的一个问题
刚才金教授说到那个点是这样
不知道多少人知道
就是我们小时候
我们这些人在西式的教育下面
导入的都是学的CODA
也就是叫因果关系
但是我们这里面实际上有很多的是相关关系
就相关关系要说清楚的话
你才可以说清楚
比方说这是我们做的洞外滩
这是做的水的模拟推演
实际上是要做很多很多transparent的事情
第三块就是要安全护保
非常重要的
大家以为AI是一个机器
实际上是需要相互之间保证它的
要保证它的电力
保证它的算力
保证它的从善力
善力很重要
不是算力 是善力
这个一把刀你可以做
完全是用作两件事情
也可以杀人
也可以做我们切菜
完全不一样的
这就是向善力
保善力也是非常非常重要的
这就是要大量的来做
我们这部分呢
保善力这块呢
我们做了城市重脑
在2014年2015年的时候呢
我们推出
这个世博会里面呢
就是这个经验呢
拿出来叫城市大脑
这个概念出了
实际上是出自
世博会里面的总控
叫城市大脑
那么实际上做到
现在又做了十年了
现在很清楚的
我们现在从两年之前
我们就开始推城市重脑
一个脑子是不够的
最后所有的数据都汇到一个地方了
我们世博会里面可以的
汇到一个地方
一个训练站中间
但是把这个模式拿到城市里做
做了那么多年
我们发现
我们自己再一次推出
城市重脑
一群大脑同时运行
非常有意思的
我们这里有主脑
边脑
辅脑
端脑
各种大脑同时运行
这样的话
比整个过去的大脑要聪明很多很多
那么这部分呢
就保证了各方参与模型
五方参与模型以后
相互之间有自己的规律
相互之间对其他人有判断
这样就保证安全很多
第四个原则就是
我们要相互之间互动和互控
人和机器相互之间要非常互动的
实际上不是这样互动的话
是没有办法保证这个
人工智能社会向前安全的前进的
所以说我们相信之间
这是我们大量的绘制的道路
和这个IP
就是说现在人的数据和相互之间的
那么我们也做了大量的自由创作
自由创作的时候
实际上是做了大量的机器的反馈
就是一边生成一边大量的反馈
这就是我们非常非常主要注重的
就是相互之间
人和机器中间不是最后一个结果
是过程之间有更多的交互
交互才能够完成这个智能社会的
一个AI社会的一个向前推进
这是我们现在在做的
最近在做的大量的叫爱媛宇宙
是创造了一个城市里面
人和自然之间青年人
大量的导入的过程
这个过程本身是有很多青年人
一边使用一边来相互之间互动的
看到他们的生存
他们的希望
然后来完成我们整个的创作
这个创作过程找了很多青年人在网上
共同参与
第五最后一个原则
我觉得论理互信是非常重要的
刚才金教授说了这个郑教授
也是个中国人
在佛罗里达他做了三个主体
美国中国和欧洲的安全内容
实际上这块东西
我们之前讨论过很多很多
实际上就是论理互信的事情
真正的做的事情
我们要做大量的予以的创新
相互之间和机器互动
能和互保
这就是我把嗨主义的五条说在嘴
今天是参加人工智能在城市规划中间的试验
我把原来一直说AI
今天加上human
human和能互动称为嗨主义
嗨主义就是人和机器要能本互动
要安全互保
要论理互义
要能和机器相互之间互动可控
最后要透明
能和机器相互的互助
那么这样互信的话
才能够真正把这个社会
这个智能社会
真正的完全的推进
因为在上海
因为在这块土地上
我就直接提嗨主义
上海的嗨
H表示能在前面
AI表示我们的
今天的社会的最重要的技术的推动
嗨主义就是我们上海诞生的一个想法
能和机必须互动
谢谢大家
非常感谢吴院士的精彩发言
他的嗨主义让我们嗨起来
他的20个字的
最后打在屏幕上
印象是非常的深刻
互助 互信 互保 互动 互育
好 再次感谢吴院士
下面一位发言的嘉宾
是来自意大利的
加布里埃尔·马治尼
Gabriel Mazzini教授
他是欧盟委员会的
官员
曾经担任
欧盟人工智能法的
起草小组的组长
但是因为特殊原因
马治尼教授
他无法到现场来参会
所以他做的是
线上的发言
下面我们请看大屏幕
Good morning
My name is Gabriela Mazzini
and I am the lead author
and the architect of the EU AI Act
Let me start by thanking
Tongji University School of Law
for inviting me
to this conference
I'm sorry I will not be able
to be with you present today
but I hope that these remarks
will nevertheless help you
have a fruitful discussion
I will spend around 15 minutes
to give you an introduction
about the AI Act
First of all a couple of remarks
about the institutional architecture
Of course now we are at the end
of the legislative process
but I think it may be helpful
to have a sense of who does what
in fact the proposal
for the EU AI Act
was put forward by the commission
which is the executive of the EU
in April 2021
The proposal was sent in parallel
to the Parliament and the Council
The Parliament and the Council
act as co-legislators
That means that they have to agree
on a common legal text
in order for that text
to become the law
This took some time
The proposal as I said
was issued in April 2021
and the final political deal
was sealed in December 2023
was sealed in December 2023
Now that we have an agreement
on the legal text
this text is going to be published soon
so indeed this conference
is a very timely event
in July 2024
and it will enter into force
in August 2024
What is important to understand
is that the conclusion of the legislative phase
doesn't mean the end of the work
In fact a new phase opens up
which is the implementation phase
Primarily implementation of EU law
is a responsibility of the member states
is a responsibility of the member states
However there is actually
a certain number of actions
that need to be taken
at EU level
notably by the commission
in particular when it comes to
adoption of guidance
delegated acts
implementing acts
of tertiary legislation
to be adopted by the commission
will also have
some degree of oversight
by the two arms of the co-legislator
so the council and the parliament
First of all a couple of remarks
about the nature of the
EUAI act
It is a classic
internal market legislation
for the placing on the market
and the putting into service of AI systems
In particular for those of you
that may be familiar
with EU product legislation
the AI act
introduces the CE mark
The CE mark
certifies that a certain
product in this case
an AI system
is in conformity with applicable EU law
Therefore
the adoption of the product
legislation approach
is aligned with what is called
new legislative framework
philosophy
of product legislation
that has been around in the EU
for many many years
and it is premised upon
a simple concept
that the law provides
essential legal requirements
that operators need to comply with
but does not enter into the
technical standards
in order to meet those requirements
Therefore the AI act
will need to be complemented
by a set of harmonized standards
to operationalize the legal requirements
Another important feature
of the EU AI act
is the horizontal approach
This means that the AI act
applies across a variety of sectors
within the EU competence
with some exclusions
notably in matters of national security
military and defense
However
although the AI act
has an horizontal nature
a number of sectoral specificities
and needs needed to be considered
in particular in areas of law enforcement
and so on
so there has been an effort
on our end
to ensure that
even though the AI act
has an horizontal approach
sectoral specificities were included
Another corollary of the fact
that the AI act
has an horizontal approach
is also the fact
that it is without prejudice
to other existing EU law
notably in matters of data protection
you may be all familiar
with the platform legislation
for instance the digital services act
or the digital markets act
so an important consideration
to make from the beginning
that was very clear
when we thought about the AI act
is that the AI act
is certainly not the only EU law
that is applicable to AI
One of the essential concepts
perhaps the most important concept
of the AI act
is the risk based approach
the risk based approach
means that
the rules of the AI act
become stricter
as the risks that AI systems
may pose become higher
therefore the focus
is not on regulating the technology
as such but on regulating
use cases
so specific use of AI systems
We have identified
four levels of risk
in particular I should say
three because the fourth one
the green one
does not lead to any
binding rules
so we have binding rules
for three levels of risk
the first one is around
risk that are not acceptable
in these cases
the AI act
foresees a prohibition
examples of this use cases
are for instance social scoring
or forms of certain cases
of remote biometric identification
to note that
the commission had foreseen
two use cases
for prohibited AI practices
and the co-legislator
concluded on adding other four
so right now the final law
will have eight cases
of prohibited AI practices
the next level of risk
is for high risk
high risk use cases
take perhaps around
80-90% of the
UAI act
I mentioned before the CE mark
so the product legislation approach
of the EU AI act
and this is exactly the type of
legal approach that applies to
high risk
when a system is considered high risk
and therefore is subject to the CE mark
the system is
subject to a number of
obligations notably requirements
essential requirements
regarding the AI
and an exempt conformity assessment procedure
so the manufacturer has to demonstrate
compliance with those requirements
we'll see
a couple of examples later
of high risk AI systems
the third layer of risk
concerns those cases
where the risk
is linked essentially to
the lack of disclosure
of information
examples would be
cases of a chat bot
where humans may not be able to distinguish
whether they are interacting
with an AI system or another person
or forms of generated content
synthetic content
in these cases the AI act
foresees an obligation to disclose
information around the
existence of the AI system
or around the
fact that the content has been
artificially generated
finally as I mentioned
the last layer is about
cases where AI systems
pose minimal or no risk
and in that case as I mentioned
the AI act does not foresee binding rules
but only the possibility for
providers to apply
products
when is a system high risk
the AI act
foresees two avenues
in which a certain AI system
can be classified high risk
and therefore is subject
to some of the stringent rules
about the AI act
the first category is around
systems that are safety components
of products that are already
subject of EU law
examples would be AI systems
that are safety components
of medical devices
of machinery or toys
radio equipment and so on
we are dealing here therefore
with the number of products
that are already covered by EU legislation
but they may have some digital components
including AI components
so the first way in which
certain AI systems become high risk
is when those AI systems
are on the one hand components
of those products that are already
regulated and those components
are high risk
so it is important this element
not all AI components of products
will be high risk AI systems
but only those that fulfill
a safety function
furthermore in order for the system
to be classified as high risk
it is essential that the product
as a whole so the product
that is regulated by the sectoral legislation
the medical device
the machinery and so on
is subject to a third party
conformity assessment
for assessing the conformity
of the product as a whole
to compliance with
existing EU law
the second categories
of high risk AI systems
is
when the AI system
belongs to a number of
specific areas
that have been identified
by the legislator
you see in the slide
eight areas
it is important to note
that not the whole area
is high risk
so therefore not all AI systems
that are included in those areas
are high risk
if you look at the annex
you will see that under each area
there is a list of specifically
mentioned AI systems
so therefore only the AI systems
that are explicitly mentioned
in the annex 3 under each area
are high risk
and the attention of AI systems
used for hiring or promoting
or terminating employees
this is an important
element to consider
because
the commission already in its proposal
had intended to allow
for some flexibility
in the classification of
high risk AI systems
in these areas
by allowing the commission
to add use cases
this was an intentional decision
to allow the AI act
to remain future proof
and therefore to adapt
as the market and the technology evolves
so to adapt the use cases
as the market and the technology evolves
this is a very important chapter
of the AI act
notably around
general purpose AI models
that has been added
by the co-legislators
during the legislative procedure
the commission had not foreseen
any rules around
general purpose AI models
we have right now
therefore a regulation
of those models
that is divided
in two tiers
first of all
what are general purpose AI models
so general purpose AI models
are those models
that are otherwise
sometimes also called
foundation models
and can perform
a variety of tasks
an example would be
models behind chatbots
like for instance chat GPT
according to the AI act
those models will be subject
to two type of regulation
according to the first level
of regulation
which is applicable
to all general purpose AI models
they will be subject
to a number of transparency related rules
in particular
around technical documentation
so those models must be documented
including as regards
the computational resources and energy consumption
there must be
a transmission of information downstream
from the provider of the model
to the downstream provider
who wants to apply the model
to a specific application
and finally there must be compliance
with certain copyright related rules
notably when it comes to the adoption
of a policy to ensure compliance
with copyright rules
and the implementation
of a detailed summary
of the content used
for the training of the model
the second category
of general purpose AI models
notably those that are classified
as models with systemic risks
are subject to additional rules
in particular
around risk assessment and mitigation
incident reporting
and cyber security
an important element
to understand is how
will be classified
as a model with systemic risk
dealing that
this triggers different
legal obligations
the AI act foresees
at least in the first moment
that the models
that are trained
with at least a certain number
of compute resources
the 10 to 25
flops will be classified
as models with systemic risks
and therefore subject to additional rules
however this is not the only way
in which those models
can be classified
as models with systemic risks
but also there is a possibility
for the commission
to designate models
as models with systemic risks
regardless of the number
of compute used
on the basis of a number
of criteria that are identified
in an index
by the way the AI office
is part of the EU commission
this consideration
is the role
of the applicability
of these roles to open source models
which is somewhat reduced
in the sense that
open source models
are not subject to
the rules around
technical documentation
and transparency
as regards the lower tier
and finally another important element
to take into account
when thinking about the future work
will have to be developed
facilitated by the commission
in order to demonstrate
compliance with the rules
around general purpose AI models
a final word
about the progressive entry
into application
as I mentioned at the beginning
this is really a very important time
because the AI act
the final version of the AI act
will be published in the official journal soon
and it will enter into
force twenty days
after its publication
however the entering into
force of the AI act
which is therefore scheduled
around the first of august 2024
does not mean that
all the rules of the AI act
apply immediately
as you can see in the slide
there is a phased entry
into application of the rules
after six months
the rules around prohibited AI systems
will enter into
application
the second set of rules
that enter into application
are the rules around
general purpose AI models
that I just discussed
12 months after the AI act
enter into force
then we have the third deadline
which is 24 months
which is the general deadline
this applies to essentially
all other rules
with the exception of the rules
regarding high risk AI systems
like for instance
medical devices or machinery
for those type of products
the application
of the rules of the AI act
will happen thirty six months
after the AI act
enter into force
let me conclude my presentation
by thanking you
for your attention
and I wish you fruitful discussions
in the prosecution of the conference
thank you
енный
perfect
 hostage
 trata
지랜
a
 нем
t
a
we
hey
this
there
is
an
a
power
аться
ad
the
t
it
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
所以没时间翻译成中文
所以今天只能靠大家的这个英文听力
还有我们那个通传翻译的工作
So today I'm going to be talking about
US-China dialogue on AI
US-China engagement on AI
And I'm going to be talking both about
government level engagement
and non-government level engagement
what we often call track two engagement
I think most people know that this May
the US and China met for the first meeting
of their sort of official high level
government dialogue in AI
they met in Geneva in Switzerland
This was a real landmark meeting
it took a lot of work to make it happen
and I think it's very important
the risks of
the safety risks of frontier AI systems
are a problem that is going to require
the United States and China's efforts
they are the central axis
that this is all revolving around
and it's really important
that we have these dialogues
but I think it's really important
I also want to give some
kind of good news and bad news
on this front
and I'll start with the bad news
so we can finish with the good news
I think the bad news is that
we should have very very low expectations
for this government dialogue
producing any kind of agreement
any kind of binding agreement
or joint statements on AI
we should expect them to talk
but we should not expect them
to agree on very much at all
and that's bad news
for governing frontier AI risks
I think the good news
is that we don't necessarily need
a government to government
binding agreement
on reducing these risks
in order to do the work
of reducing the risks
I think we can still have very productive
engagement between the US and China
just not necessarily at the government level
I think we can have very productive engagement
between policy scholars in both countries
like we're having here today
I think we can have very productive engagement between policy scholars in both countries like we're having here today
I think we can have very productive engagement between policy scholars in both countries like we're having here today
scientists between companies
and I think that's really going to be the
the backbone of ensuring AI safety
between the US and China
and I think the key idea here
that I want to communicate is
changing our mental model
changing our idea of what it means
for the US and China
to work together on safety
I think there's a traditional model
of this kind of thing
that is a very top down model
that is a very top down model
the idea is
our leaders get together
at the very highest level
they make an agreement
about what we can do
and what we're not going to do
and then that agreement
that they struck
is put down into the two ecosystems
the rules are agreed on
and then they're forced on each country
it's like a
top down system
and I think that that for AI
especially frontier AI governance
is just not realistic at all
what I would propose
what I think is going to be
a more productive model
is a more bottom up model
of working together on safety
and I tend to call this
safety in parallel
so it's not safety based on joint agreements
where we both make commitments to each other
and we both follow the rules
it's where we both are developing AI systems
we're working on safety techniques
both technical approaches
and policy approaches
and we're constantly exchanging views
we're constantly sharing best practices
between the ecosystems
but we're not having to do everything together
at the same time
we are learning from each other
but we're not necessarily striking agreements
and I think that that is going to be
it's a much more realistic approach
I think it's going to be a much more resilient approach
I think it's going to be an approach
that lasts much longer
given all the chaos
that is politics and geopolitics today
I think in this world
and maybe kind of a fundamental idea here
is that the
if the U.S. and China
are going to build powerful AI systems safely
it's not going to be because
the two leaders struck an agreement
it's not going to depend on a grand bargain
between the U.S. and China
it's going to depend on the decisions
thousands and thousands of decisions
made by more working level people
scientists, engineers, professors
everyone advising on policy in both countries
and they're going to need to make these decisions
for their own reasons
it's not going to rely on what the other country is doing
they're both going to have to value safety on its own
and I think if we do that
we can build up a sort of a parallel safety system
that I think will be more enduring
briefly on the government level dialogues in Geneva
I think we should appreciate
what a huge achievement it was
to even hold these dialogues
given the geopolitical environment
the domestic political environment
in the U.S. and China
this is extremely difficult
for I'll just speak to the American side
for the American president
for Joe Biden
his administration to say to
the Republican Party
we are going to talk to China about AI
that's a very big political risk
in the U.S. system right now
I don't think it should be
but the fact is it is
and I imagine there are similar risks on the Chinese side
and so just getting together
I think is a very big achievement
but what comes out of that
is maybe not what we'd expect
it's not going to be the agreements
right now
and especially going forward
frontier AI
frontier AI safety
is something that both countries
or frontier AI systems
both countries see this as
absolutely essential to
national power going forward
it's going to be essential to military power
economic power
international influence
they might be wrong about that
maybe it doesn't turn out that way
but that is the assumption of leaders in both countries
and when you have that assumption about
AI and national power
and you have two rivals
who are competing in every area
they are just
it's going to be extremely hard
to trust each other in any meaningful way
and to believe that the other side
is going to take steps to mitigate these risks
so it's not going to be agreements
but I think the key contribution of the national level dialogue
is that it sends a signal
it sends a signal within each country
and it sends a signal internationally
so within each country
it sends the signal to
scientists
researchers
policy advisors
that it is okay
to talk to the other country about AI
and this is a very meaningful signal
some people were organizing dialogues around this time
they were working very hard to get the Chinese participants
and the US participants
to agree to come together
this is last November
and then as soon as it was announced
that we were going to have
Biden, Xi announced the high level government dialogue
it became so much easier
to get people to join these other dialogues
I think that's maybe the most important contribution
internationally it's also sending the signal that
the US and China are working on this
there's a lot of countries who are very worried about these divisions
they're very worried about AI safety
and they're looking at both of our countries
saying are you going to get this together
are you going to develop this safely
and I think the signal that the government level dialogue sent
is very very important on this front
I'm just trying to stay to time
so I don't go over too much
anyway
on to the non-governmental dialogues
on to the non-governmental dialogues
the good news
I think that when it comes to engagement
between policy advisors
engagement between scientists and researchers
it's progress is very possible
and I think progress is actually already happening
on many levels
and again I'll go back to this kind of
safety in parallel idea
and sort of what it can mean
I think this traditional model
where the leaders strike an agreement
and it trickles down into the two ecosystems
that's not going to be resilient
because the practices
aren't embedded in each country
the safe practices are not embedded in each country
but if we in our two ecosystems
are developing these safe practices
for our own reasons
China sees it as in China's interest
to develop AI safely
America sees it as in America's interest
to develop AI safely
then we're going to have a more resilient
long term framework
but doing this in parallel
does not mean doing it in isolation
just because we're doing it for our own reasons
doesn't mean we can stop
talking to each other about it
AI safety
how to develop powerful AI systems safely
is fundamentally an unsolved problem
technically we do not know how to do it
and we do not know
what kind of regulations
are going to work best for it
and I think what's happening right now
around the world
is different countries
are running experiments
in how to govern AI
we just heard about the EU AI Act
that's a very large scale experiment
in how to govern AI safely
in China
the Generative AI Regulation
the
the
the
these are all experiments
that are being run to see
can we constrain
can we ensure safety
the model this way
in the United States
we're doing the same thing
last year we had the White House
executive order
that placed requirements
on the largest models
if you are training a model
with computing power
over 10 to the 26 flops
then you need to red team that model
you need to submit the results
of that red teaming
and as we're running these experiments
we need to be comparing notes
we need to be asking each other
how is it going
we need to be talking through
the different techniques
that we're using
and exchanging best practices
and I've seen this very
very up close and personal
I think it sounds
a little bit abstract
but I've seen it very
very effective
I've seen American scholars
directly learn from what's going on
in China
and incorporate that into
how they're thinking about
safe AI development
in the United States
I've seen Chinese scholars
look at parts of
different American proposals
or regulations
and say
we can use that part
we're going to adapt it
to our own needs
but we can use that part
and I think as we do this
we can
essentially we're going to be
building up these practices
we're going to be running
these experiments
and if we are constantly
comparing notes
between the two countries
constantly in dialogue
with each other
then I think we're going to be
much more likely
to get to a safe place on AI
and I guess
maybe going back
to the sort of
government level dialogue
for a second
I think if we do ever
get to a point
where we can have a
high level agreement
between the countries on AI
a binding agreement
that we will not
develop very unsafe AI
the only way that's
going to be possible
is if the practices
have been developed
independently in each country
they've gone from
the bottom up
from the scientists
the engineers
the policy advisors
they're already doing
most of this stuff
and then we just make
an agreement between
the countries
and then we just make
between the leaders
to essentially
codify
to make official
what we're already doing
and I think that could be
a key step
this is kind of
in a little bit
how it worked in climate change
you needed both ecosystems
to come around
on the threat of climate change
and then at a certain point
the leaders can strike
an agreement
that then turns into
an international agreement
so I'm very optimistic
about these
non-governmental dialogues
track to dialogues
and exchanges
and I'm not
totally pessimistic
about the government level dialogue
I think it has
very important uses
and it can also learn
from the non-governmental dialogue
in the same way that
we should not be trying
to strike agreements
the government level dialogue
can put its focus
on exchanging best practices
on having our
AI safety institute
talk to organizations
in China
about how are we
running these tests
what type of
red teaming approaches
are most effective
and I think that
is difficult
at a government level
there's so much
sort of security concerns
but it is possible
and we need to start
experimenting
in this way though
the government is going
to have to be looking
at what the non-governmental
actors are doing
and learning from that
and you know
we're working together
the government sends
the signal
that this is okay
and then we all
get to work
in trying to make
actual progress
on sort of
safe AI practices
so that
I'd say just puts
the responsibility
back on us
puts the responsibility
back on a lot of people
in this room
to proactively
engage with your
counterparts
to not be
try to not be
ideological
try to have some
some sense of trust
to build trust
in each other
through
sort of repeated
engagement
and I think with that
we can
both of our countries
can learn a lot
from each other
and hopefully
we can make progress
on ensuring these systems
are safe
thank you
thank you very much
match
it's a really
greated your observation
that you told
you told us some
bad news or good news
actually felt
optimistic enough
even a signal
would also be a good news
thank you so much
好
下一位呢
演讲的嘉宾呢
是来自美国的
专家
陆凯
Carmen Luchero
她呢
现在是耶鲁大学
蔡中增
中国研究中心的
研究员
有请陆凯
她的设计
是这个吧
这个
好
好
我也想
首先感谢
同济大学
还有
上海洋服区政府
邀请我来
参加这个
会议
而且做这个
发言
发言
有这个机会
就跟你们一起加油
我想你们学习也是很特别的
对我来说
所以谢谢
我今天讲的这个话题
跟我刚才那个Matt同事
有点相同的
但是我就要再回讲
就是美国和中国
他们的这个AI生态
就是他们的AI ecosystem
的一些主要差别
而且为什么这些主要差别
会产生
就像Matt谈到的
这些对话层面的一些挑战
好
所以我觉得
他有前面的一些人已经讲座了
人工智能
它比较负责
范围也比较宽
它不只是一个东西而已
不是一个政策
也不智能是一个政府部门来管理
它是一个生态
一个生态
有点像一个
我觉得这是一个
一个信息
这是比较大
比较复杂
会包括很多不同的东西
所以你看
如果你要做一个中国和美国
或者中国和任何其他国家
他们怎样来治理
或者怎样要做一种对话
实现一些目标的话
你必须也看这两个信息
具体怎么能够促进沟通和合作
好
首先从美国开始
我觉得
美国的联邦政府
还有州政府跟中国有一些主要的差别
所以我只要的就是做一个简单的总结
我觉得在人工智能这个领域
基本上有三个层面
所以有最基础的硬件的层面
就是这个会包括比如说
Semiconductor
是芯片这个层面
在这个层面
美国的政府的权力算是比较强的
它比如说能够控制
能够管理
谁可以用这些芯片
如果他们要卖
有些公司要卖给国外的一些客人
他们可以限制的
第二层面就是这个软件的
就是software和模型的层面
在这个层面
美国政府的权力可能更加模糊一些
或者要看具体哪一个领域
有一些领域
像比如说
这个跟欧盟也很相同的
这个跟欧盟也很相同的
比如说在这个医疗设备中的人工智能
这个在美国也可以比较明显的控制和管理
而且到现在美国的那个视频药品监督管理局
还是有很多就是对着这些医疗设备中的人工智能
有很多规定
最上面的就是这个内容层面
就是比如说我通过深圳人工智能
或者大模型来产生什么文章图片之类的
在这方面
美国的
政府的权力算是比较少一些
或者算是就管理不到的
然后从最宏观的角度来看
从去年开始
美国的联邦政府已经有越来越多的
就是会对着人工智能的一些新的政策和概念
最主要的就是
我的同事已经说过了
这是去年拜登政府的那个新政令
这个新政令
除了对这些最大的模型的这个报告要求之外
它大多数的内容
就是对着美国的政府部门
它会对这些政府部门有一些要求
基本上是有两种
第一种是要让各个政府部门多思考
他们会怎样用人工智能来提高他们的效率
或者做他们的工作做得更好
第二个是他们要更好的
或者更深刻的思考
他们会怎样用人工智能来提高他们的效率
他们会在自己的领域或者自己的管辖之下
怎样管理人工智能
新政令之后
今年的三月份
有这个Office of Management and Budget
在联邦政府也比较有权力的一个部门
是因为它控制钱的原因
它也出了一个这个memorandum
重新强调联邦政府各个部门
要实现的这些价值观
除了这个之外
最后也会有一个
就是跟国家安全有关的备忘录
这个还没出
可能之后几个月会怎样的
但这个是去年那个新政令的要求
所以应该会出现的
好
我觉得要看或者要研究任何国家
它怎样治理人工智能的话
你就必须主要是看这个制度
所以我觉得
制度就是命运
就是institutions are destiny
一个国家的制度会完全影响到
他们怎么把什么人工智能的
抽象的原则或者价值观
事实上落实到他们的这个社会
所以觉得研究美国或者中国的这个人工智能的治理
也必须先了解他们的基本的政治和法律的制度
所以在美国
他说
选取一个联邦系统
所以这个意思是有一个联邦政府
还有州政府
州政府他们也有自己的一些权利
是联邦政府不能干预的
也不能控制的
所以在尤其是在一些领域
所以比如说在教育
很多形式方面
这个都会属于州政府
所以如果你要看
比如说在教育的领域
在教育的领域的人工智能
很多这些管理其实在美国会来自州政府
不一定会来自联邦政府
第二个特点就是这个权利分离
就是所谓separation of powers
这个对于人工智能治理的最大的印象是
一个政府部门可能限制另一个部门的能够做的什么事情
就比如说可能有国会出什么立法
总统不喜欢
所以他会就vito掉了
就说不要了
所以他不可能成为法
或者可能国会出什么立法
或者行政部
整个白宫出什么规定
然后后来会通过法院的某个案子
然后被法官取消
所以在美国
尤其是在联邦政府层面
国会的总议员和参议员经常会谈
比如说他们对
要
现在要立马管理什么人工智能的什么什么什么的
但是过一段时间他们真的能不能做得到是有挑战的
我觉得最近对人工智能比较有印象的
或者比较限制政府的权利
主要的是这两个
这是the first amendment
这是跟英伦自由有关的
尤其是因为上周有这个新的来自美国贼告法院的一些新的判决
基本上扩大了
一方面是司法部的权利
第二方面是
就私立公司的一些英伦自由
尤其是在这个人工智能或者数字世界的权利
好
还有
我觉得前面的一些同事已经讲了
但是我美国也有很多同事也有很多同事已经讲了
但是我美国也有很多同事也有很多同事已经讲了
但是我美国也有很多同事已经讲了
但是我美国也有很多同事已经讲了
而我们也有很多这种资源的治理
而且不好意思
我这里写的这种资源是不对的
应该是资源
就是voluntary的治理
所以尤其是上读部下面的两个部门
就是MIST
还有MTLA
还有美国也有一个AI safety Institute
他们会出很多这种资源的承诺
还有资源的原则
负面上有一些人可能认为这些资源的过程是
负面上有一些人可能认为这些资源的过程
是
有点软的或者影响力不是太大的
但事实上我觉得
其实它的影响力其实是很大的
而且尤其是将来
它的影响力会越来越大
因为首先它会通过
很多企业的这种参与
所以它不只是
来自政府的一种愿望
而是这些企业
会包括他们的概念
而且如果后来
某个政府部门
真的要有一些所谓引发
就是hard regulation
他们就会从这些
自愿的原则开始
最后是去年的新政令
还有近年的很多
尤其是美国state department
出了很多发言
还有新的政策
就会比较强调
美国参与国际人工智能
智力的很多计划和事情
这个包括
就是今年的那个
联合国大会的那个决议
还有跟欧盟的一个
这个join statement
还有这个OECD的
global partnership
on artificial intelligence
这些很多他们想要的原则
其实跟昨天
刚出现的这些原则
其实跟中国人工智能
全球智力上海的宣言
也是有很多同样的一些价值观
比如说人工智能
应该符合人类的价值观
我们都应该一起合作
来产生一些安全
可信 可靠等等的人工智能
所以其实有很多
跟中国有很多相同的部分
好 我很快的讲中国的
我觉得中国的人工智能的
的治理也是一个比较大
比较复杂的
的生态
它一方面会包括
当然是政府的部门
但是除了这个之外
它也会包括
比如说企业 学者等等的
而我觉得它的一个特点是
它一方面完全不是联邦系统的
所以这个是跟美国是一个差别
但是事实上
我觉得政府治理人工智能的时候
它也必须通过一种下访
来真的落实这种
什么政策的
还有各个目标
所以这个所谓的下访有两种
第一种是从上面到下面
就是从中央政府到
比如说省政府或者地方政府的
但在人工智能这个领域
我觉得中国的人工智能治理
其实也有一种横向的这种下访
就是horizontal的delegation
因为它会从
就是很正式的政府部门去做这种下访
来下访到比如说企业平台
也到现在可以算是一种governor
或者也会比较依靠
比如说学习人工智能治理的一些学者
或者来自智库的什么专家
所以我觉得
负面上或者正式方面
中国和美国的这个系统
有很多比较重要的差别
但是我认为
事实上也有很多相同的部分
尤其是人工智能治理
必须看一整个这个ecosystem
一整个这个生态
好
所以目前人看中美人工智能的竞争
可能担心这也像一种
就是两个信息的碰撞
但说实话
我觉得尤其是通过
就是Matt之前推荐的那些做法
我觉得信息碰撞的时候
不一定必须是互相灭掉的
而他们只是有一种互相变化
都会变得可能更加光亮的
更加光明的一些新的信息
好最后我就是在说
在对话中有什么比较具体的领域
或者话题
我觉得也值得
就是中美的这种对话
第一个就是这个open source
开源的人工智能
第二是医疗中的人工智能
我觉得这个领域的潜力也比较大
也比较值得这种沟通和合作
第三是地方政府用的人工智能
比如说上海市
还有美国和欧洲的某个市政府
这种之间的对话
第四是人工智能奉献的制度
最后是太空中的人工智能
希望我可以多向你们学习
而且多跟你们谈一下这些对话的机会
谢谢
非常感谢陆凯研究员的精彩的演讲
那么下面是我们主旨演讲环节的
最后一位嘉宾
他就是
清华大学智能社会治理研究院院长
全国人工智能社会实验专家组组长
苏俊教授
有请苏教授
尊敬的各位专家
各位朋友
非常高兴能再次有机会来到上海
参加世界人工智能大学
智能社会论坛
这个论坛非常有意义
已经连续办了很多届了
今天再次跟各位专家
各位朋友一起
围绕智能社会治理问题进行讨论
我觉得也非常高兴了
前面几位专家都做了很精彩的报告
再往前面还有几位领导也做了讲话
也发布了一些成果
来自美国来自欧盟的专家
也分享了他们的一些很好的一些见解
我觉得对我们推动智能社会治理
做好人工智能赋能社会
促进人工智能向善发展
都非常非常的有意义
我今天简单给大家介绍一下
我是清华大学公共管理学院的
我是一个从事社会学管理学研究的一个学者
给大家从人文社会科学的角度来讲
来谈一谈我们如何去应对智能社会
给我们带来的一些挑战
大概说这么四个方面的问题
习近平总司司议提出要发展新制生产力
这两天我们在上海开世界人工智能大会
行行业业都在讨论人工智能技术
赋能到经济社会的各个方面去
其实大家肯定知道
我们在上海开这个世界人工智能大会
我们很有深深的体会
其实人工智能它就是在推动各行各业
形成新制生产力
人工智能就是新制生产力
是一种变革性的技术
会给我们的生产力的提升
带来很大的变化
不论是从生产要素
从产业各个方面都会带来很大的影响
你像现在我们
隔壁房间正在讨论的巨神智能
讨论的机器人
我们上海正在推动的无人驾驶
现在的脑机接口
量子通讯
其实都会成为很大的新制生产力
科学技术的发展历史
就是跟人类社会的发展历史
紧密的结合在一起的
但另一方面
AI技术的影响又是全面而深刻的
刚才很多
专家也都谈到了这个问题
每一次科技的革命的重大突破
都会带来生产力的巨大跃升
和生产关系的颠覆性变化
它是两个方面的
一方面带来生产力的发展
但是大家不要忽视了
还会带来生产关系的变化
还会带来人的观念
人的认知的升华
和社会结构的这种缠变
我们现在这个AI技术
正在重塑全球创新版头
正在重构人类文明的秩序
也正在推动人类社会的智能化转型
我们正在迈入的智能社会
我们会遇到很多风险和挑战
我们不能只看到
AI技术形成新制生产力
带来经济增长的这一方面
它对社会的这种影响实际上是很全面的
刚才很多专家其实也都谈到了这个问题
刚才很多专家其实也都谈到了这个问题
刚才很多专家其实也都谈到了这个问题
比如说这种带来的这种失业
贫富差距
去组织化的变化很大
工业社会是一个组织化的社会
我们都被组织成一个一个的社会单元
但是在智能社会里面
组织的特征正在消解
这种量子化的
被网络在赛博空间里面
重新构筑起来的这样的一个个体
这些事情都会发生
这些事情都应该引起我们的关注
另外媒介操纵对人的认知
对人的舆论的控制都会带来很多变化
带来很大的风险
人的价值观和思想认识而产生变化
我们在智能社会里面
许许多多的我们的旧的观念
旧的思想
旧的认知正在调整
我不知道大家在座的
特别是青年朋友们有没有这样的体会
许许多多的我们的旧的观念
许许多多新的认知
甚至新的文明的形态
新的合作行为
新的这种世界观
都在发生着很大的变化
你可以去体会一下
你这些年有没有这样的变化
还有社会的系统脆弱性也在发生变化
我们今天的社会越来越复杂
今天的社会是靠多个信息系统
构建的一个复杂的技术系统
这个复杂的技术系统
它会带来社会的更多的黑天鹅和灰犀牛
带来更多的潜在风险的隐患
所以你会看到今天我们的社会
会猛然之间
一个大家熟知的一个偶像
一个大V的形象
完全的塌灭
实际上就跟这个是很有关系的
对吧
另外还有一个
就对智能技术
跟我们的生态文明
也有许多对生态文明的理念和观念
还有也会带来新的挑战
一会我也会讲一下这个问题
刚才讲的这五个风险和挑战
其实我是在去年的论坛里面讲过
我刚才就很简单的给大家提一下
去年把专门讲过这五个问题
那现在我的略微简单的介绍
介绍最近我和我的同事们
我们学院正在研究的几个智能社会治理的前沿问题
略微给大家提一下
应该说我们从学术研究的角度
从社会科学研究的角度
面临的问题是很多的
需要研究的空间是非常大的
经常说时代是粗体人
我们是打卷人
我们这一代人从学校的
学术研究的角度来说
我们面临的许许多多的
很值得研究的问题
不论是在我这样的公共管理学院
还是在经济管理学院
刚才像吴志强院士说的
他们规划
你看现在都跟人工智能技术完美的结合在一起了
有许许多多的问题
像这样列的一些问题
其实都可以值得大家的关注
最近这些年我一直有一个团队
一直在研究游戏
我们现在人类花很多时间在网上玩游戏
我们小朋友
还不会说话的时候
他就会玩游戏了
游戏是人类文明的新的训练场
和人类习性的养成的地方
千万不要忽视这个问题
特别是这个促平一代
新的一代孩子们的
他们游戏对人的影响是非常大的
对吧
我简单给大家介绍一下
关于信息减房和群体集化这个问题的研究
信息减房现在越来越关注这个问题的人越来越多了
大家可以看到各种学术杂志
都在发表跟信息减房有关的一些文章
我们在智能时代
我们在今天这个社会里面
人类发明了一个非常重要的工具
叫什么
叫精准推送
精准推送这个东西在工业社会是没有的
工业社会所有的信息传播都是广播式的传播
电视广播是广播式的传播
跟受众的特质没有任何的关联
但是今天
我们各位获取信息的方式
都是跟你的个体的受众
跟你的偏好
跟你的特质
跟你的文化
对吧
跟你的学术的历史都直接有关的
这个精准推送呢
成为我们今天这个社会生活中离不开的一个东西
这个它为个体呢
提供了很便捷的信息获取和分享的渠道
提高了广告的效率
提高了营销的这个这个效率
但是另一方面呢
它加剧了我们信息减房的形成
我们每个人的知识
每个人获取的信息
都是越来越被包裹在一个像减房一样的东西里面
我不知道你们有没有这样的体会
你会觉得有一些人
他对某些问题特别的了解
对某些观点特别的赞成
对某些认知非常非常的这个这个这个这个
强烈的反对啊
强烈的这个这个抵触
社会之间的这种冲突撕裂对抗
其实越来越多了
这个问题呢
其实都是今天由于精准推送
这样的一个人类的这样发明的这个工具啊
所导致的
而且我觉得呢
随着社会的进程啊
这个精准推送导致的信息减房
所导致的社会撕裂还会越来越严重
它一定会成为我们智能社会的一个顽疾
我们以后几十年上百年
我们都离不开这样一个东西
这个影响会越来越大的
那么究竟
那这样的情况下
我们为了治理好这个信息减房
我们就要去研究这样一个基底
研究它形成的基底
研究它的这个形成的过程
所以呢
我去年呢
跟我的同事们
跟我的这个团队
一起呢
给予这个5.7亿的这个社交平台的用户数据
这个第一次的实证的呈现了信息减房的存在
信息减房是一个理论上的一个命题
但是怎么能观察到
就像人类讲的黑洞
你怎么能看到黑洞
能测量出黑洞
这是一个很难的问题
所以我们去年的研究成果呢
这个观察到了信息减房的存在
第一次实证观察了
而且研究了它的相变机理
这个归纳出了四个非常重要的影响它变化的要素
这个成果呢
在这个自然的子刊
叫Nature Machine Intelligence
这个上面发表了
大家有机会可以去看一下这个文章
我想这篇文章呢
对于信息减房基底的研究
对于我们人工智能的治理
对于平台的治理
对于算法的治理
提供了一个非常重要的一个基础
提供了非常重要一个基础
信息减房的影响是全面而深刻的
它会导致呢
这个个人认知的极化
这个个体的极端观点呢
在群体中激荡
还会导致群体的极化
这个人以类聚
人以群分
我以类聚
人群
同样观点
人群同样观点
同样认知
同样信息的人
大家注意到没有
现在都是在一个群体里面
它会互相激荡
形成马太效应
所以我们现在的群体的观点极化
在这个社会里面
也是非常严重的一个问题
对吧
这个
另外呢
赛博空间呢
为这种极端化的观点的表达
提供了环境
这个现在的这个常委效应啊
这个非常非常的严重
会导致这方面的一些变化
这个
第二个这个研究的问题呢
就是灵活就业与劳动替代的问题
今天很多
包括刚才这个几位学者
国外的朋友都讲到这个问题
就业是一个很大的一个问题
就业影响很大的问题
但是大家注意到
以前我们讨论机器人
讨论自动化
对就业影响的时候呢
都是说它是对体力劳动
对重复性劳动
对这个非智力劳动的一种劳动替代
对这个非智力劳动的一种劳动替代
今天人工智能
特别是生成式人工智能的影响
它的劳动替代
是对创造型劳动的劳动替代
对知识型劳动的劳动替代
对各位在座的各位
会产生一种劳动替代的
大家千万不要忽视
这样的一个事情
现在它在金融 医疗 法律 文艺 创作
甚至在我们教育行业
都产生了很大的劳动替代
都会对我们产生很多的影响
同时它也会产生贫富差距的分化
大家现在也在经常讨论
AR技术的发展会不会缩小贫富差距
还是会加大贫富差距
这个方面一直有这方面的深入的讨论
劳动替代会导致一个
一种是新兴的劳动行业的兴起
但是劳动替代还会产生一个很大的问题
大家注意到没有
我们以后未来的社会
大量的工作
是不用人去做的
或者说大量的人是不用去工作的
这个是一个很复杂的问题
人类社会之所以能发展到今天
是因为我们在与自然
在与野兽的搏斗中
形成了这回组织
我们把生产作为第一需要
把劳动作为第一需要的时候
我们才能构成了今天的社会
但是以后假如大量的人都不去工作
我们怎么度过这种无意义的时光
人类群体如何都不工作的时候
是个很麻烦的事情
如果你一个人两个人不工作
你可以去闲暇时光
可以去游览
可以去旅游
可以去从事文艺创作
整个社会都不工作了
是一个很复杂的事情
所以我觉得现在
我个人一直在研究就业
失业
我觉得是人类的工业社会的两种工作状态
其实在我们未来社会里面
我觉得还应该有一种工作状态叫游业
这种他不参加社会生产性的务工劳动
或者是工业的工作状态
或者不以劳动作为获取经济的回报
这个是非常重要的
这个回字写错了
抱歉
错一个错别字
回报
就是大量的人都不工作
但是他很幸福
他很有很好的经济收入
这个社会是非常重要的
所以我们要研究这个问题
现在世界各地有许多地方在推动全民基本收入实验
我一直非常关注这个工作
他就在做大规模的社会实验
但人都不去工作了
社会是一种什么样的组织形态
假如咱们上海选100万人
说100万人你们去不工作了
对你们进行跟踪调研
一定是一个非常有意义的一件事情
那个社会会非常好玩
对吧
这是一个
另外我再介绍一个我们中的做了一个工作
就是大模型的价值观的评测
由于时间的原因
我下面会介绍的快一些
大模型的社会观评测简而言之
就是把大模型看成一个认知论上的一个人
任何一个大模型
它在生成知识的时候
它都有一个本底的社会价值观
而这个社会价值观在它应用的时候
会产生放大作用
它的社会价值观是什么样子
它对应用时会产生很放大
那么我们现在就花很多时间在研究不同模型的社会价值观
现在初步的研究发现
我们现在
国家备案的这些大模型
包括国外的大模型
其实社会价值观是不一样的
这个我不知道以后会产生什么样的结果
但我觉得这个是个正常现象
就跟我们每个人一样的
大家都是叫人性本善
对吧
但是你那个发端还总要有一点点不一样
对吧
所以这个我觉得还是值得深入的这样一个研究
另外一个问题就是关于人工智能与能源的问题
人工智能与能源相生相克
我觉得大家
现在讨论的都是人工智能去促进生产力的发展
其实我更建议我们的企业家
这个人工智能的技术专家好好去研究一下
怎么用人工智能去减少碳的排放
提高能源效率
这个问题是非常重要的
我们要想尽一切办法缩小人工智能技术的发展与绿色发展之间的夹角
不能让这个夹角越来越大
这个夹角越来越大的话
我们的社会是失败的
这不是很好的一个问题
所以要关注这个问题
人类历史上应对历史的
应对技术发展的变革的经验是非常多的
今天其实大家都讲到了这样一些东西
是时间到了不能翻了是吧
抱歉抱歉
我觉得简单说吧
一个就是知识分子
社会精英
应该处于人文主义精神和强烈的社会责任感
关心这种突破性技术的社会影响
在这个方面多发声多呼吁
像爱因斯坦早期跟罗素推动的罗素爱因斯坦宣言
包括后来形成的帕克五师科学与世界事务会议
大家都可以去关注一下这个问题
这个工作对于今天我们控制核武器
控制把核武器关进制度的笼子
保持人类社会的平衡性的平衡性的平衡性
是非常有意义的
今天人工智能的全球治理
我觉得要好好学习一下
帕克五师科学与世界事务会的一些精神和一些做法
第二条就是政府基于公共利益和公共价值
采用多种综合的政策工具
引导技术创新有效规制风险
政府不能在这个时代缺失
不能在这个时代放弃它的立场
因为它们是我们进行
社会价值最大化的一种方法
一种很强烈的一种这方面的职能
应该去在这方面多做一些工作
另外还有一条就是讲给群众的
讲给我们在座的
我们这每一个普通的人的
大家要提高科学素养
增强风险意识
积极参与技术变革的治理
我认为技术变革
人工智能的影响
人工智能的国际治理
一个是社会精英的事情
是刚才讲的
路克讲的政府之间的
马克讲的
政府对话
民间的对话的问题
但更多的是要群众要觉醒
群众要参与
群众要知道这个方面的风险
社会群众不能是在社会变革中
成为沉默的大多数
应该积极地参与这样的一个活动
公共空间不能没有普通人的声音
人也不应该成为技术的附庸
在今天我们讲智能社会
讲人文精神这样一个时代
这一点是非常非常重要的
当然
刚才也讲到了企业的社会责任
企业履行社会职责这方面的事情
也是非常重要的
所以在这样的一个背景下
我想我们应该为后代留下一个什么样的智能社会
当然它是海
我这个是人文智能社会
这样的一个东西
应该是价值理性和技术理性综合平衡
社会就需要技术
也需要这种价值理性
和谐包容开放这样一个时代
这个工作得到了中央
得到了政治层面领导人的高度的关注和支持
总书记在多个场合都要讲
我们要关注我们未来的社会这样的问题
19年的时候
5年前我们清华大学的学者
还有一些其他高校的学者
发起了一个倡议
叫开展人工智能的社会实验
探索智能社会治理中国道路
这一条
我觉得应该是一个很重要的问题
应该是世界的道路
探索智能社会治理这个倡议
得到了社会各界的广泛的响应和积极的支持
现在这个工作被写入了中央的文件
中央的文件里面也专门讲到了这个工作
然后现在国家市场监督总局
进行标准化的建设
通过标准平衡公共利益
企业利益和社会的需求之间的关系
现在也专门有这样的标准化组织
在负责这方面的工作
还有就是我们的政府
八部委联合建设了92个全国的智能社会治理实验基地
我们今天杨浦区和同济大学就是基地的之一
而且也是在所有的这92个基地中
我觉得应该说是做的最好的基地之一
受到了国家的表彰
八部委最近发文
对这个工作进行表扬
进行表彰
那么最后呢
就让大家
用这个一千年前啊
宋朝的这个张载说的这四句话
大家肯定都知道
为天地立心
为僧民立命
为往圣祭绝学
为万世开太平
我想今天我们这个时代啊
大家要一起努力
为智能社会呢
要嵌入人文精神之心
我的这个介绍就这些
谢谢大家
谢谢苏老师的精彩演讲
因为时间关系啊
没有完全讲透啊
但是你听到黑丝理论也是和这个
也是一个异曲同工
这样呢
我们六位嘉宾
六位嘉宾呢
都做了精彩的演讲
大家在场呢
也都听得非常投入
相信呢
各位嘉宾的演讲啊
对于我们进一步的了解
这个相关的
各国的
人文智能事业发展的
现状和趋势
都有了很大的启发
正好呢
时间也就到了
实际上超稍微超过了几分钟啊
非常抱歉
但是人们不是说吗
这个不脱堂的研讨会
不是成功的研讨会
所以我们拖几分钟
但是呢
因为他这个场地啊
他是这个大会
他是盯着的
下午还有活动
所以就不得已呢
就现在主旨演讲
完全就只能打住了
好
那么下面呢
我们就有请啊
我非常尊敬的
我们的主席
纪伟东老师来主持
下一节的
圆桌对话环节
好
有请纪老师
纪老师呢
是上海交通大学
人文是
人文资深教授
是上海交通大学
这个人工智能治理
和法律研究中心的主任
有请纪老师
好
请其他的几位
圆桌对谈嘉宾
一起上台
在过去两百年间
内燃机互联网大模型
对社会产生了
非常实质性的影响
对社会产生了非常实质性的影响
尤其是进入
大模型阶段之后
人工智能快速迭代
我们可以看到
规矩生命技术革命
正在对社会产生
非常深刻的影响
这种影响啊
我们很难预料
它会往什么方向走
一方面当然
赋能个人
赋能平台
赋能社会
对吧
这个积极的作用
大家都看到了
它可能会使得
人类的社会
进入一个创新自由
甚至无中生有
这样一个阶段
但另外一方面呢
又让我们感觉到不安
因为发展太快
有很多的风险
那么今天呢
很高兴有机会
和五位对话嘉宾
来探讨
智能社会的
全球治理问题
首先我想请
第一位对话嘉宾
李仁涵先生
他曾经引领过
中国的
中国的智能社会
人工智能治理
而且不久前出版过一本书
就是
人工智能治理与国际规则
首先请李仁涵教授
来谈一谈
这个人工智能治理当中
各国的立场
有什么样的不同
我们需要全球治理
但是各国的立场不一样
他们有什么样的不同
那么另外一方面呢
在这样的情况下
我们如何才能加强
人工智能治理的国际合作
李教授
好
谢谢季老师
因为这个人工智能
上海的人工智能大会
我从第一届就参加
一直到今天
就是等于每届我都参加
然后呢
这个这次呢
让我感觉到特别的不一样
主要就是因为把治理加上了
过去啊
我们世界人工智能大会
主要是谈技术
主会场没有一个报告是治理的
这次呢
等于是主会场
加了一个治理的报告
也是我过去一直呼吁的
那么这次呢
兑现了
就是我特别开心了
这是一件事
第二个让我感觉到了呢
我前两届我有点失望
因为美国对中国的禁止
就是虽然我们叫国际会议
但是看不到一个从国外来的人
都是我们中国自己在讨论
而且外国专家
他本身也完全躲避了
因为美国欧盟
美国制裁嘛
欧盟就跟着
所以很多人
他连视频都不愿意播放
一个给我们
所以我们前两届
几乎我们都是中国人自己在谈
这次呢
感觉到非常开心
来自德国的美国的
还有好多国家的
我们都非常的高兴
也非常欢迎
因为从这个技术的角度讲啊
如果我们技术上不交流
我们何谈治理呢
所以在美国政府
如果对我们要求治理合作
而技术不得了
如果我们不谈合作
你说我们怎么合作
所以这是
我觉得今后一定是
技术上一定要合作
才能达到治理的合作
这是前提
那么我们再回顾现在来看了这个
人工智能技术发展到今天
现在我们确实可以这么确定的说
也是我们的研究
我们团队包括季老师在一起
我们都研究过
人工智能的基础理论体系
现在没有建立
这个我就不再太深的再往下讲了
因为我们有研究报告
然后这次的大模型的出来
世界上最强的大模型出来以后
只有60%与人是吻合的
那40%的结论是与人相搏的
那么基于这样的情况下
你能够完全相信这个大模型
所以我们的治理
今天提到这么一个高度
大家全世界都认识到
而且最近美国一直讲要把AI关到笼子里
但是建一个什么笼子
这需要大家讨论
也是季老师刚才问我的问题
所以我也想等会儿我再说一下
所以我现在首先要强调就是国际治理
一定是技术治理同时合作
才会达到最后
我们苏教授提出了这个人文的
一个智能社会
否则的话是不可能的
而且大家心平气和地做
它跟核的这个协议还完全不一样
核它技术专业性很强
只要有一部分人给它封住了
它就封住了
这个是太有普遍性
每个角落都有
无处不在的
你怎么管
这是我们人类未来的一个命题
所以另外我再讲讲
关于价值观的认识
在人工智能的问题上
实际上我们那次跟傅大使在一起
2019年我们开的闭门会议
跟国际的IHPE的主席一起讨论的结果
大家有一个共同的认识
人类的价值观实际上是一致的
跟制度没关系
它的价值观是什么
是以人为本
共同的价值观
在这种共同的价值观
大家不要再去研究乱七八糟的制度不同
怎么怎么的
实际上你只要以人为本了
人工智能的治理就能做了
就是我们要把复杂问题简单化
因为政治家们喜欢用价值观
来整这个整那个
实际上对于我们是为人民服务的国家
我们一定要把它以人为本
价值观人类的价值观是一致的
没有区别的
我是认为这个问题要简单的处理
如果你不简单处理的话
你永远卖不了这个卡
而且各有利弊的
因为时间关系我想
先把第一个问题谈一谈
就第一个问题
为什么我们要治理
因为人工智能的基础理论体系没有建立
所以它在
开发的前面的提到的一些设想
最后出来的结果
设想是达到了
但是又出来了
与你完全不知道的结果
这就是因为基础理论体系没有建成的结果
就是说
开发者开发出来的产品
最后的结果会出乎开发者的意料之外
这种意料之外有好的也有不好的
那么就是不可控了
也是不可信
那么我们怎么办
那么这是第一个问题
第二个问题我就在谈的
就是说刚才鸡老师问我
世界各国做法有什么不同
实际上世界就是
等于是目前全世界就是三大阵营
一个是美国
一个是欧盟
一个是中国
三个做法就是
而且我认为各有利弊
多有特色
他们之间没有谁先进也没有谁落后
怎么是做法不一样
关键我们是要大家坐下来好好的谈一谈
我们怎么办
无非就是这几个问题
技术标准
知识产权
技术标准
法律法规
然后
最后共同怎么监管
就把这几件事情大家一起讨论好然后
做下来
成立很多的组
来把它做好
因为我们都有特点
你说世界上如果大家可以想象一个问题
全世界如果没有中国参与人工智能治理
这个世界会怎么样
中国人工智能的人才水平不一定是最高的
但是他的队伍是全世界第一的
如果把中国拒之门外
这个结果是很难想象的
第三件事情就是关于怎么建立
你刚才问我如何构建
人工智能
这个国际秩序这个人工智能的这个组织如何构建
因为时间关系我们前两年出版了一本书
叫人工智能与国际准则
大家在网上查一下目前全世界就这一本书
你只要打写写上人工智能与国际准则就这一本书没有第二本书
我们所有的内容我们
都写在里面了
而且现在我看了以后我觉得
这一点都不落后
仍然是可以回答今天季老师提的问题
我觉得因为时间关系谢谢大家
我先说这些
李教授三番就简说明了这个问题
其中有一句惊人之语
就是把AI关进笼子里
当然因为是出于安全的考虑
但另外一方面
AI有需要发展
它能赋能社会赋能经济
这个时候关进笼子
究竟会不会
影响到AI的发展
关于这个问题我想请今天的主办方
同济大学金管学院的
钟宁华教授
谈一谈
安全与发展之间的关系
应该如何平衡
好的
主持人好
各位嘉宾大家早上好
那么很高兴能够
做一个分享
谈一谈我对于
人工智能在
社会治理和经济上面的
一些理解
那么首先就是这个经济的发展
很大程度上是
源自于技术的
更新
在过去的几百年当中大概有五六波大的技术更新
技术变革
那么都带来经济的繁荣
所以在经济学里面有一个叫康波周期理论
大概五六十年
一波大的技术变革
带来全世界至少是某一些国家
经济的
大的繁荣
那么因此我们非常期待这一波的人工智能的技术能够带来
新的
经济的繁荣
那么今天讨论的问题更主要的是在谈治理
所以我就谈一谈
我们的一些理解
就经济当中有很多的经济是一个非常
大的且复杂的一个系统
那么我看到当中的一个重要的应用就是人工智能结合大量的数据
对经济
进行一个预判
以及对经济当中的风险
进行一个识别
我跟大家介绍一下我们做的
两项工作一项工作是
我们每个月都在预测
这个上海的总出口上海大概每个月大概会有
一千万到两千万
一千亿到两千亿当中的
出口
我们要预测两个月之后上海的出口会是多少
那么我们是用一百多个变量
去
应用这个人工智能模型去做一个预测目前
这个误差率已经从原来的10%降到4%
对于出口来说这是一个非常不错的一个预测
在全国的海关当中是做得最好的
那么这就是一个应用
就是对于出口而言影响的因素太多一百多个因素
你靠人去判断是很难的
但如果你能够很好的训练模型
去判断
他的判断就会比人更加准
而且进一步他会告诉我
假如说出口出现一些下降
可能主要的原因是什么
就一百多个变量当中大概哪些因素是重要的
driving force
就比如说我们就看到上海的出口和上海跟苏南地区的
货运
之间有很大的这个关系
苏州到上海有多少货运
这个是一个很重要的一个因素
那么这就去提醒我们如果说上海的出口发现一个很大的变化
那么是不是跟苏州这边是有些什么样的一个关系
那么这就是一个例子
来对于人工智能结合大量的数据
对于宏观经济做出判断
我再举一个例子就是
这两年大家越来越关注地方债务问题
那么尤其是这个承头平台
大家知道这个承头债有多少吗
全国总共有两万只承头债
每天在交易
那么我们另外一个团队就在做
我们用三百个别的
变量去预测
哪一只承头债在未来一个月里面
可能会发现
发生大幅度的价格的下跌
就是一个影响一个承头债的因素会很多很多
它的地方的经济的情况
承头公司自己的情况
每天出现了大量的新闻的舆情
就是我们要用很多很多的模型和数据
然后去预判到底哪一个地方的承头未来有可能会出现
大的风险
其实本质上是让人工智能模型去学习
之前
出现过风险的那些承头
那些地方
它长成什么样子
或者说做一个画像
如果你能画像画得很准的话
你就能够去预判未来哪一只承头
有可能会出现比较大的风险
那么从而去提示
哪个地方的地方债务
是需要关注的
那么这就是另外一个应用
就是在经济和金融体系当中
有一些风险
那么原来那是靠人去识别的
现在如果你有大量的数据
你就可以去训练人工智能的模型去画像
然后去识别
那么它的准确度
可以不断地提高
而且它至少能够跟人的判断形成一种互补
从而能够更准确地去判断未来可能会发生的事情
以及去识别它背后的影响因素
那么在今天的
从第一个演讲到现在
其实一直出现一个词就是安全
我们也很担心人工智能的误用
所以我想
其实前面很多的演讲都提到这个问题
数据
是最重要的
对于人工智能模型的训练而言
我觉得数据至少70%到80%
后面才是算力和算法
那么对于这个数据的限制
对于数据的管制
隐私的保护
可能对于安全而言是至关重要的
因为很多前面的专家都提到这点
我就不再展开
那么出于时间的关系
我就先做这些分享
主持人
在智能社会算法构成一种权力
那么数字国家
和数字人权之间的关系
成为一个非常突出的问题
这个问题我想
请这个就是
这个
吕鹏先生
和这个罗士仙律师
分别用
两分钟的时间
对不起啊
因为时间关系
来简单说明一下自己的看法
好的
刚才那个季老师说这个
强大的国家
我们一般把它叫做数字立委谈
实际上
除此之外
我们还对
对资本
也感到非常恐惧
大家一般把
国家和资本当作是侵犯
所谓人权或者公民权的最重要的这个威胁
那有两种方式应对
第一种方式就是
消极
通过立法
通过这个铸造防火墙
公司搞这个企业社会责任做科技向上
但我想更重要的其实是一个更积极的
一面
就是我一直在倡导的
要真正的维护社会权利
就是要通过社会创新
有一个非常著名的历史学家叫克兰茨伯克
我稍微讲快一点
他有两个非常
他有六个科技进步的规律
其中两条
第一条讲科技不分好坏
但亦非中立
就有的科技本身
它的应用的过程
它其实并不是中立
第二
发明是需求之母
我们现在一旦讲到社会的时候
原则上我们可以说
社会你保护自己
社会组织起来
我们参与到自我权利保护
但为什么社会要组织自己
每个人都是个人
都是个体的
他为什么要参与到保护自己的权利呢
我们在业主维权中
如果大家知道
在业主维权中
最简单的一个现象
现代的问题不是业主跟业委会闹
是业主跟业主之间都闹得不停
他怎么组织起来去参与到保护自己的权利呢
面对这样一个非常具体的问题
实际上我想最重要的一个办法
就叫社会保护权利
社会创新
社会创新有很多维度
其中非常重要的一点
就是要依靠科技的发明创造
通过科技本身来解决社会问题
比方说
我们可以用数字化的手段
业主委员会的相应的APP
我们进行三无公开
就很好的
就能够解决业主和业委会
业委会和物业之间的关系
再比方说快递小哥
他不能够进社区
最后一公里我们没有办法打破
用各种办法可能都不好使
但可能最好的一个办法
你给快递小哥弄一个什么码
他直接就可以通过层层的限制
就能够进入到最后一公里
因为时间关系不能直接展开
所以我想讲的是
真正的要想维护
每一个个体
每一个社会群体
在数字时代的权利
一是通过立法
通过资本向善
但更重要的是要用科学技术的方式
摸清社会的办法
用发展的办法
来真正的保护公民权
好 谢谢
下面我们再来听听美国律师罗士轩先生你的看法
谢谢
不好意思 大家好
我的中文没有卡门那么厉害
所以我可能用英文讲
所以我认为
我认为
我认为
我认为
我认为
我认为
我认为
我认为
 vemos有网民去大学
我们在代出审核动员等计划
途中
尝试了解
本身的审判
上传过的
致力所以
律师想着如何套用
本身的审判
为新技术遵循
与公司谈论
但小孩子练习
为他们理解他们的 starring
 이�oston
网 那个广üm
 controlling
非常有趣的是網絡障礙、網絡安全
這些法律在全球發展中
中國在遊戲業上
已經很久都在研究這些
但在我自己的國家
英國現在有它的網絡安全法
我們看到歐盟電腦計劃
也在這方面集中
所以我認為法律
有一個非常重要的角色
當他們從他們的
學術技術體系
進入科技思維
能夠幫助社會
以及我們的客戶
甚至是從CSR的角度來看
也許可以幫助
這些新的技術和新的法律
非常感謝您的精彩評論
謝謝您的介紹
謝謝您的介紹
謝謝您的宣言
大家說一個觀點
拿出三分之一的所有的投入
來放到整個的AI安全裡面
其實這件事情
大概我們能其實感知得到
大家對這件事情的擔心和顧慮
但本身我覺得
其實是一個比較難落地的事情
我們拿三分之一的話
我們如何度量
為什麼是三分之一
不是二分之一
不是四分之一
然後我們怎麼樣去衡量
哪些是AI安全的事情
其實包括Hint
包括
Elon Musk
其實他們經常在說很多
就是說
例如說OpenAI
現在其實做了很多主力的事情
那其實他們花了很多錢
在做Align這件事情
就是對齊
那他們在做對齊這件事情
是不是一個安全的事情
其實這個都有所
我覺得定義吧
那至少從作為一個企業
或者作為一個
我這個技術人員的個體而言的話
其實我覺得我們現在
可能還不用那麼太擔心
這個
這個這個這個
這個問題
就我們可能現在還是
盡可能地不阻擋地
讓它蓬勃地發展
例如舉一些例子
就是我們因為這個飛書
其實跟很多企業共創嘛
我們會發現
其實真正起效果的
我們現在不是擔心AI發展太快
而是擔心太慢
給大家舉一個例子
一個1000人左右的公司
它現在用AI來去做一個什麼事情呢
並不是我們認為很多高大上的事情
其實最後都落不了地
但有些東西能落地
第一件事情是翻譯
就翻譯這件事情
其實我們已經做了很多年
但是我們看今天
還有同聲傳譯的這個同學
來去跟我們進行翻譯這件事情
包括做了我們做很多
Motion Learning的這些東西
但實際上我們其實有了
這波AI之後
1000人左右的公司
一年能多省76萬
來在翻譯的一個場景裡面去
我們跟很多跨境出海的遊戲公司
教育公司
大家說
我有好多外包人員
我來去翻譯
那現在由於AI來了
我這些人要不要
還是要的
但是這些人從以前的填空題
變成了選擇題
他只要檢查AI翻譯的對不對就行了
所以這其實是我們看到的一個點
另外其實
我們除了那些fancy的
我們一個是翻譯的場景
就會看到真正的效果
另外的話
整個字節跳動的話
有十幾萬的人
但其實我們只有很少數的
幾十個人
在7乘24小時的去服務大家
在這個IT
你電腦有什麼問題了
你有什麼連不上網了
這些人只要7乘24
只要這麼少的人
那是為什麼呢
其實因為我們大量的這種知識問答
已經變成AI來去問答了
那AI來去問答的就是
其實包括大家各自在這個公司
和在學校或者各種組織裡面
很多問題是被重複問的
我什麼時候發工資啊
我的無限一金怎麼繳納呀
在這個裡面我也進行了一個測算
差不多在一個單的部門裡面
就是一個800人左右的這種科技型公司
一個單的部門
例如是一個法務部門
就能一年節省30萬
就通過AI來去解答這個問題
而不是雇一個人
那其實它有HR的部門啊
行政的部門
所以這種計劃我們看到其實很多
我們現在的一個總體認知的話
總結下來
我們覺得AI還至少遠沒有達到
能給大家進行威脅的程度
包括現在我們其實很多東西
都受限於底座模型
所以我們覺得就是
短期的話呢
我們其實還是希望
能夠給AI更多的這個機會
讓它蓬勃地發展起來
因為我們看到了
其實本質上的話
很多的從前
其實重複的這些工作
很包容的這些工作
來再被AI所代替
那總體而言我們覺得
這件事情不是壞事
就是總體讓大家整體工作的幸福感
可能會更提高
包括我們有些程序員
其實在用讓它這個蓬勃發展
最後大家帶來福祉的吧
這是我們的感覺
那個關於企業的
剛才談的這個意見
李鴻教授
您從經濟和管理的這個角度來看
您是怎麼看這個問題的
其實我覺得剛才飛叔說的
就是我一直在倡導的
叫做企業社會創新
其實就是把企業的技術和能力
應用到它的社會場景當中
讓真正的所謂科技向善
能夠在產品 在服務
在這些場景當中
解決實實在在的社會問題
這我才是覺得最為可持續的
讓公民 公眾參與到
所謂AI治理當中最重要的方法
因為你首先要讓它富能
讓它有動力 有能力
來參與到這個AI治理當中
否則一切都是空中樓閣
只是紙上談兵
好的
最後我們請李仁涵教授
用一分鐘的時間
對剛才我們討論的問題做一個總結
看看人工智能治理
這個方面今後發展的方向何在
就是我在7月3號的時候
我在朋友圈裡面我發了一段
就是AI是否要被關到籠子裡
當前不一定
不遠的未來必須
這就是我今天的感受
也是跟我7月3號是一樣的
謝謝大家
謝謝五位對話嘉賓
在非常短的時間內
做了精彩的呈現
下面我們今天的討論就到這裡
時間已經不早了
謝謝各位
再一次感謝各位專家學者
帶來的精彩的圓桌對話環節
再一次感謝各位尊敬的各位領導
各位嘉賓
本次論壇的全部議程
到此已經結束了
最後再一次感謝各位領導和嘉賓的播放
謝謝各位
謝謝