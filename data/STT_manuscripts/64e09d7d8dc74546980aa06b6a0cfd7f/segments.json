[
    "请不吝点赞 订阅 转发 打赏支持明镜与点点栏目明镜需要您的支持 欢迎订阅明镜明镜需要您的支持 欢迎订阅明镜明镜需要您的支持 欢迎订阅明镜尊敬的各位领导 各位专家学者 女士们 先生们 大家上午好盛夏七月黄浦江畔 加克云集由同济大学上海市杨浦区人民政府联合举办的2024世界人工智能大会智能社会论坛隆重举行本次论坛以智能社会与全球治理框架为主题 旨在促进人工智能向善发展造福智能社会 人类美好生活接下来请允许我介绍出席今天论坛的各位领导和嘉宾他们是同济大学党委书记方守恩杨浦区委副书记区长周海英上海市委网信办副主任杨新上海市教育委员会副主任王浩同济大学常务副校长吕培宁杨浦区委常委常务副区长倪斌杨浦区副区长刘静元同济大学党委常委宣传部部长端木怡文出席今天论坛的还有十余位人工智能领域的国内外知名的专家学者同济大学杨浦区相关部门负责人及企业嘉宾等让我们用热烈的掌声对各位领导和嘉宾的到来表示热烈的欢迎和衷心的感谢接下来我们进入论坛的开幕致辞环节",
    "首先让我们掌声有请上海市委网信办副主任杨新致辞杨新致辞尊敬的方书记周区长各位嘉宾大家上午好很高兴参加由同济大学和上海市杨浦区人民政府共同主办的2024世界人工智能大会智能社会论坛我仅代表世卫网信办向论坛的举办人们表示热烈的祝贺向出席论坛的各位嘉宾表示诚挚的欢迎向长期支持上海智能社会治理工作的各位同仁表示衷心的感谢中国高度重视人工智能发展和全球治理去年10月习近平主席在第三届一带一路国际合作高峰论坛开幕式主旨演讲中提出了全球人工智能治理倡议主张坚持以人为本智能向善支持形成具有广泛共识的全球人工智能治理框架和标准规范今年5月习近平主席在法国进行国事访问期间中法两国发表了关于人工智能与全球治理的联合声明在昨天的开幕式上李强总理指出人工智能发展迫切需要各国深入探讨凝聚共识共抓机遇共克挑战中国愿与各国一道推动人工智能更好服务全球发展增进人类福祉共同走向更加美好的智能未来人工智能全球治理上海宣言也强调只有在全球范围内的合作与努力下我们才能充分发挥人工智能的潜力为人类带来更大的福祉人工智能问题正超越单纯的科学技术成为国际社会的重要一程也是中国积极参与完善全球治理体系改革和建设的重要领域由同济大学和杨浦区共同举办的智能社会论坛今年已是第三届今年的主题是智能社会与全球治理框架相信通过政府高校的久久为公持续合作发力将为我国智能社会建设和参与人工智能全球治理贡献更多理论与实践相容的路线图杨浦区是国家创新型城区人民城市重要理念的首提地也是全国唯一由政校联合申报的国家智能社会治理实验综合基地自2021年基地获批以来杨浦区联合同济大学通过聚合多主体参与整合多学科力量共同致力于智能社会治理的探索与实践取得了丰富的研究与实践成果在国家网信办等八部门口中联合组织的基地中期评估中杨浦区入选工作进展明显成效突出的综合基地名单在全国基地中名列前茅期待杨浦基地能继续紧跟前沿方向丰富场景建设在超前探索智能社会治理的实践道路和运行模式上取得更大进步那么借此机会就国家智能社会治理实验基地建设谈几点想法与大家讨论一是加快推出服务治国理政的实验成果强化研究主体力量围绕大模型等人工智能前沿技术应用挖掘典型场景提炼经验成果总结共性问题研究社会影响探索标准法规提出政策举措二是加快落地人工智能前沿技术应用充分调动实验基地技术主体应用主体的积极性强化政效及联动结合地方实际在城市管理教育养老卫生健康体育等特色领域开展人工智能前沿技术的应用形成一批特色应用场景三是强化成果交流和国际合作加强智能社会建设宣传营造良好社会氛围鼓励民众参与治理实践积极推动国际合作推动建立多边协同共治的机制把伦理准则行业规则技术标准和治理技术等纳入国际治理框架向国际社会传播好中国方案那么最后我预祝论坛取得圆满成功谢谢",
    "谢谢请入座再一次感谢杨新副主任的精彩致辞",
    "接下来让我们有请上海市教育委员会副主任王浩致辞有请好 尊敬的方书记 周区长各位嘉宾 大家上午好能工智能必然融入社会赋能千行百业能工智能也是我们上海着力发展的三大先导产业之一目前全社会正在重算力数据等方面重新发展促进人工智能科技研发和产业发展刚刚闭幕的全国科技大会国家科学技术奖励大会两院院士大会上习近平总书记指出加派新一代信息技术人工智能 量子科技生物科技 新能源 新材料等领域的科技创新教育也积极融入人工智能应用的时代潮流怀静平部长强调教育要主动拥抱智能时代把人工智能技术深入到教育教学和管理的全过程各环节作为一种具有社会属性的技术在给经济社会发展带来巨大红利的同时人工智能也承载着诸多风险挑战人工智能自理成为世界各国共同面临的重大课题继续通过对话合作凝聚共识推动人工智能朝着科技向上的方向合规发展去年10月中国国家主席习近平宣布全球人工智能自理倡议围牢人工智能发展安全治理三方面系统阐述人工智能治理的中国方案得到国际社会的高度评价早在2021年上海市教委就委托同济大学成立了上海人工智能社会治理协同协议成立了上海人工智能社会治理协同协议创新中心经过近三年的建设协同中心立足于国家战略需求积极惩罚上海事件充分协同创新开展了人工智能相关的法律伦理和社会治理问题研究和社会服务为国家和我市为国家和我市人工智能可信向善发展贡献智慧中心作为同济大学校内人工智能人工智能新平台参与了国家智能社会治理综合实验基地的申报和建设在区校协同方面进行了更为紧密的探索成绩斐然在论坛稍后的发布环节我们会看到相关的技术系统系列从书和研究报告的重磅发布这些努力为人工智能上海高地尤其是规则供给高地的建设贡献了力量在大模型研发和应用加速推进的背景下如何有效开展智能社会治理以善治促进善治这里提供三点建议供大家一起来探讨第一妥善平衡治理和发展全面深入讨论人工智能发展安全和治理问题首先科学认识人工智能的风险特点探索更科学的风险管理体系其次更新治理理念落实敏捷治理开展成效评价与社会实验活动为推动人工智能的产业发展及其社会应用贡献智慧第二深入应用场景探索治理规则首先要关心人民的真实需求深入具体的应用场景我们拥有全世界最为丰富的应用场景为提炼治理路径和经验提供了可能其次人工智能技术治理需要国际规则搭建开放包容平等参与的国际学术交流合作平台积极参与人工智能全球治理进程第三百年大计教育为本人工智能科技和智力人才的培养是支撑人工智能发展的根本力量首先人工智能的教育需要从孩子抓起2024年2月20日教育部办公厅的正式公布了全国首批中小学人工智能教育基地名单上海的也有六所学校入围其中在整个全市中小学人工智能教育的推进过程当中我们也在做一些整体布局下阶段我们会根据现在面上一批四点校探索研究的基础上会尽快的普及中小学人工智能的课程教学其次发挥高校的学科优势和育能功能在政府高校和企业更大范围协同创新联合培养卓越的人工智能教育人工智能人才各位嘉宾人工智能社会治理议题宏大影响深远我们大家共同责任在间让我们一起努力为推进智能社会治理事业的发展贡献更大的力量最后感谢本次论坛为我们提供了宝贵的交流机会祝各位嘉宾在乎工作愉快身体健康祝大会圆满成功谢谢大家",
    "谢谢 请入座再次感谢王浩副主任的精彩致辞",
    "下面让我们掌声有请同济大学党委书记方守恩致辞有请尊敬的海营区长王浩主任杨新主任各位领导各位参加女士们 先生们大家上午好今天同济大学与杨浦区人民政府联合主办的2024年世界人工智能大会智能社会与全球治理框架论坛在此举行我仅代表同济大学对各位的到来表示最热烈的欢迎也借此机会对各位长期以来给予同济大学的支持关心 帮助表示最衷心的感谢当前人工智能技术的快速发展对全球经济社会发展和人类文明进步产生深远的影响同时也将带来难以预见的各种风险和治理的挑战去年10月18日习近平主席在第三届一带一路国际合作高峰论坛开幕时主旨演讲中提出了全球人工智能治理倡议就各方普遍关切的人工智能发展和治理问题提出了建设性的解决思路贡献了中国智慧和中国方案今年3月21日联合国大会通过了首个关于人工智能的全球决议的题目是抓住安全 可靠和值得信赖的人工智能系统带来的机遇促进可持续发展这项决议汇聚全球的智慧为人工智能的治理确立了全球的共识具有里程碑的意义在过去的两年里同济大学与杨浦区人民政府连续两年举办世界人工智能大会智能社会论坛邀请了众多国内外专家报告人工智能治理前沿发布了一系列重要的研究成果受到了联合国教科文组织的关注并取得了广泛的社会影响学校与杨浦区共同打造的国家智能社会治理实验综合基地是上海唯一入选中央网信办等八部门公布的十家国家智能社会治理实验基地名单的综合实验基地也是全国唯一的政校企联合建设的实验基地经过近三年的建设实验基地建设成效在中期考核中名列前茅打造了上海市智能社会治理的示范和样板为人工智能辅能国家治理体系和智能现代化建设提供了生动的场景近年来学校将人工智能辅能战略作为学校高质量发展的重要战略举措一系列国内外一流人工智能重大平台接连落后了同济大学我们依托同济大学建设的上海自主智能无人系统科学中心是国家人工智能上海方案的重要内容在此基础上学校实现了首批标杆自主智能无人系统全国重点实验室自主智能无人系统前沿科学中心自主智能系统基础科学中心人工智能国家产教融合平台等一批国家级的研究和产教研的平台可以说我们基本上把全国的各个领域的各个部门相关的平台拿全了这个是推进了这些平台的建立推进了学校人工智能赋能教育科研的一个建设在加强人工智能基础研究和前沿科学攻坚的同时学校也加强了人工智能赋能城市建设和社会治理的应用研究有同济大学牵头建设的中国上海数字城市研究院上海新城建设研究中心上海指数研究院等将目光聚焦在超大型城市在数字化转型中的理论问题和技术问题为城市数字化夯实数字底座标准规范助力上海打造国际数字之都依托同济大学建设的上海市人工智能社会治理协同状况中心也紧密围绕人工智能国家重大战略需求和上海市重点产业的布局来开展人工智能相关法律伦理和社会问题的研究打造人工智能治理的上海模式今年5月为加快和加强人工智能辅能力度和步伐学校进一步发布了全面实施人工智能辅能学科创新发展的行动计划全面的推进智能技术辅能教育教学科学研究工程技术管理服务等创新的实践今年我们学校9月份即将入学的所有的新生将全部接受人工智能必修课程的学习在学校未毕业的学生也将在他们毕业之前根据需要提供相应的选修课来补人工智能的课程学校将全面加快构建人工智能家未来教育教学的一个新形态未来同济大学也将继续发挥在人工智能社会治理领域的先发研究优势和平台的优势加强于上海市杨浦区政府以及其他相关产学员资源的协同立足上海服务全国面向世界聚焦智能社会高质量发展与人工智能全球治理框架的建设打造具有全球影响力的智能社会的协同治理智库智力在研究和构建智能社会治理理论 方案和技术的体系夯实人工智能应用的标准 规范形成创新性的政策和制度建议建设智能社会治理人才高低等方面发挥积极的作用希望通过本次来临的论坛 各位专家和学者能够分享真知灼见碰撞思想火花共同探讨人工智能技术的应用与治理之道为构建更加美好和谐的智能社会建议现策进一步深化人工智能治理的国际合作与交流为推动人工智能全球治理框架贡献我们的智慧和力量最后预祝我们本次论坛圆满成功祝各位身体健康 学术长青谢谢大家",
    "谢谢 请入座再次感谢方书记的精彩致辞也让我们了解到了同济大学在人工智能领域的成就和成果",
    "接下来让我们掌声有请杨浦区委副书记区长周海英致辞有请尊敬的首文书记杨鑫主任王浩主任 裴明校长 宜文部长尊敬的耀初院士 志强院士苏军院长 各位领导各位专家 朋友们大家上午好很高兴与大家相聚在2024世界人工智能大会智能社会论坛共划人工智能发展共商智能社会治理首先我代表中共杨浦区委杨浦区人民政府向出席今天论坛的各位领导和嘉宾表示热烈的欢迎向一直以来关心和支持杨浦发展的各界朋友们表示衷心的感谢当前人工智能已经成为新一轮科技革命和产业变革的重要驱动力量请大家多多关注请大家多多关注新一代人工智能的发展机遇加快打造世界级产业集群是以习近平统治为核心的党中央交给上海的重大战略任务杨浦主动服务全国杨浦主动服务全国上海发展大局充分发挥区内科教资源优势创新氛围活跃的特色优势统筹发展与安全积极推动人工智能发展统筹发展与安全积极推动人工智能发展行稳致远一方面我们加快构建以数字经济为核心的创新型现代化产业体系重点布局人工智能等新兴赛道大力营造充满生机活力的产业生态目前区内集聚了抖音 美团 B站 千寻位置复旦微电子 新思科技等代表企业以及上海数学与交叉学科研究院中国上海数字城市研究院等功能性平台洋普人工智能产业正驶向蓬勃发展的快车道另一方面我们积极应对人工智能对城市管理社会治理带来的潜在挑战与同济大学合作共同打造全市唯一的国家智能社会治理实验综合基地朝前探索面向未来的智能社会治理体系推出了一批基层治理典型案例城区智能场景建设及数字化转型取得新发展新突破面向未来洋普将着力打造人工智能产业新高地坚持大学校区 科技园区公共社区三区联动的核心理念聚焦全球的智能社会最大模型 芯片设计智能算力 巨声智能等前沿领域不断优化政策服务开放更多应用场景促进产业需求与基础研究的精准对接让更多科研之华结出产业之果洋普将用心开拓智能社会治理实验田秉持科技向上理念与同济大学进一步深化合作在合规服务上数据交易 人才培养社会服务 基层治理等方面开展更多社会实验和探索事件努力为上海乃至全国提供更多智能社会治理新样板 新经验各位领导 各位专家 各位朋友在大家的共同努力下我们已成功举办两届智能社会论坛更多国内外专家在此分享真知灼见开展跨界对话贡献了一场场思想盛宴期待大家围绕智能社会与全球治理框架的主题在浦江之畔再次实现思想的碰撞迸发智慧的火花最后预祝本次论坛取得圆满成功祝愿大家身体健康 工作顺利谢谢大家",
    "谢谢请入座谢谢",
    "再次感谢周学长的精彩致辞也希望能够让各位了解杨浦在人工智能领域所做的努力以及未来的发展前景尊敬的各位领导 各位嘉宾本次论坛的开幕致辞环节就到这里接下来让我们有请同济大学法学院副院长上海市人工智能社会治理协同创新中心秘书长徐刚主持专题发布",
    "有请各位来宾好下面进行专题发布首先发布统计大学自主研发的数字沉底座IS-3基础设施智慧服务系统有请统计大学特聘教授土木信息技术教育部工程研究中心主任李小军上台介绍成果",
    "有请好 尊敬的各位领导 各位嘉宾我今天给大家发布的是我们IS-3基础设施数字底座这个诶 这个视频诶 这个视频这个数字底座呢是我们统计大学诶 诶 朱厚华院士团队经过有没有PPT是是我放还是这个放这个数字底座是统计大学我们这个二十余年的工程数字化实践的这个积累研发的这个一个自主的一个数字底座那么这个数字底座的目的呢是为了能够支撑传统的物理的基础设施能够快速的改造成为数字的基础设施在这个数字基础设施之上我们可以构建各类插拔式的应用来支撑数字治理数字经济和数字生活的各类的应用那么这个数字底座的主要的特点呢是它基于的是我们采集处理呃表达分析的设施的设施决策的信息流的第一的原理具有通用性专业性和生态性的三大创新的这个特色那么这个数字层的这个底座呢是我们同济大学联手我们上海数字城市研究院那么它主要的这个特点呢就是说我们这个数字的这个底座呢能够把我们的基础设施变成了数字的一个版本之后呢能够在上面服务于我们高校的这种城市的数字的治理城市的数字的治理城市的数字的经济以及城市的数字的生活那么接下来呢举几个典型的案例第一个案例呢就是说上海的这个地铁的这个建设的风险管控那么基于这个数字底座呢可以把它快速的搬到网上能够进行这个风险的即时的这个管控和智能的数据的挖掘和分析还有呢基于这样的一个数字底座呢可以实现我们整个城市的地下空间的精细化的评价帮助我们来发现城市的风险管控是哪里有风险哪里建设的时候风险比较高要进行及时的这个规避为我们规划提供决策的支撑那么这个数字底座呢第三个案例呢就是可以帮助我们城市的这个风险管控比如说我们的城市的这个这个韧性这个地震来了这个韧性呢在哪里还有一些缺陷可以帮助我们来做城市的这个灾害的这个模拟和韧性的评价那么同样的这个数字底座呢也可以帮助我们来做这种高速公路的这个主动的这种孪生的管控还有呢能够在我们的生活方面呢比如说我们的公园它的舒适性它的油气的这个指数可以随时的来告诉我们那么我们最近呢也在用这个数字底座呢来打造一个我们同级的这个数字的校园这个校园呢是构建了一个三维的一个实景的一个场景然后联合了我们学校的土木建筑测绘 交通 电信各个专业来打造学在同级 吃在同级数字防灾以及绿色同级这样的一个应用那么这个应用呢能够为我们学校的这个精细化的治理呢提供技术支撑为我们高质量的人才培养呢提供一个创新的一个载体那我的介绍就到这里谢谢大家",
    "好 谢谢李教授谢谢李教授的介绍",
    "下面发布的是爱生者和同济大学联合编制的负责任人工智能风险管理指南有请爱生者大中华区法务及政府事务总裁高文胜和同济大学上海市人工智能社会治理协同创新中心研究员朱悦一同上台介绍成果",
    "有请促进人工智能向善发展接下来发布爱生者与同济大学联合编制的负责任人工智能风险管理指南感谢大家非常荣幸今天可以一起发布指南正如昨天发布的凝聚全球共识的人工智能全球治理上海宣言所说企业研究机构社会主体个人要根据自身的角色去发挥各自的定位和作用要加强人工智能的监管和问责机制的建设要促进人工智能的合规使用和责任承担那也就是说今天来发布负责任的人工智能风险指南是在最合适的时间最合适的地点我想也是前瞻到了一个最合适的题目那接下来我也将时间和舞台交给高总感谢有您来详细展开谢谢朱老师各位好很高兴今天有机会在这边跟大家进行一个分享那么我们知道这个从这个什么是负责任人工智能我们要先从这个话题再讲起那么艾森哲认为我们负责任的人工智能它不仅仅是一个技术的应用那么它也是一种涵盖了应用设计模型适配跟使用部署跟维护的端到端的这么一个实践那么负责任的人工智能绝不是一个单一的技术问题或者是道德伦理问题更不是单一的企业的法务的合规问题而是一个系统性的涉及到企业每个人未来如何看待和应用人工智能的问题用好了它可以帮助企业合规促进对于技术的信任带来业务的创新但是用不好的话则有可能给企业给个人都带来伤害那本质是促进人跟机器之间的协作和信任那么了解了这个什么是负责任的人工智能以后呢接下来我们就需要非常精准的去理解人工智能风险的分类和分级并有针对性的对其进行管理那么这两个内容也是我们这一份指南的重要的组成部分那么艾森哲的全球的最新的调研显示97%的受访的高管认为自身的企业将受到AI相关监管法规的影响77%这些高管是将AI的监管列为这个优先的事项另外还有80%的受访者认为他们将投入10%或者更多的AI的总预算以满足未来的监管的要求那么在指南中呢我们就将这个人工智能风险的影响分为了三个层面包括对人的影响对组织的影响以及对生态的影响那么为了更好的去管理这些风险呢我们会建议企业就像这个PPT显示的用四个维度去负责任地进行人工智能风险的管理首先企业应该确保本身要合法合规遵循相关的这些法律的规定其次呢企业也应该明确负责任的这个人工智能的这个原则并且将其嵌入到人工智能系统和开发流程中第三企业应推动领导层将负责任的人工智能提升为其关键的业务的要求并且为所有的员工提供这个培训那么最后企业应该建立透明的健全的可持续的人工智能的文化确保每一位员工都能够理解并实践负责任的人工智能的原则那从这四个维度入手的话呢我们认为企业就可以更加全面的识别与管理人工智能的风险使人工智能的技术应用更加的负责任那么在具体的实践中呢我们是根据企业应用人工智能的成熟度将这个企业化成了三类大家可以看到从这个AI的领军探索者还有一类是这个AI的创新技术以及另外一类是AI的实践的起步者那么在指南中间我们对于每一类的企业都提出了相应的建议和行动方案那么比如说AI的领军探索者他应该全面的遵守当地的法律法规积极的参与推动AI的合规标准的制定并建立完善的AI的治理的体制而AI的实践起步者那从另外一方面则应该初步的制定负责任的AI的企业的原则并且进行相应的风险评估女士们 先生们人工智能的发展离不开我们的共同的努力负责任的AI不仅是企业的责任政府也需要加强监管和创新的支持那么学界的话应该是生化 化学科的研究和人才的培养社会组织要激发公众的参与和监督专业服务机构则应该提供专业的咨询和技术支持通过这种多方协同治理才能够有效的应对AI带来的挑战实现科技向上的未来那么最后也是感谢各位的聆听和支持让我们携手并肩共同迎接人工智能的时代的到来推动科技向上的未来祝福人类社会谢谢大家",
    "好 也感谢两位的介绍那么下面发布统计大学开发建设的全球人工智能治理数据库有请上海市教委副主任王浩统计大学党委常委常务副校长吕培明一起上台共同启用数据库",
    "有请两位请两位领导把手放在屏幕上启动也祝福数据库的正式的上线启用请入座谢谢接下来要发布的是统计大学上海市杨浦区国家智能社会治理实验综合基地等单位策划出版的关于人工智能伦理法律和智能社会治理领域的系列重书有12本我们一次性发布",
    "有请统计大学党委常委常务副校长吕培明杨浦区委常委常务副校长吕培明杨浦区委常委常务副区长倪斌一起上台为新书揭幕发布一起上台为新书揭幕发布有请请两位领导为新书揭幕请两位领导为新书揭幕请两位领导为新书揭幕我们也祝福这些新书的出版请入座请入座请入座请入座请入座请入座最后发布上海市杨浦区十大锤类大模型应用场景需求榜单请看大屏幕介绍2024年人工智能发展迈向强应用阶段发力点逐渐由通用大模型转向行业大模型杨浦区积极抢抓新一代人工智能发展机遇以人工智能驱动形成新制生产力全力打响杨树浦品牌为推动人工智能大模型赋能千行百业日日催生未来产业新模式新业态杨浦区先发布垂直行业大模型应用场景需求榜单向全社会接榜挂帅面向海量影音内容的精准分析和高质量生成需求争取文化娱乐场景大模型落地方案面向传统制造行业的智能化升级专行需求争取智能制造场景大模型落地方案面向教育行业的智能化教学和个性化学习需求争取智能教育场景大模型落地方案面向医疗服务行业的智能化升级转型需求争取智慧医疗场景大模型落地方案面向生活服务领域的大模型精准营销需求面向生活服务领域的大模型精准营销需求争取生活服务场景大模型与建筑设计与审图效率低建筑管理成本高等问题争取建筑设计场景大模型落地方案针对法律信息获取难、案件分析耗时长等问题争取法律服务场景大模型落地方案面向金融领域的交互服务与风控需求争取金融风控场景大模型落地方案面向跨界市场的大模型落地方案面向经济贸易中海量通关文件种类多、时效高等需求争取智慧物流场景大模型落地方案为解决时空智能分析精确性与适应性等难点争取智慧交通场景大模型落地方案促进人工智能和实体经济深度融合为高质量发展注入强劲动力未来无限 等您接棒从这个介绍当中我们注意到这十大应用场景涉及的领域非常广泛这也是得益于杨浦区有着丰富的科教资源良好的创新生态以及多元的数字经济和城市数字化转型的实践",
    "下面有请上海市委网信办副主任杨新杨浦区副区长刘静元统计大学党委常委宣传部部长端木怡文一起上台正式发布需求榜单有请各位请各位领导把手放在灯光柱上启动感谢各位领导请入座我们也欢迎大家能够持续地关注统计大学和杨浦区在智能社会建设领域当中的很多的努力和活动那么专题发布的环节到此结束",
    "下面有请统计大学法学院院长上海市人工智能社会治理协同创新中心主任蒋惠领教授主持主子演讲环节有请尊敬的方书记周区长各位领导各位嘉宾女士们先生们朋友们大家上午好今天上午的智能社会论坛我们是邀请到了六位重量级的嘉宾为了节约时间我在这就不显一一的介绍各位嘉宾的简历情况在会议中以及手册里面都有大家可以查阅而且因为为了节省时间我在中间就不做过渡性的评论那么最后有时间的话我再做两句点评如果没有时间我们就后面就转到后面的圆桌对话纪伟东老师主持的环节因为今天时间上午非常的紧张我们的这个主旨发言阶段主旨演讲阶段是90分钟我们有六位嘉宾这样每位嘉宾平均时间是15分钟时间差不多的时候我们会有那边的工作人员",
    "会有请提示大概剩三分钟剩一分钟好下面我们就有请今天发言的第一位嘉宾他是欧洲科学院院士国际电气与电子工程师学会会士西湖大学人工智能讲习教授金耀初教授",
    "有请金教授好那么各位尊敬的各位领导各位专家各位与会者我叫金耀初是西湖大学人工智能的讲习教授那么很高兴有这个机会来参加这个会议那我是从这个就去年11分才加入西湖大学的那么之前是在德国比勒菲特大学做这个红宝人工智能这个讲习教授我们从2017年开始呢就从事一些有关隐私保护和安全的这个方面的研究那么后来呢也很偶然去年的4月份在比勒菲特大学的时候呢就代表这个德国的这个中小型企业在柏林参与了一次这个这个AI Act这个在就在讨论过程当中的一个研讨会所以呢就是我今天呢给大家呢来分享一下我的一些有关人工智能方面的一些这个见解个人的一些看法但是呢首先我不是人工智能智力的专家所以讲的有什么不对的地方呢请多批评指正那么这个是我大概今天的这个汇报的这个内容啊就先稍微简单地讲一下人工智能历史然后呢我们再探讨一下人工智能到底哪些风险和目前已有的一些技术上的一些对付的方法是吧然后呢再简单讲一下呢就我们目前世界上主要的一些国家特别是欧美中三国家对人工智能治理方面的一些目前已有的法规那么大概比较一下它们有什么相同点和不同点那最后呢我讲一些自己的一些这个建议人工智能其实大家都可能现在是非常这个可以说是家喻户晓是吧它的历史可能可以追溯一下可以说到这个上个世纪的十七世纪的这个中期啊那么它经历了三起两落是吧三起两落有两个所谓的冬天那么大家都可能听说了是一开始正式提出人工智能这概念是在五五年那么是为了五六年的一个人工智能的研讨会就在美国那么我们也看一下这个就是五五年提出以后呢这个人工智能就是很热了啊那么马上啊就是这是一九五六年提出的是吧那么到了一九七零年左右呢就经历了所谓的一个第一个冬天其实这个冬天的原因是哪也是非常简单当时最流行的人工智能的模型啊叫感知器它只能解决一些比较简单的问题就这本书分析的啊所谓的简单问题就是所谓的线性可分问题大家看右下角如果两个不同的东西两类不同东西能用一条直线就能分开来的那就是线性可分那最早人工智能模型只能解决这样的问题所以当然被这本书指出来以后就说这不行所以呢就马上进入冬天了是吧那么一九八六年的时候呢迎来了人工智能第二个春天那当时主要就是主要的原因呢就是我们把这个最简单的感知器呢中间加了几层啊加了一两层那就叫多层感知器那这个也是啊有我们现在非常热的是图灵奖获得者包括Hinton在内的几位专家提出来的虽然之前已经有人曾经提出来过只是没引起注意好那么我们这没多少年啊一九九五年左右又来了一个第二个冬天啊这个也是刚刚我在这大开始读博士的时候我们在用神经网络来做一些解决一些控制问题建模问题没多久就发现这个是人工智能没人喜欢做了那么这个原因是什么呢因为当时的统计学习方法就我们这样比如像和所谓的叫和函数方法或者支持向来这样的一类统计学习方法呢在性能上呃完全压倒了这个当时的有一层或两层这个隐含层的神经元的模型啊所以那就又神经网络又没人住了呃那么呃直到一二零零七年啊Hinton又在这个一本期刊上啊就发表了这个所谓的深度学习的网络那么这深度学习其实就是前面这个从一层两层开始他中间加了很多层是吧所谓的深度就这个意思呃但是他当时发表这个文章以后并没有引起太多的注意啊直到二零直到这个二零一二年一个深度学习模型的一个变形叫Alex Knight他在这个一个一次竞赛当中啊完全打败了这个统计学习的方法才又在学界在人工智能学界引起了重视啊从那个时候开始呢我们基于人工就是神经网络的方法呢又又开始获得重视好那么真正在社会上引起人工智能对大家特别影响大的就是可能大家有回忆起来的话就是二零一六年是吧谷歌提出来的这个一个算法他能够战胜当时的一个韩国的这个围棋高手啊那么到二零一七年他又提出了一个新的版本就是前面这个版本是要为他很多很多的棋谱可能上一盘棋谱但到后来这个所谓叫AlphaZero的话他不需要为他棋谱了就不需要为数据了而是让两个这个算法自己相互博弈哎最后他这个性能的话比为棋谱的还更好是吧所以这是一个很大的这个进步那么第二次的大的冲击是吧我们第三次人工智能的这个高手第二次大冲击可能就是这个ChatGPT了可能大家都非常清楚了那么他的这个之所以让我们惊奇的原因呢就是他的对话的流畅性因为这个对话这种软件本身70年代就有没有引起我们太多注意但是呢ChatGPT呢彻底让我们感到很震惊啊因为是他的流畅性非常好很像人在对话那么从此以后呢这个大模型大家也知道就是飞速发展有无数多的大模型那么另外一个很重要的事情可能今年年初是吧大家都知道这个Sora是吧我不知道这个能播放吗哎哟好像不行怎么样才能播放这个东西不太清楚因为我想播放的原因实际上其实这个Sora这个出现的这个视频啊虽然是非常的惊艳是吧但其实如果你仔细看你如果不要只是看他的脸啊你仔细看的话其实下面是有很多这个这个这个这个问题在里面的但是很可惜这个放不出来这也是就是对我们在这个人工智能发展一个很简短的历史啊那么现在这个大模型出来以后可以说大家每个人都谈大模型做人工智能如果不做大模型觉得你已经不做人工智能了那么大模型的话也有很多很多的探讨那也有很多呢很乐观的说哎马上我们这个这个通用人工智能出来了这个我们有非常就是甚至比人也要聪明的是吧这是乐观的一种想法那么又有一些悲观的想法就是他人工智能会不会统治人类会不会取代人类有这样两种不同的观点那不管怎样呢就是我们需要对人工智能因为高速它的高高速发展所带来的一些社会经济的重大的影响因为它几乎涉及到所有的领域所有的领域那么目前的话如果我们要总结人工智能有什么风险的话大概有这么几类一个就是安全性第二个呢隐私保护隐私的话因为我们人工智能是依赖于很多很多的数据还有一个就是公平性另外呢像透明性以及可解释性还有呢就是鲁邦性和可靠性最后呢就是责任性和可问责性我后面稍微再探讨一下那么为什么要讨论这个人工智能模型的安全性深度学习模型非常强大大家可能知道就是说有的时候两张人脸人都分不清楚他能够分清楚同时呢他又非常的脆弱也就是说你人不会犯那些错误绝对一看就知道的问题他可能就会犯错误这是一个经常用到的一个例子是就主编大家看到这个大熊猫是吧然后呢如果你在这个图片上加上一点噪声那么变成右边的图像那我们人眼一看还是个大熊猫对吧但是深度学习模型可能是完全把它当作另外一个动物来判断所以就是说深度学习的模型很脆弱那么怎么来对付这个它的脆弱性当然有很多研究现在有很多就是说如何来设计好的深度学习模型来避免呢他这个这种对一些很小的变化就能犯大错的一个方法那么第二个呢就是说风险就是隐私了那么隐私的话因为我们依赖大量数据所以呢这个数据里面的往往会有很多这个个人信息也好或者企业的一些重要的经营信息也好那么这些信息的话如果你给泄露出来的话当然就会造成很大的风险那么隐私计算的话就如何来保护隐私要用到这些数据是吧那么有很多方法这个传统的空间安全的一些方法像独方安全计算或者差分隐私以及加密等等那么现在也比较流行的叫做叫做这个联邦学习那么这些都是一些技术性的方案来保护数据的隐私同时呢又能够充分利用这些数据的这个价值就是又既能打破这个数据孤岛又能够这个来保护这些数据的这个隐私那么第三个方面的就是它的所谓的叫鲁邦性或者可靠性为什么呢就因为人工智能模型呢有时呢也对这些一些不确定性或者噪声啊输入的信息的噪声比如传感器信息的噪声非常敏感那么怎么来处理这些已有很多的技术方案是吧比如说我们来把这个数据质量那个清晰数据那么提高数据质量或者呢在机器学习的方法上进行一些这个改变使得呢这个模型的不对这些噪声的特别的敏感那么我呢就不详细探讨这些技术的方案还有一个很重要的问题呢是就是所谓的公平性由于这个多方面的原因人的一些我们人有些天然会有些可能一些偏见然后在数据上的也有些偏见那么这样的造成或者是模型训练上一些偏见的会造成这个我们人工智能模型啊如果你要记得它做一个决策的话它可能也会有偏见那么如何来保证这些人工智能模型在决策过程当中能尽量的公平有很多很多的方法那么在我们数据的处理也好或者是模型训练也好后处理也好等等那么其实这公平性其实非常难的我举一个简单的例子一方面它涉及到多方面的不只是一个技术的问题因为你的公平性怎么来定义其实涉及到很多文化社会等等各方面的这个学术等各方面的这个因素另外呢有一个很简单的例子比如说我们这两类这个是表示男性和女性然后呢这个是这个就是说有两种肤色的假设那么它有多少人被聘用了那么如果你你只是去看单纯某一类的话就只看男性和女性或者只看肤色觉得很公平吗都招了三个是吧但如果你把这两个合在一起看的话其实还是有很多这个偏见在里面第四个要探讨的就是我们这个叫人工智能模型的这个叫可解释性或者叫透明度那么这个可能大家也都听说过有一个很有趣的现象就是说人工智能学习学得很好但到底我们不知道他在学什么是吧他学的是这个因果关系还是学的是相关性还是一种完全是一种假象或者是一种很偶然的现象那么有时也非常有意思在这个这个实际是20世纪初有个叫叫做聪明的汉斯就是这匹马所以他会做四指硬算后来发现其实并不是他只是会察言观色而已那么还有很多一些其他的这个技术方案因为时间原因的我也不是讲了这就是一个因果关系和相关性的一些区别就是同样冰淇淋消瘦很厉害很多啊但是那另外一方面你可能被晒黑了那么这样的话就是说天气热跟冰淇淋的消瘦量增加和天气热跟被晒黑这是因果关系但是呢冰淇淋的销量的增加和被晒黑这两者之间不一定有因果关系只是一个相关关系那么为了对付啊上面这么多的这个可能的风险其实欧盟在很早啊 2017年就GDPR就出来了所以很多方面的规定那么对其实这是一个最后第六个方面就是所谓的responsibility就谁来负责任那么这里我把它列了一些不同的有可能是用户方用户经理等等用户单位开发方 销售方等等有很多都有可能如果出了什么事情你可能都去会找这些人到底是谁的责任那么目前的话针对所谓的上面这些风险其实各国政府已经出台了很多的规范 法规从2017年欧盟出台的GDPR开始它就提了很多对人工智能的一些要求包括像要受人类监控技术的鲁邦性 安全性隐私保护透明度 东洋性等等还有一个问责制最近就是今年的6月份弗吉尼亚Tech和哈佛大学MIT等等一些学校就发了一篇文章这个文章把所有不同的风险做了非常仔细的分类总共有三百二十几个不同的分类非常仔细那这不同的分类可以分成四个大的类大概有这么四个就是系统和操作风险内容安全风险社会风险以及法律的一些权责风险那么这个分类的目的是为什么呢主要是它想分析中欧美三国目前已有的人工智能的法规对到底cover了哪些就涉及到其中哪些所以分析得非常详细大家如果有兴趣可以去看看那么比如像这是欧盟欧盟大家都知道2017年GDPR和今年刚刚通过的这个法规那么它当然有一些特殊的地方而我们如果回顾一下看看三个国家这些不同的法规既有共同性也有一些不同的侧重点那么这是美国和中国的也是这样就是有些共同的观点也有一些特殊的自己关心的这是三个国家的法规所共同的地方那么我最后的话利用可能一分钟左右的时间就是来探讨一些我自己的一些看法首先就是说到底要我们规范什么东西什么是人工智能其实这个定义不是很清楚特别是在一开始欧盟这个法规刚出来的时候把几乎所有的传统的像控制 优化等等技术都把它归到人工智能里面去那么其实它的影响的面积非常大那么如果我们在这边的法规上那么如果我们在这边的法规上那么如果我们在这边的法规上那么如果我们在这边的法规上如果我们在法规在设计方面太广之后那么就会影响一些中小企业对人工智能的发展第二个呢不好意思稍微用半分钟时间第二个呢就是说我们到底要规范什么东西我个人觉得就是应该规范人工智能的产品以及应用而不是规范人工智能的技术最后的话呢就是我们其实对人工智能技术其实还要分层分类特别是一些高峰性的技术高风险的包括像生成式模型或者是非常高度的自主的人工智能算法以及一些通用人工智能这方面呢可能带来的风险会比较大我们可能是因为我们需要规范的一个重点那么我今天就分享这些谢谢大家",
    "还有一些因为时间关系我就不多说了以后如果有哪位参议会者有兴趣的话我们可以在线下讨论谢谢大家好非常感谢大家谢谢金教授的精彩演讲",
    "高度浓缩时间不太够了我们下了以后再跟金老师请教好因为我们议程做了一点小小的调整那么第二位发言的嘉宾呢是中国工程院院士德国国家工程科学院外籍院士瑞典皇家工程科学院外籍院士同济大学原副校长吴志强教授有请吴院士好这个因为后面全国的那个我们城市规划的专家也在聚在上海我一定要过去我是主持人所以我把会议做一个调整我先讲掉非常重要这件事情这个我们同学们同济和杨浦专门做这个社会治理这块内容的这么一块探索吧我觉得特别重要所以我呢把自己的研究啊在为今天的那个会议专门做了一个特别的powerpoint这个报告呢就叫社会智能关于哈尔主义的破题实际上是做了那么多年实际上在2014年这个全盘的这个把城市规划导入这个AI的推进也就是那一波的时候呢我们的世博会就在这块场地上实际上当时有了解释我们当时呢世博会一天要进一百万人所以说这个压力是非常非常大的这个密度啊这个温度啊都是非常挑战大所以作为世博会总规划师呢我就把整个世博会的每一张票全部定位的所以说为了踩踏世界的房子呢是全部的每一个人进来这个说一件事情大家都可能会觉得很荒唐的这个觉得这世博会怎么会有那么大的经历呢就是因为有人说这个超过了一个平方米只要一点三人不要踩踏世界而我们世博会这块场地上一天要进一百万人就是说一个平方公米要占六个人你们知道六个人意味着什么只要有任何事件那就是超过了这个世界纪录的你必须要超标不超标就没有那么多人答应世界要破这个世界纪录的但是呢用这么高的密度又是破了中国国家的规范了国家规范一个平方米必须只能占一点三个人假如要国家规范又是要用的话那就是这块世博场地呢要扩大六倍我们不可能再扩大六倍来做这个世博场地所以必须要高密度要完成在这么一个条件下我们做了每一平方米的这个精准的模拟每一张票的精准模拟为了不踩踏事件的诞生这么样子我们就进行了大规模的数据的动态世博会结束以后一二年大家说你这套办法现在有名字了叫大数据叫Big Data现在有名字了即使的用电即使的能流即使的每一个数据的统计每一间房间的用电量那么这个时候呢把这套内容呢也就是中国工程员呢大规模来支持这套系统就是我们的城市管理城市的治理开始用作为我们的这个这套内容那么很高兴的是做了一四年开始全部到今天正好十年我们特别高兴的是实际上好多好多的数据我们碰到了很大的问题刚才金教授在谈这个问题实际上是我们是真正的碰到了这些实实在在的国内的问题那么很高兴的是我们中国工程院在14年成立这个课题我在这里面16年我们给总书记写报告中国一定要注重人工智能在我们的社会经济各个方面的推进的时候呢总书记实际上是两个星期就改了很长的一个批示让我们工程院呢就落实这个姿势吧包括我们的老校长万刚校长也是在这个中间起了很大的作用所以我们的这个计划中国人工智能这个发展报告发展规划Strategy Planning战略规划呢在16年的年底全部变完这是在中国是这件事情上推进上和全世界完全平行这16年同时我们推出来的时候美国推出来了欧盟推出来了所以说刚才金教授说的这个三波基本上是全世界最平行的三波像日本了什么都还没有到这么快那么在这个过程中间呢实际上事业啊经济啊这些问题啊都会有很多很多的担心的那么我们工程院呢从头开始就同时成立了从技术推进十个方面我待会会说到另外一个方面呢就是我们的社会的问题的同时的这个内容的全部同时来这个小组呢当时是放在我们的上海大学的原来这个小组那么这个小组呢因为后来上海大学的校长到了天大去了当校长去了所以这个小组呢又被拉到那边去了实际上这是都跟着人在走那么这块的内容呢我今天呢就是说一直说AI说了那么多年这个从17年我们在全上海组织了4000人成立了AI城市规划联盟这个在徐汇区然后18年就在我们这个场地开始做做到今天实际上这个AI这个大家呢当时呢就都压了这个AI特别好就觉得它是一个很正式的一个很重要的内容到今天呢我就想给大家把那个H加上去这个H什么呢就是Human实际上是能与AI的深度的合作这是一定要很清楚的实际上不是AI一个人可以完成的这个事情做了10年的实践啊最后得出来的结论今天给大家说第一句话就是人和AI的深度合作这才是未来的社会我们要做的事情是人与AI的共同的智慧相互之间摻在一起可以完成的是人的智慧和AI的智慧的共生和共创这是今天我们特别要说的所以我今天呢就把这个报告称为叫嗨主义Human和AI合作才是人类的明天所以呢我就讲今天就讲嗨主义的几条原则讲五条原则第一条原则就是人本互动的互助的这非常非常重要的什么意思呢就是什么事做的时候呢所有的事情AI的所有推进都必须围绕着人本身的渴望这是所有的起步你假如说AI的本身的技术的进步你就脱离了人本身的渴望好所以说这点呢大家可以说我们是大规模在运用了城市规划里面我举个例子给大家看我们可以用大规模的来完成人的需求每一个治理包括我们做了这个深圳的所有的每个平方公里的治理的数据都完全不一样这是我们做厦门做厦门的治理过去我们城市规划是走上来就是说功能怎么样道路怎么样哪里布局怎么样这是我们是挖了几十万人大家可以看很快的数据全部收集上来以后发现厦门人最最喜爱的是沙茶面提高心情最快的提升是沙茶面我们规划是过去怎么会想到沙茶面那么重要呢我们做了六个地铁站做个地铁站的时候第一件事情就想到了沙茶面要落实不落实的话不行深圳人厦门人最不喜欢的事情我们大部分建筑师过去不知道的最不喜欢的是奢靡我们过去一下子就要做新的地铁站大理是铺好做得最最漂亮根本就不是人家根本就不喜欢这样东西所以说对我们的所有的AI的推进直接导向了人心所向这是非常重要帮助我们大家可以看绍兴人臭豆腐心情最快你们知道吗你们知道吗你们不会想到的大家一想到做绍兴的老城的保护规划什么什么怎么做得很精致精美这对的但是人家心情最快乐的是臭豆腐黄酒和快乐老家所以说你就倒回去想什么是载体做什么事情最最重要绍兴人最最吐槽的是宁波修路等等你知道啊原来绍兴人想这些东西想这些东西你在做设计的时候是完全不一样的人心所向我可以举很多很多这个例子正向清去负向清去现在我们远远就所有的把大量的人工智能用到了人心所向知道每个地方人在想什么我们做到了什么程度呢我们给深圳做的是每一平方公里每一小时人的变化就是刚才做的只是给大家看一件事情实际上它是动态的什么时候变化的我告诉大家我们做了全中国的369个城市的每周的报告动态全中国人的心情变化是非常非常有规律的在波动的这个疫情的时候疫情之前2020年之前武汉人是整个中国中间所以最最乐观的一群但是一封城以后一下子掉下去20个点清清楚楚上海封城掉下去了18个点非常非常清晰的波动然后呢疫情波波打开慢慢慢慢慢慢恢复基本上到了2023年的中期全中国人民都起来了都超过了2020年的时候唯独武汉人还没有克服上海人还没有克服全中国只有武汉人和上海人还没有恢复到疫情之前其他地方都恢复了可以看到整个的心情的波动这才是我们所有的内容这个实际上数据是我们所有社会自己的根本这件事情我说掉第二个海主义的我也可以把它用中文上海话说的就是海大海的海海主义的第二条就是要透明互信刚才说了transparency是非常重要的讲了不能transparency你是没有办法相信AI的AI的过程你要让人知道为什么是这样不能说你它做出来结果就这样就这样不对的这个要transparency这个就是我们现在做了大规模的这个里面为什么你要让领导知道为什么它是这样的分布的这个老年 中年 青年各个时段他们为什么出来这个为什么这样这是大量的东西比方说我们这里当然一代代做了很快我们已经做到第四代了当时就是说你可以看到原来的城市是这样的我们不仅仅是做到未来的城市应该怎么样而且未来的城市的每一栋房子里面的人手机数量全部推演出来已经做到这样但是为什么呢你假如老不说为什么的话这是有问题的这个就是AI的很大的一个问题刚才金教授说到那个点是这样不知道多少人知道就是我们小时候我们这些人在西式的教育下面导入的都是学的CODA也就是叫因果关系但是我们这里面实际上有很多的是相关关系就相关关系要说清楚的话你才可以说清楚比方说这是我们做的洞外滩这是做的水的模拟推演实际上是要做很多很多transparent的事情第三块就是要安全护保非常重要的大家以为AI是一个机器实际上是需要相互之间保证它的要保证它的电力保证它的算力保证它的从善力善力很重要不是算力 是善力这个一把刀你可以做完全是用作两件事情也可以杀人也可以做我们切菜完全不一样的这就是向善力保善力也是非常非常重要的这就是要大量的来做我们这部分呢保善力这块呢我们做了城市重脑在2014年2015年的时候呢我们推出这个世博会里面呢就是这个经验呢拿出来叫城市大脑这个概念出了实际上是出自世博会里面的总控叫城市大脑那么实际上做到现在又做了十年了现在很清楚的我们现在从两年之前我们就开始推城市重脑一个脑子是不够的最后所有的数据都汇到一个地方了我们世博会里面可以的汇到一个地方一个训练站中间但是把这个模式拿到城市里做做了那么多年我们发现我们自己再一次推出城市重脑一群大脑同时运行非常有意思的我们这里有主脑边脑辅脑端脑各种大脑同时运行这样的话比整个过去的大脑要聪明很多很多那么这部分呢就保证了各方参与模型五方参与模型以后相互之间有自己的规律相互之间对其他人有判断这样就保证安全很多第四个原则就是我们要相互之间互动和互控人和机器相互之间要非常互动的实际上不是这样互动的话是没有办法保证这个人工智能社会向前安全的前进的所以说我们相信之间这是我们大量的绘制的道路和这个IP就是说现在人的数据和相互之间的那么我们也做了大量的自由创作自由创作的时候实际上是做了大量的机器的反馈就是一边生成一边大量的反馈这就是我们非常非常主要注重的就是相互之间人和机器中间不是最后一个结果是过程之间有更多的交互交互才能够完成这个智能社会的一个AI社会的一个向前推进这是我们现在在做的最近在做的大量的叫爱媛宇宙是创造了一个城市里面人和自然之间青年人大量的导入的过程这个过程本身是有很多青年人一边使用一边来相互之间互动的看到他们的生存他们的希望然后来完成我们整个的创作这个创作过程找了很多青年人在网上共同参与第五最后一个原则我觉得论理互信是非常重要的刚才金教授说了这个郑教授也是个中国人在佛罗里达他做了三个主体美国中国和欧洲的安全内容实际上这块东西我们之前讨论过很多很多实际上就是论理互信的事情真正的做的事情我们要做大量的予以的创新相互之间和机器互动能和互保这就是我把嗨主义的五条说在嘴今天是参加人工智能在城市规划中间的试验我把原来一直说AI今天加上humanhuman和能互动称为嗨主义嗨主义就是人和机器要能本互动要安全互保要论理互义要能和机器相互之间互动可控最后要透明能和机器相互的互助那么这样互信的话才能够真正把这个社会这个智能社会真正的完全的推进因为在上海因为在这块土地上我就直接提嗨主义上海的嗨H表示能在前面AI表示我们的今天的社会的最重要的技术的推动嗨主义就是我们上海诞生的一个想法能和机必须互动谢谢大家",
    "非常感谢吴院士的精彩发言他的嗨主义让我们嗨起来他的20个字的最后打在屏幕上印象是非常的深刻互助 互信 互保 互动 互育好 再次感谢吴院士下面一位发言的嘉宾是来自意大利的加布里埃尔·马治尼Gabriel Mazzini教授他是欧盟委员会的官员曾经担任欧盟人工智能法的起草小组的组长但是因为特殊原因马治尼教授他无法到现场来参会所以他做的是线上的发言下面我们请看大屏幕Good morningMy name is Gabriela Mazziniand I am the lead authorand the architect of the EU AI ActLet me start by thankingTongji University School of Lawfor inviting meto this conferenceI'm sorry I will not be ableto be with you present todaybut I hope that these remarkswill nevertheless help youhave a fruitful discussionI will spend around 15 minutesto give you an introductionabout the AI ActFirst of all a couple of remarksabout the institutional architectureOf course now we are at the endof the legislative processbut I think it may be helpfulto have a sense of who does whatin fact the proposalfor the EU AI Actwas put forward by the commissionwhich is the executive of the EUin April 2021The proposal was sent in parallelto the Parliament and the CouncilThe Parliament and the Councilact as co-legislatorsThat means that they have to agreeon a common legal textin order for that textto become the lawThis took some timeThe proposal as I saidwas issued in April 2021and the final political dealwas sealed in December 2023was sealed in December 2023Now that we have an agreementon the legal textthis text is going to be published soonso indeed this conferenceis a very timely eventin July 2024and it will enter into forcein August 2024What is important to understandis that the conclusion of the legislative phasedoesn't mean the end of the workIn fact a new phase opens upwhich is the implementation phasePrimarily implementation of EU lawis a responsibility of the member statesis a responsibility of the member statesHowever there is actuallya certain number of actionsthat need to be takenat EU levelnotably by the commissionin particular when it comes toadoption of guidancedelegated actsimplementing actsof tertiary legislationto be adopted by the commissionwill also havesome degree of oversightby the two arms of the co-legislatorso the council and the parliamentFirst of all a couple of remarksabout the nature of theEUAI actIt is a classicinternal market legislationfor the placing on the marketand the putting into service of AI systemsIn particular for those of youthat may be familiarwith EU product legislationthe AI actintroduces the CE markThe CE markcertifies that a certainproduct in this casean AI systemis in conformity with applicable EU lawThereforethe adoption of the productlegislation approachis aligned with what is callednew legislative frameworkphilosophyof product legislationthat has been around in the EUfor many many yearsand it is premised upona simple conceptthat the law providesessential legal requirementsthat operators need to comply withbut does not enter into thetechnical standardsin order to meet those requirementsTherefore the AI actwill need to be complementedby a set of harmonized standardsto operationalize the legal requirementsAnother important featureof the EU AI actis the horizontal approachThis means that the AI actapplies across a variety of sectorswithin the EU competencewith some exclusionsnotably in matters of national securitymilitary and defenseHoweveralthough the AI acthas an horizontal naturea number of sectoral specificitiesand needs needed to be consideredin particular in areas of law enforcementand so onso there has been an efforton our endto ensure thateven though the AI acthas an horizontal approachsectoral specificities were includedAnother corollary of the factthat the AI acthas an horizontal approachis also the factthat it is without prejudiceto other existing EU lawnotably in matters of data protectionyou may be all familiarwith the platform legislationfor instance the digital services actor the digital markets actso an important considerationto make from the beginningthat was very clearwhen we thought about the AI actis that the AI actis certainly not the only EU lawthat is applicable to AIOne of the essential conceptsperhaps the most important conceptof the AI actis the risk based approachthe risk based approachmeans thatthe rules of the AI actbecome stricteras the risks that AI systemsmay pose become highertherefore the focusis not on regulating the technologyas such but on regulatinguse casesso specific use of AI systemsWe have identifiedfour levels of riskin particular I should saythree because the fourth onethe green onedoes not lead to anybinding rulesso we have binding rulesfor three levels of riskthe first one is aroundrisk that are not acceptablein these casesthe AI actforesees a prohibitionexamples of this use casesare for instance social scoringor forms of certain casesof remote biometric identificationto note thatthe commission had foreseentwo use casesfor prohibited AI practicesand the co-legislatorconcluded on adding other fourso right now the final lawwill have eight casesof prohibited AI practicesthe next level of riskis for high riskhigh risk use casestake perhaps around80-90% of theUAI actI mentioned before the CE markso the product legislation approachof the EU AI actand this is exactly the type oflegal approach that applies tohigh riskwhen a system is considered high riskand therefore is subject to the CE markthe system issubject to a number ofobligations notably requirementsessential requirementsregarding the AIand an exempt conformity assessment procedureso the manufacturer has to demonstratecompliance with those requirementswe'll seea couple of examples laterof high risk AI systemsthe third layer of riskconcerns those caseswhere the riskis linked essentially tothe lack of disclosureof informationexamples would becases of a chat botwhere humans may not be able to distinguishwhether they are interactingwith an AI system or another personor forms of generated contentsynthetic contentin these cases the AI actforesees an obligation to discloseinformation around theexistence of the AI systemor around thefact that the content has beenartificially generatedfinally as I mentionedthe last layer is aboutcases where AI systemspose minimal or no riskand in that case as I mentionedthe AI act does not foresee binding rulesbut only the possibility forproviders to applyproductswhen is a system high riskthe AI actforesees two avenuesin which a certain AI systemcan be classified high riskand therefore is subjectto some of the stringent rulesabout the AI actthe first category is aroundsystems that are safety componentsof products that are alreadysubject of EU lawexamples would be AI systemsthat are safety componentsof medical devicesof machinery or toysradio equipment and so onwe are dealing here thereforewith the number of productsthat are already covered by EU legislationbut they may have some digital componentsincluding AI componentsso the first way in whichcertain AI systems become high riskis when those AI systemsare on the one hand componentsof those products that are alreadyregulated and those componentsare high riskso it is important this elementnot all AI components of productswill be high risk AI systemsbut only those that fulfilla safety functionfurthermore in order for the systemto be classified as high riskit is essential that the productas a whole so the productthat is regulated by the sectoral legislationthe medical devicethe machinery and so onis subject to a third partyconformity assessmentfor assessing the conformityof the product as a wholeto compliance withexisting EU lawthe second categoriesof high risk AI systemsiswhen the AI systembelongs to a number ofspecific areasthat have been identifiedby the legislatoryou see in the slideeight areasit is important to notethat not the whole areais high riskso therefore not all AI systemsthat are included in those areasare high riskif you look at the annexyou will see that under each areathere is a list of specificallymentioned AI systemsso therefore only the AI systemsthat are explicitly mentionedin the annex 3 under each areaare high riskand the attention of AI systemsused for hiring or promotingor terminating employeesthis is an importantelement to considerbecausethe commission already in its proposalhad intended to allowfor some flexibilityin the classification ofhigh risk AI systemsin these areasby allowing the commissionto add use casesthis was an intentional decisionto allow the AI actto remain future proofand therefore to adaptas the market and the technology evolvesso to adapt the use casesas the market and the technology evolvesthis is a very important chapterof the AI actnotably aroundgeneral purpose AI modelsthat has been addedby the co-legislatorsduring the legislative procedurethe commission had not foreseenany rules aroundgeneral purpose AI modelswe have right nowtherefore a regulationof those modelsthat is dividedin two tiersfirst of allwhat are general purpose AI modelsso general purpose AI modelsare those modelsthat are otherwisesometimes also calledfoundation modelsand can performa variety of tasksan example would bemodels behind chatbotslike for instance chat GPTaccording to the AI actthose models will be subjectto two type of regulationaccording to the first levelof regulationwhich is applicableto all general purpose AI modelsthey will be subjectto a number of transparency related rulesin particulararound technical documentationso those models must be documentedincluding as regardsthe computational resources and energy consumptionthere must bea transmission of information downstreamfrom the provider of the modelto the downstream providerwho wants to apply the modelto a specific applicationand finally there must be compliancewith certain copyright related rulesnotably when it comes to the adoptionof a policy to ensure compliancewith copyright rulesand the implementationof a detailed summaryof the content usedfor the training of the modelthe second categoryof general purpose AI modelsnotably those that are classifiedas models with systemic risksare subject to additional rulesin particulararound risk assessment and mitigationincident reportingand cyber securityan important elementto understand is howwill be classifiedas a model with systemic riskdealing thatthis triggers differentlegal obligationsthe AI act foreseesat least in the first momentthat the modelsthat are trainedwith at least a certain numberof compute resourcesthe 10 to 25flops will be classifiedas models with systemic risksand therefore subject to additional ruleshowever this is not the only wayin which those modelscan be classifiedas models with systemic risksbut also there is a possibilityfor the commissionto designate modelsas models with systemic risksregardless of the numberof compute usedon the basis of a numberof criteria that are identifiedin an indexby the way the AI officeis part of the EU commissionthis considerationis the roleof the applicabilityof these roles to open source modelswhich is somewhat reducedin the sense thatopen source modelsare not subject tothe rules aroundtechnical documentationand transparencyas regards the lower tierand finally another important elementto take into accountwhen thinking about the future workwill have to be developedfacilitated by the commissionin order to demonstratecompliance with the rulesaround general purpose AI modelsa final wordabout the progressive entryinto applicationas I mentioned at the beginningthis is really a very important timebecause the AI actthe final version of the AI actwill be published in the official journal soonand it will enter intoforce twenty daysafter its publicationhowever the entering intoforce of the AI actwhich is therefore scheduledaround the first of august 2024does not mean thatall the rules of the AI actapply immediatelyas you can see in the slidethere is a phased entryinto application of the rulesafter six monthsthe rules around prohibited AI systemswill enter intoapplicationthe second set of rulesthat enter into applicationare the rules aroundgeneral purpose AI modelsthat I just discussed12 months after the AI actenter into forcethen we have the third deadlinewhich is 24 monthswhich is the general deadlinethis applies to essentiallyall other ruleswith the exception of the rulesregarding high risk AI systemslike for instancemedical devices or machineryfor those type of productsthe applicationof the rules of the AI actwill happen thirty six monthsafter the AI actenter into forcelet me conclude my presentationby thanking youfor your attentionand I wish you fruitful discussionsin the prosecution of the conferencethank youенныйperfecthostagetrata지랜aнемtaweheythisthereisanapowerатьсяadthetit请不吝点赞 订阅 转发 打赏支持明镜与点点栏目所以没时间翻译成中文所以今天只能靠大家的这个英文听力还有我们那个通传翻译的工作So today I'm going to be talking aboutUS-China dialogue on AIUS-China engagement on AIAnd I'm going to be talking both aboutgovernment level engagementand non-government level engagementwhat we often call track two engagementI think most people know that this Maythe US and China met for the first meetingof their sort of official high levelgovernment dialogue in AIthey met in Geneva in SwitzerlandThis was a real landmark meetingit took a lot of work to make it happenand I think it's very importantthe risks ofthe safety risks of frontier AI systemsare a problem that is going to requirethe United States and China's effortsthey are the central axisthat this is all revolving aroundand it's really importantthat we have these dialoguesbut I think it's really importantI also want to give somekind of good news and bad newson this frontand I'll start with the bad newsso we can finish with the good newsI think the bad news is thatwe should have very very low expectationsfor this government dialogueproducing any kind of agreementany kind of binding agreementor joint statements on AIwe should expect them to talkbut we should not expect themto agree on very much at alland that's bad newsfor governing frontier AI risksI think the good newsis that we don't necessarily needa government to governmentbinding agreementon reducing these risksin order to do the workof reducing the risksI think we can still have very productiveengagement between the US and Chinajust not necessarily at the government levelI think we can have very productive engagementbetween policy scholars in both countrieslike we're having here todayI think we can have very productive engagement between policy scholars in both countries like we're having here todayI think we can have very productive engagement between policy scholars in both countries like we're having here todayscientists between companiesand I think that's really going to be thethe backbone of ensuring AI safetybetween the US and Chinaand I think the key idea herethat I want to communicate ischanging our mental modelchanging our idea of what it meansfor the US and Chinato work together on safetyI think there's a traditional modelof this kind of thingthat is a very top down modelthat is a very top down modelthe idea isour leaders get togetherat the very highest levelthey make an agreementabout what we can doand what we're not going to doand then that agreementthat they struckis put down into the two ecosystemsthe rules are agreed onand then they're forced on each countryit's like atop down systemand I think that that for AIespecially frontier AI governanceis just not realistic at allwhat I would proposewhat I think is going to bea more productive modelis a more bottom up modelof working together on safetyand I tend to call thissafety in parallelso it's not safety based on joint agreementswhere we both make commitments to each otherand we both follow the rulesit's where we both are developing AI systemswe're working on safety techniquesboth technical approachesand policy approachesand we're constantly exchanging viewswe're constantly sharing best practicesbetween the ecosystemsbut we're not having to do everything togetherat the same timewe are learning from each otherbut we're not necessarily striking agreementsand I think that that is going to beit's a much more realistic approachI think it's going to be a much more resilient approachI think it's going to be an approachthat lasts much longergiven all the chaosthat is politics and geopolitics todayI think in this worldand maybe kind of a fundamental idea hereis that theif the U.S. and Chinaare going to build powerful AI systems safelyit's not going to be becausethe two leaders struck an agreementit's not going to depend on a grand bargainbetween the U.S. and Chinait's going to depend on the decisionsthousands and thousands of decisionsmade by more working level peoplescientists, engineers, professorseveryone advising on policy in both countriesand they're going to need to make these decisionsfor their own reasonsit's not going to rely on what the other country is doingthey're both going to have to value safety on its ownand I think if we do thatwe can build up a sort of a parallel safety systemthat I think will be more enduringbriefly on the government level dialogues in GenevaI think we should appreciatewhat a huge achievement it wasto even hold these dialoguesgiven the geopolitical environmentthe domestic political environmentin the U.S. and Chinathis is extremely difficultfor I'll just speak to the American sidefor the American presidentfor Joe Bidenhis administration to say tothe Republican Partywe are going to talk to China about AIthat's a very big political riskin the U.S. system right nowI don't think it should bebut the fact is it isand I imagine there are similar risks on the Chinese sideand so just getting togetherI think is a very big achievementbut what comes out of thatis maybe not what we'd expectit's not going to be the agreementsright nowand especially going forwardfrontier AIfrontier AI safetyis something that both countriesor frontier AI systemsboth countries see this asabsolutely essential tonational power going forwardit's going to be essential to military powereconomic powerinternational influencethey might be wrong about thatmaybe it doesn't turn out that waybut that is the assumption of leaders in both countriesand when you have that assumption aboutAI and national powerand you have two rivalswho are competing in every areathey are justit's going to be extremely hardto trust each other in any meaningful wayand to believe that the other sideis going to take steps to mitigate these risksso it's not going to be agreementsbut I think the key contribution of the national level dialogueis that it sends a signalit sends a signal within each countryand it sends a signal internationallyso within each countryit sends the signal toscientistsresearcherspolicy advisorsthat it is okayto talk to the other country about AIand this is a very meaningful signalsome people were organizing dialogues around this timethey were working very hard to get the Chinese participantsand the US participantsto agree to come togetherthis is last Novemberand then as soon as it was announcedthat we were going to haveBiden, Xi announced the high level government dialogueit became so much easierto get people to join these other dialoguesI think that's maybe the most important contributioninternationally it's also sending the signal thatthe US and China are working on thisthere's a lot of countries who are very worried about these divisionsthey're very worried about AI safetyand they're looking at both of our countriessaying are you going to get this togetherare you going to develop this safelyand I think the signal that the government level dialogue sentis very very important on this frontI'm just trying to stay to timeso I don't go over too muchanywayon to the non-governmental dialogueson to the non-governmental dialoguesthe good newsI think that when it comes to engagementbetween policy advisorsengagement between scientists and researchersit's progress is very possibleand I think progress is actually already happeningon many levelsand again I'll go back to this kind ofsafety in parallel ideaand sort of what it can meanI think this traditional modelwhere the leaders strike an agreementand it trickles down into the two ecosystemsthat's not going to be resilientbecause the practicesaren't embedded in each countrythe safe practices are not embedded in each countrybut if we in our two ecosystemsare developing these safe practicesfor our own reasonsChina sees it as in China's interestto develop AI safelyAmerica sees it as in America's interestto develop AI safelythen we're going to have a more resilientlong term frameworkbut doing this in paralleldoes not mean doing it in isolationjust because we're doing it for our own reasonsdoesn't mean we can stoptalking to each other about itAI safetyhow to develop powerful AI systems safelyis fundamentally an unsolved problemtechnically we do not know how to do itand we do not knowwhat kind of regulationsare going to work best for itand I think what's happening right nowaround the worldis different countriesare running experimentsin how to govern AIwe just heard about the EU AI Actthat's a very large scale experimentin how to govern AI safelyin Chinathe Generative AI Regulationthethethethese are all experimentsthat are being run to seecan we constraincan we ensure safetythe model this wayin the United Stateswe're doing the same thinglast year we had the White Houseexecutive orderthat placed requirementson the largest modelsif you are training a modelwith computing powerover 10 to the 26 flopsthen you need to red team that modelyou need to submit the resultsof that red teamingand as we're running these experimentswe need to be comparing noteswe need to be asking each otherhow is it goingwe need to be talking throughthe different techniquesthat we're usingand exchanging best practicesand I've seen this veryvery up close and personalI think it soundsa little bit abstractbut I've seen it veryvery effectiveI've seen American scholarsdirectly learn from what's going onin Chinaand incorporate that intohow they're thinking aboutsafe AI developmentin the United StatesI've seen Chinese scholarslook at parts ofdifferent American proposalsor regulationsand saywe can use that partwe're going to adapt itto our own needsbut we can use that partand I think as we do thiswe canessentially we're going to bebuilding up these practiceswe're going to be runningthese experimentsand if we are constantlycomparing notesbetween the two countriesconstantly in dialoguewith each otherthen I think we're going to bemuch more likelyto get to a safe place on AIand I guessmaybe going backto the sort ofgovernment level dialoguefor a secondI think if we do everget to a pointwhere we can have ahigh level agreementbetween the countries on AIa binding agreementthat we will notdevelop very unsafe AIthe only way that'sgoing to be possibleis if the practiceshave been developedindependently in each countrythey've gone fromthe bottom upfrom the scientiststhe engineersthe policy advisorsthey're already doingmost of this stuffand then we just makean agreement betweenthe countriesand then we just makebetween the leadersto essentiallycodifyto make officialwhat we're already doingand I think that could bea key stepthis is kind ofin a little bithow it worked in climate changeyou needed both ecosystemsto come aroundon the threat of climate changeand then at a certain pointthe leaders can strikean agreementthat then turns intoan international agreementso I'm very optimisticabout thesenon-governmental dialoguestrack to dialoguesand exchangesand I'm nottotally pessimisticabout the government level dialogueI think it hasvery important usesand it can also learnfrom the non-governmental dialoguein the same way thatwe should not be tryingto strike agreementsthe government level dialoguecan put its focuson exchanging best practiceson having ourAI safety institutetalk to organizationsin Chinaabout how are werunning these testswhat type ofred teaming approachesare most effectiveand I think thatis difficultat a government levelthere's so muchsort of security concernsbut it is possibleand we need to startexperimentingin this way thoughthe government is goingto have to be lookingat what the non-governmentalactors are doingand learning from thatand you knowwe're working togetherthe government sendsthe signalthat this is okayand then we allget to workin trying to makeactual progresson sort ofsafe AI practicesso thatI'd say just putsthe responsibilityback on usputs the responsibilityback on a lot of peoplein this roomto proactivelyengage with yourcounterpartsto not betry to not beideologicaltry to have somesome sense of trustto build trustin each otherthroughsort of repeatedengagementand I think with thatwe canboth of our countriescan learn a lotfrom each otherand hopefullywe can make progresson ensuring these systemsare safethank youthank you very muchmatchit's a reallygreated your observationthat you toldyou told us somebad news or good newsactually feltoptimistic enougheven a signalwould also be a good newsthank you so much好下一位呢演讲的嘉宾呢是来自美国的专家陆凯Carmen Luchero她呢现在是耶鲁大学蔡中增中国研究中心的研究员",
    "有请陆凯她的设计是这个吧这个好好我也想首先感谢同济大学还有上海洋服区政府邀请我来参加这个会议而且做这个发言发言有这个机会就跟你们一起加油我想你们学习也是很特别的对我来说所以谢谢我今天讲的这个话题跟我刚才那个Matt同事有点相同的但是我就要再回讲就是美国和中国他们的这个AI生态就是他们的AI ecosystem的一些主要差别而且为什么这些主要差别会产生就像Matt谈到的这些对话层面的一些挑战好所以我觉得他有前面的一些人已经讲座了人工智能它比较负责范围也比较宽它不只是一个东西而已不是一个政策也不智能是一个政府部门来管理它是一个生态一个生态有点像一个我觉得这是一个一个信息这是比较大比较复杂会包括很多不同的东西所以你看如果你要做一个中国和美国或者中国和任何其他国家他们怎样来治理或者怎样要做一种对话实现一些目标的话你必须也看这两个信息具体怎么能够促进沟通和合作好首先从美国开始我觉得美国的联邦政府还有州政府跟中国有一些主要的差别所以我只要的就是做一个简单的总结我觉得在人工智能这个领域基本上有三个层面所以有最基础的硬件的层面就是这个会包括比如说Semiconductor是芯片这个层面在这个层面美国的政府的权力算是比较强的它比如说能够控制能够管理谁可以用这些芯片如果他们要卖有些公司要卖给国外的一些客人他们可以限制的第二层面就是这个软件的就是software和模型的层面在这个层面美国政府的权力可能更加模糊一些或者要看具体哪一个领域有一些领域像比如说这个跟欧盟也很相同的这个跟欧盟也很相同的比如说在这个医疗设备中的人工智能这个在美国也可以比较明显的控制和管理而且到现在美国的那个视频药品监督管理局还是有很多就是对着这些医疗设备中的人工智能有很多规定最上面的就是这个内容层面就是比如说我通过深圳人工智能或者大模型来产生什么文章图片之类的在这方面美国的政府的权力算是比较少一些或者算是就管理不到的然后从最宏观的角度来看从去年开始美国的联邦政府已经有越来越多的就是会对着人工智能的一些新的政策和概念最主要的就是我的同事已经说过了这是去年拜登政府的那个新政令这个新政令除了对这些最大的模型的这个报告要求之外它大多数的内容就是对着美国的政府部门它会对这些政府部门有一些要求基本上是有两种第一种是要让各个政府部门多思考他们会怎样用人工智能来提高他们的效率或者做他们的工作做得更好第二个是他们要更好的或者更深刻的思考他们会怎样用人工智能来提高他们的效率他们会在自己的领域或者自己的管辖之下怎样管理人工智能新政令之后今年的三月份有这个Office of Management and Budget在联邦政府也比较有权力的一个部门是因为它控制钱的原因它也出了一个这个memorandum重新强调联邦政府各个部门要实现的这些价值观除了这个之外最后也会有一个就是跟国家安全有关的备忘录这个还没出可能之后几个月会怎样的但这个是去年那个新政令的要求所以应该会出现的好我觉得要看或者要研究任何国家它怎样治理人工智能的话你就必须主要是看这个制度所以我觉得制度就是命运就是institutions are destiny一个国家的制度会完全影响到他们怎么把什么人工智能的抽象的原则或者价值观事实上落实到他们的这个社会所以觉得研究美国或者中国的这个人工智能的治理也必须先了解他们的基本的政治和法律的制度所以在美国他说选取一个联邦系统所以这个意思是有一个联邦政府还有州政府州政府他们也有自己的一些权利是联邦政府不能干预的也不能控制的所以在尤其是在一些领域所以比如说在教育很多形式方面这个都会属于州政府所以如果你要看比如说在教育的领域在教育的领域的人工智能很多这些管理其实在美国会来自州政府不一定会来自联邦政府第二个特点就是这个权利分离就是所谓separation of powers这个对于人工智能治理的最大的印象是一个政府部门可能限制另一个部门的能够做的什么事情就比如说可能有国会出什么立法总统不喜欢所以他会就vito掉了就说不要了所以他不可能成为法或者可能国会出什么立法或者行政部整个白宫出什么规定然后后来会通过法院的某个案子然后被法官取消所以在美国尤其是在联邦政府层面国会的总议员和参议员经常会谈比如说他们对要现在要立马管理什么人工智能的什么什么什么的但是过一段时间他们真的能不能做得到是有挑战的我觉得最近对人工智能比较有印象的或者比较限制政府的权利主要的是这两个这是the first amendment这是跟英伦自由有关的尤其是因为上周有这个新的来自美国贼告法院的一些新的判决基本上扩大了一方面是司法部的权利第二方面是就私立公司的一些英伦自由尤其是在这个人工智能或者数字世界的权利好还有我觉得前面的一些同事已经讲了但是我美国也有很多同事也有很多同事已经讲了但是我美国也有很多同事也有很多同事已经讲了但是我美国也有很多同事已经讲了但是我美国也有很多同事已经讲了而我们也有很多这种资源的治理而且不好意思我这里写的这种资源是不对的应该是资源就是voluntary的治理所以尤其是上读部下面的两个部门就是MIST还有MTLA还有美国也有一个AI safety Institute他们会出很多这种资源的承诺还有资源的原则负面上有一些人可能认为这些资源的过程是负面上有一些人可能认为这些资源的过程是有点软的或者影响力不是太大的但事实上我觉得其实它的影响力其实是很大的而且尤其是将来它的影响力会越来越大因为首先它会通过很多企业的这种参与所以它不只是来自政府的一种愿望而是这些企业会包括他们的概念而且如果后来某个政府部门真的要有一些所谓引发就是hard regulation他们就会从这些自愿的原则开始最后是去年的新政令还有近年的很多尤其是美国state department出了很多发言还有新的政策就会比较强调美国参与国际人工智能智力的很多计划和事情这个包括就是今年的那个联合国大会的那个决议还有跟欧盟的一个这个join statement还有这个OECD的global partnershipon artificial intelligence这些很多他们想要的原则其实跟昨天刚出现的这些原则其实跟中国人工智能全球智力上海的宣言也是有很多同样的一些价值观比如说人工智能应该符合人类的价值观我们都应该一起合作来产生一些安全可信 可靠等等的人工智能所以其实有很多跟中国有很多相同的部分好 我很快的讲中国的我觉得中国的人工智能的的治理也是一个比较大比较复杂的的生态它一方面会包括当然是政府的部门但是除了这个之外它也会包括比如说企业 学者等等的而我觉得它的一个特点是它一方面完全不是联邦系统的所以这个是跟美国是一个差别但是事实上我觉得政府治理人工智能的时候它也必须通过一种下访来真的落实这种什么政策的还有各个目标所以这个所谓的下访有两种第一种是从上面到下面就是从中央政府到比如说省政府或者地方政府的但在人工智能这个领域我觉得中国的人工智能治理其实也有一种横向的这种下访就是horizontal的delegation因为它会从就是很正式的政府部门去做这种下访来下访到比如说企业平台也到现在可以算是一种governor或者也会比较依靠比如说学习人工智能治理的一些学者或者来自智库的什么专家所以我觉得负面上或者正式方面中国和美国的这个系统有很多比较重要的差别但是我认为事实上也有很多相同的部分尤其是人工智能治理必须看一整个这个ecosystem一整个这个生态好所以目前人看中美人工智能的竞争可能担心这也像一种就是两个信息的碰撞但说实话我觉得尤其是通过就是Matt之前推荐的那些做法我觉得信息碰撞的时候不一定必须是互相灭掉的而他们只是有一种互相变化都会变得可能更加光亮的更加光明的一些新的信息好最后我就是在说在对话中有什么比较具体的领域或者话题我觉得也值得就是中美的这种对话第一个就是这个open source开源的人工智能第二是医疗中的人工智能我觉得这个领域的潜力也比较大也比较值得这种沟通和合作第三是地方政府用的人工智能比如说上海市还有美国和欧洲的某个市政府这种之间的对话第四是人工智能奉献的制度最后是太空中的人工智能希望我可以多向你们学习而且多跟你们谈一下这些对话的机会谢谢",
    "非常感谢陆凯研究员的精彩的演讲那么下面是我们主旨演讲环节的最后一位嘉宾他就是清华大学智能社会治理研究院院长全国人工智能社会实验专家组组长苏俊教授有请苏教授尊敬的各位专家各位朋友非常高兴能再次有机会来到上海参加世界人工智能大学智能社会论坛这个论坛非常有意义已经连续办了很多届了今天再次跟各位专家各位朋友一起围绕智能社会治理问题进行讨论我觉得也非常高兴了前面几位专家都做了很精彩的报告再往前面还有几位领导也做了讲话也发布了一些成果来自美国来自欧盟的专家也分享了他们的一些很好的一些见解我觉得对我们推动智能社会治理做好人工智能赋能社会促进人工智能向善发展都非常非常的有意义我今天简单给大家介绍一下我是清华大学公共管理学院的我是一个从事社会学管理学研究的一个学者给大家从人文社会科学的角度来讲来谈一谈我们如何去应对智能社会给我们带来的一些挑战大概说这么四个方面的问题习近平总司司议提出要发展新制生产力这两天我们在上海开世界人工智能大会行行业业都在讨论人工智能技术赋能到经济社会的各个方面去其实大家肯定知道我们在上海开这个世界人工智能大会我们很有深深的体会其实人工智能它就是在推动各行各业形成新制生产力人工智能就是新制生产力是一种变革性的技术会给我们的生产力的提升带来很大的变化不论是从生产要素从产业各个方面都会带来很大的影响你像现在我们隔壁房间正在讨论的巨神智能讨论的机器人我们上海正在推动的无人驾驶现在的脑机接口量子通讯其实都会成为很大的新制生产力科学技术的发展历史就是跟人类社会的发展历史紧密的结合在一起的但另一方面AI技术的影响又是全面而深刻的刚才很多专家也都谈到了这个问题每一次科技的革命的重大突破都会带来生产力的巨大跃升和生产关系的颠覆性变化它是两个方面的一方面带来生产力的发展但是大家不要忽视了还会带来生产关系的变化还会带来人的观念人的认知的升华和社会结构的这种缠变我们现在这个AI技术正在重塑全球创新版头正在重构人类文明的秩序也正在推动人类社会的智能化转型我们正在迈入的智能社会我们会遇到很多风险和挑战我们不能只看到AI技术形成新制生产力带来经济增长的这一方面它对社会的这种影响实际上是很全面的刚才很多专家其实也都谈到了这个问题刚才很多专家其实也都谈到了这个问题刚才很多专家其实也都谈到了这个问题比如说这种带来的这种失业贫富差距去组织化的变化很大工业社会是一个组织化的社会我们都被组织成一个一个的社会单元但是在智能社会里面组织的特征正在消解这种量子化的被网络在赛博空间里面重新构筑起来的这样的一个个体这些事情都会发生这些事情都应该引起我们的关注另外媒介操纵对人的认知对人的舆论的控制都会带来很多变化带来很大的风险人的价值观和思想认识而产生变化我们在智能社会里面许许多多的我们的旧的观念旧的思想旧的认知正在调整我不知道大家在座的特别是青年朋友们有没有这样的体会许许多多的我们的旧的观念许许多多新的认知甚至新的文明的形态新的合作行为新的这种世界观都在发生着很大的变化你可以去体会一下你这些年有没有这样的变化还有社会的系统脆弱性也在发生变化我们今天的社会越来越复杂今天的社会是靠多个信息系统构建的一个复杂的技术系统这个复杂的技术系统它会带来社会的更多的黑天鹅和灰犀牛带来更多的潜在风险的隐患所以你会看到今天我们的社会会猛然之间一个大家熟知的一个偶像一个大V的形象完全的塌灭实际上就跟这个是很有关系的对吧另外还有一个就对智能技术跟我们的生态文明也有许多对生态文明的理念和观念还有也会带来新的挑战一会我也会讲一下这个问题刚才讲的这五个风险和挑战其实我是在去年的论坛里面讲过我刚才就很简单的给大家提一下去年把专门讲过这五个问题那现在我的略微简单的介绍介绍最近我和我的同事们我们学院正在研究的几个智能社会治理的前沿问题略微给大家提一下应该说我们从学术研究的角度从社会科学研究的角度面临的问题是很多的需要研究的空间是非常大的经常说时代是粗体人我们是打卷人我们这一代人从学校的学术研究的角度来说我们面临的许许多多的很值得研究的问题不论是在我这样的公共管理学院还是在经济管理学院刚才像吴志强院士说的他们规划你看现在都跟人工智能技术完美的结合在一起了有许许多多的问题像这样列的一些问题其实都可以值得大家的关注最近这些年我一直有一个团队一直在研究游戏我们现在人类花很多时间在网上玩游戏我们小朋友还不会说话的时候他就会玩游戏了游戏是人类文明的新的训练场和人类习性的养成的地方千万不要忽视这个问题特别是这个促平一代新的一代孩子们的他们游戏对人的影响是非常大的对吧我简单给大家介绍一下关于信息减房和群体集化这个问题的研究信息减房现在越来越关注这个问题的人越来越多了大家可以看到各种学术杂志都在发表跟信息减房有关的一些文章我们在智能时代我们在今天这个社会里面人类发明了一个非常重要的工具叫什么叫精准推送精准推送这个东西在工业社会是没有的工业社会所有的信息传播都是广播式的传播电视广播是广播式的传播跟受众的特质没有任何的关联但是今天我们各位获取信息的方式都是跟你的个体的受众跟你的偏好跟你的特质跟你的文化对吧跟你的学术的历史都直接有关的这个精准推送呢成为我们今天这个社会生活中离不开的一个东西这个它为个体呢提供了很便捷的信息获取和分享的渠道提高了广告的效率提高了营销的这个这个效率但是另一方面呢它加剧了我们信息减房的形成我们每个人的知识每个人获取的信息都是越来越被包裹在一个像减房一样的东西里面我不知道你们有没有这样的体会你会觉得有一些人他对某些问题特别的了解对某些观点特别的赞成对某些认知非常非常的这个这个这个这个强烈的反对啊强烈的这个这个抵触社会之间的这种冲突撕裂对抗其实越来越多了这个问题呢其实都是今天由于精准推送这样的一个人类的这样发明的这个工具啊所导致的而且我觉得呢随着社会的进程啊这个精准推送导致的信息减房所导致的社会撕裂还会越来越严重它一定会成为我们智能社会的一个顽疾我们以后几十年上百年我们都离不开这样一个东西这个影响会越来越大的那么究竟那这样的情况下我们为了治理好这个信息减房我们就要去研究这样一个基底研究它形成的基底研究它的这个形成的过程所以呢我去年呢跟我的同事们跟我的这个团队一起呢给予这个5.7亿的这个社交平台的用户数据这个第一次的实证的呈现了信息减房的存在信息减房是一个理论上的一个命题但是怎么能观察到就像人类讲的黑洞你怎么能看到黑洞能测量出黑洞这是一个很难的问题所以我们去年的研究成果呢这个观察到了信息减房的存在第一次实证观察了而且研究了它的相变机理这个归纳出了四个非常重要的影响它变化的要素这个成果呢在这个自然的子刊叫Nature Machine Intelligence这个上面发表了大家有机会可以去看一下这个文章我想这篇文章呢对于信息减房基底的研究对于我们人工智能的治理对于平台的治理对于算法的治理提供了一个非常重要的一个基础提供了非常重要一个基础信息减房的影响是全面而深刻的它会导致呢这个个人认知的极化这个个体的极端观点呢在群体中激荡还会导致群体的极化这个人以类聚人以群分我以类聚人群同样观点人群同样观点同样认知同样信息的人大家注意到没有现在都是在一个群体里面它会互相激荡形成马太效应所以我们现在的群体的观点极化在这个社会里面也是非常严重的一个问题对吧这个另外呢赛博空间呢为这种极端化的观点的表达提供了环境这个现在的这个常委效应啊这个非常非常的严重会导致这方面的一些变化这个第二个这个研究的问题呢就是灵活就业与劳动替代的问题今天很多包括刚才这个几位学者国外的朋友都讲到这个问题就业是一个很大的一个问题就业影响很大的问题但是大家注意到以前我们讨论机器人讨论自动化对就业影响的时候呢都是说它是对体力劳动对重复性劳动对这个非智力劳动的一种劳动替代对这个非智力劳动的一种劳动替代今天人工智能特别是生成式人工智能的影响它的劳动替代是对创造型劳动的劳动替代对知识型劳动的劳动替代对各位在座的各位会产生一种劳动替代的大家千万不要忽视这样的一个事情现在它在金融 医疗 法律 文艺 创作甚至在我们教育行业都产生了很大的劳动替代都会对我们产生很多的影响同时它也会产生贫富差距的分化大家现在也在经常讨论AR技术的发展会不会缩小贫富差距还是会加大贫富差距这个方面一直有这方面的深入的讨论劳动替代会导致一个一种是新兴的劳动行业的兴起但是劳动替代还会产生一个很大的问题大家注意到没有我们以后未来的社会大量的工作是不用人去做的或者说大量的人是不用去工作的这个是一个很复杂的问题人类社会之所以能发展到今天是因为我们在与自然在与野兽的搏斗中形成了这回组织我们把生产作为第一需要把劳动作为第一需要的时候我们才能构成了今天的社会但是以后假如大量的人都不去工作我们怎么度过这种无意义的时光人类群体如何都不工作的时候是个很麻烦的事情如果你一个人两个人不工作你可以去闲暇时光可以去游览可以去旅游可以去从事文艺创作整个社会都不工作了是一个很复杂的事情所以我觉得现在我个人一直在研究就业失业我觉得是人类的工业社会的两种工作状态其实在我们未来社会里面我觉得还应该有一种工作状态叫游业这种他不参加社会生产性的务工劳动或者是工业的工作状态或者不以劳动作为获取经济的回报这个是非常重要的这个回字写错了抱歉错一个错别字回报就是大量的人都不工作但是他很幸福他很有很好的经济收入这个社会是非常重要的所以我们要研究这个问题现在世界各地有许多地方在推动全民基本收入实验我一直非常关注这个工作他就在做大规模的社会实验但人都不去工作了社会是一种什么样的组织形态假如咱们上海选100万人说100万人你们去不工作了对你们进行跟踪调研一定是一个非常有意义的一件事情那个社会会非常好玩对吧这是一个另外我再介绍一个我们中的做了一个工作就是大模型的价值观的评测由于时间的原因我下面会介绍的快一些大模型的社会观评测简而言之就是把大模型看成一个认知论上的一个人任何一个大模型它在生成知识的时候它都有一个本底的社会价值观而这个社会价值观在它应用的时候会产生放大作用它的社会价值观是什么样子它对应用时会产生很放大那么我们现在就花很多时间在研究不同模型的社会价值观现在初步的研究发现我们现在国家备案的这些大模型包括国外的大模型其实社会价值观是不一样的这个我不知道以后会产生什么样的结果但我觉得这个是个正常现象就跟我们每个人一样的大家都是叫人性本善对吧但是你那个发端还总要有一点点不一样对吧所以这个我觉得还是值得深入的这样一个研究另外一个问题就是关于人工智能与能源的问题人工智能与能源相生相克我觉得大家现在讨论的都是人工智能去促进生产力的发展其实我更建议我们的企业家这个人工智能的技术专家好好去研究一下怎么用人工智能去减少碳的排放提高能源效率这个问题是非常重要的我们要想尽一切办法缩小人工智能技术的发展与绿色发展之间的夹角不能让这个夹角越来越大这个夹角越来越大的话我们的社会是失败的这不是很好的一个问题所以要关注这个问题人类历史上应对历史的应对技术发展的变革的经验是非常多的今天其实大家都讲到了这样一些东西是时间到了不能翻了是吧抱歉抱歉我觉得简单说吧一个就是知识分子社会精英应该处于人文主义精神和强烈的社会责任感关心这种突破性技术的社会影响在这个方面多发声多呼吁像爱因斯坦早期跟罗素推动的罗素爱因斯坦宣言包括后来形成的帕克五师科学与世界事务会议大家都可以去关注一下这个问题这个工作对于今天我们控制核武器控制把核武器关进制度的笼子保持人类社会的平衡性的平衡性的平衡性是非常有意义的今天人工智能的全球治理我觉得要好好学习一下帕克五师科学与世界事务会的一些精神和一些做法第二条就是政府基于公共利益和公共价值采用多种综合的政策工具引导技术创新有效规制风险政府不能在这个时代缺失不能在这个时代放弃它的立场因为它们是我们进行社会价值最大化的一种方法一种很强烈的一种这方面的职能应该去在这方面多做一些工作另外还有一条就是讲给群众的讲给我们在座的我们这每一个普通的人的大家要提高科学素养增强风险意识积极参与技术变革的治理我认为技术变革人工智能的影响人工智能的国际治理一个是社会精英的事情是刚才讲的路克讲的政府之间的马克讲的政府对话民间的对话的问题但更多的是要群众要觉醒群众要参与群众要知道这个方面的风险社会群众不能是在社会变革中成为沉默的大多数应该积极地参与这样的一个活动公共空间不能没有普通人的声音人也不应该成为技术的附庸在今天我们讲智能社会讲人文精神这样一个时代这一点是非常非常重要的当然刚才也讲到了企业的社会责任企业履行社会职责这方面的事情也是非常重要的所以在这样的一个背景下我想我们应该为后代留下一个什么样的智能社会当然它是海我这个是人文智能社会这样的一个东西应该是价值理性和技术理性综合平衡社会就需要技术也需要这种价值理性和谐包容开放这样一个时代这个工作得到了中央得到了政治层面领导人的高度的关注和支持总书记在多个场合都要讲我们要关注我们未来的社会这样的问题19年的时候5年前我们清华大学的学者还有一些其他高校的学者发起了一个倡议叫开展人工智能的社会实验探索智能社会治理中国道路这一条我觉得应该是一个很重要的问题应该是世界的道路探索智能社会治理这个倡议得到了社会各界的广泛的响应和积极的支持现在这个工作被写入了中央的文件中央的文件里面也专门讲到了这个工作然后现在国家市场监督总局进行标准化的建设通过标准平衡公共利益企业利益和社会的需求之间的关系现在也专门有这样的标准化组织在负责这方面的工作还有就是我们的政府八部委联合建设了92个全国的智能社会治理实验基地我们今天杨浦区和同济大学就是基地的之一而且也是在所有的这92个基地中我觉得应该说是做的最好的基地之一受到了国家的表彰八部委最近发文对这个工作进行表扬进行表彰那么最后呢就让大家用这个一千年前啊宋朝的这个张载说的这四句话大家肯定都知道为天地立心为僧民立命为往圣祭绝学为万世开太平我想今天我们这个时代啊大家要一起努力为智能社会呢要嵌入人文精神之心我的这个介绍就这些谢谢大家",
    "谢谢苏老师的精彩演讲因为时间关系啊没有完全讲透啊但是你听到黑丝理论也是和这个也是一个异曲同工这样呢我们六位嘉宾六位嘉宾呢都做了精彩的演讲大家在场呢也都听得非常投入相信呢各位嘉宾的演讲啊对于我们进一步的了解这个相关的各国的人文智能事业发展的现状和趋势都有了很大的启发正好呢时间也就到了实际上超稍微超过了几分钟啊非常抱歉但是人们不是说吗这个不脱堂的研讨会不是成功的研讨会所以我们拖几分钟但是呢因为他这个场地啊他是这个大会他是盯着的下午还有活动所以就不得已呢就现在主旨演讲完全就只能打住了好那么下面呢",
    "我们就有请啊我非常尊敬的我们的主席纪伟东老师来主持下一节的圆桌对话环节好有请纪老师纪老师呢是上海交通大学人文是人文资深教授是上海交通大学这个人工智能治理和法律研究中心的主任",
    "有请纪老师好请其他的几位圆桌对谈嘉宾一起上台在过去两百年间内燃机互联网大模型对社会产生了非常实质性的影响对社会产生了非常实质性的影响尤其是进入大模型阶段之后人工智能快速迭代我们可以看到规矩生命技术革命正在对社会产生非常深刻的影响这种影响啊我们很难预料它会往什么方向走一方面当然赋能个人赋能平台赋能社会对吧这个积极的作用大家都看到了它可能会使得人类的社会进入一个创新自由甚至无中生有这样一个阶段但另外一方面呢又让我们感觉到不安因为发展太快有很多的风险那么今天呢很高兴有机会和五位对话嘉宾来探讨智能社会的全球治理问题首先我想请第一位对话嘉宾李仁涵先生他曾经引领过中国的中国的智能社会人工智能治理而且不久前出版过一本书就是人工智能治理与国际规则首先请李仁涵教授来谈一谈这个人工智能治理当中各国的立场有什么样的不同我们需要全球治理但是各国的立场不一样他们有什么样的不同那么另外一方面呢在这样的情况下我们如何才能加强人工智能治理的国际合作李教授好谢谢季老师",
    "因为这个人工智能上海的人工智能大会我从第一届就参加一直到今天就是等于每届我都参加然后呢这个这次呢让我感觉到特别的不一样主要就是因为把治理加上了过去啊我们世界人工智能大会主要是谈技术主会场没有一个报告是治理的这次呢等于是主会场加了一个治理的报告也是我过去一直呼吁的那么这次呢兑现了就是我特别开心了这是一件事第二个让我感觉到了呢我前两届我有点失望因为美国对中国的禁止就是虽然我们叫国际会议但是看不到一个从国外来的人都是我们中国自己在讨论而且外国专家他本身也完全躲避了因为美国欧盟美国制裁嘛欧盟就跟着所以很多人他连视频都不愿意播放一个给我们所以我们前两届几乎我们都是中国人自己在谈这次呢感觉到非常开心来自德国的美国的还有好多国家的我们都非常的高兴也非常欢迎因为从这个技术的角度讲啊如果我们技术上不交流我们何谈治理呢所以在美国政府如果对我们要求治理合作而技术不得了如果我们不谈合作你说我们怎么合作所以这是我觉得今后一定是技术上一定要合作才能达到治理的合作这是前提那么我们再回顾现在来看了这个人工智能技术发展到今天现在我们确实可以这么确定的说也是我们的研究我们团队包括季老师在一起我们都研究过人工智能的基础理论体系现在没有建立这个我就不再太深的再往下讲了因为我们有研究报告然后这次的大模型的出来世界上最强的大模型出来以后只有60%与人是吻合的那40%的结论是与人相搏的那么基于这样的情况下你能够完全相信这个大模型所以我们的治理今天提到这么一个高度大家全世界都认识到而且最近美国一直讲要把AI关到笼子里但是建一个什么笼子这需要大家讨论也是季老师刚才问我的问题所以我也想等会儿我再说一下所以我现在首先要强调就是国际治理一定是技术治理同时合作才会达到最后我们苏教授提出了这个人文的一个智能社会否则的话是不可能的而且大家心平气和地做它跟核的这个协议还完全不一样核它技术专业性很强只要有一部分人给它封住了它就封住了这个是太有普遍性每个角落都有无处不在的你怎么管这是我们人类未来的一个命题所以另外我再讲讲关于价值观的认识在人工智能的问题上实际上我们那次跟傅大使在一起2019年我们开的闭门会议跟国际的IHPE的主席一起讨论的结果大家有一个共同的认识人类的价值观实际上是一致的跟制度没关系它的价值观是什么是以人为本共同的价值观在这种共同的价值观大家不要再去研究乱七八糟的制度不同怎么怎么的实际上你只要以人为本了人工智能的治理就能做了就是我们要把复杂问题简单化因为政治家们喜欢用价值观来整这个整那个实际上对于我们是为人民服务的国家我们一定要把它以人为本价值观人类的价值观是一致的没有区别的我是认为这个问题要简单的处理如果你不简单处理的话你永远卖不了这个卡而且各有利弊的因为时间关系我想先把第一个问题谈一谈就第一个问题为什么我们要治理因为人工智能的基础理论体系没有建立所以它在开发的前面的提到的一些设想最后出来的结果设想是达到了但是又出来了与你完全不知道的结果这就是因为基础理论体系没有建成的结果就是说开发者开发出来的产品最后的结果会出乎开发者的意料之外这种意料之外有好的也有不好的那么就是不可控了也是不可信那么我们怎么办那么这是第一个问题第二个问题我就在谈的就是说刚才鸡老师问我世界各国做法有什么不同实际上世界就是等于是目前全世界就是三大阵营一个是美国一个是欧盟一个是中国三个做法就是而且我认为各有利弊多有特色他们之间没有谁先进也没有谁落后怎么是做法不一样关键我们是要大家坐下来好好的谈一谈我们怎么办无非就是这几个问题技术标准知识产权技术标准法律法规然后最后共同怎么监管就把这几件事情大家一起讨论好然后做下来成立很多的组来把它做好因为我们都有特点你说世界上如果大家可以想象一个问题全世界如果没有中国参与人工智能治理这个世界会怎么样中国人工智能的人才水平不一定是最高的但是他的队伍是全世界第一的如果把中国拒之门外这个结果是很难想象的第三件事情就是关于怎么建立你刚才问我如何构建人工智能这个国际秩序这个人工智能的这个组织如何构建因为时间关系我们前两年出版了一本书叫人工智能与国际准则大家在网上查一下目前全世界就这一本书你只要打写写上人工智能与国际准则就这一本书没有第二本书我们所有的内容我们都写在里面了而且现在我看了以后我觉得这一点都不落后仍然是可以回答今天季老师提的问题我觉得因为时间关系谢谢大家",
    "我先说这些李教授三番就简说明了这个问题其中有一句惊人之语就是把AI关进笼子里当然因为是出于安全的考虑但另外一方面AI有需要发展它能赋能社会赋能经济这个时候关进笼子究竟会不会影响到AI的发展关于这个问题我想请今天的主办方同济大学金管学院的钟宁华教授谈一谈安全与发展之间的关系应该如何平衡好的主持人好各位嘉宾大家早上好那么很高兴能够做一个分享谈一谈我对于人工智能在社会治理和经济上面的一些理解那么首先就是这个经济的发展很大程度上是源自于技术的更新在过去的几百年当中大概有五六波大的技术更新技术变革那么都带来经济的繁荣所以在经济学里面有一个叫康波周期理论大概五六十年一波大的技术变革带来全世界至少是某一些国家经济的大的繁荣那么因此我们非常期待这一波的人工智能的技术能够带来新的经济的繁荣那么今天讨论的问题更主要的是在谈治理所以我就谈一谈我们的一些理解就经济当中有很多的经济是一个非常大的且复杂的一个系统那么我看到当中的一个重要的应用就是人工智能结合大量的数据对经济进行一个预判以及对经济当中的风险进行一个识别我跟大家介绍一下我们做的两项工作一项工作是我们每个月都在预测这个上海的总出口上海大概每个月大概会有一千万到两千万一千亿到两千亿当中的出口我们要预测两个月之后上海的出口会是多少那么我们是用一百多个变量去应用这个人工智能模型去做一个预测目前这个误差率已经从原来的10%降到4%对于出口来说这是一个非常不错的一个预测在全国的海关当中是做得最好的那么这就是一个应用就是对于出口而言影响的因素太多一百多个因素你靠人去判断是很难的但如果你能够很好的训练模型去判断他的判断就会比人更加准而且进一步他会告诉我假如说出口出现一些下降可能主要的原因是什么就一百多个变量当中大概哪些因素是重要的driving force就比如说我们就看到上海的出口和上海跟苏南地区的货运之间有很大的这个关系苏州到上海有多少货运这个是一个很重要的一个因素那么这就去提醒我们如果说上海的出口发现一个很大的变化那么是不是跟苏州这边是有些什么样的一个关系那么这就是一个例子来对于人工智能结合大量的数据对于宏观经济做出判断我再举一个例子就是这两年大家越来越关注地方债务问题那么尤其是这个承头平台大家知道这个承头债有多少吗全国总共有两万只承头债每天在交易那么我们另外一个团队就在做我们用三百个别的变量去预测哪一只承头债在未来一个月里面可能会发现发生大幅度的价格的下跌就是一个影响一个承头债的因素会很多很多它的地方的经济的情况承头公司自己的情况每天出现了大量的新闻的舆情就是我们要用很多很多的模型和数据然后去预判到底哪一个地方的承头未来有可能会出现大的风险其实本质上是让人工智能模型去学习之前出现过风险的那些承头那些地方它长成什么样子或者说做一个画像如果你能画像画得很准的话你就能够去预判未来哪一只承头有可能会出现比较大的风险那么从而去提示哪个地方的地方债务是需要关注的那么这就是另外一个应用就是在经济和金融体系当中有一些风险那么原来那是靠人去识别的现在如果你有大量的数据你就可以去训练人工智能的模型去画像然后去识别那么它的准确度可以不断地提高而且它至少能够跟人的判断形成一种互补从而能够更准确地去判断未来可能会发生的事情以及去识别它背后的影响因素那么在今天的从第一个演讲到现在其实一直出现一个词就是安全我们也很担心人工智能的误用所以我想其实前面很多的演讲都提到这个问题数据是最重要的对于人工智能模型的训练而言我觉得数据至少70%到80%后面才是算力和算法那么对于这个数据的限制对于数据的管制隐私的保护可能对于安全而言是至关重要的因为很多前面的专家都提到这点我就不再展开那么出于时间的关系我就先做这些分享主持人在智能社会算法构成一种权力那么数字国家和数字人权之间的关系成为一个非常突出的问题这个问题我想请这个就是这个吕鹏先生和这个罗士仙律师分别用两分钟的时间对不起啊因为时间关系来简单说明一下自己的看法好的刚才那个季老师说这个强大的国家我们一般把它叫做数字立委谈实际上除此之外我们还对对资本也感到非常恐惧大家一般把国家和资本当作是侵犯所谓人权或者公民权的最重要的这个威胁那有两种方式应对第一种方式就是消极通过立法通过这个铸造防火墙公司搞这个企业社会责任做科技向上但我想更重要的其实是一个更积极的一面就是我一直在倡导的要真正的维护社会权利就是要通过社会创新有一个非常著名的历史学家叫克兰茨伯克我稍微讲快一点他有两个非常他有六个科技进步的规律其中两条第一条讲科技不分好坏但亦非中立就有的科技本身它的应用的过程它其实并不是中立第二发明是需求之母我们现在一旦讲到社会的时候原则上我们可以说社会你保护自己社会组织起来我们参与到自我权利保护但为什么社会要组织自己每个人都是个人都是个体的他为什么要参与到保护自己的权利呢我们在业主维权中如果大家知道在业主维权中最简单的一个现象现代的问题不是业主跟业委会闹是业主跟业主之间都闹得不停他怎么组织起来去参与到保护自己的权利呢面对这样一个非常具体的问题实际上我想最重要的一个办法就叫社会保护权利社会创新社会创新有很多维度其中非常重要的一点就是要依靠科技的发明创造通过科技本身来解决社会问题比方说我们可以用数字化的手段业主委员会的相应的APP我们进行三无公开就很好的就能够解决业主和业委会业委会和物业之间的关系再比方说快递小哥他不能够进社区最后一公里我们没有办法打破用各种办法可能都不好使但可能最好的一个办法你给快递小哥弄一个什么码他直接就可以通过层层的限制就能够进入到最后一公里因为时间关系不能直接展开所以我想讲的是真正的要想维护每一个个体每一个社会群体在数字时代的权利一是通过立法通过资本向善但更重要的是要用科学技术的方式摸清社会的办法用发展的办法来真正的保护公民权好 谢谢",
    "下面我们再来听听美国律师罗士轩先生你的看法谢谢不好意思 大家好我的中文没有卡门那么厉害所以我可能用英文讲所以我认为我认为我认为我认为我认为我认为我认为我认为vemos有网民去大学我们在代出审核动员等计划途中尝试了解本身的审判上传过的致力所以律师想着如何套用本身的审判为新技术遵循与公司谈论但小孩子练习为他们理解他们的 starring이�oston网 那个广ümcontrolling非常有趣的是網絡障礙、網絡安全這些法律在全球發展中中國在遊戲業上已經很久都在研究這些但在我自己的國家英國現在有它的網絡安全法我們看到歐盟電腦計劃也在這方面集中所以我認為法律有一個非常重要的角色當他們從他們的學術技術體系進入科技思維能夠幫助社會以及我們的客戶甚至是從CSR的角度來看也許可以幫助這些新的技術和新的法律非常感謝您的精彩評論謝謝您的介紹謝謝您的介紹謝謝您的宣言大家說一個觀點拿出三分之一的所有的投入來放到整個的AI安全裡面其實這件事情大概我們能其實感知得到大家對這件事情的擔心和顧慮但本身我覺得其實是一個比較難落地的事情我們拿三分之一的話我們如何度量為什麼是三分之一不是二分之一不是四分之一然後我們怎麼樣去衡量哪些是AI安全的事情其實包括Hint包括Elon Musk其實他們經常在說很多就是說例如說OpenAI現在其實做了很多主力的事情那其實他們花了很多錢在做Align這件事情就是對齊那他們在做對齊這件事情是不是一個安全的事情其實這個都有所我覺得定義吧那至少從作為一個企業或者作為一個我這個技術人員的個體而言的話其實我覺得我們現在可能還不用那麼太擔心這個這個這個這個這個問題就我們可能現在還是盡可能地不阻擋地讓它蓬勃地發展例如舉一些例子就是我們因為這個飛書其實跟很多企業共創嘛我們會發現其實真正起效果的我們現在不是擔心AI發展太快而是擔心太慢給大家舉一個例子一個1000人左右的公司它現在用AI來去做一個什麼事情呢並不是我們認為很多高大上的事情其實最後都落不了地但有些東西能落地第一件事情是翻譯就翻譯這件事情其實我們已經做了很多年但是我們看今天還有同聲傳譯的這個同學來去跟我們進行翻譯這件事情包括做了我們做很多Motion Learning的這些東西但實際上我們其實有了這波AI之後1000人左右的公司一年能多省76萬來在翻譯的一個場景裡面去我們跟很多跨境出海的遊戲公司教育公司大家說我有好多外包人員我來去翻譯那現在由於AI來了我這些人要不要還是要的但是這些人從以前的填空題變成了選擇題他只要檢查AI翻譯的對不對就行了所以這其實是我們看到的一個點另外其實我們除了那些fancy的我們一個是翻譯的場景就會看到真正的效果另外的話整個字節跳動的話有十幾萬的人但其實我們只有很少數的幾十個人在7乘24小時的去服務大家在這個IT你電腦有什麼問題了你有什麼連不上網了這些人只要7乘24只要這麼少的人那是為什麼呢其實因為我們大量的這種知識問答已經變成AI來去問答了那AI來去問答的就是其實包括大家各自在這個公司和在學校或者各種組織裡面很多問題是被重複問的我什麼時候發工資啊我的無限一金怎麼繳納呀在這個裡面我也進行了一個測算差不多在一個單的部門裡面就是一個800人左右的這種科技型公司一個單的部門例如是一個法務部門就能一年節省30萬就通過AI來去解答這個問題而不是雇一個人那其實它有HR的部門啊行政的部門所以這種計劃我們看到其實很多我們現在的一個總體認知的話總結下來我們覺得AI還至少遠沒有達到能給大家進行威脅的程度包括現在我們其實很多東西都受限於底座模型所以我們覺得就是短期的話呢我們其實還是希望能夠給AI更多的這個機會讓它蓬勃地發展起來因為我們看到了其實本質上的話很多的從前其實重複的這些工作很包容的這些工作來再被AI所代替那總體而言我們覺得這件事情不是壞事就是總體讓大家整體工作的幸福感可能會更提高包括我們有些程序員其實在用讓它這個蓬勃發展最後大家帶來福祉的吧這是我們的感覺那個關於企業的剛才談的這個意見李鴻教授您從經濟和管理的這個角度來看您是怎麼看這個問題的其實我覺得剛才飛叔說的就是我一直在倡導的叫做企業社會創新其實就是把企業的技術和能力應用到它的社會場景當中讓真正的所謂科技向善能夠在產品 在服務在這些場景當中解決實實在在的社會問題這我才是覺得最為可持續的讓公民 公眾參與到所謂AI治理當中最重要的方法因為你首先要讓它富能讓它有動力 有能力來參與到這個AI治理當中否則一切都是空中樓閣只是紙上談兵好的最後我們請李仁涵教授用一分鐘的時間對剛才我們討論的問題做一個總結看看人工智能治理這個方面今後發展的方向何在就是我在7月3號的時候我在朋友圈裡面我發了一段就是AI是否要被關到籠子裡當前不一定不遠的未來必須這就是我今天的感受也是跟我7月3號是一樣的謝謝大家謝謝五位對話嘉賓在非常短的時間內做了精彩的呈現下面我們今天的討論就到這裡時間已經不早了謝謝各位再一次感謝各位專家學者帶來的精彩的圓桌對話環節再一次感謝各位尊敬的各位領導各位嘉賓本次論壇的全部議程到此已經結束了最後再一次感謝各位領導和嘉賓的播放謝謝各位謝謝"
]