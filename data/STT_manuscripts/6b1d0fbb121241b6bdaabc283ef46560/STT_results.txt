请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请各位嘉宾把手触摸在大屏上
开始我们的启动仪式
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
请各位嘉宾把手触摸在大屏上
一个水平
那就是会对所有人
是一个挑战
它会挑战你
你的工作的意义
甚至你生存的意义
就是你努力了一辈子
你可能离它的距离
会非常远
它会挫败你
所有的学习的兴趣
这个挑战是前所未有的
我们人类从来没有遇到过
这样一个
我们自己创造的东西
它有这么强强的
我不能再说了
时间到了
谢谢大家
感谢高院长
Mr.Caspers
I know that you have
25 years experience
in domestic and international
public policy area
and also you have
a very in-depth
and out understanding
on the risks research
and so we really want to know
what do you think
are the biggest challenge
and risks in the AI governance
and also we would like to know
if you can order
at least the top three of them for us
you order please
OK well thank you very much
and it's a delight to be here
I think I'd just like to
to pick up from the last speaker
step back and say that
I think one of the
the first pieces of context
that we need to realize
when discussing this question
is that we need to be focused
not on the artificial intelligence systems
that we're seeing today
although many of them
are already raising many challenges
but we do need to look ahead
five years
possibly two years
maybe sooner
in terms of the kind of systems
that it may be possible
for humanity to create
within the AI system
within that period
that might be
far far beyond
the kind of AI systems
that we're seeing now
systems that would have
the ability to match
human level performance
across a broad range
of capabilities
and then systems
perhaps not too long after that
that could far surpass
human levels
in a very broad range of capabilities
these are sometimes known as
artificial general intelligence
artificial super intelligence
as you mentioned
the companies have got these in there
and they've got these in their plans now
I think we can't
it's
we can't be certain that it'll happen
but we also can't ignore
the possibility that it may
so what kind of new challenges
would this raise
if we are actually on the cusp
of this kind of development
and I think it's important to notice
that a lot of the challenges
that we may face
may be
ones that we can handle
at the national level
or with groups of like-minded countries
but there are some challenges
that are truly going to require
global collaboration
and I think this is
these are areas where it's inescapable
that we need to work together
because the challenges cross borders
and because we can't
preserve the safety
and the well-being of humanity
including our own citizens
unless we actually work together
with other governments
so
we've just published a paper
called a framework convention
on global AI challenges
which details this
but we really see three big areas
of challenge
the first one is actually about
realizing and distributing
the global scale benefits
of artificial intelligence
the private sector
will do a huge amount of work
and helping to generate these benefits
but we also will need
government intervention
and government collaboration
to make sure that those benefits
are fully realized
and that they're fairly distributed
at the global scale
that means about ensuring access
to AI tools for all
it means about using the most advanced
artificial intelligence
tools to generate
global public goods
and it means
distributing and sharing the benefits
in ways that are
ensuring that they're not just
concentrated among a small minority
even within countries
or between countries
so that's the first
is the really
on the benefits side
I think the second global challenge
is really around risks
around mitigating the global scale risks
and by global scale risks
what we really have in mind
are those risks to
primarily to public safety
either through the misuse
of very powerful systems
that could be used to
by malicious actors
to create new weapons of mass destruction
or ultimately
to come back to the point you mentioned
the ultimate global risk
is really loss of control
over AI systems
it may sound like science fiction
but we are entering a world
where it may become possible
to create systems that are
extremely powerful
that we actually humans
are unable to control
right now we're on track
to being able to create those systems
we're not on track yet
to knowing how to control them
and unless this changes
this could be very difficult
very dangerous
and really require governments
to come together
and find a ways to manage this
and then very briefly
the third big area
I think global challenge
is around making some
legitimate and effective decisions
and choices about
the future of artificial intelligence
and its impacts on all of humanity
because we are
if we are entering a phase
of our history
where we might be possible
to create machines
that are vastly smarter than humans
I think we need to
have a period of reflection
of careful consideration
about what kind of systems
we want to create
when
under what conditions
with what safeguards
and this needs to be a discussion
that is
these need to be decisions
that are not just made by a small
handful of people
in a few technology companies
it needs to be made
in a broader
more globally legitimate fashion
so to answer finally
if I had to pick one
that I think is most urgent
I would say that the
the public safety risks
are
we don't know
they are urgent
because we don't know
what the timelines are
there's huge uncertainty
about the timelines
and given the
speech
potential severity
and the uncertainty
of the timelines
we should be
acting now
to be sure that we're ready
and I think that we can do that
within the context
of some solutions
which I'll come back to later
Thank you so much
I think Professor Gao
and Mrs. Becks
also mentioned
both mentioned
that the uncertainty of AI
and also we don't know
when the
generative AI
no no
general AI
will emerge
and we also don't know
what is the actual risk will be
thank you so much
那么下面第二个问题
我其实想
这个也是
又受到第一个问题的启发
就当我们真正到达
我们可能期望的那种
通用人工智能
或者是极为先进的
比人类
更为能力强大得多的人工智能之前
我们还有很长的
漫长的发展道路要走
那么相信
刚才高教授也提到了说
我们对于发展这个事情
还是蛮有共识的
可是对于安全
可能相对来说
虽然有共识
但是要做的
并不知道有什么
那么就如何平衡
我们在发展创新上的努力
以及在平衡
安全治理
安全监管上的投入之间
那么这两方的利益如何平衡
我特别想请教一下
这个来自华为的刘院长
能不能从产业的角度
和您在这个产业一线时间的角度
回答一下这个问题
非常感谢主持人
提问
然后也非常荣幸
能够参加今天的讨论
作为产业的一员
从我们的视角
可能分享一点
针对这个问题的一些思考
我觉得首先可能还是
还是关于发展和智力之间的
关系的问题
我觉得正如刚才的
我们的研究报告
包括刚才专家也提到了
这个发展上
大家是达到一个充分的共识的
所以说我们认为
首先还是对于两者的关系
可能还是我们认为
智力还是为了发展去护航
为了更好的一个发展
那么还是要在发展中智力
在智力中发展
因为确实刚才我们提到
人工智能可能面临
可能相对不那么远期
实际上就有很多这种风险
或者说可能关乎到
我们人类生存底线的
这样一些风险可能是会存在
那么我们面临这样的挑战
我们当然是要去
保持足够的这种重视
另外一方面其实我们也
不应该放弃
就是技术的进步
和善意的这种应用
给我们真正的生活
所带来的这种福祉
实际上这个是几千年以来
证明过了
就是我们人类生活
福祉的这种改善
其实很大程度上
依赖于技术的进步
所以这是我想强调的第一点
那么从实际的落地的过程当中
我觉得主要有两点
就是一个是
可能还是要我们针对
采取分级分类这样的一个处理
我觉得这个分级分类
一个是我们治理的体系
当然风险本身是分很多种
长期的 远期的
包括可能涉及到人类生存安全的
包括这个
对人福祉
包括可能有一些
不那么对人敏感的这样一个风险
当然我们在真正构建
我们的治理体系的时候
我觉得也应该采取一种
就是分级的这样一种方式
比方说用法律来规定
这样一些安全的底线
来守住我们的最后的防线
另外就是我们可能
作为人工智能从业者
或者说利益相关方
应该也要承担起这样一个责任
或者构建一些充分的
这个通过自律来
在我们一线的工作当中
来承担起这样的一些义务
那么当然就是我们可能
我们也看到道德
包括一些软性的一些牵引
实际上对于我们预防一些
更潜在的一些风险
其实也发挥了非常关键的作用
那么第二点
在实际的这个逻辑当中
我觉得还有就是说
对这个风险进行分类分级的
这样一个处理
按照场景来区分
比如说同样是推荐的算法
那么其实你来推荐这个商品
和推荐这个治疗方案
实际上它对这个潜在的人的威胁
实际上是完全不一样的
所以说我觉得
风险应该放在不同的场景下
去分别地去分析和处理
这样的话避免一刀切
这样的话我觉得可能就会对一些
不那么敏感的场景
可能就会把人工智能的价值
从而发挥出来
我们不错是利用人工智能
这样的一个机会
比如说像用于气象预测等等
这样一些场景
这样的话我们来支撑我们联合国的
这些可视预犯的目标的这样实现
当然在一些领域
我们可能要非常的慎重
我觉得这个是
可能我们可以在实际的操作层面
是可以关注的
我就想分享这么多
好 感谢柳院长来自产业的声音
尤其提到了分级的分类的这种
不是一刀切的个性化问题
而是一刀切的个性化的做法
可能能给发展留足更多的空间
那么这个同样的问题
我希望问一下
我认为您的研究
对人权和人工智能有很大的研究
我们也认为
纽约国际协议
刚刚通过纽约国际智能协议
GDPR和国际智能协议
有时候被批评
以阻止美国国际智能发展
那么您认为
美国国际智能发展的关系
是什么
您对美国国际智能的改革和安全
有什么看法
绝对的
我认为这是一个
对美国国际智能发展的关键问题
因为我认为
我们总体上有两个框架
我们有一个框架
在美国国际智能发展的关系
非常符合
纽约国际智能
所称为
人权和人权
这非常鼓励
美国国际智能
在美国国际智能
提供的强化保护
除此之外
也提供了
美国国际智能的
很严厚的高风险定义
另一边
我们基本上是
对于这方面的公司
批判的公司
我认为
这是非常重要的
在美国国际智能的
逻辑上
我认为
美国国际智能的
逻辑
实际上
我认为
这个问题
非常复杂
第一个原因
是
最近的法案
仍然很难
让公司
和观察员
实际上
作出判断
如何影响
市场运动
因为
如果我们看过过去
我们经常看到
法案的改变
通常被公司
视为
威胁
或者
基本上
是
增加公司的负担
所以
这就是
通常的方式
因为
这意味着
公司需要适应
我们已经看到
在GDPR上
因为
很多公司
仍然坚持
与GDPR
辩论
因为
这实际上
是
负面费用
尤其是
如果您看
药业业
在EUA法案中
创建的
因为
通常
法案
专注于
健康
或人权
或其他
都会
根据他们的大小
与公司
辩论
所以
我们认为
公司有1000名工作人员
或
一个
数量
的
收入
或利润
会受到法则
因为他们较大
但实际上
当我们看EUA法案
我认为
这个
大小
或
我们看到
EUA法案
实际上
是
对公司
在某些
高风险领域
行业的
立即有用
所以
从
经济角度
我认为
无论
公司
正在
使用
公司的
负面费用
正如每个法则
因为
你会有
公司
指摘
以及
公司
如何
执行法则
我认为
公司的负面费用
是
公司的负面费用
因为
公司的负面费用
特别重要
当我们看
药业业
已经
非常
被
摩托
过去
我认为
几个月
我与公司
谈论了很多
基于
药业业
而
背景上
药业业
是
以EUA法案
NX-3
作为高风险
因为
它在健康上
很重要
所以
公司
也需要
考虑
关于
药业的
负面费用
但是
问题是
药业的负面费用
是什么意思
因为
这个词
并没有在EUA法案中
实际上
定义
所以
通常
你可以认为
药业负面费用
是
相当于
抵抗执行
所以
如果您看
欧洲协议的
抵抗执行法案
然后
您可以看到
药业负面费用
是
相当于
抵抗执行
但是
如果您看
药业负面费用的
学术研究
我们看到
这个定义
比较复杂
尤其是
医疗方面
在
抵抗执行
的
问题
因此
有很多关注
尤其是
药业业
但
也有关于
复杂的
医学解决方案
例如
飞机
或
自动驾驶
有关于
抵抗执行费用
尤其是
因为
在许多系统中
你不仅会有
一个高风险系统
但是
还会有很多
所以
你需要
基本上
要做
抵抗执行
和
影响执行
各种
医学解决方案
所以
这也是
我看到的
基本上
抵抗执行费用
在上升
而且
这在短时间内
对欧洲市场
来说
是
欧洲市场的
高风险
大多数
欧洲市场
认为
欧洲市场
是
高风险的
而且
欧洲市场
是
有很多
很多
高风险的
医学解决方案
我们看到
在
德国
车产业
这种
公司
有
很高的
高风险
和
高品质
所以
我们看
这两个论点
很多歐洲製造公司
可能會移民到美國或加拿大
因為他們對新興有更好的風險
但在其他業界上
公司在高規範的程度上
例如自動駕駛
公司可能會繼續留在那裡
好的,謝謝你,博士
謝謝你們的分享
其實我不知道
世界上所有人都覺得
歐洲的服務和產品
是更高級和質素高的
這也許是高級法律法律的優勢
謝謝
感謝
我們也可以看到
實際上在這個AIR Act
其實還有兩年的時間
才會最終完全生效
才會最終完全執行
所以我們也可以期待
在未來兩年之後
我們可以看到
比較嚴格的
監管會對產業和創新
有什麼樣具體的影響
那麼下面第三個問題
我也有特別想請
兩位眾望的嘉賓回答
因為第三個問題
這個Matt的中文非常好
所以我就不說英語了
第三個問題
我想請這個Matt和顧院長回答
就是一個特別重要的問題
就是在整個的AI治理當中
我們都發現
其實政府不能再像以前
發揮一個絕對主導的作用
而整個AI治理當中
不管是監管部門
還是工業界
我們的產業部門
包括學界 智庫
還有我們的專家
都在發揮非常重要的作用
那麼顧先生
其實也是來自產業界的研究部門
可以說同時兼具研究專家
智庫和產業的角色
所以這個問題
我想先請顧先生回答
就是您認為
在這樣一個AI治理當中
不同的主體
在人工智能的國際治理當中
應該發揮一個什麼樣的作用
有請
好的 謝謝主持人
感謝各位老師
今天非常榮幸有機會
能夠來這兒參加這個panel論
關於人工智能的問題
其實這個問題
我的一個個人的感受是說
如果從理論或者說詞語上來說
大家都會說多方協同共治
剛您列出來的這個政府
產業 智庫等等這些
都是一個multi-stakeholder的
這麼一個
那我們就如果拆開來說
其實我們現在看到
各個國家地區的話
關於政府的作用怎麼發揮
產業的作用怎麼發揮
以及說智庫的作用怎麼發揮
其實是不太一樣的
我這邊就先舉
一個例子
可能大家開了一天會了
也會比較困一點
一個就是講一個
一個叫面壁智能的這麼一家企業
它之前就出了一個小參數的模型
後來發現
所謂的一個
Stanford的一個抄襲的事件
其實只是一些本科生的一個
偶然的一個行為
那是通過開源社區的力量
發現了這麼一個事情
所以其實我們今天在這個
WAIC期間我們也看到
其實從會場來看的話
整個中國的人工智能行業
我的個人的判斷
感覺是說它已經在走向一個
一行百業的一個應用方面
不管是你的基礎的算力層面
還是在模型層面
還是在應用層面
因為阿里巴巴正好是一家
可以說是全站的產業鏈
全部能夠覆蓋的這麼一家企業
我們特別突出的一個感受是說
在產業側
大家都在貢獻自己的智慧
剛剛講的開源是一個
再比如說我們通過大量的調研發現
其實企業
特別是在B端的用戶側
他們不會去考慮說
這個模型是誰的
是誰家的
Benchmark怎麼樣
而是說這東西到底好不好用
我們叫不選大的貴的
是選好的
性價比高的
所以我相信其實最後
你比如說你模型的這種
在場景下的容錯率
你的性價比
以及說你對於人的這種
核心的效率的提升的能力
會最終決定
這個行業的一個發展的方向
所以我認為產業最重要的就是要
發揮好一個
我們認為應當是一個主導的力量
就是你這個力量
不管是通過開源的方式
通過基礎研發的方式
通過應用推廣的方式
能夠讓所有人用得起大模型
如果大家真的相信大模型是最大的的話
那麼我們就應當相信
它一定是
普惠的
對吧
大家都說大模型是電
是煤是等等
那它最終它一定是普惠的
所以我們不太相信說
OK
一個東西只能有一些人能夠用
或者用得特別好
永遠居於一個上游
我們不太相信這個
我們永遠致力於說AI for good
同時呢
AI也一定是equality的
這是一個產業策的一個視角
另外從政府策
其實最近我們也會去關心
你比如說像美國最近它
其實我們傳統講
美國的人工智能治理的話
在AI之前就開始了
我們當然總結了三個特徵
第一個
第一個是什麼
是強調美國的國家領導力
就是我一定要在AI方面有leadership
第二個是說
我希望是我的AI的話
我的US government
Federal government
我能夠多用
就是我政府體系內部
我要起一個示範作用
第三個是說
我一定是基於創新的監管
就是我的這個創新的措施
我監管的措施
不能去對這個發展
產造一個阻礙的作用
那剛剛很多的學者也都談到了
歐盟人工智能法
其實歐盟人工智能法對於GPAI
它還是留出了一個相當大的一個空間的
它並沒有把GPAI完全適用於那四個
高中低和核武風險這樣一個
它其實
這個中間其實它有巨大的不確定性
我們判斷
未來歐盟不會在人工智能時代
所謂讓這個布魯塞爾效應
再像數字平台時代一樣
成為一個
當然你說
Basic human rights也行
你說是一個defense作用也行
我們認為歐盟在AI時代
一定會在全球發揮它更大的一個作用
所以那咱們說回美國的話
包括加州最近的這個SP1047法案
我們當時看到它的一個
這個立法的一個思路
如果順利的話
八月份可能會通過
它設置了四種情況
我們講什麼意思呢
就是
它對於一家企業說
你如果履行了A B C D
如果你前面三步都沒有履行
那你到第四步
你才需要去承擔一個極重的合規義務
前面三個它都是說
基於你的自主的這種研究中的發現
你能夠找到一些風險點
你能夠主動把它規避掉
你採取這些措施
並且你向我做一個report
這樣的一個通報職能的話
你就可以去享受一個
它是所謂的
這個叫有限責任豁免
這實際上就類似於
我們說類似於其實平台時代
一個避風港的二三令原則
就是那個美國1990通訊規範法的
那個section 230
我們認為美國現在實際上
它在建完的時候
它是想去再發明出一個
這個AI時代的避風港原則
包括我們發現
其實美國的很多行政令也好
它的最近的加州立法
他們一直是以10到26次方的flops
總算力作為一個模型
為frontier model的一個界定的範疇
它這個是遠遠高於目前市場上
所有的這個模型的訓練能力的
所以我們看到
黨人都在為AI safety
在研究的時候
他們確實是著眼未來
它從模型的域質上
從你的這個合規義務的履行上
它實際上強調的是一個
事前的審慎
而不是一個事後的追責
強調的是一個過程的正義
而不是事後的審判
它強調的也是一種
這個企業的自主自願
和政體之間的良性溝通
而不是一個
比如說嚴格的暴僻制度
因為在模型之前
我們在這所有人
包括像科學家們
像這個首爾峰會之前
發布的這些AI safety report
都承認
包括剛剛各位老師也提到
我們並沒有一個
很強的能力去判斷到說
AIGC也好
生成人工智能
或者大模型AGI
未來的走勢是什麼樣子的
以及說
目前它的這個風險的機制
是什麼樣子的
所以我們現在是very early stage
這是我們看產業
以及說看風險
看治理目前的一個階段
以及說我們判斷這個
government也好
產業也好
它所作用的一個基本的一個維度
好 謝謝
感謝貴院長
那麼他不光這個介紹了
就是歐盟和美國
最新的立法情況
實際上也提到了
即使我們認為說
其實歐盟的立法很嚴
但實際上和美國的立法一樣
也有很多對產業的豁免
並且很多新的法律的制度
正在生成當中
那麼這個問題也特別想拋給Matt
有請
好 我挑戰一下
我試著用中文回答
但是應該說到一半就換成英文
我覺得這個問題關鍵的是
你要能保證社會的每一個主體
都有他們所需要
的這些資源
來真正的去參與AI治理
那這個在每個國家都是不同的
我先說美國
在美國這個學界
學術界學者
他們缺乏的是算力和平台
我說平台就是一個參與
那個政策制定的一個平台的一個渠道
我覺得在中國學者的
他們佔的這個位置
或者他們的角色在
就比方說
張老師
就是比美國要強很多
在美國學者是很難
他們就不知道應該怎麼去參與那個AI治理
那政府他們所缺的就是人才
在美國現在比可能三年前要好很多
但是還是我們的這些監管部門
他們最缺的就是人才
如果說行業企業他們所需要的
我覺得在美國他們
They have everything they need
他們有錢
他們有平台
他們也有這些人才或者expertise
那在中國應該是不同的
我覺得學者他們佔的這個位置
It's a little bit better
It's they participate more in governance than in the US
可能企業在中國企業所需要的
他們也是主動的來參加治理
那可能他們最需要的是一個
fundamental protection
or area of recourse from government
from government action
他們是能參與這個治理
或者治理研究的政策的這個過程
但是最後如果政府對他們有所要求
他們也沒有什麼特別靠譜的一個
渠道來fight back
So I think this is different in every society
But you just need to make sure that every part
has the things that they need to participate
It's never going to be perfectly equal
Um, but you just need to make sure that every part has the things that they need to participate it's never going to be perfectly equal
Um, but you just need to make sure that every part has the things that they need to participate it's never going to be perfectly equal
But each society can make progress on this
And I think in the US we've made a lot of progress
And in China I think there's been a lot of progress too
I think government officials, regulators
have gotten much smarter about regulating
AI in recent years through kind of
the crossing the river by feeling the stone
Interacting with companies
Learning how the models work
They've had a lot of practice with that
Our American regulators have not had practice
interacting deeply with companies and models
So I think that's kind of what we need to do
So I think that's kind of what we need to do
Thank you
I think your Chinese is much better than my English
I think your Chinese is much better than my English
I think your Chinese is much better than my English
I think your Chinese is much better than my English
I'm not totally agree with you
Because in the kind of bilateral dialogue
I met a lot of academia
I met a lot of academia
Like you
To participate in the legislation
And the consulting process
Of the United States government
Yes,当然了我也知道
MAT也对中国有很多的研究
那么稍后我再请您发表高见
那么下面这个问题呢
可能是我们今天的这个
更为重要的一个问题
因为我们在这个人工智能的
国际治理的这个panel
那么我们下面一个问题呢
实际上是想请三位专家来回答
那么
I want to ask Mr. Casper
We all know that
We have a lot of existing
International governance
Multi-electro
agreements
And kind of international organizations
Like we all know
Many effort on this global AI governance
Like AI safety summit
And we all know that
UN
Is planning to
Establish a global AI
And kind of mechanism
Collaboration on the global AI governance
So what do you think
Like we can
Have a kind of mechanism
Interest of different countries
And different sectors
Like private sector
And the public
And the academia industry
What do you think
This ideal mechanism should be
Thank you
Thank you
Well you mentioned that there are a lot of different processes
Underway at the United Nations
And the Bletchley summit follow ups
And the G7
And many others
Including many very important bilateral
Negotiations
And track two processes
And I think those are all very important
I think one problem with
Most of the official processes so far
Is that they are still focused on
The AI systems of today
And not enough of them
Are really looking forward enough
To the kinds of challenges
That we could face
Possibly in decades ahead
But there are some good reasons for thinking
That there is a possibility
We could face these
Economic challenges even sooner
So I think there is a real need
To push these
Processes to be ready
For the truly global
Challenges that I was mentioning
And the challenge
The difficulty there is
How do we find
Solutions that at the same time
Are legitimate, are inclusive
Are really global
While at the same time
Being practical and effective
And actually getting the job done
And I think the way
We are proposing that this could be addressed
Is through what we are calling
A global
An international framework convention
On global AI challenges
Now as many of you may know
In international relations
The advantage of a framework convention
Is it's a sort of high level document
Signed by hopefully all countries in the world
And it really sets out
The core objectives and principles
What do we want
As commonly as humans
We could build off
A lot of the consensus that we saw recently
With UN resolutions
Including the recent one proposed by China
And just set out
Really provide the legitimacy
In terms of where do we want to go as humanity
But then the next step
Of a framework convention
Is that it's supported by more detailed protocols
And those are the ones that really
Look at the specific
Requirements and recommendations
That's the much more contentious part often
But that
Can involve smaller numbers of countries
At least initially developing them
And so for example
What we've recommended
Is that there be at the same time
As adopting a framework convention
Probably by the United Nations
That there be a protocol be developed
Specifically
Addressing the issues
Of global scale risks
From the most advanced kinds of AI systems
And the safety risks
And that kind of
System would put very much
This idea of the stratification of risks
And identifying that some risks
Require global collaboration
And more severe regulation than others
But I think that's
I won't go into the details
Of what that looks like now
But just to say that
I think that really allows
The potential for
For example leading AI powers
Such as China and the United States
And others to come to some sort of
Swift agreement
Around the details of a protocol
Is quite challenging
They wouldn't be acceptable today
But we might need them in the future
Such as mechanisms to monitor
To make sure that nobody is
Developing an AI system
That would put other countries in danger
So these would be very challenging
But I think it might be possible
In that context
And then eventually from the core group
Then one would hope that
All countries would eventually sign on those protocols
And that we develop protocols
In all of the other challenge areas I mentioned as well
To reconciling some of those issues
And bringing all the parties involved
But the details will be
What we need to work on
And especially innovate on
In the coming years
Thank you so much
那麼這個問題呢
我也想問問這個中方的專家
也有請這個高奇奇教授回答一下
比如說您認為在這個
未來的全球人工智能治理當中呢
如何去構建一個多方參與
各方平等都能公平發表意見的
這樣一個機制呢 有請
好的 謝謝張老師
這個我理解這個問題是這樣
就是順著剛才我講的這個思路
我定義的三大類問題
就是首先是失業
第二個是失序
第三個是失控
所以它的問題呢
應該是一個非常整體性的
那怎麼去應對這些問題呢
首先呢我們可能
很多問題還是
我們今天儘管講全球治理
但是其實還離不了國家治理
所以這裡面剛才我們的報告當中
也說到要全球治理和國家治理
一個平衡
這就涉及到可能涉及到幾類
治理的主體
第一類的主體就是我們
人工智能企業本身
你要自己去構建一些
監管的這個
自我監管的一些規則
但其實是很難的
因為作為人工智能企業本身來講
它的核心任務不是治理自己
是要跑到最前面去
所以這個治理呢
其實也很難做到監管自己
其實呢
很多的監管的規則
其實還是要在國家層面形成
包括在一些像剛才提到的加州
這樣一個地方政府層面
或者國家政府層面
然後這其實就會出現一個什麼問題呢
就是國家和國家之間
還有一個競爭的問題
所以這樣一個競爭
在某種意義上
讓這樣一個治理有的時候會比較鬆動
就是說你到底是治理
還是希望我們的企業可以跑到最前面
如果你治理過重的話
它可能跑不到前面去了
所以對於主權國家來講
它還要考慮到一個
企業可能會用腳投票的問題
如果你監管過重的話
就像有的企業
它可能原來在英國就會跑到愛爾蘭去了
因為愛爾蘭比較
比較更加的寬鬆的一個環境
所以這裡面呢
對於主權國家進行治理來講也是一個難題
另外呢
國際治理有沒有難題呢
當然難題更大
全球治理的最大難題就在於
聯合國治理本身就是一個非常鬆散的框架
我們今天都知道
聯合國呢
在很多問題上都會cover到
但是呢
它的這個有效的程度
肯定比我們說
我們就今天來講這個問題
肯定是相對比較弱的
所以呢以至於我們今天都在談論治理
但是一個最大的問題
就是這樣一個治理實際上是一個
fragmented governance
是一個碎片化的治理
就是
好像我們都有很多的主體
多方協同
所以這是我剛才回應張老師提的問題
那個最難的一個問題
所以我的觀點就是
我們可以稍微把這個問題簡化一點
其實最主要是兩類問題
第一類問題呢
是在AGI
快速到來的背景之下
我們如何去應對
剛才提到那個10-26次方
以上的那樣一個
fragmented這樣一個大模型
因為它可能會被濫用
因為它有可能會被
惡意的人去用來造
各種更加厲害的武器
生化的生物病毒
什麼東西
那這個是一定要將來形成類似於
和不擴散
條約這樣的框架的一個內容
這是一類問題
第二類問題就是在於
我們還有很多的不發達的國家
全球南方
他們還要有這樣的一個access to AI
對於他們來講
其實是要推動我們的
比較小的模型的
一個合理的擴散
甚至要讓它有這樣的一個
capability building的這樣一個過程
我覺得這是第二個主題
第三類主題就是
由於大模型的緩慢的
有可能會快速的使用
它可能會剛才我提到的
像一些虛假信息啊
這樣一個問題怎麼個去對它進行治理
我是有一些思考的
就是將來可能的失路啊
有類似於
碳綜合這樣的框架
就是IPCC這樣的一個框架
就是碳的這個框架的一個
基本的思路就是說我們
每天都排出二氧化碳
那你對你排出的二氧化碳要有一個定價
然後呢你排出這個碳呢
將來呢相當於你每個人都
分配一定的碳排放權
如果你超出這樣的每個人的話
每個主體或者企業
你超出這樣的之後啊
你就需要去購買這樣一個
實際上是對碳進行一個定價
所以我的一個建議就是
將來我們能不能對人工智能的
使用要定一個價格
就是你過度的使用每天都在使用
大量產生大量的信息
我們也辨不出來它是虛假信息還是正確的信息
那這個使用其實是要定一個價
這個價呢要收了這樣一筆
所以將來去解決剛才
彌補一些剛才有可能
產生的失業的問題
或者失去的問題等等
我覺得這可能是幾類問題
可能不能完全的放在一個上面來講
對於剛才我講到那個
核不擴散的
類似於核不擴散那個
Frontier AI的一個治理的問題
那其實就要用剛才那個
要建立一個在我看來就要建立一個
類似於IEA這樣的
框架的一個專門的組織
這樣才能會有效
聯合國呢它有非常多的任務
它要有效的執行這件事情
就要有專門的機構
這是我的一個主張
然後另外的其他的問題包括其他發展啊
全球南方啊這個倒是其實可以通過一些其他的計畫
我簡單回答啊
感謝高教授
實際上從您的回答中我們也可以看到
這是一個非常複雜的需要
看出很多問題的這樣一個問題
那麼其實我還想聽聽Matt的關鍵
Sure
I'll use English this time
This is a little complicated
I won't repeat what everyone said
Yes, we need to match the right organizations to the right problems
I think maybe the one thing that's missing
is recognizing that the vast majority
of AI governance problems
will not be international AI governance problems
They will not be solved internationally
They will be solved domestically
if they're solved at all
I think about our traditional internet issues
and even when countries are very
are allies and friends
and have similar cultures
they still can't agree on it
America and lots of countries in Europe
when it comes to how to govern social media
how to govern monopolies
we can't really agree on anything
and we're supposed to be friends
and that's okay
like each society is going to have its own way
to confront these questions
I think when we're thinking about
international governance questions
limit it to the very small number of issues
that are fundamentally transnational
that cannot be resolved without countries interacting
That's probably a few categories
One of them is
catastrophic risk
One of them would probably be
this question of
interoperability of systems
If you're going to have an autonomous airplane
flying between countries
you're going to need some standards
and interoperability there
about sort of content
about maybe copyright is kind of in between
copyright has some international components
but the vast majority of these questions
are not going to be governed internationally
and I think we would make progress a lot faster
if we limited our scope
to the fundamentally international questions
I love this point
and I totally agree with you
maybe major
most of the questions
have to be solved domestically first
and then in some global scale
and global level
we can solve the problem
of international global AI
safety issues
thank you
那么我们下面也感谢前面几位嘉宾
我们下面就来到了最后一个问题
实际上这个问题
我相信也是全球南方和中国
最为关心的一个问题之一
但是这个问题我想先抛给
我们的Mr. Kripitz
We know that
the day before yesterday
China just proposed
UN resolution about the capacity building
and also we all know
global south countries
are so care about
how we can both share the benefits
from AI development
so what do you think
which kind of mechanism
can bridge the gap
between developing countries
and developed countries
thank you very much
I think the first point is
in a way like describing the problem statement
because what we tend to do
like add AI into that
but I think this is a very simplistic picture
and I believe like the problem structure
to be analyzed is much more deeper
the question first is
what is AI in that sense
because we can look at AI
from the development perspective
we say that there are discrepancies internationally
because certain countries are very much
in the development of AI
others are not
so we have like certain countries that have a leading edge
like China and the United States
and to a certain extent also South Korea with the European Union lagging far behind
when it comes to patent registrations for instance
at the same time we can also look
in a way at not just development
but also implementation of artificial intelligence
because that's also an important point
because certain societies might be very good
in developing artificial intelligence
but don't implement those technologies
so this applies also in the past to Germany
because Germany was very much up front
in building trains, high speed trains
and very much in the development of that
having a lot of patents
but not really implementing the technology
because of financial restrictions
but also sometimes because of like
reputational issues
or distrust of the population
so when we look into
implementation of AI
also trust appears to play a major role
which also then in a way
feeds back to this debate on regulation
because we need to have like some
regulatory minimum standards
so that individuals are able to trust this technology
so in a way that also
plays an important role in
like explaining further down the line
discrepancies when it comes to the implementation of AI
apart from that
I would also point out
in a way the difference between
developing and also
developed nations
because we might argue that
perhaps also in some developed nations
or traditionally developed nations
we might face certain issues
with the implementation of artificial intelligence
so it's perhaps not just the north south divide
when breaking AI
in different aspects
I would also mention here
perhaps not just the point of educating individuals
but also
looking at infrastructure
for instance
because apart from the financial means
which are very important for AI development
since it consumes a lot of
basically money
also we have the financial market component
which plays a significant role
but I also would add to that
that in certain cases we need to have an infrastructure
I think the best case to show that
is autonomous driving
because when you look at autonomous driving
as a technology it's not just about a car or vehicle
so this is also requiring
a lot of investment
which is also again then rather going
not so much into the development direction
but rather in the implementation
situation
so I think when we look at that
I think the picture and the problem statement
might be in fact even larger than we think at a first glance
simply because of the fact
that first many of those costs
in a way are not a big issue in the first years
but basically 20 years
30 years ahead when infrastructure hasn't been built
you will really see then
assymetries
so what I fear is that after
we had in the 1990s and 2000s
like a convergence in global living standards
particularly driven by globalization
that with AI and also different
degrees of AI implementation
we might come up again into
a world where we have those discrepancies
and I see here that it's not just like
this typical division between
developing countries on the one side
and developed countries on the other side
but this picture might be much more complicated
perhaps with Europe then lagging behind
certain parts of Europe
so that's also a possibility
so I think when it comes in a way to the
measures to deal with that
I think one major point isobviously finance
because this requires a lot of money
to build up an infrastructure which is really capable
of innovation
so I think that's a major point
apart from this typically raised point
about education which is often
you know we used to say okay well
let's educate people and they are AI developers
and the problem is solved
it's much more about that particularly if we think about Africa
where basic infrastructure is still needed
people need to have access to the internet
in order to start AI projects
or to implement it in the form of
online banking sometimes we might
have like smart solution and fixes
to that but I think at large
we need significant
investments I think that's the major point
so impact investment might be a very
critical component of that apart
from digital literacy which is
often mentioned in this context
and I would finally reinforce
a point I've mentioned already the role of
international trust namely that
individuals in a society
trust AI solutions
and have the readiness to accept them
and also to use them because when we look at
international surveys we see big discrepancies
when it comes to the willingness
and readiness of individuals in different
societies to implement AI technologies
this is by far not a concern in China
it is much more concern in Europe
even in comparison to the United States
this is a point where I would have worries about it
because it also has a very important cultural
dimension
maybe access to AI or big models
maybe also will be a new type of human rights
in the future in near future
thank you
那么下面呢我还想请两位来自中国的
专家也回答一下这个问题
那么相信其实我们的这个
不管是阿里巴巴也好还是华为也好
也都在世界各国都有自己的
AI产业布局
那么您二位就是认为比如说在
未来在发展中国家和
发达国家之间如何去
弥合这种智能鸿沟或者数字鸿沟呢
有没有先请柳院长
好的
简单补充几点
确实如果考虑到
我们
互联网发展了这么多几十年
到现在呢其实全世界还有
很大比的人群没有接触到互联网
所以说我觉得我们在AI时代
面临的这种智能鸿沟
其实也确实是一个非常现实的
非常严肃的一个
问题
我觉得第一点可能跟刚才
前一个问题有比较相关
就是说我们提到了
就是这种多利益相关方的
充分参与的这样一个平台
我觉得这种不光是不同的角色
比如说政府公众等等
其实我们这样一个平台
也需要充分的
有具备全球的
这样一个代表性
然后呢
通过这样一个平台能够让
更多的这样的
国家能够表达出自己的
关切和声音
我觉得这个应该是一个
非常重要的一个
一个前提的
一个条件
其实就在上个月
我也有幸参加了这个任内瓦的
ITU AIFAQ的峰会
秘书长
这个ITU秘书长
包格丹
导演包格丹女士也提到
就是全球的治理应该在
整个联合国的
体现联合国的这个价值观
并且能够不要让任何一个国家
去掉队
所以说我觉得呢
这样一个愿景
去构建这样一个平台
是非常重要的
当然就是过程当中我们可能有
很多去用实际的问题来解决
实际的工具来解决
我们所谓的挑战
刚才立法的问题提到很多
那我也想补充一下
可能我们当前的立法
可能呈现有一点差异化
和随便化这样一种趋势
但是呢我觉得
通过另外一个方面
可能也是可以
这样充分地沟通和协商
不光是为法律的落地
提供更确定性的一些方案
同时可能也是以
弥补这样一个
随便化的风险的一个
很大的一个机会
所以我觉得这样一个平台
实际上也是应该充分地去囊括全球各方
那么这是第一点
后面我就简单一点
第二个我觉得确实是在
作为一个人工智能产品和服务
提供的这样一个
一方吧
我觉得我们在真正提供相关的产品的时候
也要充分考虑到这个
不同国家
不同人群的它的可获得性
还要充分体现出这种包容性
举个例子其实我们
我们的盘古大模型其实在
大概在两年前实际上
就跟阿拉伯国家合作
在提供这种
阿拉伯语言的这种自然语言的
处理的大模型
我觉得这种的话其实也是非常
我们产品解决方案层面
是可以做出努力的
那么第三点的话就刚才提到了
这个人员能力的问题
我觉得这个确实也是非常重要的
实际上在ICT时代
华为其实在非洲等等
很多南方国家我们就设立了
这种ICT的学院
实际上给相关的国家和地区
这种人员数字素养的
这样一个提升去做出一些贡献
所以我觉得在这个人工智能时代的话
其实我们这样的工作
可以做得更多
好的谢谢
感谢刘院长还举了华为
已经确实做过的工作
来作为例证
那么有请顾院长
好的感谢
这个非常好的一个话题
其实我们倒觉得现在
这个所谓的这个
或者说叫AI
可能有的时候也是一种惯性的思维
就是我觉得还是需要和可能吧
就是我们正好五月份的时候
南非金山大学
当时我们在会上
我们也跟他们交流说
你们觉得现在这个AI governance应该怎么走
他说基本上的意思就是We don't care
他说We Africa
在历史上九十年代他们就推出了一些
类似的framework
包括立法的发展的
但是到头来又能怎么样呢
所以说其实每一个地区
它是有自己的自然的禀赋
和它的一些特征的
比如说你在这个全球力量中
你是以攻击者的身份而存在
还是以取求方的身份而存在
就是可能任何人都会
同时去在这两方
都做得特别特别的强
或者所有人都强
所以这就是平衡的意义
我们不是说有的人就应当来做攻击方
有的人就应当来做取求方
而是更多考虑到的是这种需要和可能的原则
可能说
比如说
从南方国家来说它的基础设施
很多时候现在还停留在这个
可能是信息化的这种时代
可能是智能化
还有一段路要走
那这个时候如果我们去讨论它的这个能力建设的话
可能我们更多的需要去讨论它的这个一步一步来
对吧
第二个还有个就是也涉及到治理的问题
就我们目前来看的话
讨论的很多这个AI Governance
Global Governance的问题的时候
它有个风险是什么呢
其实现在我们看到越来越多的这个所谓的AI Sovereignty
这个概念在崛起
如果我们回望互联网时代
其实从90年代开始
一个比较大的跃升
才实现了所谓对于平台
时代治理的三个
我们认为是三个最核心的问题
就是数据隐私保护
包括这个平台的责任
还包括那个公平的竞争
沉淀出这三个话题
也就是说你一个产业得需要
最早你看90年代它关于什么
关于的是垃圾邮件对吧
一直到后来它才会转到这三个话题上
所以其实你的风险也好
但是刚刚高教授也提出了
可能有一些确实是比较远期才会发生的
就是说你对于这些治理的问题
如果是过早的把它
我觉得它已经是一个
或者是一个大面积的范围
像垃圾邮件一样存在的话
它可能确实需要治理
但如果这是一个很远的东西的时候
如果短期对于这种过度强调的话
你比如说假设
如果我没有攻击能力的话
我肯定会觉得OK
I need air sovereignty to defend myself
我不太需要说OK
那到时候先污染后治理对吧
因为这些问题
对于这种业务产业链
面临很多很多的问题
特别是像一些种族问题
这种更严重的
所以这实际上就是一个
需要和可能的一个结合性
以及说考虑到这种过度治理的
这种副外部性所导致的问题
坦率来讲
当下这个时间节点
我们关于治理的一个框架
很多都是设想
我非常同意刚刚这位老师讲到的
其中大部分的议题都是国内议题
当然有一个非常好的回应性的
那如果集中解决一些人类共同面临的问题
可能会更好
另外也讲一两点像郝瑞同事一样
阿里的实践
其实这次AI4Good的Summit上
阿里最终是两个案例被评选
我讲其中一个
就是我们在东南亚的实践案例
他实际上做的很简单
就是把传统的一个翻译
通过大语言模型进行改造
最后他推出了一款达摩院做的
推出了一款模型
很简单 原来比如说
他需要一个过桥的过程
但现在可以实现小语种之间的互译
小语种互译
这实际上就是很真实的需求
你说这个东西它是能力吗
它肯定是能力
但是这种事情又会有多大的
比如说我非要建个效率中心
我要研究个大模型
这个其实是很难的
所以我们还是说基于现实的场景的需要
因为现在在阿里平台上
像我们在东盟差不多有十万的商家
在阿里巴巴的这个platform上
来做运营
如果我们每年从东盟进口的额度
可能会达到两百亿人民币左右
这时候你天然的就有大量的商家需求
比如说我要去翻译 我要去推广告
我要去做图等等
这种情况下 OK
那我的这个大语言模型怎么为当地服务
能力建设 我们认为这就是能力
同时最后再点一点
其实我们觉得AI出海也好
或者说我们全球能力的这种AI的这种
鸿沟的迷河也好
实际上要区分到底是AI还是产业
比如说如果我AI加汽车之后
我汽车出海这种那算不算当地的这种整个提升呢
还是说我们一个数据中心一定要搞一个大模型
这种才算是大家都一起了呢
还是说我们在一个好的产业链上
你有数据中心 我有模型能力
他有算法人才 最后我这有广泛的应用场景
所以最后你一个非常好的产业链
一个
其实就像那句话说的嘛
大模型本身不难对齐
难对齐的是人类
alignment实际上核心是人类比较难对齐
从互联网之内我们也能看出来
为什么230条款平台责任有这么大的争议在美国
包括在美国
那就是因为这个人的看法不一样
这样子对了我认为不是
那平台就夹在中间了
所以AI未来它一定也会是这样
我觉得现在核心的问题
其实一些治理的技术这些都是可以去解决的
核心问题就是人类得取得一个对齐
在一些fundamental的问题上
对 如果这个问题没有之前的话
其实坦率来讲
好多问题可能也不会那么快的解决
感谢顾院长
其实这个非常的一个实用主义的回答
其实有很多观点我是非常同意的
可能
与其我们去期待比如说一些全球南方的
国家from zero去建立一个
这个AI的capacity
可能不是很现实
那么如何以各种各样比较灵活的形式
把它们纳入到全球的这个AI产业链上
让他们在这个过程当中
本身成为这个AI产业链当中的一员
不被整个AI时代的
社会生产组织方式落下
可能这个是我们当前
更为实际的一个解决的方案
那么现在呢我们已经问完了最后一个问题
相信在座的观众也有非常大的收获
那么如果呢你是一个悲观主义者
你可能听不懂这个问题
也听到了我们远期很多没有预测
没有办法预测的风险
听到了全球各个国家的分歧
以及听到了我们说一些
未来我们还需要弥合的
很深远的这个鸿沟
但如果你是一个乐观主义者呢
我相信你也听到了大家的很多的共识和努力
以及我们在全球人工智力
这个领域已经做的一些工作
以及未来其实大家都相信
AI能够赋能全人类
给人类带来更大的这个发展和红利
那么今天呢也非常感谢
我们的六位嘉宾
谢谢你们的参与
那么谢谢大家
那么今天的这个圆桌就到这里感谢
Thank you so much
感谢大家
然后临走的时候
把那个同声耳机还一下
谢谢
谢谢大家
 谢谢大家