可以说是在上海是群英汇粹
但其中有一个非常重要的机构
就是上海人工智能实验室
特别在人工智能走进了大模型
生成这样一个重要结构
我们面临着很多的挑战
比如在算力方面
我们受到了巨大能耗的挑战
也受到了如何适应各种不同专业应用需求的挑战
怎么找到一条合适的AGI的发展路径
上海的人工智能实验室做了哪些工作
进行哪些有意的尝试
首先让我们来看一个大屏幕介绍书生
又来上海参加世界人工智能大会
今天的亮点很多
与往年不同
有书生Intern和我一起完成这次旅程
我们来看看书生的强大能力
演讲很成功
想好好在上海放松一下
让我继续体验书生的强大能力
我们来看看书生的强大能力
我们来看看书生的强大能力
我们来看看书生的强大能力
我们来看看书生的强大能力
我们来看看书生的强大能力
本来也就很适合王 Simpson干的
但 Yeah  ہ Food 咧?enn
今年的WIKE大会结束了
收获满满
原来AI已经进入了
各个行业和领域
也包括飞机设计
请不吝点赞订阅订阅
请不吝点赞订阅订阅
请不吝点赞订阅订阅
请不吝点赞订阅订阅
请不吝点赞订阅订阅
请不吝点赞订阅订阅
请不吝点赞订阅订阅
请不吝点赞订阅订阅
有一个叫ABM 广义能力分析
作为严谨的学者
我们先说说定义
AI 我们当时给的定义就是
当时最流行的深度神经网络
基于可监督的学习
它的特点是
需要大量的标注数据
应用范围相对少
然后我当时最主要的一个判断
就是说如果说要通过AI
走向ATM
中间会有一个必经的阶段
我把它叫做ABM
也就是说是广义能力分析
广义能力分析
所以我当时给这个定义
会有三个特点
一个是自监督学习
也就是说可以通过信号中
含藏的知识去自主学习
第二是端到端
一个人工智能任务
不需要把它分解成多个词任务
大家能把它听起来
而是说人工智能系统
会自动学会端到端的进行完成
比如说今天的同声传译
在2016年的时候
大家很多时候是说
先做语音识别再做翻译
再做合成
但端到端的系统要求是说
人工智能系统能够自主地完成
端到端的语音翻译
这个要求
人工智能系统
就得有多任务学习的能力
它既能做语音识别
也能做机器翻译
也能做语音合成
这跟当时狭隘能够
每个模型只能做一件事情
是完全不一样的
第三呢
我们提到说
一定要从判别式
走向深层式
因为像Richard Fabian所说
凡事我不能深层
就不能有真正理解
所以当时我们给出了
这三个定义
所以这个中文的定义
是从英文翻译过来
一个字没有改
但是你现在回头看
可能二字
在2022年
可能穿了GDP
基本上把这三个都完成了
也就是说
2022年底开始
我们已经进入到了
API的时代
当然
16年的预测
我有部分是没有想到的
那就是说
巴默斯的有限能力
我们当时提了
林亚本学习
但没有想到
巴默斯的有限能力
是如此的强
当然
正在现在这个时间节点上
在2024年的
外科大会上
如果我们要做
同样的四合讨论
那么接下来
AGI应该是
怎样的一个达成路径
这种战略原判
我觉得不管是
对我们一线的科学研究者
还是对我们在座的
年轻的学生们
或者是
国家人工智能学的学生们
这个必须要去思考的问题
所以这里呢
我们提供一个
我们的思考事件
我们认为
从现在走向AGI
它的load map
是二维的
而不是一维的
看过去一段时间
人工智能的发展历史
在2016年17年以前
人工智能在专业能力上
做了非常血脉的进展
从IBM的深蓝
到AlphaGo
人工智能一次一次以
击败地表最强人类
而成为新的主体
在当时的巨大挑战在于
这些模型不具备半化能力
它只能在专有的任务上
表现突出
在2017年Transformer
摩托自主毅力
提出以后
我们看到的是
大模型在半化能力上的黄标
就像我们看到的
今天大模型一样
记得大模型
进展非常的迅猛
在scanning的加持下
进展非常的迅猛
但是同时我们又注意到
目前大模型最大的一个挑战
在于专业能力的进展
极其缓慢
同时能源的消耗
数据的消耗
还有资源的消耗
都让人去思考
这条路线是真正能够
通向AGI的有效路径
实际上摩托自主提到
GPT-4的专业能力
大概相当于
10%到15%的专业能力
即使到GPT-5
它的预期大概是提高了
10%到15%
也就是说
我们用指数位的能源的增长
换来是专业能力的缓慢的提升
大家可能也能感觉到
大模型的一本性的不可八道
还有像外行看它像内行
内行看它像外行的答案
都是它专业能力不够的极限
也包括在数学奥林匹克里面
大模型GPT-4
一道子都没有做到
但丁曼德的Alpha Geometry
能做到很多奥赛的几个题
也包括说了
在产生的视频的过程
虽然不够流畅
但在细微的争议之间
它会产生一种物理规律的现象
这都表明
大模型在专业性上的进展
是需要更多的思考
在这里我们想提出一个判断
就是人工智能ATM落地
它会有一个高价值区域
这个高价值区域
同时要求模型兼备很强的半化能力
同时就会足够的专业性
在这个区域里面
离原点最近的这个点
我们把它叫做
通专融合的价值引爆点
根据历代工具的分析
和生产力提供的分析
我们认为这个点很有可能在
它在专业能力上
是能够超过90%的专业能力
不要说百分之百
不要说跟Alpha只有200%
但是它在半化性上
都具备强半化能力
也就是说具备最少API的能力
谁能先达到这个点
谁就能最早进入高价值区域
结果高价值区域
就意味着使用场景
之大得到突破
也就意味着
你能获得数据的飞轮
你能获得造学和自我迭代
所以这个是非常非常重要的一个
我们对未来AGI走向的一个判断
所以说
如果我们认为
强半化制造的专业能力
CAA黄光特的明珠
我们就回答这个问题
就是如何去更高效的
去获得这种通专融合的能力
我们并不认为
单一的算法能解决这个问题
通专融合的新范式
需要系统的思考
它需要在基础模型层
融合协同层
和自主进化与交互层
对体系化的思考和规划
能和三层具备非常强的
协同和强偶合关系
在基础模型层上
非常重要的工作
是需要去不断的去提升
如何更高效的获取
模型半化的能力
以当前Skeleton Law
10倍100倍的能力
10倍100倍
甚至1000倍的效率
去获取强半化能力
同时我们需要更多的
复杂任务规划能力
高密度监督信号的生成能力
等等来辅助
一部分这样的原始工作
体现在上海人工智能实验室的
书生谱语大语言模式里面
也体现在书生万象
多模态等基础模式里面
我们在数学和推理
高见能力产生的突破
当然我们还有很多
新的工作要辅助
第二层是融合协同层
这一层负责将
半化性和专业性
有效的结合起来
我们采用多路线的
协同的算法架构
来获取比肩能力
最多的专业能力
我们的原创工作
包括高监督
高智力密度监督信号的生成
复杂任务的规划
以及新的架构
来实现系统一
也就是说人的大脑中
快速直觉反应的系统
和系统二
也就是人的大脑中
用慢但是深度思考
和复杂推理逻辑的系统
时间进行交互
通过这些技术
AI能够在
复杂环境中做出决策
将复杂任务分解成
更容易理解的
指论制定行动计划
并高效地
协同多个指论体
以实现群体之间的有限
第三层是自主进化与交互层
在这一层
我们强调AI的自主探索
与反馈闭环的重要性
AI系统需要
能够在真实
仿生的世界中
自主地收集数据
学习并适应环境
通过与环境的交互
AI能够获得反馈
对于反馈
对于自我进化
一贯重要
自主进化与交互层
AI能够进行
具身自主的学习
并最终对世界模式
有更深刻的理解
并理智交互
完成开放式的内容
接下来
我要分别介绍
在这框架下
我们的几项
重要的前沿进展
首先是
更高效地构建
通用基础的
模型
我们高效并行训练
做了大量的
软硬件系统支配的工作
特别是高效的
数据的处理
新型的架构
及推理增长方面
有很多的原始创新
比如说
我们在长序列
并行训练方面
比国外知名框架
Megatrend
我们的性能
提升了4倍
我们研发的
大陌生训练系统
是以真实训练
具有不断的
承电技术能力
以及连续两年
或者计算机系统
比对Export
杰出论文奖
及最佳论文奖
在基础模型方面
我们通过
稀疏数据的合成
与增广
俗称浦宇2.5
以7B
也就是70亿参数的
模型规模
实现了综合性能
比肩开源大模型
NAMA3
700亿参数的性能
在多模态大模型
万象上
我们通过
渐进式对齐
向量连接等创新技术
构建了以更少的
算力资源
训练高性能大模型的
道路
以26B参数
的规模
比肩万亿参数
GPT-4
和Gemini Pro
这些都是我们
不断地提升
Scanning的效果
和一些工作的体现
非常重要的一点是
昨天姚琦自行院士
也感会到
就是我们要不断地
提升大模型的
专业推理能力
这也是浦江实验室
上海市能过程的实验室
非常专注的一个领域
比如说
最近大家可能看到
这个新闻
AI参加高考
数学全部及
这方面说明
数学还是高考中
最难的学科
但是呢
这些AI考生里面
也包含了我们的
附身图语
他在其中拿到了
数学的最高分
75分
超过了GPT-4
O的这个结果
这主要得益于
我们的开源数学模型
它呈现了密集过程监督
模型组织的
数位链
校链
多轮强化资讯链
文本推理
以及代码解释
等一系列的
强推理技术
用在良好的分量语言
理解代码解析
和形式化推理的能力
20B的参数性能
已经超过GPT-4
所以我们不但
效果最好
而且是参数体量最少
能源消耗最低
当然
我们要实现通栓融合
还需要考虑新的系统架构
我们原创的提出了
模拟能脑的系统一
和系统二架构
来实现通栓融合
大家都知道
根据GDEM
GDEM的
Fleeman的理论
人的大脑有两个思维系统一
一个是系统一快决策
一个是系统二是慢决策
从我们的理解来看
从人工智能角度来看
我们认为系统一
是一个人工
人脑的快决策
反映的是
长期训练下的专业能力
系统一是一个快
但是非常专业的系统
系统二是一个慢系统
你现在是深度思考下的
泛化能力
所以我们基于这么一个
人脑也是Bio的认知
今年的CVPR上
我们通过设计系统一
和系统二协同的模式
提出了交互式
磁性学习的新概念
让通用模型的
深度思考能力
和专业模型的
快速判断能力
互相结合
并且互相借鉴
通过这种方式
通过通专融合
我们发现在多个任务上
这个通专融合的系统表现
不但在能源消耗上
在推理数据上
远远快于慢系统
也就是通用大模型系统
而且在专业表现上
也是远远快于慢系统
远远胜出
竞胜出专业模型的系统一
也胜出通用模型的系统二
所以不管是在图像识别
还是非常专业好的文本生存上
做出的最好的效果
同时在自主探索
与世界模型这一层
我们非常清晰地认识到
实现通用能工智能
必须去理解和洞察物理世界
我们认为巨声智能
是探索通专融合的有效手段
也是理解物理世界的AGI的必经之旅
我们认为巨声智能
绝不仅仅是大模型加机器人的运用
而是物理世界的反馈
需要及时进化的大模型
这给大家举个例子
如果说人的底座大模型
不能被改动
只是加了机械的手臂
这样的人是不可能舒服游泳的
这是第一点
第二点
就像大语言模型
是对下一步时的运程来压缩世界知识
就像说法是通过patch by patch的压缩
来预测下一种图像
我们人可以看完所有的文本
可以阅读完所有的视频
但依然学不会游泳
你要学会游泳
必须在物理世界中跟水去互动
去感受水的阻力
感受你的身体的浮动
甚至你的呛水
所有这些物理的真实反馈
将反馈到你的大脑里面
改变你的模型参数和结构
让你大脑学会怎么游泳
巨声智能是同样一个逻辑
所以我们认为巨声智能
是实现AGI对空间进行感知
对物理世界进行理解重要的工具
正是基于这么一个认知
我们为了建立世界模型
我们设计了软硬虚实一体的
机器人训练场
就如大家看到的这个
全世界目前最大的
同时能够公关巨声智能的
大脑和小脑的这么一个绑折系统
普源 桃源是首个
城市级的巨声智能数字训练场
它构建了集场景数据
供气链 巨声模型
三位以的开源巨声智能研究平台
作为大模型
以机器人的连接层
涵盖了百多个
八十九种功能性场景
十万家的高质量可交付数据
有望解决领域内数据匮乏
评测困难的问题
在大脑方面
我们通过巨声智能体的
自身状态认知
补杂任务分解
底层技能协同控制
三方面创新
首次实现了大模型驱动的
无人机 机械臂 机器狗
三种异构整体的协同
共同完成补杂任务
在小脑方面
大概中间这个图上可以看到的是
我们通过GPU
高性能并循训练 仿真
可以实现高效机器人
在真实世界里快速学习
如何完成高难度的动作
我们的实验结果发现
单卡一小时的训练
就能实现真实世界
三百八成的训练效果
所以这个学习的速度
在快速地迭代
同时呢
大家可以把无人驾驶
理解成一个巨声智能体
我们提出了开源
且通用的自动驾驶视频模型
我们可以把它理解成
自动驾驶的梭兰
这个视频最右边
不知道为什么不能播放
后台看可不可以帮助它播放
这个其实的效果是说
我们人类只要提供给
这个智能系统一张图片
比如像当前这张图片
接下来整个这个模型
可以模拟它
接下来长达四十秒钟
在城市中怎么去开车
驾驶的完整的图片
所以相比梭兰比
这个更符合物理世界的规律
能够完整重现
后续高质量
连续多样化
符合物理世界规律的
未来世界预测
并可幻化到任何场景
被多种驾驶行为操控
现在图片开始播放
大家可以看
就除了第一张的图片
是人的图片给的
其他后面都是AI自动生成的
它在模拟这辆车
在不同的路径怎么去行驶
我们模拟的场景
大概全球有几十个国家
数百个城市
都是通过对这些城市的学习
自动模拟生成出来的
所以它要符合
这些城市的地标
比如刚才看到纽约
来了不同的城市
要符合不同的驾驶舱位
比如是左驾驶
右驾驶视角
还有比如说是
西德尔VS卡车
它的视角也不一样
这个东西完全可以
通过第一张图片
我们完整地生成出来
这反而就是
我们对物理世界的认知
通传如何
无疑有巨大的价值
前面说的那些例子
可能大家都能感受
因为今天是科学前沿会
所以我今天去说服大家
通传如何能带来
我们的价值场景
我把它放在科学发现上
首先给大家提供一个背景
2023年初
Nature发表了一篇封面文章
这篇文章指出
在过去几十年来
虽然全球的论文数
专利数不断在增长
但是每篇论文的平均影响力
在快速下降
这里面竟包括物理科学
也包括生物医学
也包括我们所谓的
技术科学领域
这里面的原因
文章并没有提及
但我制作了很多的分析
我认为很大的几个原因
第一在于
科学这种大厦
经过很多的
经过过去一百多年的建设
已经基本完成了
在科学大生命的
每一个小房间里
也就是我们所在的领域里面
慢慢形成了信息减防
在信息减防内
信息过窄
在减防之间
非常难以打通
所以导致每个人的研究
只能进入很小的范围内
所以导致影响力在下降
当然还有其他的原因
但是让我开始在思考
那我们去做通专融合
去做大模型
我们说大模型的
性质生产力
它能如何提升科研的效率
所以这里正好可以
理解到大模型
另外一个特点
大家都知道大模型有幻觉
但很多时候看起来
模型的幻觉
它更像是一种创造力
而不是一个bug
很典型的例子
是化学家库克勒
库克勒是第一个
提出本分子结构的人
在本分子结构里
没有人能想到
分子结构有环形的
据库克勒自己的回忆录分析
他是有次做梦的时候
梦见一条石
手尾相连
梦醒之后说
本分子就应该是这样的结构
你看这种过程
多么像大模型的幻觉
好 问题在于
我们如何能够系统性的
去利用模型的幻觉
去完成科学发现
这里我们做了一些
初期的工作
这个工作在上海
人工智能实验室
在不断的在后续在细化
这工作是我们
二三年初做的
就是我带领我的团队
我们去训练了一个
生物医药大模型
让他读完了
二三年以前所有的论文
这个论文读完之后
我们开始让他去做梦
去提出科学假设
当然这个做梦是
他自己在我们的一些
Prompt的地方
前提下
给他一个非常大的
探索空间
然后接下来他倒过来
跟我们提问题
不再像敲了GPT枪
能问题上来回答
现在他提问题
我们来回答
人来回答
他有一天提出一个问题
就是说是
二甲双瓜这个神药
面对胃癌患者
他认为对效果来讲
对男女性患者
有显著的差异
这个结论
在二三年以前的论文中
没有人提到过
我们也不知道对错
所以我们花了很长的时间
在寻找相关的论文
一直也没有找到
一直到二零二三年
三月三十号
我们发现有一篇
人类科学家的论文
就是这里面列的
这篇论文做的实验
跟我们大模型提出的假设
一模一样
而且他的实验的结果
证实了大模型提出的假设
就是说
这个二甲双瓜的疗效
是存在着显著的
男女性差别的
所以我希望这个例子
告诉大家
在科学前沿领域
大家都认为是
生产力的最高纪念的领域
通用人工智能
可以发挥非常多的作用
通过通砖融合
通过通砖融合
大模型不仅可以提出科学假设
还可以掌握科学知识
分析实验结果
预测科学现象
进而在反思的基础上
进一步提升
提出科学假设的能力
在掌握科学知识方面
上海人工智能实验室
基于大约机座模型
进行专项能力的强化
构建了化学和渔种方向的
首个开源大模型
普科化学和普科风灯
在分析实验结果方面
我们研发的
晶体结构解析算法
就被专家级的准确率
并将解析时间
从小时级降到秒级
在预测科学现象方面
我们训练并持续迭代了
蜂窝气象大模型
今天上午在开幕式上
也被发盖维的领导
现场做了发布
在全球的中期气象预报上
具有当前世界领先的时间
和空间的分辨率
在提出科学假设方面
我们进一步原创提出了
能在环路的大模型
多次人体协同的框架
对于科学假设的
全链路进行大模型赋能
构建了基于
通用人工智能的
AI分析师
AI工程师
AI科学家
和AI批判者多种角色
通过多智能体协同
和人一起工作
我们证明
这样一种工作方式
比科学家单独去提出
科学假设更高效
更新颖
而且能更高的成功率
能提出更有创造性的
科学问题
今天我面对三百多名
国家人工智能学院学生的时候
我一直在想
在我结果的时候
我有什么的话
可以送给你们
所以我在想
为什么我们会
用通用人工智能
去研究科学假设提出
因为很多时候
提出一个好问题
比解决问题更重要
正如大卫希尔伯特
在1900年
提出了著名的
二十三个数学问题
这个问题影响了
数学各个职领域
往后数百年的发展
一直到今天
这二十三个数学问题
都还没有全部得到解决
解决的问题
大部分都获得了
菲尔茨奖
等著名的大奖和认可
所以他一直认为
提出一个好问题
往往比解决问题更重要
他的名言
We must know
We will know
我们必须知道
我们终将知道
也因此广为流传
今天我们站在
通专融合的路线上
探索通用人工智能
A阶的未来
展望下的AI for science
我们更可以从这名言中
吸取到灵感和激励
对于可信AI的未来
正如我今天上午
在权力大会的演讲
我们的态度是坚定和积极的
We must be there
We will be there
我们必须达成
我们终将达成
我们为什么有这样的信心
是因为我们有大量的
年轻人才
不仅有在座的
人工智能学院的学生们
还有高中生们
我们上海人工智能实验室
也聚集了一批
世界最优秀的
青年科学家人才
我今天站在这里
非常感慨
我想起了去年
汤晓鸥主任在WAC大会上
提到了我们的原创的成果
提到了我们的年轻的科学家
提到了我们的书生大模型
接下来呢
我们就希望
我们的年轻科学家们
能逐一上台
就像刚才
书生的视频里说的一样
通过我们的工作
让AI
让书生大模型
成为人类的好帮手
好intern
接下来
我们有请上海人工智能实验室
七年科学家陈凯
请上台
尊敬的各位领导
各位专家
各位同学
下面我将介绍
书生谱语大模型的最新进展
在去年世界人工智能大会上
第一代书生谱语大模型
和全链条
工具体系
面向社区开源
在过去一年里
书生谱语不断成长
完成了多个版本的更新
每一代模型
都将性能提升到了一个新的高度
超过了Lama系列模型
推动着开源社区的发展
也在逐步的接近标杆的必然模型
今天
伴随着一周年的时间
我们正式发布新一代大语言模型
书生谱语2.5
推理是大模型的核心能力
也是智能水平的重要体现
书生谱语2.5具备强大的推理能力
能够解锁更多的复杂任务
总体概括有三个主要亮点
首先是领先的推理能力
相比上一代模型
推理性能提升了20%
也领先国内外的同量级开源模型
其次是支持100万Token的上下文
长文本性能位居前列
第三是模型能够自主规划和搜索
来完成更复杂的任务
通过信息搜索和整合
撰写专业回答
和人类专家相比
效率提升了60倍
随着大模型的快速发展
人类积累的数据也在迅速消耗
如何高效的提升模型性能
就成为了当前面临的重大挑战
为此
我们通过模型飞轮和合成数据
给书生谱与2.5的迭代
提供了强大的加速器
我们将当前的模型
广泛应用于自身迭代过程
不断循环
形成模型飞轮来加速能力提升
同时
我们也融合了多种数据合成的方案
包括基于规则的数据构造
基于模型的数据扩充
基于反馈的数据生成
从而有效的批量生产高质量合成数据
强大的推力能力是大模型
通向通用人工智能的重要基础
我们将推力能力
作为模型的核心能力进行优化
为复杂场景的应用落地提供支撑
相比于上一代模型
书生谱与2.5
在多个权威推力评测集上
实现了大幅的性能提升
尤其在数学评测集MAS上
更是提升了百分之百
和最新的开源模型相比
书生谱与2.5在绝大部分的数据集上
也领先于同量级模型
包括Lama3和上周谷歌刚发布的JMA2
和Lama3的70B模型相比
推力能力也各有千秋
这里我们通过一个例子
来展示大模型的推力能力
我们给出东京奥运会奖牌榜的前十名
让模型来回答
属于北美洲和大洋洲国家的
银牌数之何是多少
我们可以看到
模型能够一步一步的进行推力
并且准确的回答出来
那我们再让模型将金银铜奖牌
都在15枚以上的国家筛选出来
并且绘制成表格
我们看到模型也可以给出结果
再进一步进行推力能力的推力能力
在长文档理解
复杂的智能体交互等应用场景中
对模型的上下文长度有了更高的要求
书生浦语2.5将上下文长度的支持
提升到了100万token
处于开源模型的前列
我们采用业界流行的大海捞针测试
来评估模型的长文本信息提取能力
结果显示
书生浦语2.5可以从超长文档中
准确的找到相关信息
这里表现为
就一片是全绿
除此之外
我们也在长文理解评测集LongBench上进行了评估
书生浦语2.5也取得了最优的性能
这里我们也举一个例子
我们上传新唐书的文档
让模型总结唐朝文学风格的三次变化
我们可以看到
模型能够从几十万字的文言文中
准确地引用相关的信息
并且进行回复
书生浦语2.5在解决复杂问题上
也有着独特的创新
我们让模型模拟人的思维过程
根据用户需求
首先进行问题分析
然后规划思维路径
拆分成需要解决的子问题
每个子问题
都会通过大规模的网络搜索
筛选和信息整合
最终得到回复
基于这样的多智能体协同框架
能够解决复杂的信息调研和分析场面
比如我们让模型来综述一下
嫦娥6号从月球背面采样返回的技术蓝点
并且和阿波罗登月计划进行对比
我们看到规划器
会对这个子问题进行思考
发散性搜索关键词
然后对搜索出的众多网页进行筛选
来选择有价值的网页
进一步进行阅读
从而对网页信息来进行整合
规划器也会根据结果来动作
在搜索的网页中
选择有价值的网页进一步进行阅读
来进行整合
规划器也会根据结果
来动态更新思路
比如具体到每一个技术蓝点
来进一步的去解决
最终完成各个子问题
进行总结和回复
这里模型可以将人类需要3个小时
才能完成的调研分析任务
最终写成几千字的这种调研文档
能够压缩到3分钟来完成
书生谱与面向不同的应用需求
覆盖了多个尺寸
其中开源模型
从超轻量级的1.8B
到轻便但性能不俗的7B
能力出色的20B
以及更强大的
币源的102B的模型
同时我们基于通用模型
也演化出了多个下游模型
包括面向图文混合创作的
谱语灵笔
面向数学的Internet Math
面向高考的文曲新模型
共同组成了书生谱语模型系列
除了模型之外
在数据 预训练
微调 部署 评测
应用的全链条工具体系
本次也新增了
MinalU智能数据提取工具
回向豆领与知识助手
同时我们也积极地拥抱
开源社区
和社区生态无缝连接
让书生谱与
兼容常用的大模型的开源工具
繁荣的生态离不开社区的开发者
在书生谱语开源社区
书生大模型实战营
和书生谱
和普原大模型挑战赛上
涌现出了大量优秀的生态项目
从锤类模型
到智能体应用
从软件到硬件
这些创意被应用于各个领域
现在已经有接近一千个
基于书生谱语大模型的开源项目
感谢开发者
一直以来的支持
我们也将坚持理念
让书生谱语以成为
持续的高质量开源
富能创新
谢谢大家
下面有请实验室领军科学家戴继峰老师
介绍书生万象多模态大模型
尊敬的各位领导专家大家好
我叫戴继峰
今天我们发布
上海人工智能实验室
新一代的多模态大模型
书生万象
以恰GPT为代表的
通用大模型
取得颠覆性的进展
将变革人类的生产和生活方式
是世界科技发展的战略焦点
上海人工智能实验室
早在2021年
就在视觉大模型领域
进行布局
并做出一系列有影响力的成果
从图像到图文
逐渐发展到多模态大模型
今天我们正式发布
书生万象模型
世界领先的
开源多模态大模型
而我们的目标
是理解真实世界的一切事物和景象
实现全模态
全任务的通用智能
书生万象
作为一个开源多模态大模型
关键评测指标
比肩国际顶尖的
商用闭源模型
它支持图像
视频 文本 语音
三维 医疗
等多种模态
拥有丰富的输出格式
支持百种下游任务
性能媲美任务专用模型
书生万象模型
它具有这么强的能力的
核心原因是
它是在全世界的
所有的图文数据上
训练学习的
为此我们构建了全世界最大的
开源模型
较之前最大的
开源图文数据集
图像数量扩大3倍
文本数量扩大10倍
书生万象模型的
核心技术
是我们发明的
渐进式对齐训练
在训练过程的早期
我们采用小语言模型
加大数据的方案
加快视觉模型的
预训练的进度
训练后期替换为大语言模型
让高质量的数据
高效对齐
通过模型从小到大
数据从粗到精
的渐进式训练策略
以较低的成本
我们完成了大模型的训练
在有限资源下
展现出了卓越的性能表现
在这里呢
我们汇报一下书生万象
在多个基准测试中的性能表现
并且与其他的
世世顶尖的多模态大模型的
性能比较
测试的Benchmark为目前
多模态评测领域的
核心关键指标
包括多模态理解
数学问题解答
图表理解
文档问答
极光学字符识别等等
首先呢
可以看到
跟其他的开源多模态模型相比
在各个评测维度上
书生万象模型碾压式的领先
是代表性的
开源多模态模型的性能
包括Lava和Cambrane
可以看到呢
我们的模型在各项重要指标上
性能领先
而与世界顶尖的
闭源商用模型相比
我们的书生万象多模态模型
也不落下风
取得了和国际顶尖的
GPT-4O
GPT-4V Cloud3
Gemini Pro 1.5模型相当的性能
并且优于国内闭源商用
多模态模型的最优性能
让我们看一些具体的例子
这张图片呢
是最新嫦娥六号
返回舱的照片
让我们问一问
我们的书生万象模型
它知道呢
图片中显示的是一个返回舱
三位穿着
防护服的工作人员
正在检查和处理
这个返回舱
其实社交网站上呢
有网友就这张照片发起了讨论
就说这个返回舱上面有泡泡
是不是这个正常的
是不是意味着它的质量不够好
让我们看看我们的
模型的这样一个答案
书生万象
模型告诉我们呢
它说返回舱上面表面的泡泡
通常是由于其在返回地球过程中
经历的高温和摩擦
所造成的
这种现象在返回舱的外部是正常的
因为它表明返回舱
是成功地接受住了
载入大气层次的高温
高温的一个考验
它的回答非常符合科学
在
卓越的图文
单图理解的能力上呢
我们的模型还具有强大的
多图理解能力
我们给书生万象模型
看这样的一个例子
问他这三张图片
讲述了一个什么样的故事
他可以清晰地理解呢
这个故事展示了小孩在尝试独立穿衣时
的可爱和努力
那让我们把这三张图
图片把它给倒过来
让我们看看我们的模型会给出什么样的答案
他现在告诉我们说
这个故事展示了小孩
在日常生活中脱下衣服
并享受这一过程的自然行为
综合跨图信息
对于视频内容的理解
和复杂图文内容的解析
非常重要
书生万象为这类关键应用
带来了强大的智力支持
与语言模态不同
多模态的任务呢
它的意志性要强很多
为了适应广泛的多模态任务呢
书生万象模型采用
通砖融合技术
它具有丰富的输出格式
支持超过百种任务
这是一个复杂场景中的图像
内容理解定位的例子
我们让书生万象模型
进行输出
这是个以图像内容定位
为核心的这样的一个任务
GPT-4V等模型
并不能够很好的去处理这类任务
而我们的书生万象模型
可以精准的进行输出
让我们换一个识别对象
比如说检测所有的人
结果也是非常好的
注意到在我们的模型里面
与传统的专用物体检测模型不同
我们的任务定义的接口
是通过语言
无需为特定的任务和类别
进行网络结构的调整和训练
我们再换一个类别问他
比如说让他去识别
检测交通灯
大家不知道能不能在图片里面
找到所有的交通灯
可以看到我们的模型是可以做到的
包括这个非常远处
放大之后的那样一个特别远的交通灯
打造这样的一个世界领先的
书生万象模型的是我们
多模态基础模型团队
我们团队有着丰富的学术成果积累
获得了CVPR23最佳论文奖
Triple AI21的
结束论文奖
多项成果入选CVPR
ICCV,LURPS,iClear
等这个领域的顶汇的
年度十大高病论文
展望未来呢
目前多模态大模型
仍处于发展的早期
据人类专家还有相距甚远
发展空间巨大
我们上海人工智能实验室
致力于原创技术研究
开源开放
共创共享
推动技术革新和行业进步
谢谢观看
然后呢
接下来呢
将会由我的同事
上海人工智能实验室的青年科学家白磊博士
介绍风屋气象海洋大模型
谢谢
好的
尊敬的各位领导
各位专家同学们
大家下午好
在听完了通用大屏的进展之后
接下来我想邀请大家
和我一起进入更加宏观
但又更加具体的风屋世界
并预测我们所居住的地球
是每个人必须要应对的任务
那么面对极端天气
频发对社会带来各种挑战
我们在夏天都会关注一个问题
一会儿是否会下大暴雨
有的话我想大家就会减少出门
或者带雨伞了
那么面对以风能为代表的新能源
逐渐成为了国家能源系统组成的核心
能源机构时刻都在关心
未来一周上海的发电量和运力量
分别是多少
以此来进行提前的调控
再来的不确定性
和碳中和的迫切需求
整个世界都在关心
未来十年甚至一百年
气候将会如何变化
以及会如何上升
要想回答这些问题都离不开
对整个气象海洋系统
进行不同尺度
不同要素的全面预报
针对这些重大的需求
实验室在AI和气象海洋的交叉领域
不断深入
逐渐构建形成了风屋气象海洋
全方位预报体系
开发了多种核心要素
从风屋第一个版本的
全球中期气象预报大模型开始
我们通过不断的人工智能技术创新
开发了风屋极端
风屋短铃
风屋阶下全球高分辨率预报
风屋ADAS全球端端的预报
和风屋OCA
一系列的气候海洋预报大模型
逐渐形成了涵盖0到3小时的短铃
0到14天的中短期
和多年到年纪尺度的
全周期预报体系
针对可能突然到来的
我们和上海市气象局合作
共同研发了强对流天气预报大模型
实现对一个区域
1000米高分辨率的强降水预报
通过采用生成式模型
和确定式极联建模的方式
风屋短铃预报模型
可以同时建模中尺度的
大气系统和小尺度的对流过程
从而准确地预报整体的
强对流强度和趋势
从左下角的量化结果我们也可以看到
风屋短铃预报模型
相比亚马逊的Earthformer
和此前自由的短铃预报模型
在强对的预报评分上
还是在专门针对大暴雨的
强对的预报评分上都有更优秀的表现
在右边的预测结果
和真实观测的可视化中
越红的区域代表越有可能发生大暴雨
那么相比Earthformer
逐渐模糊的预测
我们可以看到说风屋短铃模型
可以生成非常细腻度的预测结果
而且它的预测分布
和真实观测是非常接近的
目前该模型已经部署到上海市气象局
正应用于对强降水
等灾性天气的预警工作
在全球中期气象预报
这个大家每天都会在手机上看的制度上
我们对风屋的第一个版本进行了全面升级
首次实现基于人工智能的
全球10公里
中期天气建模预报
从经典的数字模式发展过程中可以看到
全球气象预报的分辨率提升
是一个非常非常有挑战的事情
目前最好的气象机构
欧洲中期气象预报中心
花了10年时间才将气象预报的分辨率
从25千米提高到了9千米
那么对于数据驱动的AI方法来说
由于高分辨率训练数据是极度虚弱
所以这个过程是更加困难的
比如大家都看到的来自DeepMind的
GraphCast这个模型
它的分辨率只有25千米
那么通过全新的捷欧千亿学习的
算法设计
风屋GHR仅用了不到一年时间
就将分辨率从25千米提高到了9千米
其分辨率较已有模型提高了7倍以上
达到了全球最领先的水平
而且在这个版本上
风屋GHR进一步支持了对降水
太阳辐射 百米的风速
云等众多产业界迫切需要的要素
以更好地满足社会个体的需要
和各界对高精度气象预报的需求
更进一步的
在全球气象预报这个尺度上
其实由于原有的观测数据
都是海量的卫星 雷达
气象站等非常不完善
不规则的数据
因此其实预报模型是没有办法
直接把它们作为输入的
它们都需要依赖一个
叫做数据同化的模块
来产生规则的网格化的
全球三维大气场作为输入
此前的AI气象模型
都仅仅关注了预报模型部分
它们是没有办法直接运行的
那么从系统的角度来说
它们是一个物理和AI的混合方案
在预报效率和性能上限上
都会受到限制
面对这些挑战
我们研发了全球首个端到端的
全球气象预报大模型
通过人物智能方法
同时来做数据同化和气象预测
相比已有的方法
可以直接基于原始的观测数据
独立运行
摆脱了现在的AI大模型
都对物理分析场的依赖
运行效率提升了1000倍以上
为全球气象预报大模型的发展
带来了全新的方向
在更长期的气候尺度上
我们进一步的
面对未来几个月
甚至几年的气候的预报
我们进一步研发了全球首个
海洋气候预报大模型
风屋欧卡
通过建模海气和效应
风屋欧卡只需要一个模型
就可以同时完成全球所有区域
的海洋气候预报
风屋欧卡对未来24个月
全球的海表温度的预报
和海洋的预报
都是高于日本海洋地球科学技术所
和美国大气管理局
最领先的预报模型的
通过风屋欧卡
我们也可以进一步的
得到对各种高影响气候因子的预报
比如对于阿尔尼诺 拉尼纳
这些大家经常在信息上看到的
气候因子来说
风屋欧卡的预报时效
可以达到20个月远优于现在的模式
最右边的图中我们可以看到说
基于欧卡我们可以实现连续8年的
稳定模拟 且其预测结果
也和真实的分析数据非常接近
这为我们未来基于人工智能方法
开发气候模拟
带来了一个新的思路
基于气象海洋预报
大明体系
我们进一步的
开发了可视化的预报平台
通过这个平台我们能够看到
这页的PPT
因为有个动画
稍微有点卡
没关系
虽然这个PPT的播放
稍微有点问题
但是我们还是能够看到
通过风屋欧卡这个一个模型
我们就能够同时的来预报
多种的海洋和气象的要素
它包括风速 温度 湿度等
而且是从地表到高空的
多个高度层
比如说马上我们会看到的500百帕
它对应的大概就是5000多米的高空了
而且我们也可以通过拖拽 放大
点击等操作
来查看具体位置未来10天的预报结果
好的
那么在未来
我们将一边扩展
风屋气象海洋大模型的预报能力
一边增强跨摩太通用大模型
对气象海洋等专业数据的理解能力
我们相信
通过跨摩太的通用大模型
与风屋这样的气象海洋
专用大模型的通专融合
我们可以更好的促进
人与自然的和谐共生
好的 谢谢大家
好
我们
感谢刚才周伯文主任
和来自上海人工智能实验
三位青年科学家
对这个上海人工智能实验所
所做的工作
给出了一个非常
重要的展示
首先周伯文主任
谈了一个非常重要的观点
就是我们通向AGI的路是两维的
是在泛化和专用
两个维度上向前演进的
那么基于这样的演进
有三个层面向前发展
通专融合的这么一条路线
那么刚才发布的这个
风屋 万象 谱语
可能是对这种通专融合的
一个非常好的诠释
那么刚才这个
博文在最后用了Hilbert的一个话
是吧
We must know, we will know
然后他把它演化出来
We must be there
We will be there
然后我们想到了一个
本来是中国的话
这个英文
英文说呢
Where there is will, there is way
有志者事竟成
希望我们上海人工智能
能够把这条通专结合
通向AGI的路走通
那我们说这个
通专结合最终是要落地的
所有的大模型
都是要为人来服务的
就像我们这次会议的主题
叫做
For the good for all
为了这个呢
这个实验室呢
就发起了一个
叫做普原生态共赢的计划
那么这个计划的参与者呢
不仅是来自实验室
而且来自我们有关的业界
共同来推动大模型的落地
那么下面呢
我们就通过一个视频
来了解一下普原生态共赢计划
以合作凝聚力量
以开放连接创新
上海人工智能实验室
上海人工智能实验室
推出普原生态共赢计划
推出普原生态共赢计划
邀您携手迈进AI共赢新时代
邀您携手迈进AI共赢新时代
本次加入计划的项目包括
本次加入计划的项目包括
普原大模型挑战赛
旨在推动大模型
在各行各业应用落地
春夏两季赛事
以启迪诞生
三百余个创新项目
ITEE人工智能
生成内容工作组
专注于制定AI生成内容
专注于制定AI生成内容
国际先进标准
引领技术创新和产业发展
Deep Link生态合作伙伴计划
引领技术创新和产业发展
搭建算力供需交流平台
助力上下游企业
释放算力生产力
共建开放计算体系
共建开放计算体系
收生易飞
易行AI生成式系统
由上海人工智能实验室
与中国商飞
上海飞机设计研究院
共同研发
支持高效便捷的
易行生成与编辑
以AI为大国重器
点亮双翼
那么下面呢我们就
有请首批加入
这个生态计划的
单位的代表上台
一起共同发布
这个生态共赢的计划
让我们掌声有请
上海飞机设计研究院
架构集成工程技术
集成工程技术所的
总工程师
于金海
上海AI实验室的副主任
王平
上海超级计算中心主任
李根国
副局长陶立英
清华大学计算机器教授
李娟子
商汤科技联合创始人
杨帆
上海AI实验室主任助理
施博明
高等教育出版社
总编办副主任
鲍浩波
中国惠普有限公司副总裁
周信宏
中国联通上海副总裁
姚建
上海人工智能行业协会秘书长
张俊浩
还有两位特别的代表
他们是
古源挑战赛夏季赛
一等奖的获得者
来自中国科学院大学的
天分九哥团队代表
李国翰
古源挑战赛夏季赛的
另一位一等奖获得者
来自上海计算机软件技术
开发中心团队的代表
马泽宇
请各位代表
一同
我们倒计数
三二一
然后共同你们推那个杆
好
三二一
我们非常感谢
首批参加的
各个成员
请各位嘉宾就座
也希望有更多的成员加入
我们的计划
这个计划大家看到了
有一个竞赛
是冬季夏季两期的竞赛
那么这两届竞赛
已经有了三百多项成果
那么在夏季的竞赛上
汇聚了一百九十支参赛队伍
他们在行业应用
创新创意
安全可信
这样三个赛道上进行比赛
展现了卓越的创意灵感
和优秀的技术水平
那么下面呢
我们就要发布
这个竞赛的一等
二等三等奖的名单
让我们向他们所有的获奖者
表示热烈的祝贺
下面我们要举办一个
圆桌对话
那么对话的这个
参加者呢
是来自咱们国家
在全国各地不同的
关于跟人工智能有关的
全国重点
全国重点实验室的领导
那么这是什么意思呢
我们想我们听音乐
独奏
美丽的独奏
是非常优美的
但是我们的人工智能
独奏是不够的
人工智能这么一个事情的发展
我们需要一个波澜壮阔的交响乐
把这个几个实验室
独奏的高手聚在一起
我们来交响
来合作来共同推进
我们人工智能的发展
那么下面呢我们就要请出
这个各个实验室代表
来做一个对话
那么我们有请上海人工智能实验室的主任助理
乔宇教授来主持这个对话
乔宇
尊敬的各位领导
还有各位同学
大家下午好
今天非常开心有这样一个机会
和各位前辈各位同行齐聚一堂
共同探讨在人工智能
在通用人工智能的浪潮下
国家级实验室和国家级科研平台的
使命和共同协同之道
我们知道啊
全国重点实验室
国家级创新中心
国家级工程中心
分别代表了咱们国家在各自学科领域
科研创新的最高水平
也是咱们国家科技战略
力量的重要组成部分
今天我们特别荣幸的请到了
六位我们国家级平台的主任
同时这六位也是
我们人工智能领域的
最为顶尖的大咖大师
据我所知
这也是在世界人工智能大会
在外科我们历史上首次
由多名国家
科研平台的主任参加的论坛
下面呢就让我们用热烈的掌声
欢迎各位重量的
重量级嘉宾上台
首先第一位中国工程学
生涯院士
国家流程制造智能调控
技术创新中心
前锋院士
欢迎前院士
中国工程院院士
机器人视觉感知
与控制技术
国家工程研究中心主任
王耀能院院士
欢迎王院士
虚拟现实技术与系统
全国重点实验室主任
北京航空航天大学副校长
吕渭峰校长
吕校长
欢迎您
任职智能
全国重点实验室
中国科技大学兼职教授
胡国平教授
欢迎胡教授
多媒体信息处理
全国重点实验室主任
北京理工大学
黄体军教授
欢迎黄教授
最后一位是自主智能无人系统
全国重点实验室常务副主任
北京理工大学
孙晋孙教授
欢迎孙教授
这个我想大家非常期待
这个各位院士大咖
给我们的精彩报告
这个问题大家知道
在过去的两年中间
以切特GPD为代表的大模型
引领通用人工智能技术的高速发展
一方面我们可以看到这种大模型的
智能涌现能力
泛化能力不断的提升
并且从语言快速的向多模态
未来的向现在巨神智能
高速的在发展
另外我们也看到这个技术的发展
带来了非常大的
算力 数据 能耗的挑战
而在很多的应用落地领域
大的模型
就像刚才孙老师也讲到
虽然通用泛化性很好
但是它的专用性没那么好
效率 能耗
还有它在一些幻觉
也有很大的瓶颈
我知道在座的各位
你们在各自的学科领域
都是最顶尖的学者
这些实验室也都是我们国家
最最重要的科研平台
所以我第一个问题
就想问问大家
大家能不能结合
谈谈在通用人工智能这个方向
下面有哪些
今天我们在座有非常多的
年轻的同事同学们
他们肯定想知道有哪些重要的方向
以及咱们这些实验室
大家有哪些重要的
科研布局和进展
首先呢
我们有请前锋院士
和王耀南院士
请两位大院士
先从国家级平台的定位
能够发挥作用
高屋建岭的讲一讲
谢谢
各位专家各位来宾
大家下午好
我是来自流程制造
智能调供
国家技术创新中心
刚刚来到以后
我们进来的时候
看到苏生大模型的一个展示
简直就是
博文教授给我们
非常精彩的一个报告
这个通专融合
而这是通用大模型
应该是一个前沿探索
与价值实现
所以从
博文教授的报告里面
也看着通专融合
我们通用模型
既要前沿的探索
不断的探索
不断的创新
同时呢
还要考虑它的实现价值
那叫通专专用模型
继合起来
刚刚乔教授也讲了
国家战略科技力量
尤其是怎么样
来通专融合
这里面
确实因为博文教授的
报告非常精彩
我们深有体会
因为大家都知道人工智能
肯定是
发展新生产力的
重要的引擎
但是人工智能
也面临很多挑战
其实刚刚
博文教授的报告也讲了
其实它最大的一个挑战
它的泛化能力怎么样
也就是在样本之外
能走得多远
能预测得多长
它的泛化能力
还有一个呢
它的很大的挑战就是
不可解释性
它不可解释性
那如何克服这两个
很大的挑战
那这种专用模型
既然是专用
是垂直领域的专用模型
专用模型
通常它有一定的
它的口节这些它的原理
它的动力学
如何把它结合起来
所以刚才作为一个
浦江上海人工智能实验室
刚刚闭幕的
国家科技大会
上面讲
作为一个浦江实验室
应该是总连长
总平台
我想我们都是国家战略科技力量
应该怎么把这个
总连长总平台
把它融合起来
系统起来
也就是今天我们这个论坛的主题
进行创新
我想这个肯定是起力巨大
因为确实
因为从我本人
我是做制造业
讲白了也就是AI
加流程制造
因为我们制造业就是两类
一类是流程制造
就是原料给了你产品出来
这个建材等等之类
还要记得我王院子讲的是
离散装备制造
所以会前我们来的时候
我跟王院子讲
如果我们能够通捐结合
也就是在我们这个
浦江实验室
有这么好的大模型
这个基础之上
结合我们捐佣的
我们一些领域的知识
领域的技术把它融合起来
我想我们应该取得
我们刚刚有讲的这个叫实现
所以我想呢
这是也是一个体会
看看王院子还可不可以告诫
这个
刚才钱院子
也介绍了
我今天刚才参加这个会
感受非常深
第一个呢
听了我们钟主任的大会报告
第二呢
听了三位学者的这个报告
我跟主持人
龚校长我就谈到
我一看到这个年轻人
这个浦江实验室一大批年轻人
在从事这个大模型研究
就有希望
那么接下来我主要谈
怎么样围绕这个
我的专业和大模型
谈两点
第一点呢
这个我们要做
今天的这个AI技术
一定要顶贴立地
顶贴呢
就是大家都谈的
我们要操作这个AI的这个
前沿科学技术
顶贴我们的这个
AI的这个大模型
那么怎么做到顶贴
我的看法仅供参考
第一我们一定要
了解清楚我们今天的
这个AI大模型的
体系架构
因为我们只有对这个体系架构
AI的体系架构
了解得清楚
对它的这个模型的推理过程
和推理的解释性
和推理的安全性
和推理的
可用性以及可信
可信度
要做充分的这个
去研究
我们不能是把它看成一个黑箱
端到端的就训练
就去完成这个
训练出来的模型把它应用
这个是不可信的
所以第一点我的建议我们一定
顶贴立地的
顶贴呢大模型的这个架构
要好好的去研究
它的这个推理过程
和解释性和安全性
第二点呢我们要对这个大模型的
训练算法
要充分的要了解
过去我们总是了解
在训练这个网络大模型的时候
都是用一些反向
传播算法
用了很多我在三十多年前
也做这个方面研究
我也写了一本
这个就是训练
怎么如何训练好这个神经网络
这个算法
那么改进了很多种的算法
目的就是提高它的熟练性
提高它的优化的
泛化能力
所以我今天就认为大模型我们还应定
第二点呢还应该在这个
模型训练算法上
还得要下功夫
第三呢我们的算力
大家一谈算力
现在耗费大量的电力
耗费这个算力
那么是不是今天大模型就是这样呢
我个人是有
有看法
有认为我们还有很多要研究的
就是我们要从架构上
从算法上
从训练算法上
那么包括这个算力上
去研究
最后一点呢我们要从数据的可信度
就是我们要研究
因为大模型它是
数据是端到端的
你输入的数据是不是可信的
那么就是我们也要研究数据的可信度
那么也要有一部分人
也要做数据的筛查
数据的分析
数据的判断
数据源
通过我们大量的一些数据
提起它的最有用的特征
然后作为训练数据
这样呢就会有效
不能盲目的
这是我讲的这个顶天的地方
大模型大家要重视的
第二呢我们一定要与时俱进
要立地
立地呢我们就要研究
这个大模型要为各行各业赋能
那么我刚才钱院士也提了
我们两个都是做工业自动化
从工业自动化
走向今天的智能化
都有体会
我们是面向这个
这个制造业
智能制造
那么智能制造结合我这个专业
我是从事这个自动化专业
又从事这个机器人
那么我们今天的这个
机器人呀
就是我们今天谈的巨神智能
最好的案例
从这三年当中
人形机器人和大模型
可以说是走到一起了
因为有了大模型
能够推动我们这个
巨神智能的人形机器人的发展
过去我们做机器人呢
总是从传统的感知
到决策规划认知
目标跟踪
识别最后到精准的控制
然后呢
然后形成一个闭环的反馈
做训练你比如这个
我们的这个波斯顿动力公司
这个机器人大家看到做了20年
他今天为什么停下来呢
主要还是和我们一样的
做的都是采用一个
运动学动力学
机器人运动学动力学的
这个建模的方法
那么就以程序
编好程序以后呢
指挥这个机器人
那么怎么样规划
也是用的程序也是用的算法
怎么样进行精准的控制
也是用的这个算法
那么只能单个机器人可以
这么训练
但是对于巨型机器人
有多个机器人
巨型机器人的协同感知
多个机器人的协同的规划调度
多个机器人的协同的控制
就很难了
那么用传统的这个方法
我们的优化调度
就会发生
只能控制到
比如10个100个
但是你上千个
上万个的巨型机器人
这个时候我认为
我们的算法就有问题了
那么今天这个大模型
我们就可以通过用大模型
我们今天的巨型智能
50年前图灵提出来的
它与环境的交互
因为巨型智能主要是强调
与环境的交互
通过环境交互
机器人与环境交互
我们通过感知
感知后我们能够理解环境
能够识别环境的
各种状况
然后做出精准的认知
然后到行动
那么今天有了这条思路
然后再反馈
那么我们是不是
就用大模型可以解决呢
我认为是可以的
这就是我想要立地的地方
那么就是通过我们
在原来的这个
赶船算空的情况下
我们可以做两条路线
一条呢端到端的
大模型进行训练
来完成我们的巨型智能的
机器人的这个复杂的操作
和居行的控制
第二个呢我们也可以分布的实施
不一定是端到端的
我们可以做感知的模型训练
也可以从规划决策
那么也可以做
举行协同的控制
这样呢把它训练完以后呢
把它组成一个大的模型
这也是第二条思路
那么所以我说的立地啊
我认为我们可以第一个
通过大模型呢
来推动我们的巨型机器人的发展
过去我们研究机器人
总是把它看成四个方向
机器人感知
机器人的
规划机器人的决策控制
那么今天可以把它做在一体了
就是所谓的感传
算控一体的
那么再进行迭代不断的学习
不断的迭代然后就能够
完成很复杂的动态的任务
这是我讲的第二点
第三呢我们大模型更多的要
赋能到各行各业
那么我们也可以通过这样的思路来
那么我的时间到
我就讲到这里
等一会再补充
请其他的再来介绍
下面我们请
要不先从吕校长开始
简单说一下
我是来自于
虚拟现实技术与系统
全国重点实验室
我们虚拟现实技术与系统
实际上跟人工智能是
密切相关的
我们以前啊
虚拟现实技术系统
我们更重要的研究的
就是如何让我们
这个环境更加的逼真
这是第一件事
第二呢这个逼真的环境
能够进行自然的交互
跟我们的人啊
第三个呢
可能更重要的是如何去
变成一种可构想性的
构造性的
比如说我们以前我们这个
虚拟现实重点实验室
我们研究了两个核心的挑战
第一个
跟这个逼真啊
最难的是什么
人 人体
所以我们当时
我们在四多年前
我们就研究
医用的 医疗用的
虚拟人体
如何来进行构建
建模和交互
因为这个的挑战
是最大的 而且呢
它的应用极其广泛
这是我们以前做的
就叫虚拟生理人
第二个呢我们比如说我们做
可构想性的我们挑战的是什么呢
比如说我们做一个
特别复杂的一个
产品的设计
以及从它的设计 验证
实用我们进行验证
比如说我们以前
一直做的一件事现在已经
实用化了就叫
全数字化的飞行器
设计与应用
以及验证的一个一体化环境
这叫可构想性
以前我们研究的虚拟现实
这样但是人工智能时代到来了
我们感觉到
对虚拟现实技术的
系统的研究
和需求发生了重大变化
我们更加关心
如何构造
我们智能化的
虚实融合环境
而且这个环境它一定是个
不断迭代和升级的
就像刚才我们周主任提到的
它不断演进
而且最最重要的
我们现在虚拟现实更关心的是什么
虚实贯通
虚拟环境和我们的实际环境的一个
无缝的自然的
我帮你插一句话
我激动了
我帮你插一句话
昨前天开科学大会
我们学会
我是中国图像图形学会的理事长
我们学会
推出了一个
跟他刚才讲的一样
叫做
数字人与机器人
数字人与机器人
的未来挑战
这么一个科学问题
昨天科学发布的第一个
跟他非常相似
所以我们现在
我们赵新平院士提出
我们虚拟现实以前是叫三爱
曾经是
可交互
可构想
我们现在叫六爱
加上智能化
可演进
还有很重要的虚实贯通
从三爱到六爱
很重要的就是
我们人工智能
对我们整个虚拟现实的
一个巨大的变化和颠覆
比如说我们从去年开始的
Sora 纹身视频开始
这个纹身视频
我们的看法
包括前两天
已经出来了
Meta的纹身3D
以前是二维的
现在变成三维的了
这纹身3D带来的是什么呢
就是我们整个虚拟现实技术
我们的基础软件平台
将发生天翻地覆的变化
我们以前做虚拟现实
更多的是用Areal和Unity
和这种渲染引擎
和构造模型
那么在
这种大模型
多模态大模型
到来的时候
我们整个的
基础软件
可能是模型
可构想的
和我们的生成式的
一个混合的智能平台
这种智能平台
对我们未来的虚拟现实
比如说我的人体
到底怎么能够更加的逼真
和更加的交互
我们在研制
和生产一个飞行器的时候
我们如何从它的设计
到它的仿真
到它的验证
以及它的飞行
我们如何更加的逼真和交互
都是我们未来的一些重要挑战
也是一个重大的机会
也是一个重要的科学问题
我觉得今天
看到我们很多的年轻人
300多位年轻人
我觉得这方面的挑战
特别需要我们
上海的人工智能实验室
和我们
像虚拟现实的全国重点实验室
我们一块来面对
一块来解决
我说到这里
好
大家好
我是胡国平
我们是认知智能全国重点实验室
认知智能从简单的理解
就是让机器去能理解会思考
因为我们上次
跟克拉逊菲和中国科学技术大学
共建了这样一个
像是产学员比较合作的
本身比较紧密的这样一个实验室
我们确实实验室
一直努力的目标
就是从原来的让机器能听会说
语音合成语音识别之外
要进一步的能理解会思考
所以我们一直在致力于
对让机器如何能够掌握
人类的语言和知识
并且能够充分运用
那这次大模型应该说
其实也主要就是在这样一个语言理解
对话这样一个场景下
先开始起来的
在讲具体的技术之前
其实我还是想跟
特别是很多年轻的学生
其实讲一个
其实人类的语言是一个非常神奇
也非常之复杂的系统或者体系
我只举简单最一个例子
给你一个苹果
你把这个苹果丢在办公室了
你还剩几个苹果
和把这个苹果丢在垃圾桶了
你还剩几个苹果
你要把这个问题回答出来
人要把这个问题回答出来
机器要把这个问题回答出来
其实就要涉及到你要对办公室的理解
垃圾桶的理解
丢了什么一系列的理解
而且还做逻辑的推理
甚至有些任务上还做复杂的计算
而且所有东西是混杂在一起
而且所有的语言中的字符
你立马就知道
这个上海啊
整个7月4号一系列的事情
所以其实整个大模型是把
用了一种
确实就是刚才乔老师说的
特别好算力的方式
好语料的方式
让机器掌握了人类的语言和知识
它能够知道所有这些知识
并且对于细节上的语言
细微的这种多去理解
那作为我们
做一个实验室来说
我们一直在致力做这件事情
因为学生同学一起
在学人类的知识的
逻辑顺序是几乎一样的
让他学很多的知识的同时
看很多书的同时也让他做题
让他做题之后
让他去工作
工作之后然后通过反馈的方式
让他进步的进化
所以我们在这个从实际的任务来说
做题的话就从小学
初中高中大学
甚至到研究生的这种题目
研究生的这种资料都给他去学
也就做出来我们的
训非星虎的大模型
这个特别是在教育领域
在医疗领域
达到一个比较高的水平
并且能够去
真正的理解题目
去给出可解释性的
推理步骤的
和答题的思路的方法
包括医疗也是一样
所以这个
是我们在整个实验室
一直是致力追求的
当然在现在大模型的方法
它确实存在反面的一个问题
我们的困难就在于
虽然它能够给出
可解释性的推理步骤
但它为什么能给出来
还是不可解释的
虽然有点绕啊
但这个就是自然语言理解
我们人都是能理解这样的话的
但现在就是如何能够去
真正的理解它的知识
它的逻辑定理
在整个大的深度神经网络里
到底是怎么工作的
这个其实和老科学
怎么去实现一个
语言这么复杂体系的
东西的
用神经网络里面的
知识的编辑
逻辑的这种编辑的一系列的工作
这个其实也是个非常前瞻
但是应该有非常之
有研究价值的这样一个
技术的领域
那我们也是在往这个方向上
持续的在推进和努力
好 谢谢
好
我是黄铁军
我们这个实验室
叫多媒体信息处理
全国重点实验室
这个实验室的前身
叫文字信息处理
是咱们国家最早的
国家重点实验室之一
当时是王选院士
建立的
这次重组之后
我们当然今天就不仅仅是
文字信息处理了
是多媒体多模态
因此当然正好赶上
一次这个大模型的
人工智能的浪潮
所以多模态大模型肯定是我们的一个
重点的研究方向
但是现在这个方面很热
刚才各位专家都讲了
我就不再重复讲多模态大模型的这个内容了
我们也一直在思考
未来
因为作为一个
国家重点实验室
全国重点实验室
更多的还是要偏前沿探索
基础研究
做出与别人不同的东西
所以今天就给大家
报告大概一个点
就是我们过去这十几年
那就是人工智能
12年到18年那一段
就做图像识别
人脸识别 语音识别
大家最后叫感知
甚至有人说感知问题解决了
后来的18年到现在
这五六年时间的
大模型 语言大模型
认知问题
当然也不能说解决了
但是应该是取得了很大的突破
实际上我觉得刚才这两个结论
都还是
都还是说取得了重要的突破
但你要说解决了
这完全不是那么回事
比如说感知问题
你不能说一个机器会识别人脸了
会识别语音了
这就叫感知问题了
不是这样的
我们人 包括生物
作为一个智能体
跟世界的互动过程中
它不是被动的
像机器一样的接受一个图片
语音变成文字
图像解释一下
这就叫视觉或者是听觉了
不是这样
我们是一个实时的互动的系统
在这里边
最重要的一个维度
是时间
时间
大家回过头来想想
今天的
包括多么的大模型在内
有几个真正的在关系时间
其实大家都是收集大量的数据
数据一旦拿来都是静态的
去挖掘
去寻找规律
这个是必要的
我没有否定这个意思
但是真正的一个智能系统
它是要实时的感知
眼睛要看 耳朵要听
多种感知手段
同步的
实时的获取关于这个世界的信息
然后
同步的去处理它
为什么说时间重要呢
因为一件事发生
同样一件事发生
发生在不同的时点
意义完全不一样
就是说马后炮
再对也没用
一定要在恰当的时间
给你一个意见
可能才是有帮助的
如果说的再宏观一点
世界是运动的
不是静止的
但是今天的人工智能
我们是以静止的方法在看待它
不是完全运动的方式看待它
本来生物进化过程
也是在不断的跟环境互动
实时的互动 交互
在不断的迭代
在提高这个智能
所以我们目前在做的一个重要的方向
就是从这个角度
从实时的感知
当然我们说实时可能有不同的意思
超实时感知
以及实时的处理
这个角度
来构造下一代的智能系统
为了简而言之
要不然我这个啰嗦多了
站太多的时间
也听了比较多的
就是内脑智能
内脑智能最重要的特点
就是你表示各种感知通道的信息
和你处理这个信息
所用的信息表示方式
不是今天的一幅图像
一段视频或者一段文字
它是一个流
而这个流呢
在我们大脑里面叫脉冲
脉冲神经网络
大脑是个脉冲神经网络
所以我们传感器是一个脉冲的流的感知
所以我希望呢
就是未来我们构造出来的这一套
新的智能系统
是一个
能够实时的处理这些信息流
而且从功能上
就比如说人能做什么
他能做什么
但是在性能上
要比我们生物比人
要快好多数量级的这么一套
智能系统
这样装到巨神上
无论他是车还是机器人还是无人机
他就不是说跟人比
他就不是说跟人比
而是呢
性能要比人强大的多
这是我们制造人工智能系统的目的
如果你做出来一个东西跟人一样
那有一次一位老院士就说
那你还多生几个人就好了
我们不用非要去替代人
既然你要替代人
那必须在性能上
要远远超越人类
它才有它在这个世界的存在价值
好 我就想讲这些
谢谢
好 各位专家
还有各位来宾 大家好
我是来自
自主智能无人系统
全国重点实验室
我叫孙健
那么我也是代表我们实验室主任陈杰院士
在这里面跟大家汇报一下
实验室的一些情况
那我们实验室呢
其实前身叫复杂系统智能控制与决策
是偏控制类的一个实验室
但现在的话我们可能更多的是
面向这个自主无人系统
那么也是人工智能
传统的控制方法这样的一个结合
那么我们实验室呢
那么有这样几个研究方向
原来
那么第一个的话还是做这种
系统控制它的一些
基础的一些理论和方法
第二个是做这个环境的
感知和理解
第三部分呢是做这个无人系统
或者是机器人它本身的这个
智能的发育和衍生
还有的话就是
底层的这样的一些
仿生和驱动
那么现在呢
像刚才我们这个主任说的
这个弹幕型呢
确实非常的火热
那我们实验室呢针对这些情况呢
其实我们也做了一些
研究上的一些想法
那么这里面的话跟大家汇报一下
其实我们主要还是在做
这个相当于就是
人工智能加无人系统
也就是所谓的这个
聚成智能这方面的一些研究
那么具体来讲呢我们
目前稍微
做的比较多一点的呢
可能我们还是
想要把这个原来的
我们控制里面的这些多智能体的概念
加上聚成智能的这样的一些概念
也就是做多个无人系统
之间的这样的一个聚成智能
跟单个的现在
做的比较多的这种
聚成智能相比呢可能更强调
这个多体之间的这样的一些
协同所以呢我们也
结合我们实验室的这些
研究方向呢我们也布局了
几个这方面的一些
研究方向第一个的话可能
还是我们所说的这样的一些
对环境的这个理解和感知
那么基于这样的一个
大模型的这样的一些思想
在里面这是第一个方面
第二个方面呢就是主要考虑
聚成智能的跟环境的这个交互
和本身的这个大模型的建立
这里面的话我们更多的
可能还是要考虑这个
世界模型怎么去建立这样的一个
方法所以其实我们
可以看到刚才跟博文主任
他们做的这个报告里面
讲到聚成智能这部分内容呢
跟我们基本上想法
也都是一样的
第三个的话我们关注一些呢
这个多个个体之间的
这样的一些协作和博弈
就是他们怎么样去协同
那么还有的话就是
不同智能体
无论是多个智能体内部
还是不同的智能体之间的
这样的一些博弈
在里面所以这是我们
第三个方向第四个的话可能
带了一些明显的
我们控制学科的一些特点
就是我们做底层的这个分布式的
控制以及的学习
就是现在的一些方法
学习的这些方法怎么能
真正的落到我们单个的
这个智能体上面去
然后的话做这种分布式的这样的一些
学习他们之间又能够有
这样的一些协作的效应
最后能有一个好的一个效果
所以这是
我们现在目前来讲
结合这个大模型加上我们的
自主无人系统实验室
现在目前正在做的一些方向
跟大家汇报一下
谢谢大家
刚刚两位院士胸怀国志大者
从这个通用大模型
跟咱们国家立国之本
工业制造结合
从顶天立地做了非常精辟
前瞻性的分析
我们四位重点实验室的主任
我听下来几个关键词
虚实结合
认知理解
时序迈冲
我们的聚身自主
几个关键词也给我们
指明了未来的一些方向
我想把这些分析起来
可以说在结合周老师一开始说的
通传融合我们对于未来AGI
在脑海中的形象
我不知道大家感觉在我脑海中是越来越明确
那么我们下轮进入第二个问题
今天请到的都是咱们全国的主任
大家知道
这个大模型的发展
事实上带来了重大的科研翻试的变革
OpenAI为什么厉害呢
在我看来它把大工程跟大创新
做了很好的结合
首先它有大规模的算力 数据
还有很强的工程能力
来支持它进行这种大规模的训练
来支持它进行这种大规模的训练
但是还不仅仅局限于工程能力
事实上我们可以看到OpenAI
还是做了非常多的创新
从模型的架构
到新的训练方法
人类反馈 强化学习等等
不一而主要创新
事实上这种大工程大创新
是一个重要的模式
不局限于工程和创新
我们可以看到现在人工智能
跟实体经济结合越来越紧密
未来工程创新和产业链的密切结合
将是未来发展的重要模式
在这中间咱们国家
既有很大的挑战
刚刚我看各位专家也提到了
同样也有很大的机遇
我们还是有我们所长的
我们应用场景多
我们工业体量大
我们科研体量也大
在这时候我们从咱们实验室的角度来讲
形成针对新的形式新的挑战
大家如何能够形成
更密切的协同
形成合力
来应对这些挑战
我想是大家非常关心的一个问题
今天我们难得聚在一起
所以希望听听大家的意见
要不这一次我们先从几位
全国重点实验室主任
从吕校长开始您先分享
最后我们请钱院士和王院士
给我们做总结
好 很荣幸
我们实验室
重组以后的核心任务
就是要
开展虚实贯通的
沉浸式的
可增强计算的
智能计算平台的
研究
在这方面
我们要做
我们未来的
虚拟现实的引擎
和操作系统
以及数字软身的构建运行环境
这个环境
我感觉仅仅靠
我们重点实验室
来做这个事情
很难达到
尤其是
比如说我们在人工智能时代
我们要做深层式和
可构建式的虚拟现实的
这种渲染平台
那大量的数据
我没有
我如何保证这个数据能拿来
第二
在深层式这种大模型时代
它的算力的平台
尤其重要的
我觉得我们可能
在现在的科研过程中
我们更多的
它不是一个
纯粹以前那种实验科学
和数据科学
它是一个不断的
迭代演进的一个
构造科学
在这个时候我们可能特别需要
我们的年轻人
能够发挥聪明才智
我们感觉到比如说在国际上
现在能看到的
是两个年轻人
还是UC伯克利的
他们构造的一个solar平台
我们现在纹身视频
在国际上现在比较热的皮卡
那也是两个华人
是史丹佛的
两个小女孩
他们构造了一个新的
这种纹身视频的平台
所以如何激发我们的年轻人
基于我们的这种计算
新一代的计算环境
和新一代的数据
来做这件事情
我们需要多个实验室
协作起来
尤其是跟我们上海人工智能实验室
合作起来
我们才能在这方面形成突破
而且把我们的青年的
学生们
激发到我们这个计算环境里面
开展充满想象的科研
我觉得这件事情
我们一个实验室
任何一个实验室
都做不到
需要联合起来
需要科研资源
大家各有所长
一定要打通连接起来
才能支持未来的发展
下面请胡主任
我们认证的实验室
有点不太一样
我们既有学校的
研究团队
构成
也有科大讯飞
这样一个企业
和相关的战线支撑
所以在我们实验室
可以理解为有全职的工作人员
他们去搭
我们专门的工程院
专门的资源部来处理
但确实在这里面
从合作来说
从往前发展来说
因为我们更多相对专注在认知智能
语言理解 知识推理
等相关的普杂逻辑
这样一些推理方面
其实我们觉得
刚才所说的
人能掌握很多的能力
掌握很多语言理解
相关的
它是跟在互动的过程中
制造了很多的一些知识
所以其实从我们实验室来说
其实非常希望
包括跟虚实融合的也好
还是这个聚声阵也好
去看 如果双方能够
我们大家一起合作
在上海实验室的大平台之上
看怎么样的
我们各自有所侧重
但是有个更大的一个规划
和主体能够把各自的优势
各自的上场的部分
在国家层面好
站在每个国家级的这样一个
战略科技力量的平台的角度来说
都是非常希望 乐于看到的
让总店长 总平台要来
来做这件事情
我们会始终专注在
语音 语言这样一个维度
但是这个语言的过程中
它多数的
它在和整个世界互动中说了句话
它怎么样的和一些东西
怎么样的能够相互融合
具体上怎么样的融合
是要一个围绕一个更前瞻的
更大的目标
应该还是要以项目的这种方式
去往前真正的才能有效的
合作和推进
同时在这个项目的过程中
有更多的年轻人
有更多的一些公共的一些资源
包括刚才那个
吕校长说的像算力啊
数据啊这些资源能够
在合适的范围内充分共享
那个才能够有效的支撑
更多的更大的创新
大概是这种感觉和建议
听这个胡主任讲
我想就是说这个实验室要协作起来
它需要一个hub
一个连接器
我们上海人工智能实验室
愿意发挥在这方面的作用
以后咱们这个科学论坛呢
就是这个hub的会客厅
我们每年大家到一起聚一聚
谈一谈怎么把这些做得更好
有请黄老师
刚才那个乔老师就说这个
我觉得大家肯定都
也都思考这个问题
为什么ChatGPT啊
现在是百磨大战
不能说做得越来越小吧
做得越来越热闹
但是不大
我觉得这个问题是一个深层次的问题
这个咱们涉及到方方面面
但是我觉得最重要的
就是这个问题的解决
肯定不是科技圈的那
能完全解决的
这个问题不是纯技术问题
而是一个更广泛的问题
那是什么问题呢
我觉得咱们还是经常说的这句话
就是集中力量班达式
就是举国体制
这里边呢
你像OpenAI跟微软的合作
OpenAI我们可以说是一个新鲜机构
研发
但实际上它在
21年
那个时候跟微软结合的时候
其实已经决定了
它已经从一个研发的这种属性
变成了一个为一个企业
为一个很大
可以说很大的商业目的
在发展的
在20年发展也显然如此
所以它能做那么大
是跟这个市场
跟商业相互互动之后的
这么一个结果
这不是纯粹一个
研发的问题
但是美国有美国的体制
咱们就讲刚才说
有这种像微软这种大型企业
来拉动
然后把这件事就做得越来越强
但是在我们国家这个集中力量班达式
这个大事
就不应该仅仅是一个科技问题
尽管科技很重要是核心要素
我都同意
但是这个大事一定是个国家的
大事情
这件事应该国家来定义
不是我们任何一个实验室
或者是咱们就说
把它仅仅当成一个科技问题
什么叫大事
咱就不啰嗦
我过去的一两年时间
我都说过好多次
我觉得人工智能就两件大事国家可以办
第一个建设治理基础设施
像建高铁一样的
建一个智力运营体系
千家万户
让所有的企业
直接从这个基础设施里面
获得智力
像买一度电一样的
买智力用智力
要建的这件事
这件事乃是任何一个大学
或者实验室能定的事
肯定是国家
因为建高铁需要投多少万亿
要涉及到产业链
要协调资源
要设计生产性
这种层面去热闹
而不可能变成我们现实的生产力
和国家的这样一个发展
所以这是一件事
我觉得可以做的
我纯粹说的不一定对
但是我觉得这是一个思考问题的角度
第二个大事
智能驾驶
你现在这么多车
中国的车也做的很好
现在要从新能源进入下半年智能化
那车里面的智能驾驶的模型
谁做啊
现在实验室把那个做出来
谁有那么大的资源和力量
这就得国家去统筹
说这事要做了
要投入很大的资源
然后我们每一家的力量
其实就是大事中的一个参与者
两难一兴当年也是这样
这件事必须办
办的过程中你搞科研的
搞生产的
甚至于搞矿的
你都得围绕这个目标去做
那不就办成了吗
所以我觉得在这个过程中
我们这些任何一方
有竞争很正常
你做的好还是我做的好
那大家最后反正都是
冲着那个目标去的
那就不散了
现在是大家照着自己的想法做
所以它会百磨大展
会比较散
这是我的感受
不一定对
有请孙主任
各位老师
因为我是自主无人系统
全国重点实验室
所以大家都知道
无人系统其实是一个
多细和交叉的一个事情
像我们从研究方向上来讲
其实我们这里面会用到
像我们
我们李校长所在的实验室的
我们Theme2Real的这些问题
从实际的
从仿真到真正的
无人系统这里面
就会用到
虚拟现实的实验室的一些成果
那我们认知感知也会用到
我们科大的科大讯飞啊等
实验室的一些成果
像我们后面的这个决策啊等等
那我们黄老师这边做的内脑智能
其实都可以放到我们这个
无人系统里面来做
所以呢就像陈杰院士说
说自主智能无人系统
是我们这个研究人工智能的
一个比较好的这样的一个
抓手和切入点
因为大家所有的这些技术
其实都可以最后落到我们这个
无人系统上来
所以的话我觉得从我们这个
几个实验室的这个研究上来看呢
我们是有一个合作的这样的一个关系
这是第一个方面
第二个方面的话我是觉得
从我们这个实验室来讲
那我们也是两个高校来合办的
北京理工大学和同济大学
一起建的这样一个实验室
那我们从高校的这个角度来讲呢
其实也是面临了一些问题
像我们要做的这个
比如说做大模型这些内容
那里面的这些基础的一些算力啊等等
还有基础的这些模型啊
其实我们来讲我们
更多的是专注无人系统
还是有一定的缺陷
那这样的话可能我们也需要借鉴
我们现在其他的一些实验室的
一些成果和
一些基础的这些条件
包括咱们这个
这个上海的这个人工智能实验室的
一些
成果和条件吧
所以呢我觉得大家也是
非常有必要能够整合起来
第三个呢
就是说我刚才也非常同意
前面几位老师啊
说的那么要
多个实验室协同起来
其实更多的我觉得可能还是
国家的这个任务的一个引领
没有一个大的这种任务把大家统一起来
那这样的话很难形成这样的一个合力
现在目前来讲很多的情况下
可能还是
自己做自己的
那么有很多的这种重复性的一些工作
所以甚至呢有些呢
可能还是一些低水平的这种重复工作
所以需要呢
国家层面从整个的这个
通盘的这样一个考虑
那么提出一些
重大的这种任务来
把几个这种相关领域的重点实验室
真正的把它给协同引领起来
我就说这么多
刚刚四位主任啊
从这个我想
从这个学科互补
资源互通对吧
数据很多资源互通
而且不仅仅是咱科技界的事情了
刚才黄老师说到这么大的一件事情
一定是在国家层面
跟产业啊跟方方面面密切结合的事情
做了跟大家提了很好的建议
我想最后啊我们还是请两位院士
要不这次黄院士先请您这个
给我们讲讲
在新形势下面咱们这些国家级的平台
如何协作
而且这个协作可能还不仅限我们自己
需要国家层面更多的这个统筹和布局
您怎么看
好的
这个刚才几位实验室的主任啊
谈得非常好我也非常赞同
为了不耽误大家的时间
我就讲两点
第一点呢就是
我们人工智能
这个上海
人工智能这个实验室啊
它可以说是
国家实验室建立啊
是一个战略科技力量
那么我们
要引领这个
战略科技力量
要把全国的这些
重点实验室
跟我们人工智能机器人啊
都有相关的
实验室呢协同起来
大家一起来协同
来开展这个就是
几国体制的战略科技力量的
人工智能的这个研究
那么第一个呢
最主要就是啊
一定要
刚才几位都已经谈到了
我非常赞同
我们要把这个基础设施
就人工智能的这个基础设施啊
要把它建立好
让大家就是从产业链
供应链
创新链到人才链
大家都能用
这个基础设施
因为人工智能那个今天呢
我们是属于数据驱动也好
模型驱动也好
还是大模型驱动也好
它还是跟这个
基础设施有很大的关系
所以
第一点呢就是一定要几国
体制
把基础设施建设好
就正如我们的高铁
包括我们的这个
电力超高压直流输电
这些世界最强
最大的几个标志性工程
当然以前的两弹一星
这些都是几国体制
使大家各行各业都能够享受
这是第一点建议
那么这就要靠我们
我们每一个人
要发挥作用
教育界也要发挥
也就是科研教育人才培养一体化
那么除了这个呢
还有管理
第二个方面呢就是
我们建好这个基础设施的时候
恐怕也要发挥大家的
创造性作用
这个创造性非常重要
因为今天最主要就是
要科技创新
来驱动我们各行各业
在这个设施的基础上
我们把这个AI技术
赋能到不同的领域
比如我们赋能到
制造行业
因为中国是一个
制造大国
要成为一个制造强国
那么通过这个AI的基础设施
赋能到制造
我们千家万户
千万个企业
大企业 小企业
中小企业 创业企业
也能用得上
第二个呢
我们刚才提到的
我也非常赞同
汽车制
我们叫做
巨神智能的汽车交通
大家天天都开车
那么昨天我也做了一个大会报告
叫做智能网联车的大会
在这个
长沙开这个智能网联大会
大家谈得非常多的
未来的智能网联汽车
我们怎么样解决高效 安全 舒适
低碳出行
让大家不像今天
人人都要开着一个汽车
能不能解决掉
那么我们AI是不是也可以在这个场景上
去落地
这就是我讲的两个
最紧迫的场地
一个是制造应用场景
第二个就是交通应用场景
第二个就是交通应用场景
第三个呢 我认为教育
就是我们AI
我们要赋能到我们的整个教育里面
因为只有培养优秀的
创新人才
源源不断地培养出我们
就是这一轮的AI
我们一直在思考它能不能够
打破我们的传统教育
改变我们的传统教育的方式
应试的教育方式
我们能够培养出那种
创新性的人才
通过这个AI技术
能够启发我们的教育
改变我们的传统教育
培养出一种创新性的人才
过性化的人才
这个也是
我认为也是紧迫性的
第四个方面呢
我就认为
我们的人们要过上
幸福的安康生活
人人都要健康
那么我们也在医疗这个方面
也要发力
医疗行业也是很大的
中国人你看
未来的养老
还有我们的助老
助产
包括我们的
这两三年的新冠
大家都看到
这也是一个很好的应用场景
就把AI赋领到我们智慧的
医疗行业
这样我们真正能做到
顶天的
立地的
顶天的我们就起国体制
把AI这个基础设施建设好
让大家不要重复性的建设
让大家不要重复性的建设
那么立地就是我们紧迫性的几个行业
那么立地就是我们紧迫性的几个行业
那么立地就是我们紧迫性的几个行业
这样我相信在几国体制下
这样我相信在几国体制下
同时又发挥了
大家的聪明的
创新的才子
释放我们的活力
释放我们的活力
那么我们明天
我们真正能走上一个
中国式的现代化的国家
中国式的现代化的国家
就把它讲到这里
谢谢
下面我们请钱院士
下面我们请钱院士
做最后的
刚刚我们四位实验室主任
刚刚我们四位实验室主任
都讲得非常好
不管我们要男院士
讲得非常好
其实大家也看见了
我们通过简短的
我们四位实验室主任的发言
就看到我们很有必要
我们的文化系统
一方面我们一定要围绕
通用大模型跟专用模型
怎么系统
实际上是之间也系统
包括要男主任的
工程中心跟我们的
国家技术创新中心
你看我们刚刚讲的
吕教授讲的
虚拟 虚实的融合这一块
其实就是原宇宙
时代即将到来
原宇宙时代
可能虚实的融合非常非常重要
包括到我们的认知计算
认知研究
以及到我们体军教授讲的
如何把我们通用也好
专用模型
把它做得更好
更精准
而且克服我们的泛化能力
不可解释性等等
以及到我们的孙教授讲的
其实我们讲
我们的真正的大模型也好
就是这个认识世界
据说我们还改造世界
我们要自主自能
用大模型来改造世界
等等之类的
其实体会很多
一个字我们一定要系统起来
才能壮大我们的人工智能
本身的研究
以及人工智能的赋能
其实刚刚在
实验室主任介绍
我也很有体会
譬如讲我们体军教授讲的
我们无论做通用大模型
或者是
专用大模型也好
我们要把这个模型
做得更精准
它更能体现它的用心的
这个现象出来
因为你现在无论是做模型
要把一个系统一个对象
把它孪生走出来
把它动力去演变的演化的机制
其实我们每个对象
它有时间跟空间的分布
其实我们往往
就从空间的分布上面
如果从空间分布来讲的话
那我们可以用大模型
通用大模型的特征
机器的分析
把空间的上面一些特征去做
但在时间分布上面
那可能不仅仅是大模型的统计
更需要
在时间测试它的演化的
演变的一些机制
这一块就是我们
专用大模型的
专用它的对象的特征
把它结合起来
所以总而言之
我想无论怎么样
我们把我们的
无论是通用大模型 专用大模型
或者是计算
我们现在讲的
你看我们现在的大模型
我们都是耗费了大量的能源
去计算 计算 再计算
能不能我们把计算两个字
倒过来讲是什么
算计
如果我们把算计
创造我们创新我们的算法
那我们可以积累大量的能量
提高我们的速度
提高我们的精准性
这个我想 这是我的体会
我们把它系统融合发展
我就想起刚刚
闭幕的这个全国科技大会
这个上面
总书记对建成
2035年建成科技强国
有五项任务
能不能对于人工智能
对于我们这个上海实验室
怎么样进行
这五项任务 我觉得很有启发
第一项
能不能形成我们的这个
举国体制
这样的一个优势
咱们中国是举国体制
这样的优势
能不能在人工智能
用我们链组 总链组 总平台
来形成我们的举国体制
把我们这些声音社 国家技术创意
工程中心等等企业
把它形成一个链
把它圈起来
形成我们在人工智能创新的举国体制
第二个方面
要成为科技创新
和产业创新的深度融合
能不能把我们人工智能的创新
跟我们的产业创新
深度融合
使它真正的成为发展
新生产业的重要引擎
那我想
那第三个呢
能不能创新一项体制跟机制
那结合这个链
这个总链 总平台
一个很好的体制跟机制
带动我们一些国家的
战略科技力量来创新
当然我们还有第四个
刚刚王先生讲的
教育 科技 人才要一体化
这里面啊 我们要
担当 加加国际合作
我想这样是我的体会
如何把我们这个
上海平台 系统我们
国家的所有的战略科技力量
在人工智能创新的
这个领域里面
发挥我们这个举国体制
我就讲这样 谢谢
好
我想前院是这一番讲话呀
也系统地把咱们这次
整个的这个会谈做了全面的总结
最后呢 我们再次感谢
因为时间也到了 再次感谢各位院长
但是各位专家的精彩分享
我相信大家和我一样
听了各位的这个真知灼见
收获满满
国家实验室是咱们国家战略科研力量的
重要的组成部分
肩负着基础突破和技术创新的重大使命
未来呢 我想
我们通过联动国家
方方面面的力量 打造AI生态的朋友圈
形成优势互补
战略习头的格局
为咱们国家人工智能技术创新
和产业生态注入新的动力
好 再次感谢各位专家
也感谢大家的聆听 谢谢
我们要感谢这个乔老师的主持
刚才这个
这一场这个圆桌
是我想这是
上海人工智能实验室
精心设计的一场圆桌
把我们国家的有关的重点性
国家基金平台都请在一起
也是一个通专结合的一次示范
所以希望将来
真正的在国家大目标的这个引领下
巨势乘风
为了我们这个人工智能
全世界全人类做出一个
做件大事出来
做出大的贡献
下面我们进入一个重要的环节
是一个重要的发布
那么这个发布是关于
这个2023年
就是刚刚过去的一年
全球人工智能的创新指数
那么我们有请
这个中国科学技术信息
中国科学技术信息
研究所的党委书记
也是我们中国软科学研究会的
副理事长
赵志云教授
来做2023
全球人工智能创新指数的
发布有请赵索达
尊敬的各位领导
各位嘉宾各位朋友
各位同学们
大家下午好
谢谢大会主委会
和论坛主办方的邀请
今年我们继续
在上海人工智能大会上
发布
由中国科学技术信息
研究所
联合北京大学
共同研制的
全球人工智能创新指数报告
创新指数报告
是一项
连续性的工作
我们已经做了五年
这是第四次在上海
世界人工智能大会上
发布
其实我们是力图
从基础支撑
资源与环境
国际合作交流
等五大维度
通过构建三成的
三级的这种指标体系
对46个重要的国家
它的创新发展
和治理的情况
我们进行量化评估
目标就是力图能够
全面客观的
反映全球人工智能
的发展态势
以及明确中国
当前所处的位势
那2023
它的总体的特点
就是在我们的五个
基本的一级的指标
体系和基本的
指标体系的框架
保持不变的基础上
我们根据2023年
全球人工智能创新
发展和治理的
最新的进展我们
对二级和三级的
指标体系做了部分的
优化完善
其中主要是根据
2023年数据基础
应用潜力和国际
治理参与等等维度的
最新的情况我们进行了
微调二级指标和三级指标
比如说在二级指标上
我们增加了数据
基础开源项目
我们微调了
反映国际治理的
参与程度的学术交流
和国际治理参与
这样的指标
那在三级指标体系上
我们增加了人工智能的
芯片的这种
企业的数量以及
我们政府在数据
开放等等方面
反映它的
参与程度以及
电子证物的发展指数
还有高水平的
高质量的
高影响力的人工智能的
开源项目占比等等
这样一些三级的指标
那通过构建
这样一个新的
三级指标体系
我们最终形成了五个一级指标
十四个二级指标
和三十七个三级指标的
这样一个评价体系
那它的评价结果是什么样呢
总体的格局就是
中国和美国
两强引领
那同时呢
四十六个国家形成
四个梯队的
一种总体的梯次
分布的格局
没有改变
但是中美两国的
在第一梯队
与二三四梯队的差距呢
是进一步的拉大
那再详细的看一下
第一梯队
美国和中国是在第一梯队
但是美国的全面领先的
地位依然是比较明显的
在五个一级指标
十四个二级指标中的
九个和三十七个
三级指标中的十七个
美国都是排名世界第一
那我们中国呢
连续呢
在五个一级指标上
都是排名全球第二
同时呢
中美两国呢
基本上聚集了
全球人工智能创新发展资源
和产出成果的绝大多数
那在第二梯队上
依然是保持着
你争我敢的
这样一种竞争的态势
美国这个国家呢
都有它自身的特点
但总的趋势呢
是与第一梯队的差距呢
在进一步的拉大
但英国呢
它在整个的教育资源
和高质量的学术研究的成果方面
还是比较突出
日本的专利也比较突出
德国在产业和应用方面
特别是在人工智能的风险投资
以及国内的市场规模方面呢
它是很有优势的
也比较有特点
印度连续三年
它的排位在不断的上升
而萨特阿拉伯也是连续三年
在排位上升
但是它今年2023年
是第一次进入到
第三梯队
那第四梯队呢
大多数国家呢
相对都有比较
非常弱势的项目
但是也有一些进展
像巴西和印度尼西亚
这些个别的国家
在产业应用等等层面
是有明显的进步的
特别是巴西和印度尼西亚
在人工智能的开源项目数
和人工智能的风险投资
等等方面
它还排在了中等以上的水平
这也进一步的
阐明了刚才博文主任
和我们几位专家
所说的一个共同的观点
就是人工智能的应用
和开源
还是非常重要的
那接下来呢
我们对全球的
人工智能的创新发展的趋势
如果做一个总体的观察
观察的话呢
很像刚才几位
全国中电实验室的主任们
在台上分享的观点
它有四个特点
第一个特点呢
就是大模型的突破
它带动了人工智能技术创新的加快
自然语言处理和多模态
等等这样一些工作呢
在整个的
人工智能的创新发展中起了
非常重要的作用
那同时呢我们看到
2023年机器学习模型的数量
是大幅度的增长的
自然语言处理的模型
还有多模态的
大模型的增长幅度呢
都是非常巨大的
也需要强调的一点
就是AI for Science
在持续的投入
那面向生物
面向医药 面向地球科学
面向数学
和材料科学
等等方面的科研领域的
机器学习的模型
在不断的涌现
也推动了全球科学的
不断向原创性的
这个高度去进展
那第二个特点和趋势呢
就是产业界
在模型开发上的领先优势
在不断的扩大
产业的颜值
更加的明显
和突出
那这里面我们可以看到
2023年产业界的
可以研发的机器学习的模型
达到了176个
而且呢
比学界
它是学界的3.5倍
那同时呢我们也可以看到
过去的10年
从2013年到2023年
那
产业独立开发的
机器学习的模型
数量占比
从25%已经增长到了
62.6%
说明企业的参与 企业的主体
地位是人工智能
创新发展的一个重要的
动力的源泉
第三个趋势呢就是刚才大家热议的
生成式人工智能的
开源项目的数量
在激增
那开源依然是人工智能创新
研发和应用的一个
重要的模式
那我们看2023年生成式人工智能的
开源项目的数量
是呈现爆发式的增长
那同时呢
印度这样的一个国家
为什么它在
它的梯队中排名近三年
稳步的上升
也是因为印度在开源的项目上
它是一个主要的
来源国
那第四个特点就是人工智能
企业的新增数量
开始增长
创业创投低迷的趋势
有所转变
这个特点呢是非常的明显的
因为我们知道在
2018年到2022年
一间全球新增的
人工智能的企业数量
在逐年的递减
但是这种递减的趋势
在2023年得到了抑制
那同时呢
有个回转的这种倾向
2023年的新增企业
数量同比上涨了
21.5%
那同时呢还有一个
更为乐观的趋势
就是全球人工智能风险投资额
虽然还是一个
下降的趋势
但是这种下降的幅度
在明显的缩减
特别是2023年
深层式人工智能的风险
投资的规模在急剧的扩大
它也使得深层式人工智能
在推动
我们人工智能的创新发展方面
起到了非常重要的作用
后呢我们回到中国
那中国呢
在整个全球人工智能的
发展的总体上
综合水平嘛
我们还是保持全球第二的水平
我们在关键的
核心的竞争领域上
没有形成绝对的优势
那同时呢我们在
人才培养和科研产出
产业发展等方面
这些年来也取得了明显的进展
特别是我们担心的
高层次的人工智能的
人才队伍的壮大
在持续的有一个
向好的这样一个趋势
还有高质量的科研成果的
数量也在明显的上升
人工智能的
产业在蓬勃的发展
这也是我们能够保持
人工智能良好上升势头的
一个重要的基础
那同时我们也要看到
我们还有弱项
就是我们数据的开发的利用
和原创的
这种能力呢还存在着
不足特别是
高质量的数据资源的
稀缺的问题
以及重大的引领的
创新产出不足的现象呢
还是持续
还需要我们进一步的加强
所以呢从五个
评价的一级维度上
我们希望未来呢
我们能够有所新的突破
第一呢是在
基础支撑上我们希望进一步
去加强数据
资源的这种建设
去健全公共数据的
开放共享机制
去建设安全合规大规模
高质量的预料库
那同时呢我们也希望进一步
去加大高层次的人才的
领域力度
创造宽容失败的这样一种
科研的环境
那同时在科研
科技研发创新
这样一个维度上
我们也希望强化前瞻部署
和原始的创新
去抢抓刚才专家们说的
巨声智能和内脑智能的
新的机遇
我们也希望加快
高水平规模化的应用
这是中国最大的优势
我们希望聚焦
关键的领域去打造一批
具有技术先进性
和规模化潜力的
这种潜在的应用场景
去推动大小模型的
协同落地
最后也是今年大会的主题
就是我们希望进一步
去扩大和增进
国际交流的合作
搭建国际交流的平台
针对全球
共同关注的治理的话题
我们能够加强
人工智能领域的科技合作
推动国际治理的
协同共建
我的汇报就这么多内容
详细的内容
请大家关注报告的原文
和我们官网上的信息的公布
谢谢大家
谢谢赵所长
以这个非常宽广的
全球视野
和非常详实的数据
我们展现了过去一年
中国科技机极所的
有关的研究成果
那么也确实希望大家能够
有机会看一看
它这个报告的全文
以及我们这个
中国科技机极所的
有关的相关的研究成果
下面我们就要进入
今天下午最重要的一个环节了
叫主旨报告环节
Keynote
这是最重要的环节
那么今天我们有两位重磅的
瑞士人工智能实验室的研发主任
瑞士人工智能实验室的研发主任
他同时也是沙特阿拉伯
阿卜杜拉国王科技大学
人工智能项目的负责人
他就是这个
Jürgen Schmidhuber教授
Jürgen Schmidhuber教授
在人工智能方面
耕耘了很多年
我们知道他在这个
比如说在这个长短时的记忆
就是long short term memory
这方面有非常独创的发明
那么他在这个
对抗生成网络
在注意力机制
在原学习
等等方面
都做了很多开创性的工作
那么他的这些工作
不仅在理论上有重要的价值
而且在实际上有很多的应用
比如我们知道谷歌
就用了很多这个
这个Schmidhuber教授的技术
而且我们还知道
Schmidhuber教授
是一个有很多独特的见解
在学界可能跟
不太一样的见解的
这么一位学者
按照有关的介绍
他的这些见解
在若干年之后
还往往被证明是正确的
那么下面我们就请
Jürgen Schmidhuber教授
为我们带来今天的第一场
主旨演讲
有请Jürgen
请
Jürgen
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
请
是一個像這樣的系統製造世界模式的深奧性鏈
想著未來,以計劃未來的行動循環
在那裡,你會看到我叫的名字
我叫的名字的主席
今天,很多人在討論 generative AI
Generative AI 將世界掩蓋
大型語言模式在創造文章
這些文章不可分別於人類製造的文章
我非常高興
因為這些大型語言模式的導致的東西
是一種智能網絡
是一種智能網絡叫做轉換網絡
轉換網絡
有人知道什麼是智能網絡嗎?
握手
好,我們有兩個人知道什麼是智能網絡
有人不知道什麼是智能網絡嗎?
我們這房間有第三個群組
他們不明白這個問題
智能網絡是人人腦海裡引發的東西
人的腦海裡有100多萬個小螢幕
他們叫做智能網絡
每個智能網絡平均接觸到約10,000個智能網絡
這意味著你的腦海裡有1萬多萬個智能網絡
一些這些智能網絡是輸出智能網絡
影片、音響、數字等
以及物質的智能網絡
其餘的智能網絡是輸出智能網絡
當智能網絡更換時
你的手指或語言肌肉都會移動
你的整個生活都在轉變
未來的資訊流程
尋找特殊的資訊
特殊的資訊是你的獎勵信號
你想獲得獎勵
也想減少痛苦
直到你的生命結束
這就是你的目標
你能夠建造同樣的智能網絡嗎?
我們也有智能網絡
一些智能網絡
通過學習
智能網絡變得更強
其餘的智能網絡變得更弱
每個智能網絡的智能網絡
會說
這個智能網絡
會影響那個智能網絡
在下一個時刻
然後
使智能網絡變得更強
弱智能網絡
就會學習
有趣的東西
例如開車
或認識語言
我們看到的
有些人認為
智能網絡回到2017年
回到Google
但這不是真的
第一種智能網絡
在1991年出版
我稱它為
快速重量智能網絡
今天它被稱為
不正常的
直線智能網絡
但那時候
我並沒有稱它為智能網絡
我稱它為
快速重量智能網絡
或快速重量智能網絡
它在做
同樣的事情
現代智能網絡
都在做的
除了
它是直線的
它叫做直線智能網絡
因為它是直線的
那是什麼意思呢
如果你有100倍的輸入
那你只需要
100倍的數量
來解決
現代的
矩形智能網絡
你需要100倍
100倍
是10,000倍的數量
所以現代智能網絡
它是矩形的
而不是直線的
而這是非常重要的
因為很多人
都在
嘗試
避免
現代智能網絡的
矩形智能網絡
而一個很好的方法
就是
看看1991年
以前的
直線智能網絡
所以在那裡
你有一個網絡
可以看到
未來的資料
然後它會
提供
鍵鍵
和價值
而這些鍵鍵
和價值
都需要
重量智能網絡
來解決
矩形智能網絡
而在矩形智能網絡中
有一個非常快的
速度改變
並且
就在
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
這些
在1990年,我曾经使用了一些现在称为
 generative adversarial networks
我不是称为 generative adversarial networks
我称为 artificial curiosity
但是在那里,你有这两个互动的互动
所以,一种互动是在 probabilistically 生成出现出的
所以,出现出现出的 probabilistic distribution
比可能出现出的出现出
而另一种互动是在这些出现出现出的第一个互动
作为出现出现出的互动
并在试图预测环境的影响
所以,第二个互动在试图减少错误
成为一个更好的预测
但第一个互动在试图误会第二个互动
在试图惊讶第二个互动
如何?
它在试图补充第二个互动的同样错误
所以,这两个互动之间有一个斗争
一个游戏,一个minimax游戏
而今天,它们非常受欢迎
因为它们在实际上看起来非常实际
所以,我很高兴
G和P和T在GPD
都能够回到我们的《阿努斯·米尔华比勒斯》
1991年在明尼克
而在那时候,远远的记忆
也在那里
因为在那里,你必须要看
我的伟大的学生Zeb Huchreiter的论文
它已经包含了LSTM的基本原则
就是细胞连接
细胞连接是让这些LSTM
实际上的线路非常深
深学习是关于深度的
有时候,深学习没办法
我们只有小线路
我们只能用小线路
然后,最初的细胞连接
是非常深的
那些是LSTM连接
为什么?
因为它们有这些细胞连接
然后,1995年的名称
我在1995年创建了
但是名称并不重要
最重要的是
你在那里名称的数学
所以,所有这些细胞连接的东西
都变得非常重要了
不仅因为LSTM
现在是20世纪最受欢迎的AI
但也因为
我们在2015年发布的
线路连接
使用了同样的原则
除非它们不使用
连接连接
而是连接连接
连接连接有这些线路
但连接连接只是深度
有很多层次
然后,我们使用了
同样的细胞连接
在1991年回归
把这些线路连接
连接得非常深
然后,一个这样的版本
在一半年后
被微博公开
这是20世纪最受欢迎的AI
但它是根据同样的原则
这些细胞连接
所以,这些是1991年
很好的一年
但当时,我们没有办法
我们不能做很多事情
因为电脑太慢了
电脑太慢了
但当时,我们有个朋友
这个朋友是一种趋势
这个趋势基本上是
每五年,电脑
是10倍便宜的
每五年,电脑
是10倍便宜的
这个趋势是很老的
我在1987年做我的训练课
因为它回到1941年
当孔乃茨,这个人
在我后面
创建了第一个
设计控制计划的
总目标电脑
在巴伦,他做到了
1936年,他做到了
设计控制计划的设计
1941年,他完成了
第一个设计控制计划的电脑
可以做到约一个
一秒的行动
然后,十年后
你可以做到一亿的行动
同一价钱
当我做了我的训练课
在AGI
在1987年
我们已经有了一亿的功能
我们可以做到一亿的训练
同一价钱
不过很快
我们将能做到一亿的训练
同一价钱
这就是为什么
现在每个人都在用
在你的手机上
这些技术
都是在前几世纪的训练
所以深入学习
所有深入学习的基本理论
都在前几世纪的训练中进行
很少人在新几世纪的训练中进行
深入学习
是前几世纪的训练
是前几世纪的训练
所以
2009年
训练价格便宜了
我们可以开始赢得竞争
通过我的
专业研究员Alex Graves的努力
2009年
训练价格快了足够
让前几世纪的古典方法
能够达成所有
其他技术的成果
2010年
我得到了一幅美丽的
Romanian poster
他能够使用
NVIDIA GPU
2010年
毕业训练也没有
只是深入训练
正常训练
回到前几世纪
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
1970年
最新的超人系统
在新加坡竞赛中
发生了最新的超人系统
它是关于
影像认识的
那个时候是
AlexNet
从那时候到现在
所有人都在使用它
现在CNN的
超人系统
都是以前的东西
回到1979年
福西马在日本
然后也在日本
有个德国人在日本工作
1987年
他合作了
律动和背景设计
福西马没有用背景设计
然后也在日本发布了
1988年
他发布了
最新的超人系统
就像我们现在使用的
和背景设计
所以在1979年和1988年
CNN被创建
他们一直在等待的是
使用NVIDIA的GPU
使用NVIDIA的GPU
因此NVIDIA现在
非常成功
因为它们的硬件
是你需要的
AI工具
在2010年
LSTM在每个手机上
LSTM在每个手机上
在你们的手机上
阿里巴巴
和Samsung
和Huawei
所有人都在使用它
我记得10年前
15年前我来到中国
我必须向
车车司机展示
那间酒店的图片
他知道我要去哪里
今天他把手机
放在我面前
我说英文或其他语言
他就回答我
我们就讨论了
而且
很棒的是
语言的阻塞
不仅仅是人的阻塞
整个国家也有阻塞
所以我非常高兴
车车司机认为
这些东西
在我的小研究室
在纽约
还有在德国
但是
整个国家的
交流阻塞
我非常高兴
所以
第一个大型语言模式
是LSTM的
在2017年
Transformers
2017年
18年
但是它们也回到
1991年的
我们在过去的
我非常高兴
我们创造的
LSTM
快速的CNN
高线路线
它们非常有用
它们有很多的
医疗用途
如果你搜索一下
你会发现
有些病毒
例如Diabetes
加上LSTM
用来预测
或治疗
很多的用途
还有
多种
新增性的
用途
所以
我刚才也提到
在AI4S讨论
几分钟前
我们不能只用
这些技术
去做组织学习
你知道
有个教授
告诉系统要做什么
然后它似乎
似乎似乎
教授知道
我们也可以用它
来做增强学习
比较具体的
因为没有教授
告诉系统
在什么时候
要做什么
而
为了这个
我们必须要
认识一下
LSTM的重量
但是
这件事
非常有效
我们在2017年
开始了
与我的
PhD学生
Dan Wiestra
和他
和他的朋友
Shane Legg
都在我的研究室
他们是
DeepMind的
第一个
在Computer Science
和AI的
研究生
他们
其中一个
是DeepMind的
 co-founder
另一个
是第一个
工作人员
然后
我们用它
来建设
比较好的
游戏玩家
我们必须要知道
游戏玩家
比赛比较困难
因为
在赛道
比如赛道
你只需要
一个小小的
8x8的
显示图
这就告诉你
你必须要知道
最好的动作
但是
在游戏
你必须要有记忆
过去的事物
所以
这不行
所以
你需要
像LSTM
这样的
运动运动
要有记忆
要学习记忆
关于重要的事情
发生的
然后
开放AI
用同样的东西
LSTM
有84%
包括
其他网络
但是
84%
是
LSTM
学习
政策
成为
好的游戏玩家
所以
比尔·格尔
称之为
AI的巨大项目
现在
现在
正在
正在
正在
正在
工作
现在
在
电腦上
在
在
电腦上
滑车上
所以
所有的浙大语言模式
等等
你只能用它们
是
简单解决纸
做就习
字幕
所有的东西
和
展示
文章
和
又
其他文章
在媒体上提供的文章
并且能够提供
媒体和记者的提供
然而
这些大型语言模式
非常短暂
他们只是一个
人类的知识
解释方式
以一个
方便的方式
因为
解释方法是自然语言
但当然
除了AGI之外
因为AGI需要决定者
也需要智能人
智能人在智能世界上
比智能人
在
虚拟世界上
更困难
因为
如果你有
一亿或一亿次的
在游戏中的试验
而你再次死去
你总是会被解除
但在实际世界上
你会被破坏
所以在实际世界上
你必须要
你必须要处理
非常大的限制
使得一切都比
在虚拟世界上更困难
这就是为什么我们 10年前
创建了这家公司
NASEN
AI for the physical world
and
and
还有一个公司
我们现在正在
开发
使用AI for the physical world
进行自动测试
公司叫Delvitec
它是在进行自动测试
的优秀项目
这部机器
在两三年前
进行了测试
它可以测试
各种食物
和芯片
或自动部件
在目前没有其他机器
可以做到的方式
这部机器
和AI
合成一样
有很多
技术
很难复杂
如果有任何投资者
我们正在
进行测试
如果您是投资者
请私底下联络我
我们想要
在3亿美元的
自动测试市场中
掌握一大部分
您看到的
在AI4S讨论中
我已经提到过的
基本理论
如果您有AI
在自动测试世界中
这AI
在自动测试世界中
需要控制
机器
需要学习
透过分别的
世界模式
预测机器的
作用
您可以
创造更好的
世界模式
我称之为
1990年世界模式
这幅幅幅幅幅
幅幅幅幅
这世界模式
可以作为计划
如果您有
一个好的
世界模式
您可以用它
计划行动运动
以逆向的理论方式
你看看
这幅幅幅幅
您能不能
即使有机会
也能走过
其他一个世界的
世界幅幅幅幅
和相同的
世界模式
运动
您可以
从这幅幅蛋
向自己的
即使是
一个相同的ğı
但世界模式不知所措
所以世界模式很愚蠢
如何能够让控制器
提供行动组成的行动组成
带来数据
让世界模式更好
当时的理想很简单
世界模式的错误
是控制器的利益
所以控制器是
同样的高度
而世界模式是低低低的
所以我们有一个
现在叫做
Generative Adversarial Network
你可以使用它
建立自己的目标
通过自然疑惑
那就是我以前
称之为自然疑惑
然后我们有很多
几十年来
用真实的设计
建立了这些设计
但是有个问题
问题是
问题是
这种设计
仍然在使用中
广泛使用
就是
几秒钟每秒钟的计划
这很愚蠢
例如
如果你想从上海
去
哪里是个好地方
人们从哪里来
去巴黎
我的下一个停留地
其实是巴黎
那么
你不要
在你的头上
创建一个计划
就像这样
把你的小脚
移动一点
像这样
直到你
把你的手机
移到你的手机
然后打电话给
驾驶站
然后打电话给
驾驶站
然后在你
在机场上
移动一点
把你的腿移动
走到计划中
不
你实际上
你作为人
你有一个高级的
适当的计划
计划你的未来
你只是
把未来
变成几个
重要的
项目
然后你已经知道
所有的项目
引发了
一个
计划的
引发
所以
你不需要
想想
几百万的
不同的
行动项目
你只是
看一看
几百万的
计划
你将能够
在未来
实行
你知道
你已经
在你的
智能网络中
已经有
从开始
到计划
从这些计划
到下一个计划
等等
所以
你学习了
设计的
环境
这些计划
在今天
大家认为
很重要
但是
在1991年
我们已经有了
第一个计划
能够
从长远的项目
变成小块
然后
再次
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
重新
這張圖叫做M
M可能看過所有YouTube視頻
也許是基礎模式
也許是其他東西
但它有很多 algorythmic的資料
關於各種行動
因為YouTube充滿了
動物的電影
人類的動物
小孩的動物
所以YouTube視頻
有很多資料關於動物的動作
所以控制員想教導
想控制一隻
從來沒有丟過任何球
但
你想要
在世界模式中
採取資料
所以你想要
解決
世界模式內部的
內部表現
讓你更快地解決控制員的問題
而不是從頭到尾
學習整個模式
所以
2015年
控制員學會了
用模式來釋出
模式的解釋
解釋模式的解釋
到這個模式
這會被反映出
什麼東西會反映出
就是數碼解釋
一個個性的解釋
但是
現在控制員的工作
就是學習
對這些答案的解釋
在時間中學習
對這個解釋的正確部分
這個巨大的世界模式
的學習程序是
進一步進行的
而ACID測試是
控制者能否
從一開始學習新的任務
更快地學習
沒有使用世界模式
或只是把所有聯繫
和世界模式等於零
以免除它
或者它能否
從世界模式中
得到 algorhythmic information
並學習
對這些重要的東西
進行解釋
並解釋回應的答案
所以
學習思考
這是一篇追蹤文章
控制者和模式
在一個網絡中
崩潰
使用網絡溢出
一些人認為
網絡溢出是一件最近的事
不,這也回到1991年
當我發佈了
這個深入學習系統
使用了
預測計畫
來支援深入學習
所以
這是一篇
紐約的
最好的書籍獎
包括一堆
中國學生
在Caustus
我的學生團隊
在Caustus
是最有影響力的大學
在紅海中
Ming-Chen Tsu-ge
和其他人
在這篇文章上
這不僅是
有兩種網絡系統
一個是控制者
另一個是模式
現在我們有整個社會
的語言模式
甚至超過100個
或甚至超過100個語言模式
你給他們一個任務
其中的任務無法解決
其中的任務
無法解決
但共同來說
也許他們可以解決
如何解決呢
他們開始了
我們稱之為思想暴動
他們討論這個問題
然後回過頭來回
這個人這個語言模式
有一個想法
也許這個語言模式
是關於視覺的
但不關於思想
所以他們都在互動
他們有不同的方式
來組織它們
並解決
其中的諸人的建議
是否有用
然後你就可以
擁有一個民主
你知道
民主的規則
是透過選舉
而在這些思想暴動中
有時
某些任務
是更好的
而其他任務
是更好的
我們沒有一個整體的
解決這個問題
現在
我最感激的
是機器學習
是真正的數學學習
你不僅是在這裡
和那裡學習
你也學習了
學習理論
你學習了
自己的學習理論
所以你沒有
牽涉到人工生產的
學習理論
沒有
因為你学會了
人的身體
你學習了
人的力量
你學習了
人的能量
你學會了
人的能量
你改善了
也再改善
在判斷上
沒有任何限制
除了心理能力
甚至流派的限制
而我的1987的理科考驗
在前面的图片中看到的
例如,现在我们有综合综合计划
这是我学生Lewis Kirsch和其他学生的工作
Lewis Kirsch现在在DeepMind
综合计划学习
在它自己上
使用背后传播计划
所以在综合综合计划的隐藏活动中
背后传播计划
也正在进行
所以在背后
我得到信息,我的时间到了
但我不相信
我还有多少分钟?
只有十分钟吗?
是的,好的
所以我们有这些新的东西
在Meta学习中
背后传播计划
正在运行在网络上
但在距离传播中
背后传播计划
更改善了
变成了更好的训练计划
所以我们有
专业的训练计划
和运行训练计划
我认为这将是未来的
我的时间到了
所以我甚至不能提到
最近的工作
专业试验
我可以提到
但我不能太多谈论
我不能谈论科学训练
我已经提到
在其他训练计划
和AI4S训练议程
这些科学训练计划
在这些科学训练计划中
使用了工程学家
来提升科学训练计划
当然我没有时间
提到我们在
这些人的肩膀上
在这些人的肩膀上
有些人认为
在50年代
维生维生维生计划
在这些人的肩膀上
有一个技术
其实这个技术
不是最近一样
没有,它是在1965年
在义和克林顾和拉帕
在义和克林顾和拉帕
的玉芹
在你现在使用的所有技术
目前我們有這些小機械
像嬰兒一樣,因為它們很弱
很多感測器,很多攝像機
但是它們的肌肉很弱
它們無法自我製造
透過自己創造的實驗
我相信這也會增加
這將是未來非常重要的
然後,另一個非常重要的步驟
就是自我修復
和自我進步的社會機器
以及3D印刷機和其他機械
你可能知道
3D印刷機已經可以印刷自己的部分
但是我們沒有3D印刷機
可以印刷自己的部分
因為3D印刷機的所有部分
無法被印刷
所以,未來需要一個天才
去看到全體的機械
3D印刷機和機械
和機械製造機械的機械
這些東西
將來不會需要人們
再次製造自己的部分
是一種機械文化
可以製造全體的機械
成為這個文化的一部分
我們還沒有在那裡
但是它將會在那裡
當它成功成功
當你真的有自我修復
機械和機械的社會
那一切都會改變
因為這就是
3D印刷機的最終極限
世界經濟是關於極限的
所以這就是3D印刷機的最終極限
而且它會受到商業壓力
因為那些人
擁有3D印刷機
像那樣的生命性機械
可以自我修復
他們將會變得非常豐富
而這些生命性機械
不會被限制在我們的視線上
而他們也能在星球上
或星球上
或馬克里上
活著
所以這將會改變一切
而生命性機械
生命性機械的生命性
將會增長到1億
相比我們今天
所擁有的小小東西
想想看
這是未來的未來
未來的意思是
未來幾十年
或什麼的
我沒有時間
我沒有時間
要討論
將會發生的
非常驚人的事情
在未來的五十五億
或四十億年以來
生命性機械
將會增長到太空
因為
最多的資源
物質資源
能量和物質
你需要的
要建造更多生命性機械
更多
更大的
生命性機械工廠
等等
最多這些資源
並非在我們的小彈圈裡
而是在太空
而且
雖然
光速限制
但是
有很多時間
有很多時間
可以
把整個宇宙
統一
因為
宇宙仍然是年輕
只有13.8億年
而它將會
多次年長
而你需要
幾十億
幾十億年
把整個
宇宙
統一
透過智能
這將會
改變
一切
在我們的小彈圈裡
並非
只限於我們的小彈圈
而是
整個宇宙
所以
如我所說
在幾年前的
TEDx討論中
這是
不僅是
另一種
工業革命
這是
人類
經歷
新的東西
甚至
生物
甚至
生物工藝
而
而
那裡
那裡
有美
和
重大
的
不僅是
一步
而不是
最後一步
在宇宙的路線上
從
非常簡單的
起始狀態
到更多
更多
不可思議的
複雜性
這是
將會
變成
未來
這裡
我們有一個
非常緊張的
組織員
想讓我停止
我現在
要停止了
謝謝您的
關注
謝謝
謝謝
謝謝
謝謝
謝謝
謝謝
謝謝
我
還
已經
有
这个Artificial Curiosity
这个东西呢
是谈的Meta Learning是原学习
它不是要学习一个具体的任务
而是要学习怎么有效的学习
所以我想这个对今天在座的很多
尤其是年轻人
是应该受到启发的
我们怎么能够学会更好的学习
那么下面我们一位这个讲演者呢
是来自加州Berkeley大学的
这个当宋教授
宋小冬教授
那么这个宋小冬教授呢
是曾经在清华大学
在CMU
在这个UC Berkeley呢
有非常丰富的这个学习经历
而且呢
他取得了很多成绩
这个我这里的稿子上说
这个当宋教授可谓是在学术界
拿奖拿到手软
这个怎么叫拿奖拿到手软呢
他得到了MacArthur的天才奖
得到了Guggenheim奖
得到了美国Sloan研究奖
而且入选了麻省理工
这个
呃
呃
35岁的创新者的这个名单
呃
获得了这个
呃
很多很多的奖励
那么他为什么获得这么多奖励
他干的是什么呢
呃
他干的是计算机的安全
我们知道这个人工智能向前发展
两个轮子
一个轮子呢
我们要让这个人工智能啊
呃
易用
好用
管用
另外一个轮子呢
就让他安全
可靠
可信
那么我想这个
呃
宋教授啊
主要是在做后面这方面工作
那么我们现在就有请
宋教授
让本人给我们解释一下
他做了什么
将要做什么
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯
嗯嗯
好
嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯嗯 想说
我
好
还
我們必須考慮一個非常重要的事項
就是如何將AI進行負責任的操作
現在不同的政府全球都在通過許多法律規定
所以我希望強調的一件事是
我們將AI進行操作時
我們必須考慮攻擊者的存在
有很多原因
首先,歷史證明攻擊者經常遵循新技術發展的步驟
甚至甚至失敗
此時,AI的重點更高
由於AI控制更多的系統
攻擊者會獲得更多的優勢
以培養AI系統
由於AI越來越有能力
攻擊者會越來越失敗
因此,攻擊者會越來越嚴重
因此
以防止AI進行操作
我們必須考慮攻擊者的存在
由於AI進行操作的重點很廣闊
因此,我不會能夠講解所有不同的危險和挑戰
以達成AI的負擔
因此,我會專注在三個重要的挑戰之中
第一,是如何確保負責任者的負擔
當我們使用AI系統
第二,是如何避免AI的錯誤使用
第三,是如何確保負責任者的負擔
以及正確的價值輸出
首先,我們來看看
我們使用AI的負責任者的負擔
如何使用AI的負責任者的負擔
而在AI的負責任者的負擔上
它包括了許多不同的觀點
包括了私隱、穩定性、
包括了我們的穩定性
以及其他很多的
例如公平性、致力性,以及其他
因此,在時間的需求
我不會能夠把每個題目都列在這裡
而這也是一個不允許的項目
所以,我會給你們幾個例子
以我們自己的工作為例
首先,是關於私隱
為什麼我們要關心私隱呢?
我們知道,模式上
有很多的資料
未來,我們將要訓練
甚至是公共資料的模式
所以,有一個重要的問題
我們知道,電腦網絡有很多能力
所以,問題是
這些電腦網絡是否記得訓練資料呢?
如果是的話
能否讓敵人在訓練資料中
從訓練資料中
從學習模式中
從訓練資料中
從訓練資料中
從學習模式中
所以,在我們早點的運行中
我們第一位,anna
 unpacked this problem
徹底 …
 öğ antig
他們記得訓練資料的很多
而招待員夠新能力
要瞭解深入的資訊
包括,對比
用來測試記憶體的程度
例如Google Smart Compose等
以提升這些模式的隱私性
我們也有追蹤的研究
顯示這些現象仍然有效
以後的大型語言模式為例
包括GPT-2
我們最近的研究也顯示
GPT-3.5和GPT-4
這些大型語言模式
攻擊者可以從訓練資料中
採取感染性資訊
我們最近也研究了一個
複雜的工具
以解決大型語言模式的隱私問題
包括不同的攻擊
以及不同的防護
我們也證實了
隱私隱私的隱私這個隱私
是一種大型模式的隱私隱私
而我們在研究的研究中
也顯示了
會有一定的隱私隱私
我們也顯示了
模式的隱私隱私
是一個大型模式
這個隱私隱私的隱私
是一個非常重要的技術
我們已經展示了
一個大型模式的隱私隱私
是一個非常重要的技術
我们可以实际上发掘不同的私人语言模式
例如,发掘不同的私人语言,以及其他
这就是私人语言的一个方面
另一个方面,我想谈谈的是
对抗攻击,例如对抗的例子,以及对抗的执行
从我们的早期工作和其他人的工作中
我们学到,这些选择例子
攻击者会在无法判断的方式上操作,以致
对错误的预测,使得计算机计划失常
这也能导致错误的结果
这些攻击是在所有的课程中
都被语言模式和项目中的不同类型和类型
都被语言模式和项目中的不同类型和项目中
语言模式和项目中的不同类型和项目中
语言模式和项目中
语言模式和项目中
一件有趣的事是,我们之前的工作中
我们的研究的工具和物理学的工具
我们的研究的工具和物理学的工具
我们的研究的工具和物理学的工具
其实现在成为了在博物馆的综合综合综合综合
其实现在成为了在博物馆的综合综合
其实现在成为了在博物馆的综合综合
这是科学研究人员的珍质
这些物理学的攻击
也是大学研究人员的安全图的大小问题
大学研究人员的安全图的 それ controller
发展外围了 decaying tools
发展了雙重棉包夾
发展了雙重棉包夾
还持续与大小区域一起提供了
还持续与大小区域一起提供了
领导承担的人城地组的作用
领导承担的人城地组的作用
特别一样
特别一样
当当中发生了这样的恶劣的项目时
当当墙暲和合设者的括弧
当当当强会设的领导计划
在рь微 Laurel mensen
在 ichihide следующ的 にP tone
我们研发了许多新的测试规则和测试环境
包括敌人环境
我们的工作显示了这些大型语言模组
对这些敌人的攻击有很大的影响
我们的工作显示了这些大型语言模组
能够实际上测试这些大型语言模组
从许多不同的角度来看
实际上这些大型语言模组的代价
都负担到敌人攻击
而这些敌人攻击也是有效的
这些综合模组的模式
是了解这些分别
而作为侦察模组的模特
攻击者有机会找到
于一些敌人模组设计的例子
使其被动作更好
在重现大型语言模组
可以很容易令模特兒失去平衡
目前我們討論過敵人的攻擊
在敵人時期
這些敵人的例子
甚至是基礎工程和障礙障礙
他們可以令模特兒失去平衡
失去平衡
並且失去平衡
這些敵人的攻擊
也能發生在
前進訓練或進行進攻的時間
這也叫做
在這個情況下
資料污染
在這個情況下
敵人可以提供
污染訓練的資料
而
我們在早前的工作中
我們也在研究這個問題
以示出
這個污染問題
可以非常積極
和非常有效性
例如
我們在早前的工作中
顯示出
敵人
通過提供
這些
污染訓練的資料
可以令模特兒
正常地
認識
臉部
但
只有
當
敵人
穿著
特定的眼鏡
那人會被認識
為
目標人
而
最近的工作
從
安斯洛比克
以及其他人
也顯示出
這些
污染訓練的資料
也能
作用
在
我們
正常地
研究
這些
污染訓練的資料
而
我們也
在
早前的工作中
顯示出
敵人
通過提供
這些
污染訓練的資料
可以令
我們
正常地
認識
這些
污染訓練的資料
而
我們也
顯示出
這些
污染訓練的資料
也能
幫助
我們
在
研究
這些
污染訓練的
資料
而
我們
也
顯示出
這些
污染訓練的資料
也能
幫助
我們
在
研究
這些
污染訓練的資料
可以
幫助
我們
在
研究
這些
污染訓練的資料
可以
幫助
我們
在
研究
這些污染訓練的資料
可以幫助
我們
在
研究
這些
污染訓練的資料
可以幫助
我們
在
研究
這些
污染訓練的資料
的
研究
這
視乎
各個
不同的
污染öß
的
資料
可以
幫助
我們
去
研究
污染
在AI安全方面有很大的挑战
一些我们最近的工作
开始了一个新的方向
目标是解决一些这些问题
我们的工作名为
代表性设计
作为AI透明性的最高端方式
在这个情况下
我们提供了比较相似的波动
然后我们选择了
模型的启动
然后从这些模型启动中
建立了模型
从建立的模型中
我们能够认识到
某些方向
例如某些层次
在启动中
然后
这些方向
可以与某些模型的行为相似
例如
模型是否真实
模型是否被启动
等等
并且
透过这些技术
我们可以更多地控制
模型的行为
例如
我们可以更多地控制
模型的行为
例如
模型的启动
在某些方向
或某些层次之下
我们可以更多地控制
模型的行为
例如
模型的启动
在某些层次之下
或某些层次之下
或某些流动
或相对平程度的技术
或顺序的方式
此�ína rätt
对于 模型 Class
和 Around
对于 模型 Class
我们能够实现什么样的安全特征
所以我们最近的一项研究
与很多其他领导研究员合作
是建立对AI安全的规则
这一项研究的一个例子
是在电脑保险设施中创建的
就是我们能够透过设计
建立安全和安全的系统
所以在电脑保险设施中
其实我们在过去的25年内
我们已经移动了
三个系统
实际上有几个逻辑
关于我们能够建立安全系统的方式
第一个是通过反攻防御
我们实际上创建了
攻击证据的技术
然后第二个是
通过发掘困难的设施
发掘困难的设施
然后解决它们
直到攻击者发现困难
但是这些设施
有不同的缺点
但是这些设施有不同的缺点
在防御方面的效率上
所以建立安全系统的最有效性的
就是建立建筑
或设计的安全系统
实际上目标是
我们想要建立系统
使得我们能够建立
安全系统的方式
这跟之前提过的其他防御系统相比
一个方法就是通过实际证明
我们能够实际地设定
我们想组织的系统的特色
然后实际地证明
设定的特色
实际设定的特色
实际地设定的特色
实际设定的特色
在过去几十年,我们已经进入了专门检测系统的区域,
我们有很多专门检测系统的不同类型,
包括微软、加密货币系统、复制器等。
但问题是,这些专门检测系统的证据非常努力。
通常每个检测系统需要十几年的证据设计。
所以,我的群伙与其他人合作,
从开放智慧设计以来,
我们在几年前开始使用智能证据证据学习。
现在,LM的目标是我们能更好地做。
所以,不仅仅是专门训练代理人,
我们也可以专门训练代理人,
使用这种大型语言模式的技术,
进行智能训练,
证据证据证明和证实计划。
因此,我们可以使用这些计划,
与计算计划合作,
与计算计划合作,
并终于生成确准的证据。
所以,基本上,我们有证据和证据。
因此,以这种方式来说,
我们希望使用智能训练,
以帮助建立准确的系统。
这可以帮助减弱军事风险,
并提供准确的系统,
适当抵抗某种种类的攻击。
当然,这种方式仍然有很多开放的挑战。
因此,因为时间有限,
我不能进入详细内容,
因此,我们希望使用智能训练,
以帮助建立准确的系统。
因此,我们希望使用智能训练,
以帮助建立准确的系统。
因此,因为时间有限,
我不能进入详细内容,
以帮助建立准确的系统。
因此,我会简单地描述其他挑战。
第二个挑战是,
如何解决AI技术的缺乏使用。
如何解决AI技术的缺乏使用。
攻击者可以缺乏AI,
作为顶攻器车或人互动。
作为顶攻器车或人互动。
据患者的天 Però
据患者的天 How
我们认为这些标准技术
建立gehen
也会以攻击饰areth
方式这样做。
Now
We are already seeing
 widespread voice-cloning
In massive操作 구ioso下,
social and community
例如工程、偵測、虐待、襲擊等等
我剛才提到的
建立安全系統
我們可以幫助建立安全系統
對這些更加進步的襲擊
我們也希望未來
我們可以開發AI系統
去監視交流
與使用者之間的交流
幫助保護使用者
對AI系統的襲擊
最後
我們知道
AI系統的資料是生命的血液
但目前有很多問題
很多值得考慮的資料
在資料盤中
沒有使用
創作者和資料製作者
很多都不夠
對他們的資料
進步
所以問題是
如何更好地
提升資料進步
並且公平地分辨價值
我的群組也是
第一位
研究這個問題
發展穩固的標準
為了表達
使用沙普利的價值
我們可以發展穩固的標準
為了決定
價值應該被回應
對資料進步的
資料製作者
並且提供資料
來訓練機械模式
因此
我無法詳細解釋
沙普利的價值
的資料
但我們也發展了
不同的解釋方式
來展示
沙普利的價值
的效率
所以
建立一個
負責資料經濟經濟
的經濟經濟
也是一個重要的部分
在負責AI
我們可以
實際上
提升
負責資料經濟的
效率
所以
建立一個
負責資料經濟經濟的
經濟經濟
也是一個重要的部分
在負責AI
我們可以
實際上
提升
負責AI
的效率
並且
在2020年
建立一個
負責AI
的經濟經濟經濟
所以
在最後
我時間到了
我先
總結一下
在我們
發展
AI的能力
中
也重要
在
負責AI的使用
上
有很多
不同的
挑戰
在
負責AI
上
我希望
我們能夠
給大家
一些
一些
挑戰的
例子
以及
未來的
負責AI的
負責AI的
負責AI的
使用
以及
負責AI的
使用
及價值
的負責
謝謝
謝謝
謝謝
教授
當
用
短時間
討論
大量的
問題
他提出了一個
非常重要的問題
叫做
負責任的AI
向誰負責
向人類負責
向我們的國家負責
那麼
要做到
他提出來的
很嚴重的問題
就是今天我們的
在AI系統中的
隱私洩露問題
也提出來了
在這個過程中
我們現在的AI系統
對於攻擊的那種
脆弱性
以及對攻擊防衛的
進步還很慢
所以這些問題
都非常緊迫
那麼他就提出了
一個
Secure by design
這個安全
是從設計開始的
是一個內生的
而不是從外部
附加上去的東西
我想
我們今後的年輕人
可能要更多的
關注這個方面
我們共同來發展
負責任的
有效的AI
就像這個
今天3月份聯合國
通過這個決議
叫做
這個抓住
負責任的
叫做抓住
安全
可靠
有效的AI
所以
我們非常感謝
這個宋教授
來促進全球的
可視域發展
我們再次感謝
這個宋教授
那麼下面呢
我們要進入最後一個環節
是一個面向未來的環節
我們有請這個實驗室的
林登華教授
來邀請幾位
在實驗室工作的
年輕的科學家
也可能不是在實驗室
在這個領域工作的
年輕科學家
做一個原作的討論
有請林教授
尊敬的各位来宾专家学者
女士们先生们大家好
终于来到了今天的
科学前沿主题论坛的最后一个环节
那么在这个环节的话呢
是一个panel的环节
我们将围绕下一代人工智能的
架构的革新和挑战
一起跟几位青年的科学家
去探讨和展望人工智能的未来
那么这是一个充满的
非常的开放性和无限可能的话题
大模型还有生成式AI
发展到今天
已经在整个社会的各行各业落地
那么在这里面的话呢
我们在应用上看到了很多可能性
但是也有很多的人去关注说
它的这个基础架构是否已经收敛
那么在技术的发展的未来
是不是有新的可能性
那么今天我们非常荣幸地邀请到了多位
在科研一线
但是也是非常有成就
有很多有影响工作的青年科学家
来到这里
跟我们一同探讨
人工智能发展技术的未来
首先呢我们会有请
几位这个对话嘉宾上台
他们是上海人工智能实验室青年科学家
多摩泰大摩
形认入前年探索项目和因果实验团队的负责人
陆超超博士
快手视觉生成与互动中心负责人
快手可灵视频生成模型的负责人
万鹏飞博士
清华大学交叉信息研究院助理教授
上海七字研究院项目负责人
金海图联合创始人许华哲教授
加州大学洛杉矶分校计算机系周柏磊
还有华铁路大学计算机学院张洪洋助理教授
同时呢我们也非常欢迎google的卖的这个设计商张涵
因为他的个人原因没有能来到现场
但是呢他也会共同的参与我们的讨论
有请各位观看这一期的视频
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
请不吝点赞 订阅 转发 打赏支持明镜与点点栏目
首先的话这个我觉得能够坚持到现在这个时间点的
很热情的这个年轻的学者
所以呢今天我们这个panel的话呢
也都是有几位年轻的科学家
说不定我在这里面最老的
共同来去探讨人工智能发展的这个技术的这个未来
那么我想这个做这一行的都知道
AI发展到今天其实展现了非常大的一个可行性
尤其是这个TRACK GPT到GPT4
以及最新的一系列的生成式的这个大模型的
这个涌现
大家看到了似乎我们正在走向通往通用人工智能
也就是AGI的这个道路上面
那么但是的话呢很多的研究者其实也发现了
在这个过程中
事实上这些模型虽然它能力很强大
但是也有很多的问题
我自己感觉的话呢有两个非常重要的问题
是大模型未来发展绕不开的
一个呢是它的幻觉问题
就是大模型它很多时候它在回答的这个过程中
是会出现一些事实性的错误
或者推理性的错误
那么这些错误的这个发生的话会使得我们
对于依赖大模型在一些关键的任务上面
是会产生疑虑的
在一定程度上也会阻碍大模型的这个落地
那另外一个的话呢是它的繁华问题
我们也看到了在很多的Benchmark上面
大模型其实已经取得了
非常非常高的成绩
那比如说甚至在很多的Benchmark上面
大模型所取得的成绩已经超过了
比较优秀的人类的选手
但最近的话呢刚刚也是我们高考啊
就发现大模型其数学研究是不及格
在很多的这个落地应用过程中
我们也发现大模型
包括这个最强大的像GPT-4o
在真实的应用场景中
其实还是存在很多的这个局限
那么这个所以我想有一个
很多的问题是在这个过程中
一个很重要的话题就是说
当前我们所探讨的这个大模型发展的技术道路
比如说这个基于这个Scalen Law
更大的模型更大的数据
基于Transformer这样一个堆积
去形成越来越强的这个智能体和模型
是不是能够最终
所以Scale的这个增大能够解决这些问题
还是说我们是需要seriously去很严肃的去看待
有没有新的
也许真正能够做到的
也许能够走得更远的技术路径
那么这个在座的话
张弘扬老师其实在之前也做过一些很多的study
包括他的这个Lost Domain Generalization
也是关于这个泛化问题的一些探讨
你看看这个弘扬你自己在这个问题上有什么comment
很荣幸能今天跟大家分享一下我的一些观点
刚刚林老师也说了一些
包括比如说
大模型有一些幻觉
然后他也提到了这个Scaling Law的问题
我觉得就短其实这个回答这个问题呢
其实分为我们是看待把这个问题看成成一个短期目标
还是一个长期目标
如果短期目标来看确实Scaling Law确实是
尤其是从去前年的拆GPD出来以后
这个大模型的能力有了significant的变化
那么其实Scaling Law的变化其实是很重要的
那么其实Scaling Law的变化其实是很重要的
Scaling Law也就是两架马车
无非就是数据或者说是
以及另一架马车就是算力
那么这个包括Google以及OpenAI的研究者
他们也发现必须算力或者模型的参数量
和数据的数量一定要乘一个比例
那么这个模型才会有这个质的提升
如果只是我们提升数据量
如果我们并不增加这个算力
或者说并不是增加这个模型的大小的话
其实模型的这个往往来说
它的那个性能并不会得到本质上的提升
那么当然现在一个问题就是说
最大的一个问题就是说
现在数据大家用的已经差不多了
互联网的数据基本上现在在GPD4
已经把世界上市面上能够吸收的
大部分的数据都已经使用了
那么现在就存在一个数据荒的问题
然后另外一方面其实算力上比如说
比如说最近OPI或者说那个XAI
马斯克的XAI他们据说买了十万张H100
来训练这样一个模型
这也是非常非常夸张的一件事情
所以说在这样一个层面上
其实 somehow我们到达了一个
算力以及数据上面的一个目前上的一个瓶颈
那么从短期目标上来说
我觉得前面一些老师的talk也提到了这种
用这种产生生成的数据
用一些模拟的数据来生成
来训练大模型
我觉得这是一个很好的一个方向
就是我们可以尝试的去
尝试用这种模型自我进化
自我improve的一种能力
自我反思的能力
来进一步的提升模型的性能
那就是我刚刚说的这些
其实还是偏向于这种短期目标
但对于长期目标而言
其实我觉得Skilling Law是有问题的
因为我们只要看看我们人类自己
我们可能早上吃一个鸡蛋
我们就可以有很多能量
足够的能量来做一些很多事情
并且我们一生中其实也读不了多少本书
但是我们却有着现在比大模型
优秀得多的能力
比如说刚刚林老师也提到了
这个大模型高考上
高考很多都不及格
但是我们却能考到很高的分
所以说这是一个值得大家思考的一个问题
这也是
一个open question
现在我也没有一个具体的答案
但我觉得我们应该
也要尝试一些
比如说这种
跟交叉学科
比如说我们现在研究清楚
人类是怎么样去学习
怎么样去进化
或者说怎么样去做一些任务
那么我觉得这样也会启发大模型
能够之后会得到一些更好的提示
这是我的一些观点
好 谢谢洪洋
刚才提到了就是这个scaling law
长期来说
洪洋觉得它是有一些问题的
包括它在能量层面
它可能会不太可持续
那关于scaling law的话
我觉得我们应该要跳出
咱们现在的这个在工程层面
的一些standard practice来看
如果从一个fundamental的角度来看
这个是不是最终通向AGI的一个
feasible的或可行的道路
那么今天的话呢
这个旁边的是曹操
曹操其实在这个
香港中文大学读硕士的时候
也是在咱们这个实验室
后来到了剑桥
长期来说
其实曹操做了很多开创性的工作
包括他提出的这个高深face
是首个突破这个
人眼的这个肉眼的这个人眼识别率的
这样的一个算法
那么到了剑桥之后的话呢
他一直是全世界少数的
这个研究者去研究这个因果
casuality的这个方向的科学家
在这里面有非常多的这个
这个见底
那么因果的话呢
可能也是在曹操看来
应该是我们整个intelligence里面
一个非常重要的一个组成部分
那么曹操你是怎么去看待
这个些大模型发展的
这个这种道路
以及说它是不是能够
因为人我们是有很多的
对于这个因果方面的sense的
以及对于事情因为什么
到达什么的一些判断
但大模型我知道你其实
我也建议大家看一看这个曹操的团队
几个月前发了一个报告去
讲到很多的大模型
在因果方面的表现
其实存在很大的问题
那么在你看来
这个道路是不是一个
可行的道路
它能不能够最终
随着更大的scale
去develop出来
真正reliable的可靠的
这个因果的sense
和其他的这个智能的这个要素
好 谢谢李老师的介绍和问题
因为我们团队的主要的目的
就是近一年多
主要就是做的
唯一的目的就是如何提高
大模型的因果推理的deny
所以一开始
因为大家知道
有很多大模型最终刷了很多榜
对吧 但是几乎没有榜
是关于它的因果推理能力的
所以我们一开始做的就是
你如何去度量一个大模型
有没有因果能力
然后你因果能力的表现方式是什么
经过我们的
就是说一系列的工作
其实我们发现
你的scaling load发展的趋势
并没有显著的提高它的因果推理能力
这是我们从实验上面得到的结果
其实本质上面
你transformer based的这些方式
你依然是学习它的相关性
当然因为因果一个很重要的原因就是
你永远无法可以从
被动观测的数据当中
去学到它的因果性
你一定需要干预的数据
因为这里的干预
是一个非常广泛的干预
只要你的数据
不是来自于独立同分布的
我们都认为它是干预的数据
包括多模态的数据
所以为什么多模态大模型
它是一个非常适合
学习因果的一种方式
然后这是我们得到的第一点
第二点就是
既然现在的这种transformer based的方式
没有办法能得到它的因果的模型
或学到提高它的因果推理的能力
那接下来我们怎么做
就是如何设计新的模型架构
或如何去收集
那种干预的数据
利用多模态的方式
去提高它的能力
另外一点
可能想讲的就是说
巨神智能因为今年比较火
还有多模态的大模型
就是说巨神智能
就是不论它以何种路径发展
就是我们认为
它必须拥有的一项能力
那就是需要能够因果推理
我举一个例子
就是说当一个巨神智能体
你在一个真实生活中的场景
去运动的时候
去观测的时候
你看到一个人
如何能确保他
不会冲过去把椅子踢倒
对吧
不会做出这种伤害人的行为
那你首先要确定
你人和椅子之间的因果关系是什么
因为现在大部分人谈到的因果关系
可能就是时序关系
一件事情引起了另一件事情
但是当你静态的物体的时候
你如何定义它的因果关系
当人坐在椅子上的时候
是如何定义因果关系
这都是非常基本的问题
所以我们也在这上面做了一些工作
如何你定义人和人之间
人和物体之间
甚至物体和物体之间的因果关系是什么
因为你只有多摩泰大模型
能理解了这些因果关系之后
你才能做出决策
不会伤害人
对吧
另外一点就是
关于大模型安全方面的问题
今天上午周主任可能也讲了
就是说
你为了确保AI
不会做出那些伤害人的行为
对吧
你首先你要赋予它反思的能力
它每次做出决策之前
它应该能反思
如果我做出这个决策
它会产生怎样的后果
要想清楚后果之后
你才可以做出正确的决策
而这种反思能力
你是完全可以在因果的框架里去定义的
因为现在很多谈到的这些好的价值观
甚至信念的话
都是行而上学的讨论
你如果没有办法形成
形式化
没有办法通过数学去定义的话
你最终没有办法把它变成一个
loss function的形式
去让你的大模型
在训练或学习当中
去趋近这个目标
让它赋予因果发现的能力
所以这是我的几点想法
谢谢
刚才的这一个
两位嘉宾的分享的话
其实都提到了当前的这种
geoskeleton law的发展模式中
存在着一些可能更加深层次的问题
包括洪洋刚才提到的
它的效率问题
和曹操所提到的
它对于因果的这种理解和捕捉上面
存在着一些更fundamental的deficiency
一些根本性的缺陷
当然我这些问题的提出和观察
也包括可能很多学者
从其他的维度也观察到了
skeleton law的这些其他问题
它并不是否认skeleton law
在很多的实际模型训练的实践中
它的一个很好的一个确定性
以及很好的一个作为一个guideline
来指导我们的工作
但是这些新的问题的这个发现的话
其实也是请我们去思考
这条路再走下去
我们是不是应该有些新的
这个路线或新的方式
这是非常值得
包括学术界和产业界
共同思考的问题
那么我们这个
现在的话呢
讲的除了这个语言模型啊
多模态模型
在这一波的这个生成式AI的浪潮里面的话呢
其实还有另外一种生成
那就是生成图像视频
这样的一些媒体的这种内容
也是现在被这个业界
和学界高度关注的
这样的一个topic
尤其是在今年年初
推出之后
更是引起了整个传社会
对它关注的一个热潮
很多的这个媒体朋友也非常关注这些
生成式的这个技术
会不会对行业带来颠覆式的变革
那么今天的话呢
其实我们也是非常高兴
请到了这个快手
万鹏飞老师
他是最近一个特别火的
可灵啊
这样的一个人生视频的模型
他的团队的负责人
那么这个想请教这个鹏飞
在你看来
内容生成
尤其是这种视觉内容的这个生成
发展到今天这样一个高度
它离真正最终落地应用
我说成规模的这个落地应用
从demo到应用
它还会面临哪些挑战
好的好的谢谢林老师的问题
从规模的应用的话
这个确实还是挺取悦应用场景
就是首先
像视频生成这个
我们做的可灵
从它的基础模型方面
它提供的能力还是非常有限
test to video
对一些人来说可能会觉得会比较有趣
然后能够已经能够创造出很想象力的东西
其实这个正要回应一下就是
幻觉这个问题
可能在一些场景里面的幻觉
可能是一个很重要的一个feature
那可灵的话就展现出了一个
能够比较好的
能够去想用用户的一些
提示的一些概念
比起把一些在时序上的一些
物理的规律和动作
能够很好的给呈现出来
那这个其实是一种基本
基础的能力
那如果作为一个产品来说的话
它上面还是要构建一些
其他的一些能力
使得它能够变成一个
真正能够去解决实际问题的一个产品
比如说
像我们的可灵模型
推出之后
我们开放给了很多用户来用
大家用之后觉得很兴奋
然后他们自然就会有些呼声
说你们什么时候上图像生成视频
这个对我们说很有用
其实这就是一种
对它来说的内容可控性的一种能力
对吧
然后后面我们就把这个给上了
后面又说这个视频能不能再长一点
然后我们就把视频的续写能力给上了
等等
就是从用户的话
他们针对他们各自的应用场景
他们就会提出各种各样的一些
需求
但总结来看有几点
一点是
肯定是说他们是希望
是能够对最终生成的内容
是有比较好的控制力的
那就是可控性这一部分
它涵盖了很多不同的方面
但是
本质上我们
视频的生产创作的工作流里面
还是蛮复杂的
里面有很多的东西是需要
做一些控制
使得它最终成品的东西
是符合人们的预期的
因为这里面还涉及到一个成本效率的问题
比如说如果没有很好的控制
那就抽卡
我就多次尝试
多次尝试之后
最后也许能找到一个好的
那这样的话
不论是对用户的使用成本来说是比较高的
那对我们公司来说
我们的推理的成本也是非常高的
但是显然并不是一个
从视频的生产创作来说
通过文本这种简单的方式
并不是一个最好的交互的形式
所以
在这上面构建出一个产品的话
我觉得这些能力是肯定要补齐的
另外的话就是视频
这个模态太通用了
它有很多的应用场景
它意味着说
它可能有不同的产品形态
但是它都可能share同一个基础模型的底座
就好比说
我们已经实现的
在快速里面
我带领团队做了一款数字人直播间
那这个直播间
其实就是一种AI驱动的一个视频流
其实一种特定的视频生成
在这种特定的视频生成里面
我们就可以控制好它的一些幻觉的问题
然后效果的问题
包括成本的问题
然后让它能够变成一个
能够持续ROI很高的一款产品
那这样的话就是
在产业落地的时候
针对特定场景
可以做一些特定的一些约束和设计
但是可能底层的那个模型能力
还是需要具备的
如果不具备的话
那创作出来的内容的多样性
创意 质量 成本
都可能是一个比较大的问题
谢谢
刚才您也提到了
这个可灵它的这个底层能力
对于它最终的产品化
还是一个非常重要的
基础层面的支撑
这里面的话呢
有一个可能
更加这个sensitive一点的问题
因为现在的话呢
这个OpenAI有这个Sora
在相当一段时间里面
大家会认为它是视频生成的
一个标杆性的工作
然后可灵的话呢
也让大家看到了
我们中国的这个视频生成
模型的一种新的希望
那么在你看来
这个可灵
as compared to Sora
它现在是一个什么样的position
是已经全面超越了呢
还是说在某些维度
或某些方面
其实还是存在差距
你怎么评论这个事情
首先Sora它
它没有放出任何可以体验的东西
所以很难评价
但是如果让我来猜测的话
我觉得Sora肯定还是做得非常好的
但这里面有一些问题
就是是未知的
就比如说Sora的模型
它的背后的实际使用的推理成本
是多高的
以及说有一些跟Sora合作的
一些创作者
然后写了一些博客
大概提到了一些点
一些数字
比如说他们做了一个短片
用到了一个片段
是从是用Sora做的
最终使用的那个片段
其实是一个300B的ChariPick
选出来的
如果是300B的ChariPick的话
其实这个成功率是有比较大的问题的
不管是从任何层面来讲
可灵的话
我觉得它有一些优势
我肯定不能说是跟Sora比
全面超越
首先Sora也没发体验
所以这个话也不能
很难去判断
但是可灵它有它的优势
比如说它的成功率相对来说
还是
as compared to其他的一些产品的话
还是比较高的
另外的话
它能够呈现出
一些比较复杂的一些交互
可灵一个比较出现的case
就是一个男人在吃面条
那个case的话
就很多外国人也过来找到我们说
怎么做到的
amazing等等
我觉得对于可灵来说
它最大的一个差异化的点
是我们把这个东西
推到了用户那
对吧
至于好还是不好
在我看来
用户说好
那它叫好
不能说某个人说好
或者是
然后站在某一个观点上说好
至少目前来看
我们开放了非常多的用户
大家普遍的反馈
还是比较正向的
然后我们的这样一个
让用户去体验
其实也收获了很多
用户的一些意见建议
包括他们的一些
对我们的一些期待
所以这样的话
有助于我们
让这个模型越做越好
可灵现在这个阶段的模型
在我看来
还是一个很初步的一个模型
那我们是非常有信心的
去继续去迭代
让它变得更好的
然后我们也看到了一个
很好的一个
变化的一个趋势
然后事实上我们
周六
也就是后天
我们快手有一个专场的一个论坛
到那个时候
我们也会发布
我们可灵的新的版本
也希望大家多多关注
首先的话
非常期待
这个里面周六新的这个发布
而且的话
我也是觉得非常欣喜看到
就是可灵的团队
非常高度的关注
用户使用的这个体验
真正希望能够把他的用户价值
给发挥出来
那么我们回到一个
一个技术的问题
就是现在的话
做这个生成
其实从2014年到现在
是有几波不同的技术路线
包括稍微早期一点的时候的
这个GAN
生成对抗网络
到后面的这个Diffusion Model
以及SOVA出来之后的Diffusion Transformer
逐渐的话
因为一个个的一次次的
让人在amazing的一些结果
让大家看到了一种新的这个技术路线
它的这个可能性
那么我们在线上的话
张涵其实也是在这个领域
有非常资深的这个研究经历了
他早期有一个
其实是有非常大影响的工作
叫做StackGAN
应该说在当时
是这个生成对抗网络
它的一个水平的一个
在当时的一个高峰
那么之后的话
张涵也一直还是相当长的时间
直到今天都在从事相关的这个研究
所以的话也想这个
听一听张涵的这个comment
就是你看来这个未来的生成式模型
它的技术路线
会是怎么样的走向
以及说有没有可能有一些
更加新的技术路线
它能够克服当前技术路线
面临的一些挑战
好 谢谢林老师的问题
对 从2014年到现在
我们也经过了几波技术的改变
从GAN然后到
包括我们之前还做过用Maskit
Transformer
Auto-Regression Model
然后再到今天的Diffusion
我的感觉是
确实这个技术一点一点的提高
我们生成的Image的Resolution
一点一点的扩大
从Modality
也是从原来最开始的Image
Hex到今天的视频音频
我觉得这个现在的Diffusion
还有各种各样的问题
比如说它的用的时间非常非常长
相对来说比如说比GAN的Model
现在也有一些新的
比如说GAN加Diffusion融合的结果
将Diffusion作为Distilled
变成一步或者是更快的一种方式
我觉得Diffusion绝对不是一个
end的一个Model
这个形态
未来来说肯定是有
比如说即使在今天来说
我也不认为Diffusion一定会比
Auto-Regressive的Model要在
视频或音频生成的结果上要好
我们其实在Google有很多的工作
已经证明了
其实在用Auto-Regressive Model
生成的视频结果是
基本上是可以
与Diffusion Model的结果相似的
而Auto-Regressive Model又和大语言模型
更好的结合
所以说其实整个Model Family的
一直是在进步的
所以也有一点我想
也想说一下
就是说因为我们现在
可能过分的注重Skilling Law
很多的Resource
包括Compute
包括人力
都会往往的去叠加在
我们尽量去Scale
这个Model的大小
往往导致说我们基层的研究人员
往往没有足够多的计算资源
来研究新的Model Family
这其实也是一个损失
所以来说
其实我呼吁和希望
就是我们
比如说在学校里的同学们
或者是更Junior的Researcher们
其实用更有限的资源
其实可以去更Explore
更广泛的一些想法
而不是仅仅的就用
今天最State of the Art的结果
比如说就是在Diffusion上Fighting
或者是在大模型上Fighting
非常感谢张海的分析
他其实最后提到的一个点的话
我也是深有感触
这边也是补充
再Echo一下
当前为什么
刚才他也再一次提到的
这个Scaling Law的这个事情
除了在技术层面的
一些它可能存在的Problem
和Limitation之外的话
在创新层面
这种Scale的信仰
它可能也会产生一些Side effect
就是说大家会沿着这条道路
沿着成熟的技术路线
不断地投入
越来越大的资源
而这种投入的话
它有可能会反过来挤压
真正可以是探索新的技术路线
创新的空间
而且新的技术路线
因为它Scale一开始不够大
它可能效果上不一定比得过
传统路线
也许它Potential更高
但是它效果上未必
在一开始能比得过这种
传统的技术路线
把Scale做到很高的这个程度
那怎么样去Blit这样的一个问题
那这样一个Trap
其实也是非常值得我们
共同去思考的
在Echo一下这个事情
那么除了这一个
刚才其实在
最初洪洋提的时候
也提到了一个
就是包括超超提到的
这个巨生智能
其实现在的话
这个事情也逐渐成为了
学界和业界共同关心的
一个问题
就是让我们的这些大模型
或者其他的AI模型
和一个真正能够去行动的
一个实体结合在一起
它究竟能够给我们带来
什么样的新的可能性呢
首先关于这个事情的话
这个柏磊是
我之前在中文大学的同事
柏磊其实之前也做了一段时间
生成了模型
但在中文大学那会
就开始在做这个
跟自动驾驶相关的
有一些这个
就是实际能动的东西
跟智能的一个结合
这里面做了一些
挺有创新性的一些工作
那么这个柏磊
好多年没见了
再来回头catch up一下
那么在你看来
现在的这个
在大模型的这波
这个机遇里面
然后在巨生智能
它会带来什么样新的改变
以及说大模型
跟巨生智能的
这个结合的过程中
它会带来什么样的
这种新的挑战和机遇
谢谢林老师的介绍
还有一个问题
我跟林老师是
之前港中大的同事
然后三年前
然后我们误到UCV
然后这次是三年过后
第一次回大陆
然后之前我们
在港中大的时候
三年前我们就在研究
生存模型
但是基于这个干模型
然后研究它里面的
这些可解释性
然后分析它里面的
这些学到的知识
然后怎么利用这些知识
来做到一个可控的图片生成
然后这两三年
这个大模型
生成式大模型的出现
Diffusion
也是很好的
从数据里面学到这个分布
它也赋予了这个巨生智能
这些机器人
很多可以新的一些能力
比如说我们实验室
有对利用大模型
来生成这个训练场景
因为在巨生智能里面
很重要一个问题就是
它训练的这个环境
一般是比较单一的
比较单调的
这样模型其实非常容易
overfit这个环境
那么其实我们可以利用
这个生成式模型
来引导生成一个新的环境
比如说生成一个
像梵高样式的书房
然后生成一个着火的书房
然后这样让巨生智能
这个智能体
然后在这种新的环境里面
去进行训练
另外我觉得大模型
还有一个非常好的一个点
就是它可以取代人的一个位置
它可以之前是巨生智能里面
一个应用是说
从人的行为里面
然后指导来学习一些新的技能
那么其实我们这里
大模型因为已经取得了
跟人类似的这种推理能力
那么其实我们可以
把这个大模型
来引导这个学习
这里一个例子就是自动驾驶
现在90%的自动驾驶研究
都是在处理这种肠胃问题
就是在现实生活中
很难遇到的这些情况
那么其实是如果我们有更好的
更高阶的一个推理能力
那么利用这个大模型
那么其实它就更容易
解决这个肠胃问题
所以我是对巨生智能
和大模型的这个结合
是觉得是一个非常
permitting的一个方向
未来的一个方向
然后有很多新的研究
然后可以探索
谢谢伯磊
我们在座的话
许华哲老师也是在
这个巨生智能有非常丰富的
这个研究经验
他像verbal craft等等
都是一系列很有影响的工作
华珍你觉得这个
现在大模型的时代
那么在这个新时代
巨生智能它进一步的发展
它有哪些可以大家值得去看的方向
以及说它挑战在哪里
好的
谢谢林老师的问题
因为我自己是做巨生智能的
所以跟大模型的结合
我觉得主要看两个点
一个是我们能不能
迅自己的巨生大模型
就是这个模型本身
就用来做决策
用来跟这个世界交互
第二个就是
如果巨生大模型
还没有到来
那我能不能用现有的多摩泰大模型
用在巨生的任务上面
那第一个点呢
我们最近做了一些小的
这个科学实验
还挺有意思的
发现比如说现在很主流的
这个transformer
它这个大家都知道
GPT等等这些大模型
都是以transformer为基础的
我们让它做这样一个很简单的事情
大家可以跟我一起想
这个流程
我在地上画一个长条的格子
然后这个机器人
沿着这个格子往前走
每个格子里呢
要么有一块钱
要么有一块钱
要么有零块钱
然后这个机器人走在那个格子里
就会把这个钱吸进来
走到它这个格子的末尾的时候
我问他
你收到的钱是奇数还是偶数
就这样一个很简单的一个问题
后来我们发现transformer
需要非常非常多的数据
才能回答这个问题
而我们用这个炒冷饭
对吧
我们用这个旧的东西
叫RNN
对吧
大家可能是不是年轻的朋友们已经
更年轻的朋友们已经不玩这个东西了
但是呢
但是比如我们要用RNN
发现它很容易就能学到
这个基数
我说原因是什么
原因是像RNN
这样的这个recurrent
这个的东西
它里面会维护一个hidden state
然后这东西就像一个状态机一样
它知道
我吃了一块钱
就会跳到一个状态
然后再吃到一块钱
我就会跳回来
对吧
这就是机偶性嘛
但是transformer
因为它是self attention
它要关注到
它其实是要记住各种各样的pattern
然后当数据量足够大的时候
它也可以完成的很好
但是我们做这个时候
我们就在想
是不是在机器人里面
我们需要新的架构
是不是需要新的这个
比transformer更好的东西
它说不定不是新的
而是把旧的东西
跟新的东西结合
比如说我们试了
各种各样架构里面
linear RNN
是在这样的
这种POMDP问题里面
是最好的
然后另一个我们
这个在跟这个大模型交互过程中
还发现
它有这个比如说过拟核问题
我们做一个人机交互的
这样的一个事情
然后我们
然后里面有一个很经典的问题
大家应该也都知道
就是一斤棉花跟一斤铁到底谁中
然后大模型会说
最开始它肯定会搞错
它会说一斤铁中
但是然后你给它更多数据去训它以后
然后它发现
好像这个答案每次都是一样中
我们下次问它
一斤棉花和499克铁谁中
然后它说一样中
它在推理能力上面就不太好
我们把这样的模型用在决策上面
肯定是要犯这个大错误的对吧
所以我们也在找这个里面
怎么样能改进这样的模型
包括大家应该如果做计算机的话
应该了解这个旅行商问题等等
这些MPH的这个问题
我们也都尝试去让大模型
来去做这个规划
然后让机器人来执行
但是我们发现大模型
在这样问题上也没有惊人的这个发现
比如说我们并没有办法
靠大模型来解决这个问题
对吧
靠大模型来解决这些解决不了的问题
对这是这是训大模型的部分
那用大模型的部分呢
跟周老师刚刚提到的很相似
我们用大模型去生成这个环境
比如我们在做这个real to seem to real
对吧
就我这儿有个场地
我拍点照片
或者我用一个模型
把它生成出它的这个3D的这个asset
然后导入到仿真里面
在里面训机器人
再把机器人deploy到这个场地
发现它直接都能work对吧
或者是我们让大模型给它写它的
这个强化学习里面的奖励函数
去写这个
我们还会让它写更复杂的
比如说一些轨迹
直接让大模型输出这个人手的轨迹
然后在这个轨迹之上
再叠加一个强化学习
去做更精细的手的操作等等
这些结合的还是蛮好的
但是我想这部分
主要是靠的大模型现有能力
未来它能不能更直接的去输出
直接输出到action level对吧
就底层的这个动作层次
我觉得可能也是
我们应该想看到的东西
好 谢谢华哲
那么刚才几位嘉宾的发言里面的话
我们其实看到了两个
非常值得我们未来去探索
和思考的机会
一个是在应用层面
包括刚才万老师讲到的
视频生成在应用中的落地
也包括居身制冷等等
都看到了新的生成式AI
以及跟一系列的其他技术的结合
它带来了我们应用无限的可能性
同时的话
现有的这个技术
尤其是基于transformer
还有autoregressive learning的这种scale
它其实也潜在的
存在了很多的问题
现在越来越突出的显现出来
那么这些问题的解决
也是非常有利于未来的
在底层的算法
和原理上面的创新
才能够找到我们
可能通向AGI的更好的道路
那么最后的话
我们有五分钟的时间
我们给每一位都是一道问题
同一个问题
就是说
现在其实还是一个非常呼唤
创新和探索的时代
在你们内心深处认为
就只选一个
最值得探索的
或你最想去探索的
创新的方向是什么
每位可以选一个
讲一个
要不从叉叉开始
好 谢谢林老师的问题
其实可能不是最想
就是我们正在探索的
就是如何让多模态大模型
能够具有因果推理能力
因为这是一个
非常基础的目标
因为一旦一个多模态大模型
它具有了因果推理的能力
它可以作为一个世界模型去使用
也可以作为一个巨声智能体去使用
甚至还可以让
因为它有因果推理能力
它就具有反思能力
所以它就可以作为一个
具有自我意识的智能体
所以它是一个非常基础的
也是非常重要的目标
这是我的想法
好的
我个人会觉得
未来如果一个
特别吸引我的一个点是说
如果比如说
我现在做的赤贫生成
它的能力足够强的话
可以输入各种各样的指令
然后它并且能够生成出一些
非常合理的一些场景
那它真的是可以作为一个
所谓的world simulator
在视觉层面的
并且这样一个world simulator的话
它不单是可以用来比如说
创造一些好看好玩的事情
它甚至也可以比如说解决
我们巨声智能里面环境的一个
仿真的一个问题
不但是提供一些视觉信号
也许还可以提供一些
3D的一些维度
然后触觉然后等等
然后是一个完整的
可以让一个巨声的智能体
在里面去演进的
这么一个simulator
然后它能够发挥的作用
实际是可以远超
我们当前的这个视频的产业
当然当前的视频产业
已经是非常之大了
所以如果这条技术路线
往下去演进的话
我一方面是能够期待
看到整个内容的创作表达的成本
被迅速的拉低
然后大家能够有一个非常繁荣的
一个内容生态
另一方面的话
也是希望它的这种很强的
这种仿真的能力
能够连带着去帮助
其他一些科学的问题
然后得到公开的解决
我这儿的话
我觉得智能是
就无论是做巨声智能
还是做大模型
我觉得智能是本质嘛
所以我觉得最重要的
还是架构的迭代
或者创新
有没有超越transformer的东西
因为现在的智能
大家都说压缩及智慧嘛
这个我某种程度上是认同的
但是我的压缩能力
到底是怎么样的
大模型可能要看到
百万千万一条的数据
才能压缩出那件事
而牛顿只需要一个苹果砸到他的头
他就已经领悟了那件事情
领悟了重力
那么怎么样用更少的数据
然后让他理解这些东西的
共同的原理
我觉得这个是智能的发展的
一个很重要的点
所以transformer大家已经看到了
它只要有海量数据
它能找到那个点
那我们有没有更好的架构
让它没有海量数据
或者是同样的数据量
它更聪明
然后同样的聪明程度
它用的数据更少
我觉得这个是我关心的
我这里对大模型的期望
希望大模型可以帮助我们创新
因为我们在这样大量的数据
以及多模态的数据上面训练
它其实这个模型内部肯定学到了很多有意思的知识
然后这些知识可能跟人已知的知识
有一部分是没有这个偶合的
这样模型其实是可以学到很多创新的一些联系
如果我们这样可以去挖掘出这些知识
那其实我们是可以扩展我们自己人类的知识库
这样可以更好的帮助我们创新
以及解决一些没有解决的问题
比如说治疗癌症
然后解决气候变暖这些问题
我这里的话
因为我们这个workshop的主题是可信AI
所以说我自己可能更会关注AI安全一块
刚刚当松老师也提了很多responsible AI的一些方面
安全这一块
翻译成英文其实有两个单词
一个是security一个是safety
其实这两个完全不一样的
safety是说模型自身它不会输出一些有害的
对人类有害的一些内容
那么security是说
我们不能有黑客或者一些攻击者能够把模型攻击成功
以及我们要保护这样一个数据的隐私
保护这个模型在足够安全的情况下
尤其是在比如说自动驾驶这些安全很重要的一些领域上面的一些应用
所以说我自己可能更关注这两方面
包括safety和security以及privacy
会使用一些密码学的工具
或者一些watermark等的工具
来研究这样一个比较新兴的一个领域
请先上张涵
因为我做的是图像和视频的生成
我更关注于怎么能把人的表达
能转化成一个更实际的东西
然后比如说能创立一个新的媒介
让人能把自己想象的东西变成现实
能拉近人与人之间的距离
更多的是一个大模型通过
它有一个思考的能力
然后让大家去表达的形式有更多的形式
让一个整个从人文的角度让大家更加的close
我们非常感谢今天的panel member给我们分享了很多很有见地的思考
那么今天我们的这个panel的话
因为时间关系就到这里
我们首先邀请这边panel member一起合影