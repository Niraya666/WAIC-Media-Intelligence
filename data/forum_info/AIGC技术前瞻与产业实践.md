# AIGC技术前瞻与产业实践

**地点:** 世博中心617会议室  
**封面图:** ![封面图](https://static.worldaic.com.cn/IMAGE2024/2024-06-06/a3e16f6bf5bb47d2bd13eb684a0a6893.png)

近年来，AIGC技术在多个领域取得了显著成果。京东云作为京东集团的技术与服务核心平台，专注于京东自有的零售、物流、健康、协同办公等核心场景，打造了一系列成熟的大模型与AIGC技术实践应用。这些应用包括数字人直播间、支持零售品牌商运营提效的大模型工具、AIGC驱动的远程医疗和慢病管理模式创新，以及协同办公场景的大模型应用等。京东云持续利用技术降低供应链成本、提升供应链效率、优化用户体验，为用户和企业创造更多价值。

### 会议日程

| 时间     | 演讲主题                             |
| -------- | ------------------------------------ |
| 09:00-09:20 | 边缘大模型赋能智联网的应用探索与实践 |
| 09:20-09:40 | 生成式人工智能与决策优化             |
| 09:40-10:00 | AIGC基础模型发展与产业创新           |
| 10:00-10:20 | 大模型、AI能力赋能北京市政务协同平台  |
| 10:20-10:40 | 人工智能助力城市数字化转型          |
| 10:40-11:00 | 京东大模型发展及场景应用最佳实践     |
| 11:00-11:20 | 医疗产业大模型的技术实践和应用       |
| 11:20-12:00 | 圆桌派:大模型时代，AIGC的创新与零售场景应用 |

### 嘉宾介绍

- **曹建农** - 香港理工大学，欧洲人文和自然科学院院士，香港理工大学研究生院院长
- **王梦迪** - 普林斯顿大学教授，普林斯顿人工智能创新中心主任
- **何晓冬** - 京东探索研究院院长兼京东科技人工智能业务负责人，IEEE Fellow
- **龚义成** - 京东云副总裁，京东云laaS产品研发部负责人
- **王国鑫** - 京东健康智能算法部负责人
- **徐薇娜** - 上海家化总经理
- **范文竹** - 伊利数字化转型部负责人
- **周 威** - 同仁堂电商副总裁
- **王爱飞** - 京东科技智能服务业务部创新产品负责人


### 大模型时代的控制与智能 -- 王梦迪

那说到生成是人工智能作为人工智能领域的一颗璀璨星星，它能够模拟人类的创作过程，生成前所未有的文本、图像、音频甚至是视频内容，并且在数据分析、模式识别、创意生成等多个维度展现出惊人的能力。技术的蓬勃发展也会让很多人感到忧虑：大模型是否可控？生成式AI是否可控呢？

接下来的时间就让我们用热烈的掌声有请普林斯顿大学教授、普林斯顿人工智能创新中心主任王梦迪女士来为我们揭秘探讨大模型时代控制与智能。掌声有请。

大家早上好，非常非常荣幸今天应何晓东和院士的邀请来分享我们在学术界从大模型角度做的一些学术前沿的研究。在大模型时代呢，今天我想讨论的问题是如何让大模型可控。今天正好我第一个讲，所以可能我们稍微回顾一下历史。首先就是什么是人工智能或者什么是智能？这个概念其实是在上个世纪40年代、50年代有非常多的这方面的讨论。一个公认的智能的一种定义是首先所有的机器和生物都是智能系统，都是控制系统。那么什么叫智能呢？只要我有一个系统，然后有一些不管是生物、是机械、是电子还是什么样的方式能够去了解到这个机器的状态，并且反馈给这个机器或者说这个生物体让它维持在一定的状态轨迹上，或者简单可以是简单如钟表，或者像动物像人类这些都是智能系统。本质上智能是控制系统，然后这个概念最早是来自于1948年出版的控制论，然后这个诺贝尔·维纳他是一个美国的数学家，他也被公认为是控制论之父。然而当我们讨论控制系统的时候，其实越精密的仪器比如钟表或者等等其他的这些机械仪器当它们越精密的时候，它们的智能其实越狭窄。

当我们现在讨论人工智能的时候，控制已经不是传统意义上的我可以在任何一个复杂的系统或者复杂的环境里面通过大规模的神经网络去学习环境的信息，去学习环境的世界模型，并且不断地迭代对于环境的价值函数和在环境里面执行的动态决策，那么这就是强化学习。然后关于强化学习，我觉得第一次让全世界人都知道强化学习是什么，应该是2014年的AlphaGo，这是一个双智能体对抗的强化学习。然后呢在今天，强化学习已经到处都是了，比如我们如果去玩一个游戏，去玩王者荣耀，那么我们对战的AI就是一个强化学习的算法。这个强化学习算法它们也可以互相对战，可能如果它们训练得好的话，可能比人类还要厉害。然后机器人、巨声智能和自动驾驶，这也是我们已经几乎在生活中快要接触到的强化学习。

然后另外一个我觉得很有意思的是可控和巨变。如果我们看2022年人工智能技术最大的突破，我想基本上每个人都会认为是2022年底的ChatGPT。但是很有可能ChatGPT不是那一年最大的突破。这是2022年DeepMind在Nature发表的一篇论文，它用强化学习能够非常精确地把核聚变reactor里面的等粒子场控制在一个非常高的精度。而核聚变的控制这被公认为是自动控制能源最难的问题，因为它本质是一个混沌的chaotic system。然后当核聚变的控制问题能解决的话，它说明我们离清洁可控的核能源非常非常接近了。对，然后所有的这些都是强化学习。

但我们今天要讨论的是大模型。那么大模型，或者我们先来说大语言模型。大模型首先它可控嘛？然后这里我想跟大家推荐一本神书，这是Kevin Kelly在1994年整整30年前出版的一本书叫《失控》。这本书其实是从控制论开始介绍起，并且这本30年前的书现在其实是不管是互联网的从业者还是人工智能学家，很多人都读过这本书，并且从它里得到启发。这本书在30年前就预测了大规模神经网络，并且它预测了当有很多很多简单的这些元件组合在一起的时候，会有超出这个底层元件不能理解的智能在高等级涌现。所以涌现(emergence)这个词最早来自于30年前的这本书。这本书预测了就是后来的科技发展，包括神经网络，包括涌现等等。但这本书最后留了一个开放式的结局，它说当这种涌现的智能超越了人类所能控制的范围那时候该怎么办？所以这本书预测的这个结局在现在30年以后已经是我们现在的处境了。2023年OpenAI发布了Intelligence Intelligence，那么这也就是失控这本书预测的未来的结局。那么在这个时间点如何能够保证这样一个AI系统，比人类聪明的AI系统还能够为人们所用，还能够被套上缰绳，这其实就是这本书没有预测到的。这也是现在大模型领域最重要的研究问题。那么这个问题就是现在被称为super alignment。alignment意思是对齐，如何让人工智能，让大模型和人类想要的功能、人类想要的偏好来对齐。那么如何对齐，然后现在最前沿的方法，当然它远远不是最好的方法，现在最前沿的对齐方法是通过人类的反馈去进一步的微调来对齐一个已经预训练好的大模型。然后对齐的方式是强化学习。它大概分成几步。基本上我有一个预训练好的大模型之后，我们后面会做这个supervised fine tuning，就是进一步用人提供的数据来进行用用户的数据fine tuning。然后呢，我们需要收集真实用户的这个反馈数据。这个反馈数据可以是一个点赞，或者可以是一个踩，或者这个反馈数据可以是就是我给他几段不同的这个生成的图片或者是语言，让用户选择他更喜欢哪个。就是这样非常非常简单的在互联网逻辑中。并且在这个基础上，最后一步是用强化学习算法来微调大模型，把大模型的生成过程理解成是一个动态的策略，并且在这上面进行微调来更好的向人类的喜好对齐。所以这是一个基本的技术思路。然后这个算法有非常非常多的变体。

那么说到这种对齐的强化学习算法，强化学习算法虽然有很多年的研究，但是还有非常多的不足。就举一个例子，我们先不说大型模型，我们就说机器人或者说这种巨深的这种控制问题，如果我只是单纯地收集人类数据，用普通的方法去训练一个奖励函数，然后直接用强化学习的话，其实这里面会有好多的地方容易出错。一个最常见出错的地方在于我收集的数据并不能真正覆盖我们想要的那个最优策略它对应的概率分布，所以这里面会造成一个out of distribution的shift。然后这件事情我们在一个机器人的一些场景里面去做了这个测试，用最好的对齐强化学习算法会发现这里有一个很大的一个能达到的实际的奖励和真正的理论最优有一个非常大的gap。然后为了解决这个问题呢，我们之前有一系列工作，然后最近的是去年的一个工作。我们的解决方案是要做一个嵌套式的双层强化学习。我不光想对齐最优策略，我还想对齐数据的分布。当我同时做这两件事的时候，一个接约性的提高。所以这个是对齐强化学习在机器人。然后进一步在大语言模型，大语言模型的强化学习和机器人的强化学习有很多不同的地方，有很多就是跟大模型跟Transformer model本身一些具体的技术问题要解决。然后这里有很多不同场景。然后我自己的研究组，我们最近在这里面希望能够做出很多不同的工作吧。然后比如从对齐角度一个问题就是说我有一个大语言模型，我可能要在不同的场景对不同的用户的对不同的user group要进行对齐。如果我对每一个user group都重新微调这个大模型的话，那么我就需要微调很多个模型。但我们其实想要的是最好是一个模型，它能够同时去解决不同的目标。但是从强化学习角来讲这里面有很多技术上的难点。所以我们专门设计了一个针对多目标对齐，尤其是少数的用户不会被大部分用户就是少部分用户的一些小众的喜好不会被大部分用户直接淹没掉，而是能够让强化学习算法同时顾及到不同人的不同的喜好和不同场景的不同目标函数。然后就是在不同的一些数据的，在不同对应的数据场景里面，比如这个对齐算法可以有很多很多变化。比如说如果我们不是仅仅做一个单智能体的强化学习，我们可以引入一个adversarial critic来做这种对抗式的学习。这样也可以提高对齐的效率。然后同时我们最近还刚发布了一个在线实时收集数据的在线强化学习对齐算法。然后这里有些图吧，应该比最好的这个迭代式的DPO效果也能提高是30%到70%之间。然后这是对齐。然后强化学习在大语言模型除了对齐，其实还有其他其他的有很多可以其他的用法。比如一个用法叫Speculative Decoding。这个概念是2023年的Google Demand提出的，这个用法是我不是为了对齐人类了，我是为了能够加速大模型的推理。因为大模型我每推理一次我基本上是要在整个的模型上做一个forward pass，它是很贵的。一个可能的解决方案是我们可以把一个大模型和一个小模型组合起来，或者说一个大模型很多小模型组合起来。那么当我想生成任务的时候，我这个推理我让小模型先做，然后大模型只要监督就好了。如果小模型做的不对，大模型就打过去说你重做。就像是你要学生干活，然后老师带着这个学生，然后这样可以节省这个老师的时间。那么这件事情呢，那么怎么样去协调大模型和小模型什么时候小模型让大模型去监督，希望这个整体的suitable的更好。这个是叫special decoding。然后我们刚刚发布的一个用强化学习来协调大模型和小模型之间的这个生成和间度的这个双向循环。然后我们可以把推理速度提高超过两倍多，对去解决更复杂的推理，甚至是coding，甚至是数学定理证明等等等等的问题。就是希望能够找到复杂场景那个真正的最优策略，它对应的奖励函数叫Q star。Q star这个词最早也是open AI人讨论了然后漏出来的一个词，所以大家现在就用Q-Star来指代这个理想中的有推理能力的最强大模型。我们最近一个工作是说如果我从一个已经对齐或已经优化好的模型出发，我们其实可以在这个de-coding的层面再去训练一个轻量级的强化学习的Head。然后在这个基础上我们可以把一个原来已经对齐的模型对齐到一个新的更复杂的一个奖励函数，去寻找一个新任务的这个所谓的Q-Star。对，所以我们这里说的是大模型大语言模型的可控。当我们说控制的时候我们可以理解成我已经有了一个非常强大的一个预训练模型。你想象就是我们来了一个外星人，他非常非常的聪明，但是我们需要让他学会怎么按照我们人类想要的方式来做事情，解决我们想解决的问题。在不同场景，不同的离线再线一些各种各样不同的情况下怎么做这件事情。这些都是怎么样控制大语言模型的生成。

那接下来换一个话题，接下来就讨论另外一个模型。刚才是大语言模型，现在我们讨论生成式AI。我们一般说生成式AI的时候叫做扩散算法或者扩散模型。那么这个模型一般认为是和语言模型并驾齐驱的两个最重要的大模型。它们可能结合在一起是能解决最多的，是能够最大程度上推进人工智能的发展。那么这种生成式AI是否是可控的？然后先简单介绍一下这种生成生成式AI它的一个非常非常短的历史。这个概念其实来自于2013年。然后VE这个模型是用来把高维的数据压缩在低维，然后再重新展开。那么作为这种压缩模型的一个副产品，然后人们很快发现说这个Decoder很有意思，因为我可以完全不要这个Encoder，我直接在Decoder上输入一个随机的一个高维的向量，然后这个Decoder也能生成一个像模像样的图片。这是最早它作为一个副产品。然后另外一个当时曾经火过很长一段时间的模型叫做这个GANS对抗是Generative Adversarial Networks。然后对抗是这个GANS最早也是用来做预测做Classification。但是同样它因为有一个对抗的结构在里面，所以它带了一个这个Generator，一个生成器。然后同样就是这个生成器发现比Classification更有意思。我发现我们可以生成一些现实中没有但虚虚如样。所以现在我们说生成式AI的时候基本上是一系列算法能够从噪声变成数据，然后可以做视频、可以做音频、可以做文字、可以做很多很多其他应用等等。所以这些叫生成式AI。

所以说我们虽然可以想象,即使我们可以去训练一个非常大的、非常非常大的神经网络，直接从噪音变成数据，但你可以想象因为这是一个很复杂，并且它的landscape很崎岖的一个转化过程，这个训练就几乎变成了不可能完成的。那么扩散模型是完全不一样的。扩散模型以及代表的新式的生成式AI完全改变了人工智能学者对生成的定义。扩散式模型天然就是一个控制过程。我们是需要找到一个控制的可控的状态轨迹，从初始的噪音最终生成一个图片。这个天然就是控制过程。那么这时候我们的神经网络并不是说我要训练一个大神经网络从零直接到最后，这是一个unet，而是说我要训练一个神经网络它可以调控这个一步一步的从零一直到data的这样一个过程。所以我们现在学习的是一个控制过程它的drift function。所以换句话说生成式AI天然就是一个控制问题，并且我们可以在这样一个基础上让它更加的可控。

对，然后多说两句扩散模型Diffusion Model。因为我自己是偏数学出身，这个基本上是所有技术学习模型里面数学上最优美的一个，因为它本质上就来自于我要对一个随机微分方程求逆。因为从噪音生成数据是一个很难的问题，但是从数据生成噪音是个特别简单的。所以它的方法是我先找到一个非常非常简单的从数据变成纯白噪音的一个过程，然后用它的这个数学原理去找到它的逆过程，然后用训练的方式找到逆过程的这个draft function。然后我们组也一直在做一些理论工作，我们去年是基本上是证明了关于扩散模型的第一个统计理论，并且我们证明了为什么扩散模型即使它从一个非常高维的白噪声出发能够生成在一个隐藏的低维流形上面的数据。这也就解释了为什么我们可以从噪声生成图片、从生成视频等等。因为不管是图片还是视频，它们其实都是有一个内在低质的一个隐藏的流形结构。然后更进一步就是说我们可以让扩散模型更加的可控。如果是从一个数学优化和求解器的角度来想这件事情就是说任何一个优化问题，往往我们在想一个优化或者说是一个设计问题的时候，我们可能是有一个目标函数，然后这个目标函数有一个landscape，然后我们要找一个算法，可能是这个模拟退火，可能是梯度，可能是蒙特卡罗。我们想说的是我能不能直接生成一个优化问题的最优解。这件事情是可能的。我们设计了一套通用的解决方案，你可以给我任何一个已经训练好的扩散模型，它已经是一个可控的过程。我们可以在上面加一个额外的控制量，它是某一种基于T2的规定guidance。它可以同时保证我可以优化任何一个新的目标函数，还能够保证我不会损失掉我已经学过的这个数据本身的低维流形结构。也就是说我们可以利用扩散模型的泛化能力去从数据里面找到我们想生成的目标的内在的几何结构，并且用非常轻量级的方法把任何一个扩散模型，它生成我们想生成的新的问题的解。

那么这件事有什么用呢？除了生成视频和美图，除了手机上我们能看到我们经常接触的应用，生成式AI其实是可以生成很多很多非常重要的我们想象不到的生物学上的设计、工程上的设计等等。比如我们普林斯顿我们刚刚成立的这个AI创新中心，我们在积极地用扩散模型想去生成电路图的设计，然后想去生成芯片的设计。Demand Paper，然后因为晶体结构是需要有对称性，需要满足很多拓扑上的逻辑的，它们这些晶体结构都是可合成的。然后这篇论文还估计如果他们没有用这种生成式模型而是用传统的方式去找的话，可能人类科学家需要800年才能把这些所有的晶体结构都找到。不是一个人类科学家，是所有的人类科学家。

然后另外一个生成式AI应用是我们组今年年初在Nature Machine Technology上发表的。我们发表了一个基于语言模型的MRA的生成模型。那么为什么要生成MRA呢？首先我们收集了大量的这种MRA的数据，跨不同的物种，这样我的语言模型也能够学到这个MRA数据的内在逻辑。然后我们在生成的时候我想生成翻译效率更高的MRA。那么翻译效率为什么重要呢？就任何一个MRA疫苗，如果我们把它打一针打到身体里的时候，它必须要翻译成蛋白质才能有用。那么它多大程度上它是20%翻译成蛋白质还是90%翻译成蛋白质就直接决定了这个疫苗有没有用。所以我们找到我们的MRA语言模型生成的MRA，我们找了合作的实验室进行了一个闭环的验证。比现在临床上用的最好的MRA疫苗还要效率提高了30%多。

然后另外一个特别有趣的事情就是我们在讲强化学习，强化学习本身可以用来微调扩散模型，但是用扩散模型equation，而是直接从数据里面去找到一个机器人系统它内在的几何结构，然后生成一个比数据里面更好的一个新的控制机器人的策略。这种叫diffusion policy。diffusion policy应该已经是所有的机器人领域、巨神智能领域都在用的一个技术。对，所以最后总结一下，不管是扩散模型还是大语言模型，如何让它可控，一是让它安全，二是让控制它满足我们具体的要求，解决特定的优化问题，我觉得这是大模型通向真正能让我们能用，通向AGI的一个必然的一个必经之路。



### 边缘大模型赋能智联网的应用探索与实践 --曹建农

近年来，随着人工智能和大模型技术的迅猛发展，边缘计算和大模型技术正在深度融合，引领智联网进入一个全新的发展阶段。这一变革为我们的工作和生活带来了前所未有的改变。接下来，我们请来欧洲人文和自然科学院院士、香港理工大学研究生院院长曹建农先生，为我们带来“边缘大模型赋能智联网的应用探索与实践”的主题分享。掌声有请，大家早上好！

谢谢大家，早上好！首先感谢京东论坛的邀请。今天我要讲的是大模型如何在边缘计算中实现更多的应用，例如人工智能和物联网在大数据深层边缘终端中的应用。王老师刚才提到，大模型在控制和生成方面有广泛应用。我们正处于一个大模型的时代，国内外的大模型研发和应用都在蓬勃发展，应用场景非常丰富。王老师已经提到了很多应用，但对我们个人和家庭而言，更需要的是工厂控制、家庭AI智能体对话和小朋友的辅导学习等应用。这需要人工智能和大模型技术在更接近我们的终端设备上进行研发。

目前，大模型的训练需要大量计算资源，通常在云端数据中心使用大量GPU进行训练。但这存在一些局限性。首先，并非所有企业和个人都能获取这些资源。其次，许多人不愿意将自己的数据上传到云端，因为大模型可能会收集这些数据，从而影响数据的适应性。此外，网络延迟问题在一些实时性要求高的应用中，如机器人控制、机床实时监测、导航和无人驾驶中，可能无法满足需求。因此，边缘计算成为一个热门话题。边缘计算将云端计算推向网络边缘，靠近用户和数据生成和使用的地方，从而克服一些限制。

例如，数据无需上传到云端或中心服务器，特别是工业互联网和物联网的传感器产生大量数据，通过网络上传占用带宽且有延迟。如果在网络边缘进行计算，可以避免大量延迟。此外，物联网涉及大量设备，如果都连接到云端，可扩展性会受影响。因此，近年来边缘计算成为热门研究领域。过去，边缘计算主要是指计算任务分解，边缘服务器等都是边缘计算节点。随着人工智能的兴起，边缘计算扩展到人工智能模型的训练和推理，变成边缘AI。边缘AI是指将复杂的人工智能模型在云端训练好后，部署到边缘设备进行推理，推理所需资源比训练少很多。

应用大模型时，大多数情况下利用实时产生的数据输入到大模型，通过推理得到所需结果。边缘AI近年来有许多研究和实际应用。大模型是一种特殊的人工智能模型，需要的资源远远超过一般人工智能模型。能否将大模型部署在边缘设备上，是一个研究课题。如果能将大模型部署到边缘设备上，物联网应用将获益良多，例如大模型的生成能力和理解能力比传统AI模型强很多。传统AI模型可能只能做决策或简单任务，但大模型具有泛化能力和复杂模式的理解和推理能力。

例如，过去的AI模型可以观察人的行为和健康，但需要专门开发模型。而大模型通过大量数据学习，具有强大的分析能力和泛化能力。如果能将大模型放在边缘设备上，将为物联网和家庭应用带来变革性的变化。那么，我们能否做到呢？由于边缘设备的计算资源有限，需要将大模型缩小。例如，手机上已经有一些大模型，通过模型压缩技术，如剪裁不需要的神经网络权重、知识蒸馏（从教师模型变成学生模型）和量化（将参数表示的精度从32位压缩到4位），使大模型尺寸减少。

有两种方法，一种是将大模型压缩后部署到边缘设备上，另一种是开发小模型，专门为特定任务通过大数据训练，参数可能只有几十亿。例如，Meta的LLaMA小模型有38亿参数，效果好过一般大模型，因为它是针对单个任务在终端设备上开发的。虽然可以开发更多这样的应用，但边缘设备的存储能力可能不够。

另一种方法是协作式边缘计算，多个边缘设备共享资源，共同完成大模型推理任务。去年在香港，我们与几间大学合作开发了一个系统，连接不同边缘设备，通过网络将资源抽象成可共享的资源池，将大模型分割成小任务，调度到不同边缘设备上进行推理。实践证明这种方法可行。

我们设计了一个协作式边缘计算大模型部署调度系统，叫EdgeShark（边缘鲨鱼）。这个系统能通过分割大模型任务到不同边缘设备进行推理，并保证数据隐私。系统可以根据不同边缘设备的资源配置，选择适合的模型版本，并实时动态调整资源配置，实现大模型的需求。EdgeShark平台上可以开发各种大模型应用，如个性化聊天机器人（Chatbot）。

个性化Chatbot可以通过对话分析用户情感和性格，并生成相应反馈。例如，学生在学校可能有情绪问题，Chatbot可以通过对话了解学生情感和性格，提供相应支持和建议。Chatbot可以部署在个人PC或手机上，数据不会泄露，隐私好，响应速度快，不需要网络连接。

我们在EdgeShark平台上开发了个性化Chatbot，它可以根据用户输入生成相应反馈，并进行实时情感和性格分析。这种Chatbot可以用于教育、健康等领域，通过个性化对话提供支持和建议。

未来，大模型在边缘设备上的应用前景广阔，但也面临很多挑战，如边缘设备计算资源受限，模型压缩和小模型开发需要大量人力和资源，持续学习也有难度。Retrieval Augmented Generation（RAG）是一种新方法，通过查询产生新答案，作为微调的一部分，解决大模型持续学习的问题。

协同式边缘计算和大模型推理还有很多优化空间，如将大量边缘设备连起来，共享资源，实现大规模协作式边缘计算。我们正在研究这些方向，通过EdgeShark平台实现大模型在边缘设备上的应用，带来更多变革性的变化。

### AIGC基础模型发展与产业创新 -- 何晓东博士

近年来，基础人工智能和大模型技术迅猛发展，AIJC能力如何更好地与产业结合成为研究重点。作为京东对外提供技术和服务的核心平台，京东云在多模态大模型和深度智能等领域有许多探索，并在内容生产和营销等领域实现了颠覆式创新。接下来，请大家欢迎京东探索研究院院长、京东科技人工智能业务负责人、IEEE Fellow何晓东博士为我们带来“AIGC基础模型发展与产业创新”的主题分享。掌声有请！

首先，我要特别感谢今天到场的各位嘉宾，也感谢刚才曹院士和王教授的精彩分享，他们介绍了最前沿的技术发展，包括大模型和边缘计算。今天，我想更多地谈一谈技术在产业中的应用。我们知道，产业和研究就像学科领域的两条腿，只有协同发展、互相促进，才能走得更远。

我们今天论坛的两个关键词是“大模型”和“AIGC”。这两个概念其实有一些区别。AIGC本质上是一个应用术语，主要指内容生产。早期的内容生产包括新闻、电影、短视频等，通常需要专业人士如导演、演员、记者来完成，质量高但成本也高。后来进入了UGC（用户生成内容）阶段，比如抖音上的视频由用户自己上传，内容丰富但质量参差不齐。所以，我们一直在思考如何利用人工智能来解决内容生产的效率和质量问题。尽管这个想法早就有了，但在大模型出现之前，人工智能生成的内容效果并不好。直到大模型出现，AIGC才开始流行起来。

AIGC最早因ChatGPT而为大家熟知。ChatGPT主要生成文字内容，但我们现在已经发展到可以生成语音、音频、图像和视频的阶段，甚至包括综合性的数字人，这些都提供了综合性的人际交互服务。

从技术角度看，AIGC和大模型的发展经历了漫长的历程。早在2013年，神经网络模型开始应用；2014、15年，提出了注意力机制（Attention机制），这是Transformer的核心理念。随后，Transformer引入了多头注意力机制，大大提高了计算效率。从BERT、GPT到ChatGPT，语言生成技术迅速发展，同时图像生成技术也不甘落后，如GAN和Diffusion技术的出现，推动了图像生成的发展。

京东在大模型领域也做出了重要贡献，许多论文在行业内被广泛引用，证明了我们的技术实力和创新能力。

在谈论产业时，技术转化为产业价值是关键。技术的核心和颠覆性应用共同定义了每个技术时代。比如，智能手机定义了移动时代。京东在基础技术和应用产品方面进行了广泛布局，从客服到营销再到数字人和AIGC，努力探索高价值的颠覆性产品和应用。

大模型技术虽然进展迅速，但在实际应用中仍有许多挑战。比如，大模型生成内容的幻觉率较高，在关键的商业应用中这是不能容忍的。因此，降低大模型的幻觉率是一个重要的研究课题。

京东的大模型被称为延熙大模型，旨在通过整合京东多年的业务数据，使其在零售、物流、金融、健康等领域拥有深厚的行业知识，真正满足产业需求。通过我们的K-Plug模型，我们大大提高了对特定行业专业知识的准确率，如客服中的实体属性抽取问题。

在多个场景中，京东已经大规模应用延熙大模型，包括文案营销、智能客服、数字人、商品图、智能诊疗、物流仓储等。我们还构建了延熙AI开发计算平台，帮助合作伙伴快速构建各种智能体，降低商家营销成本，提高效率。

接下来，我将展示一些基于延熙大模型的应用视频，包括语言、图像、视频和声音生成的实际效果。

我们还在探索多模态技术，即理解和生成文字、图像、视频和声音的能力，并且迈向巨神智能阶段，使大模型从数字世界走向实体世界。通过智能海报生成、商品图渲染等应用，帮助商家提升营销效果。

我们也在研究如何通过AI生成情感丰富的声音，打造声音内容供应链，以更好地帮助品牌与用户建立情感联系。

此外，我们的数字人技术也在快速发展，成为新的颠覆性产品。数字人可以作为数字员工，提供24小时高效的交互体验。比如在618活动期间，京东数字人刘强东总的分身为京东图书带货，取得了很好的效果。我们也为格力等品牌打造了数字分身，提高了企业家的IP价值。

最后，我想总结一下，京东认为大模型技术的发展应以产业需求为导向，致力于打造高可靠性、颠覆性的AI技术产品，让每一个普通用户从中受益。谢谢大家。


### 京东大模型发展及场景应用最佳实现 --龚一诚

我们知道，大模型和AIGC的应用离不开数字基础设施的支持，那么先进算力如何支撑大模型的发展？企业又如何快速训练出自己的行业模型？接下来，我们请出京东云副总裁、京东云赖斯产品研发部负责人龚一诚先生，为我们带来“京东大模型发展及场景应用最佳实现”的主题演讲。掌声有请。

大家好，我是京东云的龚亦诚。今天我将分享京东大模型在各种应用场景中的最佳实践。刚刚何博士和曹验士提到很多关于大模型应用的落地。实际上，在刚刚过去的618活动中，京东在AI智能体的应用中，已经有数百个应用场景，包括何博士提到的数字人、零售商品的图像生成、金融领域的财富管理和营销增长等。我们稍后会展示一个短视频，展示这些应用场景。

在代码生成方面，我们京东已经实现了20%以上的代码由AI生成。在京东内部，大模型已经广泛应用于各种场景。前面提到的数字人数据，曹先生也谈到了很多企业的数据都分布在各自行业的内部场景中，并不总是能通过基础模型获取到。因此，很多企业会结合自己的行业数据，开发专属的行业模型。

京东在大模型的推进过程中经历了三个阶段。首先，在2021年，我们在重庆建立了亚洲最大的superport A100超算中心，开始研发基础大模型。随后，我们进入了行业模型阶段，利用大量产业数据开发了营销增长、医疗问诊等行业模型。基础模型在具体行业中缺乏专业度，因此我们开发了许多行业模型。

现在，我们进入了智能体阶段。京东内部已经有大量智能体应用于各种碎片化场景，如OI场景。智能体能够解决企业端的实际问题，是我们希望看到的。智能体在落地时需要感知外部环境，结合模型和企业规划，完成企业端的应用落地。

接下来，我要介绍京东沿西的AI开发平台。无论是基础大模型、行业模型还是智能体，企业做这些事情的门槛都非常高。比如基础模型的训练、算力调度和资源利用率提升等，都需要大量的人力和资源。因此，我们开发了沿西智算平台，分为三个层面：基础设施层、模型开发层和智能体构建层。

在基础设施层，我们的智算平台兼容各种GPU型号和网络，结合高性能智能网卡和云海统一存储引擎，实现高性能计算和数据流转。在模型开发层，我们支持模型的开发、微调和评测，提供有代码和无代码的操作方式，支持高级功能如模型的放大、缩小和拼接。在智能体构建层，我们提供各种通用模板，帮助企业快速构建智能体应用。

京东沿西智算平台从基础设施、模型开发到智能体构建，满足不同企业的需求。我们的目标是服务和融入产业，推动大模型和AIGC的蓬勃发展。以上是我的分享，谢谢大家。


### AI技术重塑医疗健康服务 -- 王国新
其实很多人都说今年是AIJC的应用元年，那么当AIJC与医疗相遇，会碰撞出什么样的火花呢？它能否成为医生诊断的得力助手？能否帮助患者更便捷地获取个性化的健康建议？或者优化医疗资源分配，提升医疗服务效率与质量？接下来，让我们有请京东健康智能算法部负责人王国新先生，为大家带来“AI技术重塑医疗健康服务”的主题演讲。掌声有请，谢谢！

刚才龚先生的演讲引出了这个应用环节。其实医疗应用是我们大家最熟悉的领域之一，因为我们大多数人都是医疗服务的消费者。然而，医疗应用中存在一个所谓的“不可能三角”。简单来说，就是又便宜又方便，而且质量又好的医疗服务是不可得的，至少在医疗经济学的角度来看是不现实的。

但如果我们回顾过去一百年的历史，有一个关键因素在不断地改变这个“不可能三角”，那就是技术。如果回想20世纪的三大医疗变革，首先是以抗生素为代表的化学药物；其次是六七十年代以X光和CT为代表的影像医学；然后是90年代以基因和小分子为代表的医学技术。这些技术的进步都为医疗环境带来了巨大的改变。

从我们的视角来看，我们认为当前的人工智能（AI）也是一次巨大的机会。AI能够帮助医学突破“不可能三角”，提供低成本、高质量的医疗服务。基于这个观点，京东健康在过去两年中制定了AI驱动的产品和解决方案计划。

首先，让我们看一下我们的技术基础。我们在精一千寻的医疗大模型上构建了整体的医疗基础，融合了多模态的临床推理数据、患者数据和诊疗方案数据。在此基础上，我们开发了智能问诊、智能诊断、智能问答和数字疗法等产品。这些产品构建了四个核心解决方案：面向患者、医生、医院和企业。这些解决方案与合作伙伴一起，构成了从健康监测、诊断到治愈的完整流程，这是我们过去两年中AI驱动的主要工作。

我们的精英签询大模型是基于延熙的通用大模型平台构建的，并于2023年7月在北京发布。过去一年中，我们在这个模型上做了三项重要工作。首先，我们不断提升医学的安全保障。由于大模型本身是概率模型，存在一定的误差和幻觉，在医疗场景中，我们要求其准确率至少达到99%以上。

其次，我们努力将大模型与现有的医疗信息系统有效结合。大多数医院没有强大的计算资源，因此如何有效利用院内资源和系统是我们解决的重点问题。

第三，我们致力于将大模型与患者的个性化数据深度结合。我们希望通过持续学习和隐私保护，将大模型与患者个性化数据有效整合。这三点是我们过去一年中解决的核心问题。

总结来看，我们的目标是让大模型学会它不擅长的部分；学会如何与线下数字化系统结合；并尽可能利用个人数据。接下来，我们将讨论大模型的应用。我们认为，垂直大模型需要用行业内认可的数据进行训练，尤其是教科书和医学指南等数据。同时，大模型需要符合医学推理的要求，才能获得行业专家的认可。

最后，我们需要识别合适的应用场景。虽然技术在快速发展，但场景应用还在追赶。我们需要找到遵循医学实践的人机协作流程，才能实现行业的降本增效和增长。

接下来，我们将介绍几个实际应用场景。第一个场景是在多个三甲医院中已落地的项目。我们大多数人都有排队两小时看病五分钟的经历。我们的智慧诊前服务可以在挂号报到时，通过数字医生助理收集病情和检查数据，从而减少院内等待时间，提高患者满意度。

第二个场景是AI与医生的结合，作为医生的助手，降低医生工作强度，提高诊断准确性。同时，这也有助于提升诊间对话和医生决策的数字化水平，沉淀数据，加速行业迭代。

第三个场景是慢性病管理。我们与智能设备结合，实时监测患者数据，帮助医院和患者更好地管理慢性病，降低医保费用和复发率。

此外，我们还有一个面向C端的产品叫ABC健康，希望成为每个人的健康建议者和行动指导者，连接各种医疗资源。

最后，希望AI技术能够推动中国医疗产业的发展，谢谢各位！


### AIGC成为生产力 -- 范文竹

今年，京东云的新一代数字人服务了超过5000家品牌商。接下来，让我们热烈欢迎伊利消费者运营数字化负责人范文竹女士带来主题演讲：《AIGC成为生产力》。掌声有请！

各位领导、同事和同行们，大家好！我今天要分享的内容是关于我们在产业链前沿的应用。很多嘉宾已经提到了一些实际应用场景，而我们伊利在消费品领域处于最前沿，因此我想和大家分享一下我们如何实际应用AI的能力，包括我们的一些功能试点和能力布局，也希望能和大家一起探讨在消费品、零售和营销领域的新机会。

首先，简单介绍一下伊利集团。大家对这个品牌应该不陌生，很多喝牛奶的消费者都知道我们。我们已经成为全国乳业的第一名和世界乳业的前五。最新的财报数据也非常亮眼。除了大家熟知的伊利品牌，我们还涉猎了冰淇淋、奶酪、冷饮、酸奶、矿泉水和宠物食品等多个领域。

今天参加这个人工智能大会，我们希望一方面分享我们的实践经验，另一方面也是带着任务来的。我的部门是伊利的数字科技中心，负责带领和赋能整个集团的数字化转型。我主要负责营销和消费者运营领域，因此我们希望能找到更多合作伙伴，共同创造更多合作机会。

今天的主题是《AIGC成为生产力》。一年前，AIGC还只是在我们集团的领导层会议上提到，每次我们展示SORA生成的视频时，领导们总是问这与伊利有什么关系。如今，我们可以自信地在集团会议上汇报，利用外部新生产力来助力伊利引领乳制品行业的发展。

我们在2021年开始布局品牌内容营销数字化产品和中台，现在每天有超过十亿消费者通过新媒体获取信息。我们需要每天分发数十万甚至上百万条内容，通过各种触点和渠道打动消费者。

我们的数字内容中心从1.0版本进化到2.0版本，形成了从内容洞察、生产、创意、制作、分发、审核到数据回流和自动分析的完整闭环。我们总结了AI在品牌营销中的四大场景和核心工作流程，包括洞察、创意、制作、管理分发和价值评估。

我们数字科技中心找遍市面上所有AI工具，并将其整合到我们的平台中，帮助内容运营人员提高效率。例如，通过AI工具，我们可以快速识别最匹配的热点，减轻试错成本。在内容策略和创意方面，我们希望通过生成式AI一站式生成灵感。

在内容生产工具上，我们应用了数字人口播、直播切片、AI混剪、文生图、外呼关怀、文本和语音合成、数字人直播等工具。这些工具解放了内容运营人员的工作，使他们可以大规模生产内容，并通过各种触点分发。

例如，数字人直播在白天用真人主播测试话术，晚上用数字人直播，以降低成本和风险。我们还开发了自己的猫狗模特，用于广告片制作，显著降低了成本。

在AI外呼应用方面，我们使用明星代言人的声纹，为消费者在生日时打电话，提供关怀和个性化体验。

在内容管理方面，我们结合AI打标和人工打标，提高了素材管理的效率。未来，我们将继续探索和优化AI合规检查，确保内容标签和数据的准确性。

最后，我想感谢今天所有分享的嘉宾，感谢现场和线上的观众，以及所有幕后工作人员。谢谢大家！我是主持人李静，期待在今后的活动中再次见面，开启更多精彩内容。谢谢！
