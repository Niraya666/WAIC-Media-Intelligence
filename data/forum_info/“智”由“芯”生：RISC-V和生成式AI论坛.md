## “智”由“芯”生：RISC-V和生成式AI论坛

![](https://static.worldaic.com.cn/IMAGE2024/2024-06-17/14938b4c92c3419aabe31d508311b1ac.jpg)

### 引言

在生成式AI技术迅猛发展的今天，各行业的应用层出不穷。无论是云端的训练还是终端的推理和微调，AI模型对算力的需求与日俱增。作为一种开源指令集架构，RISC-V凭借其灵活性和可扩展性，正在为AI芯片的技术创新和产业化开辟新的道路。本次论坛汇聚了来自业界的专家、学者和企业代表，旨在探讨RISC-V与生成式AI技术的融合与发展，促进国际间的交流与合作。

### 论坛信息

- **时间**: 14:00 - 17:00
- **地点**: 世博中心517会议室



### 论坛日程

| 时间      | 主题                         | 演讲嘉宾 |
| --------- | ---------------------------- | -------- |
| 14:00-14:05 | 欢迎辞                       | -        |
| 14:05-14:15 | 嘉宾致辞                     | -        |
| 14:15-14:35 | 大语言模型的原理与发展应用   | -        |
| 14:35-14:55 | AIGC芯片的机遇和挑战         | -        |
| 14:55-15:15 | RISC-V：下一代AI芯片的目标 | -        |
| 15:15-15:35 | 多样的开源RISC-V处理器赋能AI的创新 | -        |
| 15:35-15:55 | 生成式AI的释放：MIPS和RISC-V的变革力量 | -        |
| 15:55-16:15 | 休息                         | -        |
| 16:15-17:00 | 圆桌论坛：生成式AI和RISC-V的融合与创新 | -        |

### 嘉宾名单

- **戴伟民** - 芯原微电子（上海）股份有限公司，董事长兼总裁
- **张晓东** - 乌镇智库，理事长
- **戴路** - RISC-V国际基金会，理事长
- **练维汉** - Tenstorrent Inc，首席CPU架构师
- **Durgesh Srivastava** - MIPS，首席技术官
- **孟建熠** - 知合计算技术（深圳）有限公司，首席执行官
- **高奇琦** - 人工智能与大数据指数研究院，院长
- **彭剑英** - 芯来智融半导体科技（上海）有限公司，首席执行官



请各位嘉宾入座，会议马上开始。特别要指出的是，RISC-V 的主题非常有趣，其他与会者也展示了类似的图片。我们今天展示的内容，尤其是引用了Hennessy和Peterson的文章，表明当前的计算机性能已不如以往。过去计算机发展迅速，但现在似乎已经到达瓶颈阶段，性能增长趋缓。我们经常听到人们说摩尔定律已经放缓甚至停止，但实际上问题在于我们对计算机速度的期望没有得到满足。那么，我们为什么要展示这些呢？这是因为RISC-V 提供了新的架构可能性，这是我们不断探讨这个主题的原因。

目前，计算机供应普遍不足，正如我们之前提到的，价值也很低。因此，满足AI需求成为了关键。NVIDIA 的GPU已经展示了性能的大幅提升，而CPU也必须快速跟进，这使得计算机之间的性能差异显得更加明显。这种差异带来了更大的问题和挑战，但同时也创造了新的机遇。我们要抓住这些机遇。

一个重要的观察是，我来自智能和系统架构领域，我仍然是一名智能架构师。我们先开发硬件，再开发软件。过去是这样，先有智能电脑，然后整个应用系统才逐步完善。但现在情况不同了，我们有了以智能电脑为基础的解决方案，但软件开发却滞后了，整个应用系统尚未完全成型。因此，我们必须解决这个问题。

前几位发言者提到，智能电脑能解决部分问题。混合和匹配是关键，这个领域非常重要。第二点是电池分配。以前，我们把电脑放进机箱，然后将其转变为信息中心。但现在，我们需要更灵活的电池分配方式，以适应不同的计算需求。我们需要确保能够灵活地分配计算资源，如CPU、内存和存储器，并将它们连接到DPU（数据处理单元），以实现高效的信息处理。

RISC-V 的优势在于其灵活性和开放性，可以自动进行架构调整，这对于建筑师来说是梦想成真。RISC-V 允许我们改变指令集，这是其他架构所不具备的。这使得RISC-V 在处理向量计算和混合任务时具有独特的优势。

我们也在研究如何利用RISC-V 来重新定义计算资源的分配和调整，以应对AI和计算需求的快速变化。我们希望在未来继续开发工具，增强RISC-V 的强大功能，实现开放标准下的创新。

最后，MIPS 是 RISC-V 的重要合作伙伴，我们正在探索如何让数据中心和自动驾驶领域更高效、更安全。我们相信 DPU 将成为数据中心的核心，CPU、GPU、控制器和内存都将围绕 DPU 构建。我们会继续与 RISC-V 合作，确保建立一个成功的生态系统，满足未来 AI 和计算的需求。谢谢大家。

接下来进入今天最后一个环节，圆桌论坛。今天讨论的主题是生成式AI和RISC-V 的融合与创新。本次圆桌论坛由中国 RISC-V 产业联盟理事长、新元创始人、董事长兼总裁戴伟明先生主持，参与讨论的嘉宾包括 RISC-V 国际基金会理事长戴璐先生，华东政法大学政治学研究院院长、人工智能与大数据指数研究院院长高奇奇先生，之和计算 CEO 孟建义先生，新来智荣半导体科技上海有限公司 CEO 彭建英女士，乌镇智库理事长张晓东先生。请各位嘉宾入座，并带上手机参与互动投票。未加入会议微信群的嘉宾请扫描大屏幕上的二维码入群。圆桌讨论开始后，我们会邀请大家对讨论话题进行投票。这里也有会议的实时照片供大家下载。请各位嘉宾入座。现在我把时间交给圆桌论坛的主持人戴博士。

### 圆桌论坛：生成式AI和RISC-V的融合与创新

今天我们的讨论小组有几位重要的嘉宾。其中一位是高教授，他是华东政法大学政治学研究院院长，也是能工智能大书记指数研究院的院长，同时还是国家新一代能工智能治理专委会的委员。大家知道这次大会除了是能工智能大会外，还有一个副标题：人工智能全球治理高级别会议。你们知道这是什么吗？为什么还要加一句话呢？实际上，这是因为我们在全球治理上对能工智能有一定的限制，但在安全治理上还是可以讨论的，这非常重要。

高教授昨天也参加了一个专门讨论这个问题的分论坛。我想先请高教授讲一讲这个事情。刚刚我们提到的关于被开除的那位的事情，也涉及到了超智能的安全问题。我觉得这是一个大家都关心的问题，因为这关系到治理上的安全。这个问题很重要，因为虽然我们现在是强智能，没有太大问题，但未来五到十年内，如果出现超智能，可能会带来新的问题。高教授，你能不能先大概给我们讲讲昨天你们讨论的内容，或者你最近研究的成果？政府也在研究这个问题。你觉得有没有解决方案？好，谢谢戴总。

关于这个问题，我简单讲几点。首先，我们需要谈一下大模型的发展，特别是在大模型的帮助下，通用人工智能（AGI）的快速到来。如果刚才OpenAI的研究员所说的2027年实现AGI是真的，那对我们将会带来很多挑战。我简单地定义了三个可能的风险：

第一，失业问题。随着自动化进程加快，就业冲击是不可避免的。如果速度太快，我们可能没有足够的准备，这是一个严重的问题。

第二，失序问题。大量AIGC应用可能导致信息过载和信息泡沫，导致我们难以信任信息，进而影响社会和政治秩序。

第三，失控问题。AGI的到来可能带来两种失控风险：一是AGI可能产生自我意识，二是恶意分子可能利用AGI的超级能力制造病毒或超级武器。这两种情况都非常危险。

针对这些问题，我们需要对大模型进行分级管理，特别是对超级大语言模型（如AGI）采取类似核武器的安全控制方法。尽管核武器有检查机制，但大模型的控制更加复杂，需要类似于区块链的多方信任机制。

对于规模较小的大模型，如GBT4以下的模型，许多国家还需要增强自身能力建设。人工智能是一场生产力革命，将改善人类生活。我们可以借鉴碳中和的思路，对人工智能的使用收取一定的税费，以解决其带来的问题，并促进公平。

关于“失序”和“幻觉”的问题，自动驾驶中的幻觉非常危险，但在创作中，幻觉是一种类似于人类想象力的特性。我们需要找到一个平衡点，不完全消除幻觉，而是在特定场景中进行对齐和调整。

最后，我们讨论了几个大模型集中化的问题。前Google CEO Eric Schmidt提出，未来可能只有少数几家巨大的模型主导全球。这种情况可能会导致知识生产的单一化和文化的边缘化，因此许多国家开始研发自己的主权AI模型。

今天我们来讨论芯片问题。因为恋恋不在，所以今天孟博士的任务可能会多一些。我会把我们两个人的问题都问你。你刚才提到air和lucify，练一组说这两个东西很巧地一起来了。其实，它们看起来并不是一样的东西。一个是CPU，一个是air。那么lucify到底是什么？它是air的扩展吗？也就是说，lucify可以扩展DSP、DPP和AI指令集。还有一种说法是，lucify只是air的一部分。你觉得air和lucify怎么结合，怎么把两者的优点结合起来？现在有点困惑，你能不能谈谈你的看法？

我一直在研究lucify和AI的关系。我的观点是，lucify从CPU开始，但它的未来应该在AI上。它们之间的关系，今天来看，首先有一个需求存在。今天的架构不能满足当前和未来的算力需求，所以架构必须创新。我们看到，可能从CPU做扩展，也有小CPU作为数据流处理器，还有纯计算一体和近存计算。

今天的需求在那里，所以架构要创新。今天我忘记介绍，不是阿里，有个资格计算CPU，可以有点子路式。这个资格计算的CPU没有广告，我对这个东西的看法是，形态很多，没有确定。过去的10年20年，计算机体系结构基本确定，一个CPU加上很多加速器。今天各种PU都有，APU、BPU、CPU、DPU都有。从这么多PU的角度来看，都需要面向开发者有一个好的开发界限。今天来看，支撑未来大生态的架构只有RISC-V架构。因为它开源，在变化中，像水一样。今天地形怎么样，有人会根据地形设计出一个好的处理器。但它还是RISC-V。最终，做各种PU的人多了，对架构的贡献也多，软件生态也越来越繁荣。所以我觉得RISC-V包容性强，把各种硬件架构和具体设计纳入RISC-V的程序模型里。所以这是它的生命力。我相信还会有更多创新，这些创新要经过产品化的考验才能走出来。这是我的想法。

你来评论一下哈佛的学生搞的那个收服。他说比英伟达快20倍，你觉得这个路径怎么样，算不算ASIC。对，这其实是一条ASIC的加速路径。这条路径很有意思，把NVIDIA吓出一身汗。这个比NVIDIA快20倍的数字确实非常棒。当然在这里面，我觉得大家都在做创新。这个之后，大家看到我们做计算架构的人还可以继续往前走。下一个可能比他好10倍也有可能出现。所以一直在延展我们对计算架构的理解。

当然，这个项目刚启动，真正和NVIDIA竞争还有很多问题，不管是产品化、软件生态，还是算法训练的过程。因为它只支持Transformer，如果算法在训练过程中怎么办，还面临不少问题。但这是一个非常好的尝试。

你的意思是说，可能走得太远，transformer变了以后它可能就有问题？对，我觉得在RISC-V领域，我们有强的包容性，走得远也没关系，它会走回来的，我觉得这是很好的尝试。

那它用RISC-V吗？它应该没用，但我觉得未来会用。如果它的IP加上RISC-V，可能更好。对，因为要变得可编程、可使用，还得有个架构支撑它。

我们有个投票，会不会ASIC取代GPU？这条路线是ASIC，谷歌的TPU tensor flow也有点ASIC。有没有可能这种ASIC取代GPU？这就要看系统是否工作，还要加一个并存选项。可能大部分都选并存，这是送分题，看看系统是否work。很有意思，ASIC是专用的，但灵活性少。有时候不能走太远，孟博士讲的对，有时候走得太远，回来一下比较好。有可能走得太远，transformer还是transformer。你刚刚说从数学角度，train machine是最后的计算，这个意思吗？比方说next token prediction，现在用transformer比较有效。最近有很多研究论文试图改进transformer或提出完全不同的架构。昨天看了一家公司，claim比transformer好多少。先不管对错，如果出现比transformer更有效的算法，会对这类公司有影响。所以短期内可能是共存问题。

transformer做翻译，但现在视频和音频切成token，视频切成块，但还是next token prediction？对，视频和语言过去认为不同，但现在视频模型完全用next token来做，把视频切成很多patch，一个patch就是一个token。后面的算法完全一样，所以效率很高。从某种意义上证明next token prediction作为第一性原理可能是work的。

我补充一下，今年的sora把transformer引入到原来的纹身图，用扩散模型，效果完全不一样。特斯拉端到端自动驾驶，以前光图像不可能达到，但用transformer方法理解图像。我们以前觉得不大可能，但机器理解语言和我们不太理解自己理解语言的方法是一样的。所以我和张老师的观点一样，机器理解自己也是黑箱，机器也是预测下一个单词。我认为思维就是语言，没有语言就没有思维。

刚才看到公司做的transformer是20 times faster，有人说只做了一两年怎么那么快。实际上很多年前的NPU已经比NVIDIA的GPU快十倍，但最近AI take off，很多人不会太注意NPU，主要是NVIDIA的CUDA software。所以你快二十倍，还需要一个software ecosystem support，因为所有应用都要基于CUDA。对大模型公司，time to market很重要。Illya说你省一倍算力so what，对他来说一倍的算力不重要，重要的是time to market。

我们下一个问题是生态问题。大家知道X86 ARM和RISC-V，这三个东西和生态有关。高通把windows port到ARM上，花了很大力，其实是高通在port。因为window是习惯，很难replace，苹果也弄个window上。这就是个问题，比如到数据中心是X86。那你觉得对AI来讲，X86 ARM和RISC-V哪一个更有优势？当然你讲过和AI的关系更有优势。从整个过程中，RISC-V大部分在下面手机的IoT水平化，优点是水平化给每个人extension。所以要取代手机和电脑比较困难，但变成AI手机AI的PC有机会吗？

AI的问题，如果年纪稍微大点记得2000年每个公司都叫web。现在AI那么红，不管你芯片适不适合AI，不说适合生意就没了。X86最老的，architecture和AI完全没有关系，但可以加additional instruction改成AI挂得上一点沟。因为它不说AI，X86将来怎么卖？它的优势是有一个很大的install base，软件应用加一点AI，别人可能就继续用。这是它的一种做法。它在silver market抢RISC的生意时也是这样。现在做AI，X86还想重新试一下这个做法，用生态的install base。但在AI上，生态不占主导地位，AI生态的主导地位是NVIDIA的CUDA。所以很多公司做GPU不是为了做GPU，而是为了做AI。从生态上，NVIDIA的GPU占优势。

ARM和RISC-V都属于RISC这条线，architecture非常low power，所以ARM用在手机电脑上省电。AI的computing power耗很多电，虽然机器插在电源上，但省电是因为太贵。所以ARM和RISC-V在AI上有优势。ARM和RISC-V之间的区别是，RISC-V有customizable的feature。RISC-V解决了AI其他几个挑战，比如每个公司都想做自己独特的大模型，但不想告诉别人。如果都不告诉，那做芯片的人怎么做？每个帮你做一块太贵。但用RISC-V，可以做成一样的base model，加几个custom instruction，这样成本低一点。用户可以用成不一样。还有一个是security，每个地方不想做成一样的security，AI要保护自己的安全，但RISC-V可以定制化安全。

所以RISC-V在AI上可能占优势。谁有想补充？我们可以说其他架构，比如NVIDIA的架构，谁都不属于，但其他人可以做成类似NVIDIA的架构，CUDA compatible的，或者做一套自己的CUDA。

接下来，其实还有一种办法，在手机下面IoT，在手机上面是Leader Center，手机边上，ARMS很强。机车相对封闭，一天到晚破坏。以前MIPS在机车上很强，现在没提MIPS，等会儿会讲MIPS。汽车方面的事情，孟博士是新来，他的背景也很好。在Synopsis ARC和Marvell都有经验，现在是RISC-V中国产业联盟秘书长。孟博士讲一下汽车，好像两年前开始做，通过车规还是领先的。

孟博士，能不能介绍一下你们公司在汽车领域的工作？

就真的很凑巧，我和孟博应该算是同门师兄弟。我们来自同一个实验室，只是他比我晚一届。我们一直从事处理器相关的工作。孟博从浙大毕业后一直在中天，后来去了阿里，现在自己创业到了滋贺。我本人毕业后加入了马威尔，然后到Synopsis，一直在产业界做处理器IP相关的工作。我们公司于2018年成立，正好赶上了RISC-V的风潮，我们认为这是国内的一个好机会。

刚才我们讨论了很多关于RISC-V的话题，比如它与AI结合的优势，以及在不同领域中与X86和ARM的优缺点。我们还讨论了像SOHO这样的ASIC与通用架构的区别。实际上，我们做处理器这么多年，传统的CPU架构变化不大。无论是哈佛结构还是流水线和内存架构，都没有太多变化。AI的兴起确实带来了新的市场机会，无论是在汽车、服务器还是终端设备方面。这些增量市场让很多公司在ASIC与通用GPGPU和通用CPU之间不断寻找平衡，这个平衡实际上就是硬件和软件之间的平衡。我们可能都知道，以前做DSP需要写汇编代码，对编程语言的要求很高。现在全球的趋势是，懂C语言的人越来越少，大家更多使用C++，甚至是Python。AI领域的人更是如此，他们通常不需要写示例代码。因此，AI的兴起对于很多创业公司来说也是一样的，不断在ASIC和通用CPU或GPU之间寻找更好的权衡。

在汽车领域，我们公司去年第一个获得了ISO 26262功能安全最高等级的产品认证。我们认为，汽车电子是一个非常有前景的增长市场。过去，汽车是一个非常封闭的系统，尤其是燃油车。现在，随着特斯拉和国内新势力的带动，自动驾驶算法和芯片的开发逐渐成为趋势。从车身控制到预控、ADAS和智能座舱，这个趋势已经非常明显。软件驱动的架构设计已经成为主流，这对芯片架构和设计带来了巨大的变化。不仅仅是算力的增强，比如ADAS对算力的需求不断增加，智能座舱的体验感也需要提升，APP要能无缝集成。车内不同芯片的底层逻辑和需求其实是共通的，如AI软件的通用性、功能安全、信息安全和实时响应等。

未来，汽车芯片的融合需要一个统一的架构，这也是RISC-V的一个机会。RISC-V的架构具有可扩展性和延展性，可以满足汽车电子从低到高的需求。它的软件不像手机和PC那样完全开放，OEM和T1在硬件到软件到模组的闭环控制中起着主导作用。因此，我们认为RISC-V在汽车电子领域有巨大的机会。

最后，我想总结一下，我们公司的策略是确保终端推理卡和微调推理卡的功耗比NVIDIA更好，即使可能不如它快。我们还在汽车领域推广RISC-V和ARM，确保它们都通过车规认证。未来，不同芯片之间的融合需要一个统一的标准，如UCIE，这将有助于芯片的物理接口和联接层的标准化。

感谢今天到场的媒体朋友们，已经发布了十多篇原创深度报道，让我们会议的成果可以得到更广泛和持续的传播。通过今天的讨论，大家对RISC-V和生成式AI的未来发展有了更加深入的了解和更多的期待。谢谢大家。


