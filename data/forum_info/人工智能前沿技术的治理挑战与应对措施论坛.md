## 2024世界人工智能大会·人工智能前沿技术的治理挑战与应对措施论坛

### 活动介绍

随着通用人工智能的广泛应用和深入研究，前沿人工智能的发展潜力和安全风险更加直观地展现出来。各国政府、研究机构和国际组织加强对话与互动，如何通过国际合作防范快速发展人工智能所带来的极端风险已经变得刻不容缓。“2024世界人工智能大会·人工智能前沿技术的治理挑战与应对措施论坛”将围绕人工智能前沿技术的发展与治理，交流人工智能的最新研究进展，探讨人工智能治理挑战与应对措施，探索构建人工智能治理全球框架。

![论坛封面图](https://static.worldaic.com.cn/IMAGE2024/2024-06-17/04f27966b3c24cf4a51f9890e6a71d1b.png)

### 会议时间与地点

**时间：** 2024年7月17日  
**地点：** 世博中心515会议室

### 会议议程

| 时间     | 主题                                             |
|----------|--------------------------------------------------|
| 14:00-14:15 | 嘉宾致辞                                        |
| 14:15-15:15 | 主旨报告                                        |
| 15:15-15:20 | 《中国人工智能重大应用场景白皮书》及“智能向善全球伙伴计划”启动仪式 |
| 15:20-15:30 | 茶歇                                            |
| 15:30-16:30 | 圆桌对话: 人工智能前沿技术的治理挑战与应对措施     |

### 嘉宾名单

- **齐利德齐·马瓦拉**  
  - **单位：** 联合国大学  
  - **职位：** 校长  

- **薛澜**  
  - **单位：** 清华大学人工智能国际治理研究院  
  - **职位：** 院长  

- **姚期智**  
  - **单位：** 清华大学交叉信息研究院、人工智能学院院长  
  - **职位：** 院长  

感谢高院长 Mr. Caspers。我知道您在国内和国际公共政策领域有25年的经验，并且在风险研究方面有非常深入的理解。因此，我们非常希望了解您对AI治理中最大的挑战和风险的看法。您能否为我们列出其中最重要的前三项？

好的，非常感谢。我很高兴能在这里发言。首先，我想从最后一位发言者的观点出发，进一步讨论。在谈论这个问题时，我们需要意识到，我们不应该只关注当前的人工智能系统，尽管这些系统已经提出了很多挑战。我们需要展望未来五年，甚至可能是两年，或者更早。到那时，我们可能会创造出远远超越现在的人工智能系统。这些系统将能够在广泛的能力范围内匹敌甚至超越人类水平，这些被称为通用人工智能(Artificial General Intelligence, AGI)和超级人工智能(Artificial Super Intelligence)。正如您提到的，现在一些公司已经将这些纳入了他们的计划中。虽然我们不能确定它们一定会发生，但也不能忽视这种可能性。

那么，如果我们真的处于这种发展的边缘，会出现什么样的新挑战？我认为需要注意的是，许多挑战可以在国家层面或志同道合的国家之间处理，但有些挑战确实需要全球合作。这些挑战跨越国界，我们不能在不与其他政府合作的情况下，保障人类的安全和福祉，包括我们自己的公民。因此，我们刚刚发布了一篇名为《全球AI挑战框架公约》的论文，详细阐述了这一点。我们看到的三大挑战领域是：

第一，实现和分配人工智能的全球效益。私营部门将在生成这些效益方面做大量工作，但我们也需要政府的干预和合作，以确保这些效益在全球范围内得到充分实现和公平分配。这意味着确保所有人都能获得AI工具，利用最先进的人工智能工具创造全球公共产品，并公平分配和共享这些效益，避免它们仅集中在少数群体或国家之间。

第二，减轻全球规模的风险。全球规模的风险主要是指对公共安全的威胁，比如恶意行为者滥用强大的AI系统制造新型大规模杀伤性武器，或者最终导致对AI系统失控。虽然这听起来像科幻小说，但我们正进入一个可能创造出极其强大且无法控制的系统的世界。当前，我们正朝着创造这些系统的方向发展，但还没有找到控制它们的方法。除非这种情况改变，否则将非常困难和危险，需要各国政府合作找到解决方法。

第三，关于人工智能未来的合法和有效决策。我们可能正进入一个可以创造出比人类更聪明机器的历史阶段，我们需要反思并仔细考虑想要创造什么样的系统，在什么条件下，以及应具有什么样的保障措施。这需要全球范围内的讨论和决策，而不仅仅是由少数科技公司做出。

最后，如果让我选择一个最紧迫的问题，我会说是公共安全风险。由于时间表的不确定性和潜在的严重性，我们现在应该采取行动，确保我们已经做好准备。我们可以在一些解决方案的背景下做到这一点，我稍后会再回到这个问题上。

非常感谢。我认为高教授和Beck女士也都提到了AI的不确定性，我们不知道通用人工智能何时会出现，也不知道实际的风险是什么。非常感谢。

那么，下面的第二个问题实际上是受到第一个问题的启发。我们认为，在实现通用人工智能（AGI）或者比人类更强大的人工智能之前，还有很长的路要走。相信刚才高教授也提到，我们对发展的共识较高，但在安全方面，虽然有共识，但具体措施还不清晰。如何在发展创新与安全监管之间取得平衡？我想请教华为的刘院长，从产业角度谈谈您的看法。

非常感谢主持人的提问，也非常荣幸能参加今天的讨论。作为产业界的一员，我想分享一些我们对这个问题的思考。首先，我认为发展和治理的关系非常重要。正如刚才的研究报告和专家所提到的，我们对发展的共识已经非常充分。因此，我们认为，治理应该为发展保驾护航，而更好的发展也需要更好的治理。我们在发展过程中要注意治理，而在治理过程中也不能忽视发展。

人工智能可能面临许多风险，甚至威胁到人类的生存底线。面对这些挑战，我们必须保持高度重视。但同时，我们也不能忽视技术进步和善意应用所带来的福祉。历史证明，人类生活质量的改善在很大程度上依赖于技术进步。这是我想强调的第一点。

在实际应用中，我认为有两点非常重要。首先，我们需要采取分级分类的处理方式。风险有很多种类，包括长期和短期的，涉及人类生存安全的，以及对人类福祉有影响的。我们在构建治理体系时，应采取分级处理的方法，例如通过法律规定安全底线，守住最后的防线。同时，作为人工智能从业者或利益相关方，我们也应该承担相应的责任，通过自律来履行我们的义务。道德和软性引导对预防潜在风险也非常关键。

第二点是按场景进行风险分类和处理。例如，推荐算法在推荐商品和推荐治疗方案时，对人类的潜在威胁是完全不同的。因此，风险应在不同的场景下分别分析和处理，避免一刀切。这样，我们可以在一些不那么敏感的场景中发挥人工智能的价值，例如气象预测等，从而支持联合国的可持续发展目标。当然，在一些领域，我们需要非常谨慎。这是我们在实际操作中需要关注的。

非常感谢刘院长的分享，特别提到分级分类的个性化处理方法，为发展留足空间。这个问题我也想请教另一位专家。

那么，关于国际协议，如纽约国际智能协议、GDPR等，有时被批评为阻碍了美国的人工智能发展。您怎么看待美国人工智能发展的关系，以及对美国AI改革和安全的看法？

我认为这是一个关键问题。我们有两个框架，一个是符合纽约国际智能协议所称的人权和伦理，这对美国AI提供了很强的保护；另一个是对公司的批评框架。法案的变更通常被视为威胁，增加了公司的负担。GDPR就是一个例子，许多公司仍在辩论其负面影响。特别是医药行业，EUA法案对高风险领域公司有直接影响。

在经济层面，无论公司如何适应法规，它们都面临负面成本。特别是在医药行业，EUA法案定义了高风险，这对医疗解决方案有重要影响。高风险系统的抵抗执行成本在上升，这对欧洲市场是一个挑战。许多欧洲制造公司可能会移民到美国或加拿大，但在高规制领域，如自动驾驶公司，可能会继续留在欧洲。

感谢您的分享。我们可以看到，即使欧盟的立法严格，但对产业也有豁免。下面我想请Matt和顾院长回答下一个问题。

在AI治理中，政府不再绝对主导。监管部门、产业界、学界、智库等都发挥重要作用。顾院长，您怎么看待不同主体在AI国际治理中的角色？

感谢主持人。多方协同共治是关键。各国对政府、产业、智库的作用有不同看法。我举个例子，一家名为面壁智能的企业通过开源社区发现并解决了一个问题，体现了多方合作的重要性。在中国，AI应用已广泛渗透到各行业。产业界贡献智慧，通过开源、基础研发和应用推广，让所有人用得起大模型，实现AI for good和equality。

从政府角度，美国强调国家领导力、政府示范作用和创新监管。欧盟AI法对GPAI留有空间，但也有不确定性。美国最新的SP1047法案，通过自主研究发现风险并主动规避，可以享受有限责任豁免，这类似于平台时代的避风港原则。未来的AI治理将强调事前审慎而非事后追责，强调过程正义和企业自主性。

感谢顾院长的分享。Matt，您怎么看？

我试着用中文回答。在美国，学者缺乏算力和参与政策制定的平台。政府缺乏人才。企业有足够的资源。在中国，学者和企业更积极参与治理，但需要更多的基本保护和反馈渠道。每个社会都需要确保每个主体都有所需资源参与AI治理。美国和中国都在这方面取得了进展。美国监管者需要更多与企业和模型的互动。感谢您的问题。

我同意您的看法。各国的学者在双边对话中参与了很多立法和咨询过程。

那么接下来的问题可能是我们今天讨论的一个重要议题，因为我们在人工智能国际治理的讨论小组中。接下来的问题实际上是想请三位专家来回答。我想请教一下Casper先生，我们都知道，现有很多国际治理的多边协议和国际组织。比如说，在全球人工智能治理方面有很多努力，例如AI安全峰会。联合国也计划建立一个全球人工智能机制来协作全球AI治理。那么，您认为我们应该如何建立一种机制来协调不同国家和不同行业的利益，包括私营部门、公共部门和学术界？您认为这种理想的机制应该是什么样的？谢谢。

谢谢。您提到在联合国、Bletchley峰会后续、G7和其他很多双边谈判以及二轨进程中，有很多不同的进程正在进行，我认为这些都非常重要。我认为目前大多数官方进程的一个问题是，它们仍然专注于今天的人工智能系统，而不是足够展望未来可能面临的挑战，这些挑战可能在未来几十年内出现。但也有一些很好的理由认为，我们可能更早面临这些经济挑战。所以，我认为确实有必要推动这些进程，为我提到的真正的全球性挑战做好准备。

挑战和难点在于，我们如何找到既合法、包容、真正全球化，同时又实用有效的解决方案。我认为我们提出的解决方案是通过一个我们称之为全球人工智能挑战的国际框架公约来解决这一问题。在国际关系中，框架公约的优势在于，它是一种高层次的文件，希望由全世界所有国家签署，并明确提出核心目标和原则。我们可以基于最近联合国决议，包括中国提出的最新决议，来达成共识，明确人类共同的目标。

框架公约的下一步是通过更详细的议定书来支持，这些议定书通常涉及特定的要求和建议，这是更具争议的部分，但可以由少数国家首先制定。例如，我们建议在联合国通过框架公约的同时，制定一个专门解决最先进人工智能系统的全球性风险和安全风险的议定书。这个系统将非常注重风险的分层，识别出一些风险需要全球合作和更严格的监管。

虽然我现在不会详细讨论这些内容，但我认为这确实为中国和美国等领先的人工智能大国提供了快速达成协议的潜力。虽然今天这些协议可能难以接受，但将来可能需要它们，例如监测机制，确保没有国家开发会威胁其他国家安全的人工智能系统。这些会很有挑战性，但在这个背景下可能实现。

然后，希望核心小组中的所有国家最终都能签署这些议定书，并在我提到的所有其他挑战领域制定议定书，以调和这些问题，带动所有相关方参与。具体细节将是我们未来几年需要努力和创新的内容。谢谢。

那么，我也想请中国的高奇奇教授回答一下，比如说您认为在未来的全球人工智能治理中，如何构建一个多方参与、各方平等发表意见的机制？有请。

好的，谢谢张老师。我理解这个问题是这样的，顺着我刚才的思路，我定义了三大类问题：首先是失业，其次是失序，第三是失控。所以它的问题应该是一个非常整体性的。那怎么应对这些问题呢？首先，尽管我们今天在谈全球治理，但实际上离不开国家治理。我们的报告中也提到要全球治理和国家治理之间的平衡。这涉及到几类治理的主体。

第一类主体是人工智能企业本身，它们需要自己构建一些自我监管的规则，但这其实是很难的，因为人工智能企业的核心任务不是治理自己，而是要跑在最前面。所以自我监管很难实现，很多监管规则还是要在国家层面形成，包括地方政府和国家政府层面。这样就会出现国家间竞争的问题，这种竞争在某种意义上让治理变得松动。主权国家需要考虑企业可能会用脚投票的问题，如果监管过重，一些企业可能会从英国迁到爱尔兰，因为那里的环境更宽松。

对主权国家来说，这也是一个难题。国际治理有没有难题呢？当然难题更大。全球治理的最大难题在于联合国治理本身是一个非常松散的框架。我们都知道，联合国在很多问题上都有所涉及，但它的有效性相对较弱。所以我们今天在讨论治理，但最大的难题是治理实际上是一个碎片化的治理，有很多主体多方协同。回到张老师的问题，这就是最大的难题。

我的观点是我们可以简化这个问题，主要是两类问题。第一类问题是在AGI快速到来的背景下，我们如何应对那些被滥用的大模型，因为它们可能会被恶意用来制造更强大的武器、生物病毒等。这需要一个类似于不扩散条约的框架。第二类问题是很多不发达国家，尤其是全球南方，需要获得人工智能的使用权。我们需要推动小模型的合理扩散，并且帮助它们建立能力。

第三类问题是大模型可能会快速使用，并带来虚假信息等问题。我的想法是类似于碳综合框架的解决方案，即对人工智能的使用进行定价。如果过度使用，产生大量信息，我们无法辨别其真实性，这个使用需要定价，并通过这种方式解决失业等问题。我认为这几类问题不能完全放在一起谈。

对于不扩散条约的治理问题，我认为需要建立一个类似IEA的框架，一个专门的组织才能有效执行。联合国有很多任务，要有效执行这件事情需要专门机构。这是我的主张，其他问题如全球南方的发展可以通过其他计划解决。我简单回答这些问题，感谢高教授。

从您的回答中，我们可以看到这是一个非常复杂的问题，涉及许多方面。其实我还想听听Matt的观点。

好的，这次我用英语回答。这有点复杂，我不会重复大家说的话。是的，我们需要将合适的组织匹配到合适的问题上。我认为也许缺少的一点是，绝大多数AI治理问题不会是国际AI治理问题，而是国内治理问题。如果解决这些问题，大部分不会通过国际途径解决，而是通过国内途径解决。

例如，在传统互联网问题上，即使是盟友和朋友的国家，文化相似，他们也无法达成一致。美国和欧洲很多国家在如何治理社交媒体、垄断等问题上无法达成一致，但这没关系，每个社会都有自己的方式来面对这些问题。

当我们考虑国际治理问题时，应该将其限制在那些无法通过国家之间互动解决的根本性跨国问题上。这可能包括几个类别，其中之一是灾难性风险，另一个可能是系统的互操作性。如果有一架自动驾驶飞机在国家之间飞行，需要一些标准和互操作性。

大多数问题不会通过国际治理解决，我认为如果我们将范围限制在根本性的国际问题上，会进展更快。我完全同意，大多数问题首先要在国内解决，然后在全球层面解决国际AI安全问题。谢谢。


那么，感谢前面几位嘉宾的发言。现在我们进入最后一个问题。我相信这是全球南方国家和中国最为关心的问题之一。这个问题我想先抛给Mr. Kripitz。我们知道前天中国刚刚提出了关于能力建设的联合国决议案。我们也都知道，全球南方国家非常关心如何共同分享AI发展的成果。您认为，哪种机制可以弥合发展中国家和发达国家之间的差距？谢谢。

非常感谢。我认为首先要描述一下问题的现状，因为我们倾向于简单地将AI引入其中，但这实际上是一幅非常简化的图景。问题的结构要更深入地分析。首先，什么是AI？从发展的角度来看，国际上存在差异，因为某些国家在AI发展方面非常领先，而其他国家则没有。一些国家如中国和美国在AI发展方面处于领先地位，韩国在某种程度上也是如此，而欧洲联盟在专利注册方面远远落后。例如，我们不仅可以从发展的角度来看AI，还可以从人工智能的实施角度来看，因为这也是一个重要的方面。某些社会在开发人工智能方面非常出色，但没有实际实施这些技术。这在过去也适用于德国，因为德国在建造火车和高速列车方面非常领先，拥有大量专利，但由于财务限制和公众的不信任，实际上并没有实施这些技术。因此，当我们考虑人工智能的实施时，信任显然起着重要作用，这也反过来影响了关于监管的讨论。我们需要有最低的监管标准，以便个人能够信任这项技术。因此，这在解释人工智能实施方面的差异时也起到了重要作用。除此之外，我还想指出发达国家和发展中国家之间的差异。我们可能会争辩说，在某些发达国家或传统发达国家，我们也可能面临人工智能实施方面的某些问题。因此，这不仅仅是将人工智能分为不同方面时的南北分歧。我还想提到，不仅是教育个人的问题，还有基础设施的问题。除了资金非常重要之外，人工智能的发展需要大量资金，金融市场因素也起着重要作用，但在某些情况下我们需要有基础设施。我认为最好的例子是自动驾驶，因为当你看自动驾驶作为一项技术时，它不仅仅关乎汽车或车辆，还需要大量投资，这不仅涉及发展方向，更涉及实施情况。因此，当我们考虑这个问题时，问题的结构和图景实际上比初看时要复杂得多，因为许多这些成本在前几年并不是大问题，但在基础设施没有建立的20年或30年后，你会真正看到不对称。所以我担心的是，在1990年代和2000年代由全球化驱动的全球生活水平趋同之后，随着人工智能和不同程度的人工智能实施，我们可能会再次进入一个有差异的世界。我认为这不仅仅是典型的发展中国家和发达国家之间的分界线，这幅图景可能要复杂得多，也许某些欧洲部分地区会落后。因此，在应对这些问题的措施方面，我认为一个主要的点是资金，因为建立一个具备创新能力的基础设施需要大量资金。这是一个主要点，除了通常提到的关于教育的点之外，我们通常会说，让我们教育人们，让他们成为人工智能开发者，问题就解决了。但特别是如果我们考虑非洲，基本的基础设施仍然需要，人们需要能够访问互联网以启动人工智能项目或实施它，有时我们可能有聪明的解决方案来解决这个问题，但总体而言，我们需要大规模的投资。因此，影响投资可能是一个非常关键的组成部分，除了经常提到的数字素养之外。最后，我想重申国际信任的重要性，即社会中的个人信任人工智能解决方案，并准备好接受和使用它们。因为当我们看国际调查时，我们看到不同社会中个人实施人工智能技术的意愿和准备存在巨大差异。这在中国根本不是问题，但在欧洲则是一个更大的问题，甚至与美国相比也是如此。这是我会担忧的一个点，因为它也有一个非常重要的文化维度。也许未来访问人工智能或大模型可能成为一种新的基本人权。谢谢。

那么，接下来我还想请两位来自中国的专家也回答一下这个问题。相信无论是阿里巴巴还是华为，都在世界各地有自己的AI产业布局。二位认为，在未来如何弥合发展中国家和发达国家之间的智能鸿沟或数字鸿沟？柳院长，您先来？

好的，简单补充几点。确实，如果考虑到互联网发展了几十年，到现在全世界还有很大一部分人群没有接触到互联网。因此，我认为我们在AI时代面临的智能鸿沟确实是一个非常现实和严肃的问题。第一点可能与刚才前一个问题相关，我们提到多利益相关方的充分参与平台。我认为不仅是不同角色，如政府、公众等，这个平台也需要具有全球代表性。通过这样一个平台，更多国家能够表达自己的关切和声音。这是一个非常重要的前提条件。上个月我有幸参加了日内瓦的ITU AI for Good峰会，ITU秘书长包格丹女士提到全球治理应体现联合国的价值观，不让任何一个国家掉队。因此，构建这样一个平台非常重要。当然，过程中可能会遇到很多实际问题，需要实际工具来解决。刚才提到的立法问题，我想补充一下，当前的立法可能有些差异化和随意化，但通过充分沟通和协商，可以为法律的落地提供更确定的方案，同时也是弥补随意化风险的一个机会。因此，这个平台应充分囊括全球各方。这是第一点。第二点，作为人工智能产品和服务提供方，我们在提供相关产品时要充分考虑不同国家和人群的可获得性，体现包容性。例如，我们的盘古大模型在两年前与阿拉伯国家合作，提供阿拉伯语言的自然语言处理大模型。这是我们在产品解决方案层面可以努力的方向。第三点是人员能力问题，这也非常重要。在ICT时代，华为在非洲等南方国家设立了ICT学院，为相关国家和地区人员的数字素养提升做出了贡献。因此，在人工智能时代，我们可以做得更多。谢谢。